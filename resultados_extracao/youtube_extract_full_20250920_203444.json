{
  "executed_at": "2025-09-20T20:34:44.957160",
  "mode": "full",
  "total_channels": 10,
  "total_videos": 76,
  "params": {
    "days": 15,
    "max_videos": 30,
    "mode": "full",
    "no_llm": false,
    "asr_provider": "faster-whisper",
    "format": "txt",
    "translate_results": "pt-br",
    "resumo_max_palavras": 150,
    "llm_model": "gpt-5-nano",
    "ui_extras": {
      "selected_groups": [
        "Ideias e Negócios com IA"
      ],
      "selected_channel_labels": [
        "ColeMedin (@ColeMedin)",
        "DanGalletta (@DanGalletta)",
        "DataCouncil (@DataCouncil)",
        "Incomestreamsurfers (@Incomestreamsurfers)",
        "LiamOttley (@LiamOttley)",
        "SaraFinance (@SaraFinance)",
        "eusoukelvincleto (@eusoukelvincleto)",
        "krishnaik06 (@krishnaik06)",
        "matthew_berman (@matthew_berman)",
        "nocodemba (@nocodemba)"
      ],
      "manual_entries": "",
      "translate_titles": true
    }
  },
  "channels": [
    {
      "channel_id": "@ColeMedin",
      "name": "@ColeMedin",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "BcvjGTxzK40",
          "title": "The Future of AI and SaaS is Agentic Experiences (Here's How to Build Them)",
          "title_pt": "O futuro da IA e do SaaS é experiências agenciais (Aqui está como construí-las)",
          "url": "https://www.youtube.com/watch?v=BcvjGTxzK40",
          "published": "2025-09-18T23:34:45.778078",
          "published_relative": "há 2 dias",
          "duration": "20:47",
          "date_published": "2025-09-17T17:00:12-07:00",
          "transcript_available": true,
          "transcript": " Eu tenho algo muito interessante que eu fui explorando recentemente, que eu quero compartilhar com você.  É tudo sobre criar experiências agentes, com algo chamado AGUI.  Agora, deixe-me sete o sete para você um pouco primeiro.  Há uma boa chance que você está cansado da ideia, que nós precisamos de construir  aplicações ou platforms de sas por meio de nossos agentes AI, mas isso não é onde o futuro está  atentado. A verdadeira muda os agentes em nossa aplicação, então eles sejam  uma parte natural da experiência do produto. E parece que é natural, certo?  Eu acho que quando a baixa da baixa de baixa do AI, os produtos que terão que ser leftados  geralmente não serão os que competem como agentes, mas instantes,  os que deeply integrateam agentes AI em um produto que envia o seu próprio valor único.  Isso é o que eu digo pelas experiências agentes e o futuro da sas, porque essas platforms  são os que não terão que ser espalhados, como os mais generalos agentes,  como o operador de chat, sejam mais poderosos e sejam mais agentes de baixa,  simplesmente irrelevantes. Então agora eu vou te introduzir a como construir  esses tipos de experiências agentes, que não são atentados, por favor,  geralmente um pouco mais difícil do que construir chatbots isolados,  mas, felizmente, eu tive a texta para você fazer isso simples. Então eu vou te introduzir  para isso, entrar em alguns demos e princípios muito importantes,  e depois vamos construir juntos. Eu vou até mesmo tomar um agente que eu  criou anteriormente no meu canal e criar uma aplicação completa sobre isso.  Então a parte principal da nossa texta aqui é um protocolo desenvolvido  pelo time co-pilot chamado AGUI. Eu coveri no meu canal,  quando ela primeiro veio, uma coisa muito poderosa. Agora, a grande pergunta é,  o que isso realmente faz para nós? Bem, simplesmente, AGUI standardiza como  aplicações de front-end se conectam a agentes AI. É como mcp,  mas, em vez de conectar agentes a tools, nós estamos conectando agentes  a nossas aplicações em uma maneira standard. É totalmente open source,  então eles têm esse repo de GitHub, que eu vou linkar no descrição.  Eles têm um bom diagrama aqui que mostra como funciona em um nível alto também.  Então temos AGUI, como um cara meio-man aqui, que dá uma comunicação standard  entre as aplicações de front-end e os agentes AI. E então,  enquanto ambos têm suporte para AGUI, que todos esses frameworks de agentes AI  fazem, então temos essa comunicação semelhante que faz para que nós possamos  construir aplicações em milhas de linhas de code,  em vez de milhares em milhares. E isso é o que nós vemos,  como nós construímos juntos e vamos por alguns desses demos. E então, nós temos que  escolher o nosso front-end library e o nosso framework de agentes AI. E então,  AGUI take care of a lot of things. E então, para a nossa front-end,  nós vamos usar co-pilot kit. Isso é um library de reagentes que faz  isso muito fácil para nós, para construir aplicações agentes e integrar  nativemente com AGUI, claro. E depois, de todas as opções que temos  para a nossa framework de agentes AI, você sabe que se você está seguindo  o meu canal, que AGUI é o meu favorito. E eles recentemente adicionaram  uma primeira parte de integração direta entre co-pilot kit e AGUI  através de AGUI. Eles ainda têm uma AGUI doque sectiona em AGI. Então, eu estou muito  emocionado por isso. Isso é o catalyst para mim para fazer esse vídeo. E eu estou  falando com a equipe de co-pilot kit sobre isso e realmente perguntando  para essa integração. Então, eu estou muito emocionado que é finalmente aqui,  porque agora podemos construir esses tipos de aplicações de interacção de usuário  com agentes de AGI under o rio, dirigindo as coisas. E esses são os demos  que eles têm para nós, que eu estava falando de antes. Eu vou linkar isso  no descrição. É uma ótima ressourção para explorar o poder de AGUI. Então, eles têm  todos esses diferentes demos que representam algo que seria muito  não ser perigoso para construir sem AGUI. Mas com AGUI, é realmente fácil. Você  pode até ver o código para botha a frente, como com a co-pilot kit aqui,  e a abertura. Eu tenho AGI selecionado aqui. Mas você pode até selecionar  qualquer AGI framework que você quer. E ele irá descarregá-lo em  o fundo e nós temos que mudar nada no fundo. Isso é o que AGI nos dá,  essa comunicação estástando, então podemos mover do langraft para agno,  ou agno para panantei. E no app no fundo, não tem que mudar nada.  Então, vamos ver essa inação. Eu quero que você veja como isso realmente  enlouquece experiências agentes para nós. Como nesse exemplo aqui,  é um builder de recepção. E tem um sync de estado entre o nosso fundo  e o nosso fundo, graças ao AGUI. Então, por exemplo, eu posso adicionar  um ingrediente aqui. Eu posso dizer, eu estou adicionando bife, um pão de bife,  e aí eu posso perguntar ao meu agente, o que são meus ingredientes? E ele irá  imediatamente reconhecer as mudanças que eu fiz no fundo aqui, porque nós  temos esse 2-way sync. Aí vamos. Nós temos o nosso ingrediente. E aí eu  posso fazer o outro caminho. Eu posso dizer, eu quero fazer uma recepção com  um lote de bife. Então, agora, em vez de sincerar o fundo  e o agente no fundo, é agora o agente que vai  updatear o nosso fundo aqui. Então, é criando a recepção e boom!  É rendido em tudo em um muito lindo jeito no fundo. Então, nós temos  nossa aplicação típica no lado direito, mas então é  deeply integrated into the rest of the components of our front end.  É o que eu quero dizer, experiências agentes. É realmente,  realmente legal. Nós temos as nossas instruções aqui. Nós podemos  actually improve it with AI as well. We have our list of ingredients.  And I can continue to collaborate with the agent here making changes  back and forth to make my perfect recipe. And obviously, it's just a very  simple example here. But yeah, definitely play around with these  different things like human in the loop collaborating with our agent.  Tool based generative UI. So, we can actually build tools in our front end  that we give into our AI agent dynamically. There's so many  powerful things here. And like I said, we can view the code. So,  we can see exactly how the front end was built with copilot kit  and how the back end is built with the pedantic AI agent.  All right, so now that you know how AGY works and what it really gives us,  let's get into actually building with it. So, the easiest way to get started  with building these agent experiences with AGY  is to follow this quick start, which I'll link to in the description.  And so, this is the copilot kit documentation and they have an entire  section for working with pedantic AI specifically. And they do that  for all of their integrations. It's really, really cool.  And so, to get started, we just have to have MPM install in our machine  and we can copy this command here. So, I'll actually go  into my terminal and let's walk through this really quickly.  So, it's going to set up a new project for us using copilot kit  as the front end. And then, we're using AGY here  and we can select our agent framework. And so, I'll just say  test here because I have something else set up already  that I'll demo for you. And there we go, we can select  our framework. Like I can say, I want to use pedantic AI.  There we go. And so, it's going to open up your  browser for authentication because there is a cloud  version of copilot kit. We don't actually have to pay for  anything though. And so, we can just get through this and  authenticate. And then, I'll come back once I have this done.  Okay, there we go. So, I'm signed in. It creates a copilot  kit cloud API key as well if you want to host with them.  You don't have to though. And so, for demonstration purposes,  we're not going to be doing anything with that right now.  But yeah, they even give us some documentation here. And so,  we can open this new folder that was created for us.  And so, I have it open right now. And then, there's a read me  here that walks you through the quick start. So, how you can get  things set up in both the front end and the back end.  And it's literally just a couple of commands. Like, it's so  easy to get this up and running. And that's going to give us  a quick start. That's going to look kind of like the  demos that we saw here. But now, we have something that  is running entirely locally. And there's a couple of  different things we can try to really see the power of  AGUY. And we can start to build on top of this  application as well. But I'll just show you  really quickly. Like, for example, I can say, set the theme  to green. And so, this is a tool that we actually build  in the front end and send into our agent. So, our back end  agent, thanks to AGUY, doesn't even have to know that  there's a tool to change the theme. And we just pass that in  from the front end. I can also say, write a proverb  about the difficulties of SQL. All right. So, we'll send  this in. It'll make a proverb for us. And boom, we  immediately have that state sync. Like, that other demo I was  showing you, where now our front end has this proverb  here. And it's displayed and rendered out in a nice  ring. I can say, write another one. And so, we can do  another state sync here. And then, I can delete one of  these as well. Like, I'll just delete this first one.  And I'll say, I deleted one. Which is left, right? So,  we can know that the front end is also syncing back to  the back end as well. And then, the last thing  that they have for the demo here. I'm just trying  to like show you the different kinds of things that  we can do with this front end. It's really, really  neat. We can also render out components in our chat UI.  So, we're not limited to just having a bland  conversation here and then passing things into the  rest of our app. We can also render out cool things  here. So, I can say, what is the weather in Orlando,  Florida? And it's going to render out a really nice  looking card here. So, we can take tool calls  from the back end and standardize the format.  Like, actually make it look like a nice component  in our React front end. So, super cool. That's what we have  for our quick demo here. But now, let's actually use  this as a starting point to build our own  applications on top. Now, to build on top of this  application, we're not going to dive straight  into implementation. There's one really cool  thing first. Because the co-pilot kit team,  they have built a Vibe Coding MCP server.  Now, you know that I'm not the biggest fan of Vibe  Coding. So, maybe this isn't the best name for  what I'm about to use it for. But this is an MCP  server that's kind of like Archon for knowledge  retrieval. It gives our AI coding assistant the  ability to search through the co-pilot kit and AGUI  documentation and best practices. So, it becomes our  expert guide on our implementation. Super  cool. So, if you're building any kind of  agentic experiences with this tech stack,  definitely use this MCP server. That's what I'm  going to be using right now. And they have  instructions here based on your AI coding  assistant, like cursor, or client, or windsurf,  exactly how to hook it up. Now, they don't have  instructions here for Claude code  specifically. But I've got that for you  right now. So, you can copy this URL right  here and then go into your editor. I have  my terminal open here and I'll just paste  the command right here. So, it's Claude MCP add  and then SSE is their transport and then  you just can call this server whatever  you want. And then the SSE URL is the  one that we copied from the documentation.  So, I'll add that in here and then I can  also do a Claude MCP list to test the  connection. And so, this is a remote MCP  server completely free to use. Now, Claude  code is able to search the co-pilot kit  documentation. Super cool. Okay, so now  armed with this MCP server, we can now  build any kind of agentic experience  that we want on top of this  starter template. It provides a really  good foundation for us. And so, yeah,  I'll send in a request here. I'll show  you what it looks like to build on top.  And then I'll even show you how far I  went taking a RAG AI agent that I built  with Patentic AI on my channel  previously. And I'll show you how I  built a full application around with  AGY. So, we'll get there in a second,  but right now, I just want to send in  a simple request here. And first, I'll  actually tell it to use the  co-pilot kit MCP server to  understand how to build  this feature. And maybe I don't have  to call that out explicitly, but I  just want to to make sure  that it leverages the MCP. So,  what I want to do here, if I go within  the source and page.tsx,  one of the things we have here  is the co-pilot kit action.  This is our front end tool  that we're passing into our agent  to give it the ability to change  the theme. And so, I want to add  another tool here to do  something else. Let's say, maybe  clear all the proverbs that we have  on the front end. I think that's a  get example here. So, I'll say,  I want to make another  front end tool with co-pilot kit  to clear the proverbs  that we currently have.  And so, since we have that state  sync as well, the agent will  immediately recognize that  everything is cleared in the front end.  And so, I'm going to go ahead  and send this in right now.  And it should, after maybe  looking at some of the files we  have in our starter template  here, or actually, yeah, right  away, it searches the co-pilot  kit docs. Take a look at that.  Use co-pilot kit action, custom actions,  front end. And we can do control O  to expand and actually see  the chunks or the snippets,  as they call them, that were  retrieved from this rag implementation.  It's really, really cool. So,  we're pulling in the  documentation from co-pilot kit.  That's a part of our context  engineering here.  Giving our coding assistant  all the information it needs  to actually build out the  implementation here. Now,  this is a very simple example.  And so, it could probably just  look at what we already have  for a front end tool  and then implement that as well.  But I hope that you can see that,  like, if we didn't have  any front end tools at all,  it would have no idea  how to use  use co-pilot kit action.  So, it would need to search  to the documentation  like we are doing here.  And so, yeah, let me  actually scroll down.  Let me exit out of this.  There we go. All right.  Yeah, there we go. It is adding  in a clear all proverb tool.  And so, when this is invoked  from our agent,  it's going to, yeah,  just clear the proverbs  in the state that we have.  And that will immediately be  synced to the back end as well.  Looking really, really nice.  So, cool. Yeah, I'll pause and come back  once this is fully, fully implemented.  There we go. I just paused  for like 20 seconds.  And then we are done.  So, we have that new action.  And then we just have the button  that it added for us  to be able to clear things  right here. So, there we go.  We got our updated UI.  So, now I can say  add a bunch of proverbs.  All right. So, we'll have  to populate it first,  obviously. So, the agent  has generated some proverbs.  There we go.  We have, oh, wow,  it is adding a lot.  All right. So, we added a lot  of proverbs here.  And now I can clear all of them.  And so, I'm going to  send this in,  click this button here,  or I could just ask it  to clear the proverbs.  So, well, I'm actually  going to click this button here.  It's clear all proverbs.  There we go.  And now we have that state sink.  And so, I can say  what proverbs do I have.  And it's going to say  that there are none.  There we go.  It is currently empty.  And I can also show you.  So, I'm going to say  add some more.  I'll also show you  that like I can have  the agent clear them as well.  So, it doesn't just have  to be this button.  So, I can say  clear the proverbs.  And so, just based  on a simple text request  to our agent,  we can do the same thing  that that button did.  And so, I hope that  this just helps you see  how our agent  is starting to interact  with the website.  And we can build  these agentic experiences  where AI agents  can actually help us  navigate through  a website as well.  Like, this is a really  simple example  where it performs  an action of a button click.  But this could be  a full onboarding experience  where the agent  is actually like  walking me through  clicking on different buttons  in my app  depending on  what I'm talking to it about.  Like, oh, I have this question.  And then it's like,  okay, well, let me click  on this button  and then highlight  this section of a website.  Like, there's just so many things  that we can do with this.  And so, that's like  the higher level  principles that I wanted  to be speaking to  in this video.  Like, it's cool to like  see AGY  and Panentic AI  specifically.  But like the most important  thing that I'm trying  to get across here  is the general principles  of like  we need a way  to sync the state  between the front end  and the back end.  The agent needs to know  like where we're currently at  in our front end  and that is what AGY  makes really easy for us.  Along with the fact, of course,  that our back end  is so incredibly simple  thanks to AGY.  Generally, you'd have to  build an entire back end  with API endpoints  and middleware and everything.  But our back end right now  is literally just a single file.  We have our agent.py.  And so, this is our  Panentic AI agent  where we have our agent  defined.  We're giving it some tools.  It's going to look very similar  for other frameworks as well.  We have our primary system prompt  and then the only thing  we have to do  to turn this Panentic AI agent  into a fully working  API endpoint  compatible with AGY  and our co-pilot kit front end  is to call this to AGY function.  So, so easy.  And so now our agent  is running on port 8000  and it is good to go.  And we have everything handled  here with the state syncing  and conversation history.  We can even dynamically  adjust the system prompt  based on the front end.  There's so much integration  that we have here  for literally 100 lines of code.  Like this is just so, so easy.  And so there are a lot of things  that are made possible  thanks to AGY  not because we couldn't build it  without the protocol  but because it just makes it  so easy to do so.  And it's the same kind of thing  with like the model context protocol.  I mean we can connect agents  to any tools  but MCP just makes it very easy  and accessible.  That's what we have here.  And like I said I would cover.  I even went as far  as to take an existing  Panantic AI agent  that I built on my channel  previously  and create a full application  around it with AGY  and co-pilot kit.  And that's what you're looking  at right here.  And so I'll link to the video  right here where I built  this rag agent.  I built it with cloud code  and a team of sub agents.  And in that video  we're just using the command  line, a simple CLI tool  to talk to our agent.  So it's a perfect opportunity  to take an existing agent  and barely having to change  the code at all  thanks to the Panantic AI  and AGY integration  to build out this full app.  And so now I can ask it  a question.  It's a rag agent.  So we have this knowledge base  with all this information  about AI startups.  So I can ask it  about OpenAI's funding  for example.  And we'll get the answer  on the right hand side  like a normal chat bot.  It's got streaming  and conversation history  and everything.  But then also  it takes all the chunks  that we returned  from the knowledge base  and it populates  the front end with them.  So we have this super  interactive rag agent  where we can actually like  view the chunks  that it retrieved.  We can see the match percentage.  We can click  into view the contents  of the chunks  and all the metadata  like the document  that it came from.  I mean this is definitely  taking a typical rag agent  that you would have  in just a chat interface  taking it to the next level  where we can actually see  under the hood  what information it's using  to give us  the answer that we have  in the chat box.  So really, really cool.  And man was it easy  to build this out.  I'll just show you  the code really quickly here.  I had to define  some classes here.  That's for the state sync.  So that the chunks  that we have in the front end  is synced  with what the agent knows  it's displaying.  And then I defined  my agent very,  very much the same way  like I always do  with Padantic AI  giving it tools  as well to search  my knowledge base  both with semantic search  and hybrid search  like a keyword search.  And so I'll scroll down here.  We have the system prompt  as well.  This is also dynamic.  So all of the chunks  that we have as a part  of that state sync  through AG UI  we're passing those in  as a part  of the system prompt.  And then all I have to do  just like our starter template  is called  a rag agent dot  to AG UI.  And now we have  the full back end  infrastructure spun up  with the agent running  on a port 8000.  Absolutely beautiful.  And we could swap this out  for a lang graph agent  and not even have to  change the front end  at all.  That is the beauty  of AG UI.  And to build all of this  all I did is I followed  the quick start here  in the co-pilot  kit documentation  for Padantic AI.  They have instructions  specifically for  how you can take  an existing  Panantic AI agent  and turn it into  something that's compatible  with AG UI.  So I use this  as a reference point  and then I went  into clod code.  I took that starter  template that I already  showed you building  on top of  put in the code  for my existing agent  hooked in the  vibe coding  MCP server  and just had a go ham.  So yeah,  using the MCP  for documentation  and then the existing  template to build  on top of  I just told it  exactly what I wanted.  I want you to  take the co-pilot  kit application  make it work  with this rag agent  so I can actually  see the chunks  and all the metadata  and it knocked it  out of the park.  It was so easy  to build this out.  So there you have it.  That is everything  you need to know  to get started  building agentic experiences  with AG UI.  Now here's the thing  Panantic AI,  AG UI,  co-pilot kit  these are just tools  to get the job done.  The higher level  principles are what  I really want you  to focus on.  Things that I covered  here like human  in the loop  and front end tools  and state syncing.  That's what you really  need to make  these agentic experiences.  AG UI  is just the protocol  to standardize things  and make it that much easier  to build out  this kind of application.  Like I literally built this out  in like a half hour  after I brought in  my existing agent.  It was so easy to do this  with the help  of an AI coding assistant.  So there you go.  If you appreciate this video  and you're looking forward  to more things  AI agents  and AI coding  I would really appreciate  a like and a subscribe.  And with that  I will see you  in the next video.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como criar experiências de usuário baseadas em agentes (Agentic Experiences) usando AGUI para padronizar a comunicação entre front-end e inteligência artificial, com suporte do Copilot Kit para construção rápida de aplicações com agentes integrados.",
            "resumo": "O vídeo apresenta a ideia de experiências agentes, em que os agentes de IA não são apenas ferramentas, mas parte essencial do produto. O protocolo AGUI padroniza a comunicação entre aplicações front-end e agentes IA, tornando possível construir aplicações com menos código. O apresentador destaca o Copilot Kit como biblioteca de front-end, com integração direta com AGUI, permitindo selecionar o framework de IA (ex.: Pedantic AI) e gerar aplicações de interface que interagem com o agente por meio de sincronização de estado bidirecional. Demonstra um builder de receitas onde o ingrediente é atualizado no back-end e o agente reflete no front-end, e vice-versa. Também aborda construir ferramentas na UI para o agente e a importância de colaboração humano-no-loop. Finaliza com um guia rápido de getting started e recursos/documentação.",
            "assunto_principal": "Experiências agenticas (Agentic Experiences) com AGUI e Copilot Kit para integração front-end com inteligência artificial em aplicações SaaS",
            "palavras_chave": [
              "AGUI",
              "Experiências com agentes",
              "Kit Copilot",
              "integração de front-end com IA",
              "sincronização de estado bidirecional",
              "humano no loop",
              "IA pedante",
              "código aberto",
              "interfaces com agentes"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto: as experiências com agentes representam a evolução do SaaS, integrando IA no núcleo do produto.\n- AGUI: protocolo que padroniza a comunicação entre front-end e agentes de IA, de código aberto.\n- Copilot Kit: biblioteca de front-end que facilita a construção de aplicativos com AGUI e IA.\n- Fluxo de integração: escolha de framework de IA (ex.: Pedantic AI) sem alterar o front-end.\n- Demonstração: construtor de recepções com sincronização de estado bidirecional (estado entre front-end e back-end sincronizado pelo AGUI).\n- Conceitos-chave: sincronização, colaboração humano-IA, interface do usuário baseada em ferramentas.\n- Como começar: passos rápidos de instalação, autenticação e configuração.\n- Recursos adicionais: repositório e documentação para exploração.",
            "prompt_tokens": 2028,
            "completion_tokens": 2910,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 360.4265899658203,
          "language": "",
          "view_count": 15797,
          "has_transcript": false
        },
        {
          "id": "5gUR55_gbzc",
          "title": "Este novo protocolo mudará a codificação da IA ​​para sempre (ACP)",
          "title_pt": "Este novo protocolo mudará a codificação da IA para sempre (ACP)",
          "url": "https://www.youtube.com/watch?v=5gUR55_gbzc",
          "published": "2025-09-11T23:34:45.778150",
          "published_relative": "há 9 dias",
          "duration": "22:34",
          "date_published": "2025-09-10T17:00:11-07:00",
          "transcript_available": true,
          "transcript": " O futuro da coding AI é aqui, e meu amigo, eu quero dizer que sinceramente, ZED  já introduziu o protocolo clínico de cliente, ou ACP, em breve.  É um standard, só como MCP, mas para conectar qualquer assistente de coding a qualquer editor de  codos.  E ZED's integração é apenas em beta, mas se você quer uma glimpsa em como vamos  trabalhar com a AI no futuro, isso é tudo.  Então agora, eu vou te mostrar a acp na acção e como você pode começar com  isso mesmo agora.  Um monte de coisa muito interessante hoje.  Eu vou começar de te mostrar como você pode usar botha clodca e gemini CLI threads em ZED  e se switchar entre eles no clicar de um botão.  E com a acp, nós recebemos updates live em nosso editor de codos, como o assistente de coding  está trabalhando e nós podemos aceitar e rejeitar as mudanças, que são coisas que eu sempre  quiserem em clodca, que faz a experiência de desenvolvimento muito melhor.  E, como a acp é um standard, nós podemos criar nosso próprio agente custom que  nós podemos atacar como agentes de codos em qualquer editor, como com a mcp, nós estamos  capazes de construir teus que nós podemos conectar em qualquer agente.  Eu vou te mostrar como isso funciona também e até te mostrar algumas ideias que estamos  coitando alongo essas linhas com a Archon.  Então eu vou ter certeza de como a acp trabalha em um nível fundamental também, definitivamente  é importante entender essa nova tecnologia incrível.  Então eu primeiro encontrei a acp de esse announcement de ZED, anunciando que  eles agora têm suporte para clodca.  Se você não sabe ZED é um editor de codos, só como a code VS e as forças como Windsurf  e Cursor.  E então eu estava realmente interessado em como exatamente eles integraram com a clodca, então  eu clico no redor do clodca, e eles imediatamente acreditaram em mim, que eles não só  construíram uma integração de um off com a clodca.  Eles queriam construir algo melhor, e isso é o protocolo cliente agente.  O standard, como eu disse, para conectar algum agente de codos em qualquer editor de codos.  E isso é apenas um jogo-changer, que faz que é tão fácil de alterar a assistência de codos.  Isso está sendo muito importante agora.  Quando começamos a ter mais e mais opções, a clodca codos está sendo menos e menos de  um vencedor obvio agora, e então queremos que entre esses editadores de codos e  tentar diferentes de um semia, e isso é o que a acp nos dá.  É um tempo em que temos esse standard.  E mais sobre isso depois, isso faz que é mais fácil para a gente usar um lote de  agentes de codos em paralelo.  E tudo que você tem que fazer para começar com a acp é instalar ZED, que estamos  procurando aqui.  É um editor de codos de codos completamente free e open-source, e eu vou ter links no  descrição para instalar isso, dependendo de seu sistema de operação.  E eu sei que no futuro, vamos ter um monte de outros editadores de codos de codos  como VSCode também ajudam a acp, mas agora temos ZED.  E então para a assistência de codos, a CLI da Gemini tem uma  integração direta com a acp, e então a clodca codos é um adaptor.  Mais sobre isso depois.  E eu sei que eles vão ter um monte de assistência de codos em  o futuro anterior aqui que também vai suportar a acp.  E depois que você tem o instalamento, a clodca codos ou a clodca codos dentro de ZED  não poderão ser mais fácil.  Literalmente tudo que você tem que fazer é abrir esse agente panel na  direita-handa.  Então é só esse botão na direita-handa para atingir isso.  E depois você clica nesse botão de plus aqui, e você pode começar um  novo thread de clodca codos, ou algum agente custom que você  construa, que eu vou mostrar um pouco aqui.  Então, por exemplo, vamos começar uma thread de clodca da Gemini.  Ela vailoadar a conexão para a clodca da Gemini, ela vai ter que  authenticar se é a sua primeira vez, que isso está todo  feito dentro do clodca-editor também.  Então é super, super fácil.  Eu posso re-authenticar se eu preciso.  Eu não tenho que fazer nenhum set up external para  trazer essas assistências de codos para o meu editor, porque isso também  é um parto da acp.  É uma coisa linda.  E então agora eu posso enviar um requerimento aqui, tipo,  mudar a mensagem do greeting e eu posso apoiar os files como  que você iria esperar para algo random.  Todos os features natais que temos  para essas assistências de codos  funcionam com Z through ACP também.  Então, coisas como subagentes e commands custom  como que temos com clodcode,  tudo isso ainda vai funcionar.  Então, vamos perder nada  e agora temos tudo em este desenvolvimento.  Então, podemos ver essas mudanças live em nosso IDE.  Podemos aceitar e rejeitar essas coisas,  o tipo de coisa que eu sempre quiserem ter com clodcode.  Então, vou rejeitar esta para agora.  Eu não preciso de correr esta comandante.  Porque sim, é só um demo de demo de gemini CLI.  E se eu quiser, bom, aí vamos.  Eu agora loadei um novo thread para clodcode.  E eu posso fazer outra requesta,  tipo, mudar a mensagem de bom para algo random.  Ou eu poderia construir o slash comandante para fazer isso.  E então, sim, enviando esta requesta,  vai fazer uma edição só como a gemini CLI,  mas está usando uma assistência de codos completamente diferente.  Mesmo que parece que não,  porque era tão fácil de switchar entre eles.  E aí vamos.  Nós temos a rejeita do clodcode.  Tudo parece igual a gemini CLI.  Eu posso mostrar como rejeitar isso agora.  Então eu posso rejeitar e dar feedback.  O tipo de coisa que eu useda fazer em windsurf e cursor  todo o tempo,  que eu tinha que fazer mais de uma rejeita do clodcode  para revertir as coisas com clodcode até esse ponto.  Agora, eu vou dizer que esta rejeita  definitivamente parece que é em beta em algumas formas.  Primeiro de tudo, às vezes, quando eu open  um novo clodcode de gemini CLI,  o thread vai ficar lá,  tentando load ou conectar com o clodcode de gemini CLI.  Obviamente, está trabalhando aqui.  Eu tinha isso acontecer há um par de vezes.  Também parece que a história do thread  não funciona, que é meio um bummero.  Então um par de clodcodes,  eu acho, que precisam ser trabalhados por aqui.  Mas eu espero que você possa ver  que isso é definitivamente o futuro para clodcode AI.  Justo veja como fácil isso foi  para interromper com a assistência de clodcode  no meu IDE e switch entre eles também.  É também muito importante entender  como a ACP funciona fundamentalmente.  Eu useda dizer isso todo o tempo para a MCP também.  Mesmo se a ACP não enda sendo  a prêmio standard adoptada  para conectar a agentes de clodcode  para o clodcode,  o que seja o que o clodcode tende a ser,  vai ficar muito como a ACP.  E eu posso dizer isso com confiança  porque ZED claramente tem uma boa  cara nos seus dedos com essa implementação.  Ele levou muita inspiração  de outros protocolos, como a MCP  e também o protocolo de serviço.  Isso é o standard  para conectar as línguas programadas  para o clodcode.  Então, é definitivamente o protocolo mais simples.  É estado por cerca de um décimo agora  e então estão construindo no topo  os dedos de agentes aqui,  definitivamente fazendo isso certo.  E então eu quero focar em ACP aqui.  Eu não vou dar um tonho  para leverar assistência de clodcode  neste vídeo,  ou apenas focar em protocolo.  Eu vou dizer,  se você quer fazer o workflow de clodcode  de 10x,  realmente take it to the next level.  Check out this link  that I'll have on the screen right here.  Eu tenho um realmente excelente workshop  que você não quer perder.  Eu vou deixar o nugget gold aqui.  Definitivamente, cheguei esse site.  E com isso, vamos lá.  Então, eu vou ter um link  na descrição para essa documentação de acp.  Se você realmente quer  ir para a arquitetura  e como funciona o under the hood.  Eu vou cover  as ideias de alto nível aqui  para ajudar você a ver  como poderoso isso realmente é.  E então temos o primeiro diagrama simples aqui,  onde temos o nosso editor de clodcode  que tem um standard IO.  Então, é apenas uma conexão local  para a assistência de clodcode  que temos que está funcionando.  Então, é um instante de um instante do Jemenai CLI  ou um instante de clodcode  no under the hood que está conectado  dentro de Z.  E é muito similar a como o mcp funciona.  Então, como eu disse, eles definitivamente  estão tomando inspiração  de esses protocolos  que estão funcionando muito, muito bem.  E se vamos para um overview do protocolo,  isso é onde eles começam a falar  sobre como a comunicação  funciona no under the hood  entre a assistência de clodcode  e o editor de clodcode.  Então, é seguido  um Json RPC protocolo  que é como o mcp faz.  E então, eu vou mostrar um par de exemplos  sobre o que isso parece.  É muito simples  porque há apenas um pouco de operações  que um agente de clodcode  vai performar.  Então, vou para o tab Prompturn.  Então, você pode ver o que isso parece.  Primeiro de tudo, criamos uma sessão  entre o cliente e o agente.  É tipo de um handshake.  E aí, apenas quando as coisas estão acontecendo,  como chamas de tool  ou requerções de permissão  ou só cunhas de textas  que precisam descender,  eles estão voltando  entre o editor de clodcode  e o assistente de clodcode.  E então, esse é um exemplo  do Json Event  para uma mensagem de usuário.  Então, quando temos um usuário  entrar algo em um editor,  ele vai enviar esse Json Event  através de um acp  para o assistente de clodcode.  Então, ele pode entender  o que o usuário está perguntando.  E isso pode incluir coisas  como imagens  ou recursos  chamando de files específicos  que queremos editar.  E quando o agente responde,  há um par de respostas  que ele pode dar.  Primeiro de tudo,  esse é um exemplo do Json  que precisamos de nosso assistente de clodcode  para dar através de acp  quando ele quer comunicar  uma lista de tasks  que ele quer knockout.  Nós vemos isso todo o tempo  com clodcode.  Ou se ele quer  enviar algum texto planejado,  parece assim.  Nós temos um tipo de  mensagem de usuário.  Aqui é o texto que  ele vai enviar.  Então, nós podemos  enviar isso em nosso editor.  Ou se ele quer  fazer um update  para um file  ou ler um file.  Esses são todos  feitos através de  os teclas de usuário.  E então, nós temos  um update de  clodcode.  E depois podemos  dar um título.  Algum outro tipo de metadata.  Basicamente, qualquer coisa  que você ever ver  dentro de clodcode  ou de clodcode  onde você pode ver  o clodcode,  você pode ver o file  que está afetando  ou os números de linha.  Todo esse metadata  foi passado  através dos payloads de Json  com acp.  E há um par de outras coisas  que eu não quero  ir super profundo.  Agora, definitivamente  veja isso se você  está curioso  e se você quer  construir seus acessentes  porque, com essa informação,  nós podemos começar  a jogar a ideia de  não usar clodcode,  não usar Jemen ICLI,  mas, na verdade,  construir nosso próprio  acessente custom  e eles têm um exemplo  de isso em GitHub, também.  O sponsor de hoje  é Fly.io,  uma plataforma de clod  de desenvolver  que faz deployar  seus acessentes,  frontends,  realmente, qualquer tipo de aplicação  é super direto.  Estamos falando  de usar acessentes AI  em este vídeo.  Você pode construir  coisas incríveis com eles,  mas você tem que ter  um lugar  para aplicar  a produção.  E isso  é onde Fly.io  E o que faz eles  ficar de fora  é que eles têm  suas próprias infraestruturas.  Não só eles são  um rapaz de AWS,  que significa  que tudo vai ser  mais fácil  e mais rápido  para você  e você pode deploy  muito facilmente  não importa  o frame-work  que você usa.  E tudo que você  tem que fazer  para começar  com Fly.io  é criar um acessente  para você  começar.  E depois você pode  instalar o CLI  para você  trabalhar com isso  no seu computador  e depois você  loga com o  clodcode  e depois veja isso.  Eu posso ir para  a diretoria  onde eu tenho  minha aplicação  e Run  Fly  Launch.  Ela vai  automaticamente  reconhecer  o tipo de minha aplicação  e configurar  coisas para deployar  tudo automaticamente.  Há basicamente  nada mais  que eu tenho que fazer.  É tão fácil.  Eu posso customizar  qualquer configuração  que eu quero.  Senão  eu só vou com  os valores defaults.  Então eu fui  antes e comprei  o container  para meu tipo de aplicação.  Deployou para o clode  e me deu um domínio  que eu posso customizar  depois.  Então aqui no dashboard  podemos ver a nossa aplicação.  Clicar no url aqui  e boom,  aí vamos.  Nós temos  o nosso front-end  deployado  na I.O.  Global Infrastructure.  E esse é o front-end  que estamos construindo  no topo  do workshop  que eu mencionou  antes.  É tão fácil  para ter tudo deployado  para a produção.  E o I.O.  é livre  para começar.  Então se você tem  esses ótimos projetos  que você está construindo  com a A.I.C.  Assistência  e é hora de  trazer-los para a produção.  Essa é a sua plataforma  para fazer isso.  Eu recomendo  cheque-los  link no descrição.  Então se queremos  construir um acústimo  agente  usando a ACP  precisamos construir  uma aplicação  que segue  essa arquitetura.  Nós usamos o modelo  de idioma  no fundo  para acessar  regras  para fazer  mudanças de código  e usar tools  para fazer isso  e comunicar  isso de volta  através da ACP.  Então eles têm  um exemplo de typescript  na repositora de GitHub.  Eu vou linkar  esse abaixo  também  se você quer  ver isso.  E isso é o que  vamos testar  dentro do Z  agora.  E então eles tem  instruções  nesse repo  onde você pode  só clonar  e depois  você adora  para a configuração  no Z.  Eu vou te mostrar  o que parece  um pouco  também.  E então clicando  em agent.ts  eu vou te mostrar  como isso funciona  muito rápido.  Isso não vai ser  uma conversação inteligente  com um agente de código real.  É apenas um monte  de mensagens  de código  que vão ser  enviadas por ACP  quando a gente envia  um regrasso.  Então é só  um demo  que temos aqui.  Mas primeiro  nós temos  a função inicial.  Isso é o que acontece  quando vamos fazer  uma nova conexão  para a assistência de código  para setar as coisas  e depois  vamos fazer  uma nova sessão  ou no Z  um novo thread.  Essa função  é ran.  E então  once  nós estamos no mode de prompting.  Isso é onde vamos  simular um turn  e então esse  simular um turn  funcione.  Isso é onde você  typically  invoca o modelo  de língua de idioma  e dá o regrasso  para  ler certas fios  ou editar certas fios.  Em este caso,  como eu disse,  a gente tem  um protocolo de  mensagem de JSON  seguindo o protocolo de ACP  para dar esses  notagens para o  regrasso.  Então a gente envia  um regrasso  e o agente  é um regrasso  para comunicar  através de ACP  para voltar para o  editor de código.  Eu vou te ajudar com isso.  Vamos começar  a ler alguns fios  para entender a situação  atual.  E aí,  ela envia um  protocolo de Mock  dizendo que vai  ler um fio específico.  E aí,  ela faz outro update  aqui dizendo que  ela vai  replicar  algum conteúdo  em um fio.  Então,  apenas comunicar  alguns fios de protocolo  que  agente  como o agente  iria agir  se houve um real  agente de código  abrindo aqui.  Tudo bem,  então,  para voltar em ZED  porque eu  segui as instruções  no GitHub  para  ter o meu  acústimo agente  instalado.  E a maneira que você  chegar à configuração,  by the way,  você clica  no top right.  Vamos para as instruções  e nós podemos  adicionar um agente externo.  Como eu já fiz aqui.  Então, você tem o Gemini  CLI, você tem o clado de código.  Agora, podemos adicionar  o nosso próprio.  Então,  abre este JSON  aqui para você  direto para adicionar  o caminho  para seu acústimo agente.  Como neste caso,  este é o fio de typescript  que temos  puxado  do GitHub.  Então, eu vou  acelerar aqui.  Eu não preciso adicionar  outro,  mas eu posso salvar este.  E aí, você terá  seu acústimo agente  que você pode conectar.  Então, para voltar aqui,  eu posso abrir um novo  thread  com meu acústimo agente.  E  não é nada fã  aqui.  É apenas essas  mesmas de hardcoded  que vimos  passando por acp.  Mas olha como  semelhante isso.  O code  foi bem simples  overall  no file de typescript.  Mas agora,  temos tudo integrado  já com Z.  E com qualquer editor de code  no futuro que funciona com o acp.  Então, é tão fácil  para construir o nosso acústimo agente  com todas as operações diferentes  que temos que ver  com o acústimo.  E como eu lutei antes  e eu prometi  eu iria clicar mais.  O cláudico não tem  uma integração direta  com o acp.  Então, para Z  para colocar em sua plataforma,  eles tinham que construir um adaptor.  E isso é mais simples  do que você acha.  Obrigado ao acp.  Então, podemos olhar  o cláudico de source aqui  para o adaptor.  Eles têm um agente.ts  só como o exemplo de acústimo agente  que vimos um pouco antes.  E clicando em isso,  um pouco do cláudico  vai ficar muito similar  porque basicamente  tudo que temos que fazer  para conectar o cláudico  para qualquer editor  através do acp  é que precisamos convertir  qualquer mensagem de cláudico de sdk  para o formato  que o formato de JSON  necessário  para o acp standard.  E então, essa função aqui  tem qualquer mensagem de cláudico.  E basedado no tipo  como se o texto  ou o modelo está pensando  ou se usa um tool  para ler um file  vamos tomar o output  do cláudico de sdk  como todos os valores diferentes  em esses trunques  e vamos transformar  isso em um objeto de JSON  necessário para o acp.  Então é realmente só  uma mudança de data.  Estamos só mudando o formato.  Isso é tudo que faz.  E então, essa integração,  esse full adapter  para cláudico de z  através do acp  é apenas cerca de 600 lindas de cláudico.  É tão simples.  E nós podemos tomar  essa notícia bonita  de esse standard aqui  e aplicar isso  a outros tipos de integrações.  Como eu vi isso,  minha mente começou a running wild  para as possibilidades aqui  com o arcon em particular.  Meu projeto de open source  que é o Centro de Comandos  para A.I. Coding Assistência.  E uma das coisas que sempre  queremos construir  é integrar  com diferentes agentes de coding  direto em acp  é definitivamente o nosso ticket  para isso.  Então eu já tinha Rasmus  na minha equipe.  Ele fez um proofo de conceito  integrando o arcon com acp.  Então sim,  vamos dar uma olhada  para isso agora.  É muito, muito interessante.  Tudo bem, então nós só  tomamos uma olhada  em implementar agentes custom  em z through acp.  Agora, a habilidade  para nós  para fazer esse tipo de integração  nós mesmos  foi aberto  as ideias de floodgate  para mim e Rasmus.  Então eu me trouxe aqui  para mostrar um proofo de conceito  que ele fez para o arcon  usando acp com o arcon  para conectar-se  ao cloncode  e outras acp.I. Coding Assistência.  E isso é muito um POC  neste momento.  Mas eu só quero compartilhar  com vocês  alguma visão que temos aqui.  Algumas formas  que podemos implementar  o arcon  com esses agentes de coding  usando acp.  Nós sempre queremos fazer  algo como o que você vai ver.  Mas acp  só faz isso muito mais fácil  porque se proporciona  esse standard  para conectar  aplicações como o arcon  e outras couturas  para os agentes de coding.  Então Rasmus,  obrigado por estar aqui  e construir este proofo de conceito.  Por que você não compartilha  alguma visão de você  para conectar o arcon  para os agentes de coding?  Sim, então sim.  Obrigado por me estar aqui.  E o que você disse  a visão sempre foi  para ter o arcon  ser capaz de invocar agentes de coding  não só clado de clado  mas outros agentes  como o CLI de Gemini  ou agentes de cursos  ou até o Devin  ou  qualquer um dos agentes de coding  realmente.  E o que o acp  nos permite  é fazer isso  em um arcon.  Então se todos esses  outros agentes  também adoptam esse protocolo  nós serão capazes de implementar  todos eles  muito, muito facilmente  e muito, muito rapidamente  enquanto nós temos  a base de acp implementação.  Então o que temos aqui agora  e sim, eu estou tendo um blast  construindo isso com o arcon  e aqui nós temos  a POC com clado de clado  mas nós podemos  usar, sim, facilmente  usar a CLI de Gemini  porque ambos estão trabalhando  como outros agentes  com acp.  E esse é agora  diretamente integrado  em arcon  a POC  onde você pode  basicamente conectar  o seu diretor  para o arcon.  Então a visão long-term  aqui seria para  como conectar  o seu repositor  para o arcon  e você pode  conectar o seu conhecimento  base para esse diretor  e você pode conectar  seus servers mcp  para esse diretor  para que você possa  gerar todos os contextos  que você precisa gerar  para o seu agente de codos  antes de você enviar  o seu agente de codos  para o  background  para fazer um  tasks background  para você.  Então o agente  vai poder spinar  o seu buraco,  o seu ambiente  onde ele pode  fazer o que quiser  e ele vai voltar  para você com um PR  quando está pronto.  Então basicamente  você pode  dizer onde  isso deveria funcionar  eu vou te dar um passo  para um dos meus projetos  eu posso começar  a sessão de codos  e eu posso ver  essa interface aqui  onde eu só tenho um chat  nós temos uma sessão ativa  e  nós podemos enviar  um task fácil  eu vou te dar um exemplo  um Task here  para criar  3 different  files de hola  um em Rust  um em Go  e um em Python  e  vamos justa  ver o que é feito  então nós devemos ver  isso aqui  o que eu tenho aberto  é realmente  o back end de TCP  que é escrito em Rust  e você pode ver aqui  que faz  é realmente  spawns  você pode ver que  é spawn  3 subpagens  que é feito  em um sweep  então é que foi  um task bastante ineficiente  também  eu posso ouvir os files aqui  também  e nós podemos ver  que tudo  sim eu criou isso  eu criou isso  e isso  então é um exemplo muito simples  mas  uma forma muito poderosa  de trabalhar com agentes de codos  e eu acredito que o Task vai ser um futuro  um jeito de trabalhar com  agentes de codos  e RGOM é  a nossa interpretação  ou será a nossa interpretação  da nova interface  para codos  exatamente certo  isso é lindo  sim e  como Rasmus disse  isso é apenas um conceito  não vem de qualquer momento  ao RGOM necessariamente  e isso é um exemplo basicamente  mas  o poder disso  é que nós não interagimos  com o clod de clod  diretamente  nós não usamos o clod de clod  SDK  nada assim  é tudo através de ACP  isso é como nós estamos communicando aqui  e então realmente  seria um descanso  em replacimento  para qualquer outro agente  tipo GEMI CLI  que também suporta ACP  isso é a luta disso  e outra coisa que podemos fazer com o RGOM  é que podemos fazer um muito fácil  para manejar  muitos agentes em paralelo  todos usando ACP  então uma interface de usuário  como assim  mas ser capaz de  clicar em diferentes agentes  como eles são ativos  trabalhar em  longestos running tasks  algo obviamente  mais longa que o  quick demo aqui  então  sim, há tantas formas que  nós podemos construir isso com o RGOM  sim, exatamente  e imagina uma interface aqui  onde você pode realmente  selecionar seus agentes  você pode selecionar cursos  ou você pode selecionar  GEMI CLI  você pode selecionar codecs  ou qualquer coisa  e você pode  enviar isso  você sabe  e você tem  basicamente um chato  que você pode abrir ou cerrar  você pode inserir  o que está fazendo  ou você pode ignorá-lo  e no final do dia  ele vai voltar para você  com o PR  de qualquer forma  que você pode revisar  no final  então  isso é realmente um  um jeito  para  para botar isso  para  para o fundo  e fazer o trabalho para você  então é muito similar  para o que  o cloud de codecs  está fazendo  mas que  a diferença é que você pode fazer  isso  com qualquer agente  e você faz isso localmente  em sua própria máquina  certo  sim, é uma coisa bonita  então  muito obrigado Rasmus  por mostrar isso  trabalhando no conceito profundo  os dois grandes motivos  que eu queria  colocar isso  no vídeo aqui  é um  para mostrar alguns  planos ótimos  que temos para o RGOM  que  sempre teremos  mas o ACP vai fazer  mais fácil  e também  eu espero que isso  possa enlutinar  ainda mais  sobre o que o ACP  evita  e por que eu realmente  acho que é o futuro  de coding AI  então  obrigado por estar aqui Rasmus  e até o resto do nosso vídeo  então eu espero que essas ideias  ao arcon  realmente tem que ser  sua chuva de coração  está flowando  há tantas formas  que o ACP  realmente é o futuro  de coding AI  e também Rasmus  tem um vídeo  que está vindo  no canal  que eu vou linkar  no descrição  quando é disponível  checa isso  se você quer  dar  ainda mais  em essas ideias  ao arcon  e acp  então sim  isso é todo o conteúdo  que eu tenho para você agora  no ACP  é apenas uma tecnologia incrível  um estando  que eu definitivamente  vou seguir mais  e colocar mais conteúdo  como nós recebemos mais integrações  com diferentes editores  de couto  e assistência de couto  então  se você aprecia esse vídeo  você está olhando para mais coisas  coutos AI e agentes AI  eu estaria realmente apreciado  um like e um subscrito  e com isso eu vou ver você  no próximo vídeo",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o ACP (Protocolo Cliente-Agente) da ZED e demonstra como integrar assistentes de codificação aos editores, permitindo alternar entre Gemini CLI e Clodca, receber atualizações em tempo real e aceitar ou rejeitar mudanças diretamente no IDE, com uma visão de futuro e limitações atuais.",
            "resumo": "Neste vídeo, o apresentador explica o ACP, um padrão de protocolo cliente-agente para conectar assistentes de codificação a editores. Ele mostra a integração da ZED com Clodca e Gemini CLI, destacando como é fácil iniciar uma thread de Clodca ou de agentes customizados e autenticar dentro do editor. Com ACP, os usuários veem atualizações ao vivo no editor, podem editar, aceitar ou rejeitar mudanças, e trocar entre diferentes assistentes com um único clique. O vídeo aborda o fluxo de instalação simples (ZED, instalação de plugins), o painel de agentes, limitações da versão beta, como threads às vezes demoram a carregar e bugs no histórico de alterações, e reforça que ACP facilita rodar múltiplos agentes em paralelo, conectando-se a editores diferentes. Também menciona a inspiração no MCP e convida para a documentação e para o workshop.",
            "assunto_principal": "Protocolo ACP (Cliente-Agente) para integração de assistentes de codificação com editores, com foco em ZED, Gemini CLI e Clodca, visando facilitar uso, atualizações em tempo real e múltiplos agentes.",
            "palavras_chave": [
              "ACP",
              "Protocolo Cliente-Agente",
              "editor de código",
              "integração de assistentes",
              "ZED",
              "Interface de Linha de Comando Gemini",
              "Clodca",
              "assistentes de codificação",
              "beta",
              "multiagentes",
              "padrão",
              "autenticação",
              "MCP",
              "arquitetura ACP",
              "oficina",
              "documentação",
              "Archon"
            ],
            "resumo_em_topicos": "- Visão geral do ACP: definição e objetivo\n- Integração com ZED, Gemini CLI e Clodca\n- Demonstração prática: criar threads, autenticar, alternar entre agentes\n- Fluxo no IDE: atualizações em tempo real, aceitar/rejeitar mudanças\n- Extensibilidade e agentes personalizados; menção ao Archon\n- Status de beta e limitações atuais (carregamento de threads, histórico)\n- Impacto e padronização: facilitar múltiplos agentes e interoperabilidade\n- Recursos adicionais: workshop e documentação",
            "prompt_tokens": 2142,
            "completion_tokens": 3706,
            "model": "gpt-5-nano",
            "cost": 0.0066
          },
          "analysis_time": 446.3558201789856,
          "language": "",
          "view_count": 19144,
          "has_transcript": false
        },
        {
          "id": "iV5RZ_XKXBc",
          "title": "Seu modelo de agente n8n RAG AI ULTIMATE acaba de receber uma atualização massiva",
          "title_pt": "Seu modelo de agente n8n RAG AI ULTIMATE acaba de receber uma atualização massiva",
          "url": "https://www.youtube.com/watch?v=iV5RZ_XKXBc",
          "published": "2025-09-06T23:34:45.778168",
          "published_relative": "há 2 semanas",
          "duration": "19:19",
          "date_published": "2025-09-03T17:00:50-07:00",
          "transcript_available": true,
          "transcript": " Retrival Augmented Generation é uma maneira de ir para dar seus agentes acesso à sua base de conhecimento.  E durante os meses passados, eu estou experimentando com toda a estratégia de raga no sol,  e combinando o melhor juntos, em um single n8n agente para você.  E eu estou evoluindo isso por um longo tempo agora,  começando com uma raga super básica como uma introdução,  tudo o que temos agora, com várias estratégias de raga combinadas.  Eu estou fazendo algumas grandes upgrades a essa estratégia que eu quero mostrar hoje,  e eu quero mostrar para você como você pode usar esse template para você.  Agora, o motivo de colocar tanto esforço em essas estratégias diferentes no primeiro lugar  é que uma implementação básica de raga não é suficiente.  Se você não é estratégico sobre as estratégias de raga que você usa,  vai parecer que a raga é fundamentalmente foda.  Então, o que eu quero dizer com isso?  Bem, eu tenho a primeira versão do raga de raga de n8n,  para que eu possa explicar as fases fundamentais que temos com uma implementação básica.  Agora, vamos ser claros.  Esse template é uma introdução boa para o raga,  mas há uma razão que eu estou evoluindo muito no ano passado.  Então, cada implementação de raga tem dois componentes.  Nós temos nossa pipeline de raga,  onde nós convertimos documentos do nosso store de documentos  para o formato que nós vamos instalar em nosso base de conhecimento.  Então, nós chumamos as coisas em um pedaço de pedaços para o nosso LLM.  E depois, nós damos as tools para nosso agente.  Esse é o segundo componente para procurar por nosso base de conhecimento.  Então, eu vou lhe dar um exemplo aqui.  Eu vou perguntar uma pergunta,  onde vai ter que procurar documentos que originam no meu Google Drive,  ir para o base de conhecimento para encontrar a informação para responder a minha pergunta.  Agora, em bothas as pipeline de raga e as tools de agente,  há um lote de risco aqui,  que eles missam o contexto quente e a informação relacionada.  Quando nós fazemos essas procuradas muito direitos,  muitas vezes, nós não precisamos do que precisamos da base de conhecimento.  Se você não é muito certamente  sobre como você está chugando e curando o conhecimento para o seu base de conhecimento,  não importa como afetar suas estratégias agentes,  seu agente irá se separar.  E a mesma coisa aplica se nós curando o nosso conhecimento muito bem,  mas não temos estratégias efetivas para procurar.  Então, nós queremos resolver tudo isso.  E isso é o que eu tenho para você  no último verão da raga de raga de n8n.  Então, isso é o que evolui agora.  Isso parece muito mais complexo,  mas eu vou deixar isso no vídeo.  Nós temos estratégias para a curação de conhecimento efetivo  e a procuração de conhecimento efetivo.  E também, eu quero ouvir de vocês  as outras estratégias que você quer me adicionar  a esse templo quando continuo a evoluir.  Eu posso adicionar grafes de conhecimento  ou embedos contextuales.  Muitas formas diferentes para construir no topo disso.  Deixa eu saber no comentário o que você acha.  Porque eu só queria dizer isso muito rápido,  mas sim, vamos entrar agora.  E realmente, essas estratégias raga  vão ser muito ajudadas para você  não matter do agente que você quer construir.  Então, você pode usar esse templo como um começo.  Eu vou falar de como você pode fazer isso  e adaptá-lo para o seu caso de uso  durante esse vídeo também.  Então, aqui são as três estratégias  que vamos cobrir no vídeo  que eu adicionei ao templo.  Primeiro de tudo, nós temos um agente quechão.  Depois, eu quero dar uma raga agente.  E, finalmente, vamos cobrar a rangueira.  Agora, uma rangueira agente  é algo que eu adicionei  na última evolução deste templo.  Então, veja este vídeo aqui  se você realmente quer dar uma raga na raga.  Mas o que eu adicionei pela primeira vez agora  é uma rangueira agente e rangueira.  E, cara, essas estratégias  fazem um grande diferença.  Então, essas são as grandes opções que eu estou falando sobre.  Eu estou muito emocionado de estar cobrindo isso com você agora.  Agora, a primeira raga estratégia  que eu quero dar com você que eu adicionei  é uma rangueira agente.  E essa é muito poderosa.  Porque o que estamos fazendo  é leverar a inteligência  de um modelo de idioma larga  para nos determinar  como chutar nossos documentos.  Em uma implementação mais tradicional,  como neste templo aqui,  nós estamos usando uma approach mais determinista  em que nós estamos aplicando documentos  de cada 1.000 carácteres  ou 400 carácteres.  E o problema com isso  é que nós estamos agora explodindo ideias  no nosso documento  entre diferentes chunques  que nós queremos realmente ter uma rangueira.  E isso vai até assim  para explodir no meio das palavras  e das palavras  com uma implementação muito básica.  E nós podemos ter um pouco mais de elaborado  e tentar respeitar  a razão e o parágrafo,  mas você ainda vai estar explodindo  no meio das ideias  que você quer ter uma rangueira.  E então, isso justamente  leva a um monte de lojas de contexto  quando nós procuramos a base de conhecimento  e nós estamos procurando esses chunques,  bem, talvez o que temos nesse chunque  nós realmente queremos ter parte  desse chunque  para realmente ter aquela ideia completa  para responder a pergunta do usuário.  E então, com a chunca genética,  este é o poder aqui,  é que nós estamos dando o documento  para o modelo de idioma larga  e estamos dizendo isso,  tipo,  based no necessário que temos  para manter ideias juntos,  como nós devemos explodir este documento.  E então, agora indo para o meu database,  então este template usa postgres.  Eu já evolvi,  para que você possa usar  qualquer database de postgres,  tipo,  superbase ou postgres self-hosted.  Eu estou usando neon aqui  para o meu database.  Nós podemos ver isso  com uma chunca genética.  Se eu clicar em algum de os chunques  que temos aqui,  nós podemos ver que  nós começamos  com o começo de uma sentença  e nós vamos todo o caminho  por todos esses pontos de coletão.  Então, nós estamos mantendo  essa ideia completa,  como essa lista de pontos de coletão  juntos.  E você verá esse mesmo tipo de coisa  quando eu vou por os diferentes chunques aqui.  Nós não estamos explodindo  em meio de palavras ou sentências  assim.  Isso é o que queremos preservar aqui.  Agora, nós temos que chuncar  documentos.  Se não podemos justificar  todo um documento  como um recorde  aqui, porque isso é muito  muito para pular  para o modelo de língua maior.  E isso vai fazer as embedrinhas  realmente inaccurais.  Então, nós precisamos ter  essas partes de bytes de informações,  mas, como nós podemos,  queremos manter  as ideias concretas  juntos,  explodindo o documento  com a ajuda de um modelo de língua maior.  Isso é o que a gente  chunca nos dá.  E o resto de este pipeline  é realmente o mesmo  do que a edição anterior  deste templo.  Então, de novo,  cheque o videojante agente  que eu linko antes  se você quer  dar mais para isso.  Então, deixando as coisas  concisinhas aqui,  focusando em estratégias  também.  Mas, apenas para uma rápida recap,  nós temos o nosso documento  que, em meu caso, é o Google Drive.  Você pode facilmente  update isso,  para ser algo como  Dropbox ou SharePoint  instead.  Então, nós estamos assistindo  para fios que são  criados ou updateados.  E se um fio é updateado,  nós também queremos  deslizar os old rows  para insertar  apenas os novos.  E depois nós deslizamos o fio  do Google Drive.  E depois, based no tipo de fio,  nós temos esses diferentes novos  em N8n  que extractam  o texto  da forma de fio.  Então, nós even supportamos  data tabular  com Excel e CSV fios.  Então, eu vou  dar um pouco mais  quando eu falo de agente.  E depois nós temos os fios de texto.  Então,  Google Docs,  documentos textos,  documentos marcado,  PDFs.  Então, nós extractamos o texto  de lá.  E depois, para esses tipos  de documentos,  este é onde nos  nos nos  nosso sistema de chunca agente.  E,  porque este é um pouco mais  de uma implementação custom,  não há realmente um jeito  para fazer isso  sem fio.  Mas este é onde a liga  da liga de  fio de lá  vem.  Então, nós podemos atacar  um modelo de idioma  que podemos usar  com a liga de fio de lá  em N8n.  Isso é uma coisa de fio.  E eu uso clod  de fio  para me ajudar a construir isso.  Então, basicamente,  as coisas importantes aqui  é que nós temos  este prompt  que nos feda  para nosso modelo de idioma  que descreve  seu rol  e as instruções  para como nós queremos  intelligente  documentos de fio  para manter as ideias coreais  juntos.  E você pode ver aqui  que,  baseda de alguns dos fios,  isso não é ideal.  Mas, por mais parte,  isso muito é  iniciar as chuncas  e finalizar  elas  com uma ideia quente  captada juntos.  Isso é o que estamos tentando  completar aqui.  E este fixa um lote de problemas  que temos com o RAG  onde nós só temos  muito contextos fragmentados  entre  os diferentes chuncas  que temos para nosso documento.  Então,  eu envio este prompt  para o LLM  e basicamente,  o LLM  vai dar uma palavra  para splitter  as chuncas.  Isso é como nós criamos  essas chuncas por tempo.  E tudo isso  vai ser construído  em nosso database de vector.  E então,  você poderia muito  swapar isso para usar  um outro database de vector  tipo Quadrant ou Pincone  se você quiser.  Geralmente, eu amo  usar Postgres.  Então, eu também envio este template  para trabalhar  não só com Superbase  como eu tinha antes,  mas também  qualquer database de Postgres.  Agora eu estou usando Neon  que eu ensinou  recentemente.  É blazing fast,  serverless Postgres.  Freio para começar.  Eu vou te mostrar realmente rápido.  Se você vai para o dashboard,  clica no botão de conexão.  Isso te dá toda a informação  no clima de conexão aqui  para você conectar  com seus credentials Postgres  em N8n.  Então, é super fácil  para começar.  E realmente,  isso é tudo  para a chunca agente.  A última coisa que eu quero dizer aqui  é que  a outra  bonita parte  da chunca agente  é como flexível é.  Porque você pode  tweakar este prompt  based no seu caso de uso  para ficar realmente específico  com como você quer o LLM  para splitter os seus documentos.  E então, eu tenho tentado  um lote de outras  estratégias para a chunca,  como o recurso de  arquitetes texturais  trabalhando com documentos marcado  e outras subsexões diferentes.  Eu tento a chunca semantica,  que é realmente  usar modelos de embedo  em vez de grandes modelos de línguas  para determinar  estes bairros.  Mas, cara,  a chunca agente  é apenas o mais flexível  e o mais poderoso.  Então, eu absolutamente  amo isso.  E isso é realmente  a grande coisa  que me ajuda  a curação do conhecimento,  a pipeline de raga  para este templo.  O sponsor de hoje  é Deepo  e suas boas  ágeas remotes  para a clodcode.  Eu vou entrar  em um pouquinho.  Mas o que Deepo  tem construído  é uma gênera  globalmente distribuída  para a infraestrutura  e a cacha persistente  para fazer  extremamente rápidas  aplicações,  coisas como  contador de remoto  e runners de acção de github.  E as empresas  que se mudaram para Deepo  têm feito  55 vezes  uma aumentação de performance  para as construções  e há um tono de integrações  com coisas como  acções de github,  círculos C.I.,  docker,  e githlab.  E a infraestrutura de Deepo  tem posicionado eles  perfeitamente  para construir o que eu sempre  queria para a clodcode,  remoto agentes sandboxes  e agora eles estão aqui.  É uma coisa bonita.  Basicamente, o que podemos fazer  é botar um tono  de sessões de remoto clodcodes  em paralelo,  todos trabalhando  em diferentes features  e problemas  em nossas repositorias de github  e é nunca running  em nossa própria máquina.  É tudo running  na infraestrutura de Deepo.  E começar  é super fácil.  Então, eu vou linkar  esse quick start  na descrição também.  Você só tem que seguir  esses steps  para instalar o Deepo C.I.,  ter seus credentials  estrangeiros conectados.  E aí, nós só operamos  no termo  como nós fazemos com a clodcode.  Então, por exemplo,  eu me pergunto  para sumer  a repositoria de arcon  linkado para o repo.  Isso é botar um sessão  que podemos ver  todas as sessões  no dashboard aqui.  Eu posso clicar em isso  e nós podemos ver os logs  só como estamos trabalhando  com a clodcode em nossa máquina.  Mas isso é tudo running remotely.  Podemos even  botar isso de um mobile device  se quiser.  As possibilidades  são finalizadas  para isso  e o poder que nos dá.  Então, se você sempre  quer ser um clodcode  mastermind  botando um tono de sessões  em paralelo  de qualquer lugar,  definitivamente check out Deepo.  Eu vou ter um link  na descrição.  Agora, a próxima estratégia  que eu quero clicar  é uma regra genética.  Essa é um jogo-changer  e a implementação  pode differir muito  dependendo da sua utilidade.  Mas a ideia general  que eu converto  com essa regra  é que você quer  dar ao seu agente  a habilidade de explorar  o seu conhecimento  de diferentes formas  dependendo do que funciona  melhor  para o documento específico  e a pergunta de usuário.  E a forma que o agente  determina onde se olha  é só based  na promessa do sistema.  Então, você dê a habilidade  de procurar em diferentes formas  e depois no promessa do sistema  você descreve  o que isso exatamente  parece.  E você pode tunar isso  para o seu caso de uso.  Então, queremos ser  flexíveis aqui.  Isso é tipo o tema  para muitas dessas estratégias.  Então, vamos para a  nossa template original.  Há duas razões por que  é inflexível.  Primeiro de tudo,  nós só damos ao agente  um single tool  para procurar o nosso conhecimento  base.  E estamos tratando  todos os tipos de fios  em nossa pipeline  da mesma forma.  Mas funciona muito melhor  se nós nos tratamos  de todos os tipos de fios diferentes  com respeito.  Tipo, vamos para  o mais up-to-date pipeline.  Por exemplo,  estamos tratando data tabular  em uma maneira muito diferente.  Estamos retornando os recordes  individualmente  eu vou olhar isso.  Se eu voltar para o meu database  postgres e neon,  nós temos uma tabla especial  chamada document rows  especificamente para  instalar os rows  para as tablas que estamos  ingestindo de Google Drive.  Como eu tenho essa  fake mock data  que é generada  para uma spreadsheet de revenues aqui.  Estamos instalar  cada um desses recordes  como um row individual  em esta tabla document rows.  E a coisa muito legal  com isso.  E, de novo,  eu vou dar um pouco mais  em meu vídeo agente  específico  é que estamos dando um tool  para nossos agentes  especificamente  para gerar  quadros de sequo  para calcular coisas como  sums, averages  e maximos  sobre esta data tabular  isso é o tipo de coisa que  o rairo normalmente  completamente caiu na sua face.  Então,  nós não podemos  procurar data tabular  apenas como nós procuramos  data textual.  Nós não podemos ingestá-la  da mesma forma.  E isso pode aplicar  a um monte de tipos de file  também.  Então, eu espero que você  comece a ver a ideia aqui  da flexibilidade que nós  estamos adiantando  um rairo agente.  Outro exemplo muito bom  é que, às vezes,  se seus documentos  são shortos  para fitar  no contexto  para o LLM  confortável,  você realmente quer  ver o documento inteiro  ao invés de  apenas procurar  um par de cunhas.  E então, isso é  outra coisa que estamos fazendo  aqui  dentro do rairo agente  mais amplificado.  Nós estamos inserindo  o que é chamado  o documento metadata.  Então, essencialmente,  nós temos esta  separada tabula aqui  onde, ao invés de  instalar todas as cunhas  explotando,  nós só temos um recorde  pelo documento.  E então, se o nosso agente  decide, tipo,  oh, esse cunha é útil.  Deixe-me ver o documento inteiro.  Ele pode realmente fazer isso.  Então, nós damos um tool  para listar  todos os documentos  que estão disponíveis  na base de conhecimento.  Então, ele vai query  este documento metadata  da tabula.  E então, quando ele encontra  um documento, tipo,  oh, eu deveria olhar  no livro de pesquisa aqui.  Ele pode realmente  combinar  todas as cunhas  juntos  para gravar o documento completo  para olhar  com uma foto muito mais  holística.  Então, nós temos esse tool  também,  especificamente  para pegar  todo o conteúdo de file  para um file específico,  just based on the file ID  that we have coming in  from Google Drive.  So, now, I'll actually  give you a couple of demos  here.  So, we can see  agentic rag in action.  So, I'll open up the chat  and I'll say what is  the average revenue  in August of 2024.  And so, this is going to  query the sheet  that we have right here.  And so, I'm going to go back.  We can see that it first  listed the documents  that we have available to us.  So, it's querying the metadata.  It's seeing that we have  these specific columns here  so that it can write  that SQL query to query  the rows that we have  in document rows.  So, here's our query  that it created.  We got back the answer  of 309.5,  which is what it gave us  and that is looking  really good.  If I actually go  in the sheet here  and do an average  of B2 to B,  sure enough,  we've got 309.5.  So, this is looking great.  And then I can ask  another question here.  Like, let's just pull up  the marketing strategy  meeting.  So, I'll pull this up  and I'll just ask it  to view the entire  marketing strategy  meeting doc  and give me a summary.  So, I'm just being explicit  here that I wanted  to use the agentic rag tools  to get the full  contents of a file,  which is what it did  right here  for the marketing strategy  meeting  and then we'll go back  to our chat  and yep,  here is our summary  based on this document  right here.  So, sometimes you want  to do that kind of thing  where you want to  pull the entire document  when it's short enough  like this  to do something  like a full summary  that we wouldn't  necessarily be able to do  if we just returned  a couple of chunks  with a classic  semantic search  rag look up.  So, that is everything  for a agentic rag  and it's pretty neat.  Like, with agentic chunking  it was just touching  the rag pipeline.  Then, with agentic rag  we are hitting on  both the rag pipeline  and the agent search.  And now, last but not least  we have re-ranking  which is specific  to the search part  of our rag system.  So, what even is a re-ranker?  Well, you can think of it  as a special kind of model  not a large language model  but a re-ranker model  where it's sole job  is to take in  a massive amount  of chunks  from our knowledge base  from our search  like, in this case  I have it set to 25  and it's going to re-rank  and filter those out  only returning the top four  and you can adjust  these numbers  based on your use case  as well.  Now, the reason  this is so powerful  is if we were to return  25 chunks  straight to the large language  model  it would completely  overwhelm it.  It's going to make our  agent more expensive  a lot slower  and 25 chunks  leads to a very high risk  of hallucinating  because it's just so much  information coming in.  But re-rankers  are designed  to handle this much information  and they're a lot cheaper  and faster  so they don't have  general intelligence  like a large language model  we can't  build agents  around re-rankers  but they're made  to take in all these chunks  and do  that kind of re-ranking  and filtering.  And so going back to  are the very first  version of our template  with RAG  we're only ever  picking  four chunks  at most  from our knowledge base  but that's pretty limiting  what if we want to  actually deal with  dozens of chunks  and then just pick  the top ones  well that's what  re-ranking  nos permite.  Então eu vou te dar um exemplo aqui  eu vou abrir o chat  e eu vou dizer  me dê uma overview  de Nerovers  isso é apenas um de  as companhias  que eu tinha  Claude Generate  para o Mockdata aqui  então nós estamos usando  a sessão semelhante  de search tool  que é o classic  RAG search  que nós tínhamos  por toda a interação  do nosso template aqui  e se clicar em isso  nós podemos ver  que nós estamos só  retornando  quatro chunks  mesmo que o nosso limite  é 25  porque veja isso  se clicar  em  o modelo de re-ranker  e nós vejamos  o input que vinha  da nossa base de conhecimento  há muito informação aqui  nós estamos tomando  25 chunks  veja isso  é um index zero  então isso significa  que há 25 chunks  em total  e depois nós estamos  retornando  o top 4  depois que nós usamos  esse re-ranker  para figure os que  são os mais relevantes  based no nosso question  de  me dar um overview  de Nerovers  muito muito legal  e então o modelo de  larga língua  se veja  no prompt  que vinha  isso é o  completo prompt  para o modelo de larga língua  não é tão grande overall  nós temos um chunk  dois chunks  três chunks  quatro chunks  como parte do nosso prompt  então é para adicionar  contextos  para a geração de agroneira  isso é muito melhor  do que se nós realmente  geramos 25 chunks  mas  nós ainda tínhamos que sifter  através disso  usando o re-ranker  para se dividir  com toda informação  antes de ir para o LLM  então  isso é re-ranking  e há apenas uma opção  para um re-ranker  agora no final  usando os modelos cohere  mas cohere é  realmente fantástico  então você só tem que  cohere.com  você pode criar um api free  eu estou apenas no free tier agora  então eu não estou pagando  nada para isso  só como eu não estou com o neon  então é como você pode  re-rankar  em seus agentes n8n  então isso é tudo que eu tenho  para essa versão massamente  upgrade  do agente n8n  agente template  e eu espero que eu tenha cobrido  muito bem  como você pode adaptar isso  ao seu uso específico  escolhendo e escolher  algumas estratégias de agroneira  ajustar certas primeiras  mesmo adicionar  suas próprias estratégias  e há muito mais  que eu poderia cobrar  também. Então definitivamente deixe-me saber  nos comentários  se você quer me cobrir  conhecimentos de conhecimento  em isso  ou embedos contextual  tantas outras estratégias  que eu poderia incluir  também  e reg  é tão importante para o AI  então eu sempre vou  cobrir mais  com meu conteúdo  então se você aprecia isso  e você está olhando para mais coisas  agentes AI  e reg  eu aprecia um like e um subscrito  e com isso  eu vou ver você no próximo vídeo",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "Atualizações massivas do template de agente n8n RAG AI, com estratégias avançadas de RAG, ranqueamento e divisão em blocos para melhorar a curadoria e recuperação de conhecimento em pipelines de dados.",
            "resumo": "O vídeo apresenta as mais recentes melhorias no template de agente n8n RAG AI, enfatizando o uso de Retrieval Augmented Generation (RAG) para oferecer aos agentes acesso à base de conhecimento. O apresentador destaca que uma implementação básica não é suficiente e divide a solução em duas partes: o pipeline de RAG, que transforma documentos da fonte (por exemplo, Google Drive) em trechos coesos para o modelo de linguagem, e as ferramentas do agente, que consultam a base de conhecimento. Novas estratégias incluem um ranker (classificador de ranking) e um ranker de agente, além de um chunking genético que preserva ideias completas durante a divisão dos documentos. O template agora suporta PostgreSQL (Neon) e pode ser usado com outras bases, com ingestão de diversos tipos de dados (texto, PDFs, planilhas) e atualização incremental de arquivos. O autor convida comentários e apresenta possibilidades futuras, como grafos de conhecimento e embeddings contextualizados.",
            "assunto_principal": "Atualizações do template de agente n8n RAG AI com estratégias avançadas de RAG, integração de rankers, chunking genético e fluxo completo de ingestão e consulta de conhecimento.",
            "palavras_chave": [
              "Geração Aumentada por Recuperação",
              "Geração Aumentada por Recuperação",
              "n8n",
              "modelo",
              "agente",
              "segmentação",
              "classificador de ranqueamento",
              "ranqueamento",
              "base de conhecimento",
              "pipeline de Geração Aumentada por Recuperação",
              "Google Drive",
              "PostgreSQL",
              "Neon",
              "ingestão de documentos",
              "representações vetoriais",
              "grafos de conhecimento"
            ],
            "resumo_em_topicos": "- Contexto: RAG como forma de fornecer acesso à base de conhecimento aos agentes.\n- Estrutura: pipeline de RAG + ferramentas do agente; separação entre transformar documentos e consultar a base.\n- Evolução: combinações de estratégias novas no modelo para maior robustez.\n- Novas estratégias: introdução de ranker (classificador de ranking) e ranker de agente, além de um chunking genético que preserva ideias completas.\n- Detalhes de implementação: chunking que evita fragmentação de ideias dentro de palavras e sentenças; uso de um modelo de linguagem grande para orientar como dividir documentos.\n- Fonte de dados e ingestão: suporte ao Google Drive com a possibilidade de adaptar para Dropbox/SharePoint; ingestão de texto, PDFs, documentos marcados, planilhas, etc.; atualização incremental de arquivos.\n- Armazenamento: uso de PostgreSQL (Neon) e possibilidade de usar outras variantes de bancos de dados PostgreSQL.\n- Fluxo de operações: extração de texto de diferentes tipos de arquivos, atualização de pipelines e sincronização de novos dados.\n- Futuras possibilidades: grafos de conhecimento, embeddings contextualizados e outras estratégias a serem adicionadas; convite para comentários e sugestões dos espectadores.",
            "prompt_tokens": 2081,
            "completion_tokens": 4079,
            "model": "gpt-5-nano",
            "cost": 0.0072
          },
          "analysis_time": 389.0683698654175,
          "language": "",
          "view_count": 31325,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@DanGalletta",
      "name": "@DanGalletta",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DataCouncil",
      "name": "@DataCouncil",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Incomestreamsurfers",
      "name": "@Incomestreamsurfers",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "EKk6yZiMMtc",
          "title": "Claude Code + Codex = O NOVO Construtor de Sites Definitivo",
          "title_pt": "Claude Code + Codex = O Novo Construtor de Sites Definitivo",
          "url": "https://www.youtube.com/watch?v=EKk6yZiMMtc",
          "published": "2025-09-19T23:54:47.227310",
          "published_relative": "há 1 dia",
          "duration": "15:12",
          "date_published": "2025-09-19T04:38:46-07:00",
          "transcript_available": true,
          "transcript": " Can you via code an entire ecom store cloud code with codex design doca and play right mcp  Can we make an entire ecom website from just a csv?  Let's find out together. So I'm gonna be using Wu commerce  I actually didn't really like Wu commerce until I had to add it to SEO growth  Now that I've actually used it a lot, but it's really interesting  Now just before we continue if you need any help your SEO and you're on either Wu commerce or Shopify  This video is sponsored by SEO Grove SEO Grove.ai. It's a sas that will grow your store automatically  You can still join the waitlist. There's still the special offer for our founding members  Which is $99 for three months. Sorry. Nice $10 a month for three months and then going up to 499  But yeah, basically I didn't actually realize this but Wu commerce is pretty damn  Interesting, so what we've done is I basically just found this which is a load of products on  GitHub  Right, it's just an example csv  And what I'm gonna do is I'm gonna see if I can make an entire website from it  So let's just open up terminal because I just turned my computer off for the first time in a while  And let's zoom in a little bit here and actually we need visual studio code as well, and I'll just do a new  Windo. Yeah, sure. And then file open folder  I really need to learn how to do this without doing it manually and we'll call this  WordPress Wu com  Because that's just what came into my mind and then open that folder. So what I'm gonna do is I'm gonna use codex for the design here  And then I'm gonna use  Cloudcode to create the thing  So I'm really curious to see just how good or how well this is going to work  So let's start by giving codex to csv, which obviously it doesn't accept it  So let's go here instead, and I'm gonna say please design me a home page a full  Home page with as many design elements as possible  For an e-palm store selling the follow products you can  use  Image links to really show  the quality and modernity of your  Build just use HTML CSS JavaScript. There we go  And then we'll send the products  So while codex fires up  Let's actually set up cloud code as well. The reason I'm using cloud code, by the way  Is because it's much better at using docker and things like that and I'll also just generally it's just much better with  It's much better with  WordPress basically. So let's CD inside. What did I call this WordPress?  WordPress.com, there we go. And then let's  Do let's add the playwright mcp. First of all, so upon google playwright mcp  There we go. And we'll just add this  Do we need any other mcps? I don't think so  Okay, so inside  Oh, wait  Permissions create a new folder called  Ecom site and then inside that's start a fresh docker instance  with  WordPress for development and we  Commerce install  Okay, I will just send that  So let's just check out what's going on here  Okay, still just doing stuff. That's fine  Let's actually just open docker as well  Someone said that the main flex is that your docker started in such a short amount of time  I have one of the new max guys. That's probably why  I think I could run LLMs on this thing, honestly  But I think I think when all of these active I think I was just using 60 gigabytes of ram or something before I  Turned my computer off Jesus. No wonder man  No wonder it froze yesterday while I was playing League of Legends. I think that's probably on me  Okay, so we should actually just yeah, we can basically open this already  I'm gonna install everything I'm gonna show you guys everything that I actually do here  So the containers are running  Let's wait a moment for WordPress to fully initialize then set it up  So I'm just waiting for it to set it up for me. You could run through this manually, but I'm just gonna let it do  You know, I'm gonna let it do it itself. This is what I use Claude code for, right?  I just kind of want to demonstrate what I use Claude code for  And it's it's mainly stuff like this like if I want really  So I've said just install the CLI there so I do keep an eye on it, right?  So we've said here the WordPress image blah blah blah doesn't have it  Installed by default. Let's install WordPress 3d. I don't like that  So I said just install the WordPress CLI because I want to use the WordPress CLI  So this is the kind of stuff I use it for any shell commands any  Annoying thing and MCPs docker that kind of stuff  You're gonna run it run into huge problems trying to do that, right?  if you do it with  If you do codex, right?  And then codex raw power and raw ability to code is  Really nice. Ok, so let's have a look  Why does a failed?  Ok, interesting. Let's just put it all in an indexed HTML file  Ok, so this is the the design that  Codex came out with which is really really nice actually super super good. So can we  Turn this into a WordPress website with one  Problem, that's the question. This is this is actually insane. If I can if I can do this  This looks really really nice. I think it could even be I think it could be even better  But like I mean compared to what you'd normally get from AI. This is pretty  Insane I would change the header person is the father, but let's just let's just go with the flow here, right?  So  There we go WordPress is now set up  So let's open this. There we go. It's got we commas que as you can see as a checkout  Let's just check what the username and password is. Sorry for flicking around admin. So let's just copy the password  Ok, so let's go to slash WordPress admin and then admin and then log in. I'm sorry  I'm not one prompting this. I'm vibrating this I should say. Ok, so we're in let's see  themes  Ok, so there's no theme or anything like that. That's fine  Ok, so let's first of all, let's just attach this CSV and let's just say add these products  either via  CLI curl or  Import CSV, whatever just get them on my site  Right? I would personally say if you've got a lot of products do it via  CSV import I would say  That's probably the best way to do it  But if you've just got 10 products like this, then you can also just let it do it semi-manually, right?  Ok, so let's just see if this this works. It's basically create a python script  It's converted 20 products from Shopify to WooCom as format and then it should theoretically just import them all, right?  Maybe you can kind of see where I'm coming from guys, but I'm very excited about  this because  Like I didn't even know this was possible until very recently  So can we create basically an entire business in 10 minutes now?  That's kind of kind of the question I'm asking today, right?  Ok, so let me install the CSV importer. So you would have had to do all this yourselves  You know blah blah blah. I'm just sat back relaxing feet up and it's just doing it, right?  Now I could just technically take this CSV that it created and just import it  So I might just quickly see if that works  It's just I'm curious  So let's search for this and then wait  So am I  Search for that and can I track this there?  No  Ok, so I just selected it here. Let's just see if this works  Run the importer  The products are now being imported  Ok, so it says 20 products imported there we go  So I mean that still saved me a lot of time, right?  I didn't even have to convert the files myself and then instead of it doing that. I said as I'll just say I just  Imported them through the admin and you check you have the products  So this is what the website currently looks like now that has products, right?  It's pretty obviously it's basic, but this is kind of manual  This is automatically created by the theme right the product page. So there we go. It can see the products  Wpwc product list there we go  No, I don't care about that. Ok, so now I want you to  So what I would do at this stage is I'm just gonna say I want you to  I  Don't know what's wrong with my mac recently. So I want you to  create five categories and  Assign products to them and then put  Let's just do that. I just want some categories  For two reasons. Number one, you guys should always have categories  So I'm just showing you that this is an important part of the process and number two is I want them because I want to be able to display  Categories on the homepage and it's part of the design and therefore I just have to quickly also create some categories  Now you can see it's super super easy. It just created five categories for me in like literally one second  So if I go to categories, we should see some categories here and that's going to assign the products  So we'll see that in a second as well  Now let me assign products to their appropriate categories. So I'm basically just  creating an entire business  Now the  Main thing is can it take the design index.html and turn it into a full blown website  That's  Kind of that would be the exciting thing to see. So there we go  We now have some actual SEO able stuff. We have some categories. We have some stuff  I've been doing this for like 10 minutes guys and I've already  Got, you know, the bare bones of an entire website  Okay, so that worked good  Ok, now take the design in index.html  Inside your root directory, not inside  What's it called? Econ  site and  Use it to precisely to create a WordPress  Econ website around that design  Yeah, I mean, let's just give it a simple  There we go  Wait  I'm just gonna say ultra think it because I have a theory that  One of the reasons codex is so much better and cloud code is  Degenerated so much is that we're not actually giving it the time to think, right?  Ok, so it seems they want me to think deeply about this. There we go. So now I'll let this run  It's just read  1457 lines of code. I just want to see what it actually says here  Honestly, if it says it's like a manageable task or if it's going to have problems or  Whatever it might be and then literally you would just add some blogs and you'd be pretty much done  This is a beautiful modern e commerce design for rustic or a home and garden  Furniture decor store the design features color scheme  Key sections  Interactive elements 9 to convert this into a WordPress theme with newcomers integration  This will involve creating custom theme converting HTML to WordPress PHP templates marking the products dynamic using yeah, perfect  This is exactly what I wanted to do and yeah  I could literally just go to sleep right now and hopefully wake up with a full  Ecommerce store. Obviously, I'd need to add things like a contact page and you know all that  But I mean, yeah, we'll see how this does  Ok, so it's currently testing it and I just want to kind of show you guys this process. So  This is what we've got you can see it's  I'm just gonna pause actually. I normally I just made a test, but I want to see wow  This is pretty mad guys, it was that that was six minutes  That is that is crazy. That is crazy  That was about 20 minutes in total to make this entire store. I honestly am blown away  I'm blown away. I  Can't believe this is possible. I mean, it still needs a tiny bit of work. Obviously, it's not completely perfect  But I did stop it early  Yeah, with a little bit more prompting guys like this was simple prompting  So imagine this with a complicated prompt where you're  Really, you know going at it to do all the SEO and you know bla bla bla me, you know do a pop-up and  I  Guys, this is this is crazy. Holy shit  So yeah, guys, if you do end up using this  Definitely check out SEO Grove AI if you need the SEO done for if like on a more consistent basis  Or honestly just vibe code it yourselves  Yeah, I'm gonna leave the video there guys. This is an absolute game changer. I'm not gonna lie  Like you can literally just generate an entire  Beautiful looking ecom store in under 20 minutes, which I did not think I did not have that on my bingo card  Thanks for watching guys. If you're watching all the way to the end of the video as usual  You're an absolute legend and I'll see you very very soon with some more content. Holy crap. Peace out",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "O vídeo demonstra como criar rapidamente uma loja de comércio eletrônico usando IA (Claude Code, Codex) e Cloud Code para projetar, configurar WordPress/WooCommerce com Docker, e importar produtos a partir de CSV, tudo visando automatizar o processo de construção do site.",
            "resumo": "Neste vídeo, o autor investiga se é possível montar um site de ecommerce completo apenas com código e IA. Ele utiliza Claude Code para gerar o design da homepage e Codex — com apoio do Cloud Code — para estruturar o ambiente de desenvolvimento em Docker com WordPress e WooCommerce. O fluxo começa ao preparar o projeto, instalar o WordPress CLI e levantar um ambiente de desenvolvimento, depois importar produtos a partir de um CSV disponível no GitHub (converteu de Shopify para o formato do WooCommerce). Ao final, ele demonstra a importação de 20 itens, a visualização da loja e a organização em categorias. O objetivo é mostrar como a automação pode reduzir drasticamente o tempo de setup, chegando à possibilidade de criar um negócio online em minutos, ao mesmo tempo em que aponta algumas limitações e a utilidade de as ferramentas IA nesse processo.",
            "assunto_principal": "Automação de criação de lojas online com inteligência artificial utilizando Codex, Claude Code, Cloud Code, WordPress/WooCommerce e Docker, com importação de CSV.",
            "palavras_chave": [
              "Inteligência Artificial para desenvolvimento",
              "Codex",
              "Claude Code",
              "Código em nuvem",
              "WooCommerce",
              "WordPress",
              "Docker",
              "importação de CSV",
              "Playwright MCP",
              "automação de lojas",
              "comércio eletrônico",
              "design assistido por inteligência artificial",
              "desenvolvimento de sites",
              "integração com GitHub"
            ],
            "resumo_em_topicos": "- Ideia central: explorar a possibilidade de montar uma loja completa com IA.\n- Ferramentas utilizadas: Claude Code, Codex, Cloud Code, WordPress/WooCommerce, Docker e Playwright MCP.\n- Fluxo de trabalho: gerar design com Codex, configurar ambiente com Cloud Code, levantar uma loja WordPress local com WooCommerce via Docker.\n- Dados e importação: utilizar um CSV de produtos (convertido de Shopify para WooCommerce) e importar via CSV/CLI.\n- Resultado: loja com produtos visíveis, categorias criadas e automação reduzindo o tempo de setup.\n- Conclusão: demonstração de que um negócio online pode ser montado em minutos, com ressalvas sobre limitações da IA.",
            "prompt_tokens": 2012,
            "completion_tokens": 4077,
            "model": "gpt-5-nano",
            "cost": 0.0071
          },
          "analysis_time": 204.54344606399536,
          "language": "",
          "view_count": 1897,
          "has_transcript": false
        },
        {
          "id": "rw_CCEFe4ks",
          "title": "Replit concluído: GPT-5-Codex ONE SHOTS aplicativos inteiros",
          "title_pt": "Texto: Replit concluído: GPT-5-Codex ONE SHOTS aplicativos inteiros",
          "url": "https://www.youtube.com/watch?v=rw_CCEFe4ks",
          "published": "2025-09-18T23:54:47.227375",
          "published_relative": "há 2 dias",
          "duration": "10:31",
          "date_published": "2025-09-18T07:26:13-07:00",
          "transcript_available": true,
          "transcript": " Oi pessoal, eu queria falar sobre algo hoje, e eu estou fazendo, eu estou currently running another benchmark, as nós falamos, mas  Eu queria falar sobre como, em minha opinião, like, replete é provavelmente  Done, para ser honesto com você, porque, eu mean, sim, ele sempre tem um espaço e um lugar em as pessoas's hearts e coisas, mas só como o  O que é o ponto nesse, certo, se você pode literalmente dizer para codex  Então, eu just ran esse prompt, como você se sente sobre me fazer em Itaia South, eu só quero uma página de casa  Que parece incrivelmente moderno, um dashboard, as opções de cinco lados, o tool deveria ser um básico AI powered CRM, bla, bla, bla  E eu justi went straight into it, and it just started creating it, and now I'm just sitting and waiting to see what it actually produces  E o que é o diferença, certo, por que você iria usar replete ainda mais quando replete é muito mais expensivo  Tipo, isso pode ser muito chico, mas, tipo, você não tem  Como a usagem infinita para isso, você pode ver que você põe as vezes que você põe as vezes que você põe as vezes que você põe as vezes que você põe as vezes que você põe  Então, você vai terminar de pagar muito mais dinheiro do que você pode pensar, porque  Você  Will have to use this a lot if you're creating an entire sas  Agora, codex, por exemplo, eu estou bem seguro de que eu estou usando meu codex 20 bucks subscription  Income stream surfer é um account pro, eu estou bem seguro  Sim, então eu estou pagando 23 bucks a mês, e eu estou usando codex, e eu não queria  Eu nunca tive um limite de rato, nada, tipo, e eu estou usando isso muito, não é como eu só uso um pouco  Eu estou usando isso para o grove, eu estou usando isso para vídeos, eu já construi tipo três diferentes websites  E eu ainda não fiz nenhum limite de rato, então  Eu estou só pensando, tipo, onde é o replato, onde é o loveable, onde é a bolsa, even sit on this  Tipo, o que eles fazem que é especial, eles podem correr o seu codex para você  O que, você não pode correr npm, run dev, então você tem que pagar  Pai, como você põe a usagem, e francamente, tipo, pras prisas ridículas, quando você fica lá  Tipo, eu lembro que estamos pagando, eu acho, 75 bucks a mês para o loveable, 50, talvez  E sim, é só, tipo, o que eles realmente fazem, onde você pode conectar o superfície, ótimo, você pode conectar o GitHub, uau  Tipo, o que estamos fazendo aqui? Eu não sei, é estranho, eu vou dizer uma coisa, mas  Isso me deu para a geração, tipo bolt.new e tudo, mas as vezes que eu vi isso, eu estava tipo,  Isso não está fazendo nada especial, e agora é o momento em que você pode justificar o seu próprio AI e dizer  Aí você vai, cara, você vai, faça isso para mim e depois, sim, voltar em  Um pouco de horas  Agora, essa é a coisa que realmente me interessou quando eu fiz esse artigo de ontem  No canal, no vídeo, eu vi isso aqui  codex  Durante o testemunho, nós vimos que o gbc5 codex trabalha independentemente por 7 horas  Em um tempo, em grandes tasks complexos  Quando eu vi isso, eu pensei, oh meu Deus, isso é um, isso é um breakthrough, 7 horas  Em um tempo, e eu testei isso, então, não faz 7 horas, obviamente, tipo  Eu não sei o que é o que eles promptaram para ficar por 7 horas, mas, tipo,  Foi funcionando por mais de 1 hora, para mim, no exemplo do site que eu fiz  No vídeo de ontem, vamos só ir no vídeo real rapidinho, e eu só quero dar um pouco de perspectiva  No site que eu fiz  Então, sim, eu acredito que isso é o site correto, não, não  Ok, é essa aqui, então, isso é mais ou menos o melhor site que eu nunca vi  Generado por AI, claro, é melhor que replete, é melhor que lovable, é melhor que  Qualquer outro, é melhor que o code, é literalmente perfeito também  Tipo, se você faz isso com replete, você terá problemas, algo vai errado, etc, etc, mas  Isso é literalmente perfeito code, certo?  Ok, então isso é dizendo que isso já é feito, eu realmente não sei como é  Managé para terminar isso já, mas eu acho que podemos ter um look  Assemble o dashboard com notificação do site, implementado  Client site crud, canvan render, autosign, documental, local, realimitação  O clínico não pode simular respostas localmente, ensinando o roteiro  Com o CLA guidance, não é feito porque o ambiente tem  Restricted Network Access para servir  Para verificar se o vôde estático, por exemplo, esse e abrir esse  Ok, você pode realmente fazer um sass  Então isso é o que é criado por agora, de qualquer forma  Isso parece bastante standard para o video, eu não estou muito feliz com isso, mas  Oh, tem um mode de luz, é louco, muito, muito legal  Então eu acho que esses são, sim, são apenas links, mas eu justiço  Para realmente implementar tudo, o que acontece, sim  Ok, então, de novo, isso diz que isso é feito, eu vou só colocar o m variable  Ok, então eu fiz isso, e depois para o stripe, não é tão complicado,  Gente, honestamente, eu vou fazer um vídeo sobre isso, mas  Não é tão complicado como eu pensava que era  Então eu estou usando mpm install, para as variables de stripe, você literalmente precisa  Pricedie, e você precisa do clínico developer, que é, se você clica  Developers aqui, e aí você vai para o overview  Então você pode pegar todas as suas clíadas que você realmente precisa aqui, então o clínico secreto  É o que eu preciso dessa vez, e aí você só faz o stripe log-in  Usando o clínico, e aí você faz o stripe listen  E aí você tem esse wh-set-key, que é aqui  E aí você só faz tudo  Ok, então tem algum tipo de mpm-issue aqui, então eu vou pegar isso e enviar-se a gpt5  Ok, então o mpm-install worked at that time, oh, nós temos um crash  Oh, já em uso 3000, vamos mudar o port  Ok, então agora está ouvindo o local de 3600, aí vamos  Então isso deve ter alguma funcionalidade agora, o sign-in ainda não deixa eu,  não deixa eu criar um account, mas eu não realmente aski para fazer isso, então é ok  Vamos ter uma olhada, então vamos adicionar um cliente, então isso é bob, bob, e os mms  Ok, então tem um valor valente quando eu tento entrar um número  Ok, então ele me deixa adicionar um time, se eu refreshar isso, vai salvar  Vamos falar do time, ele faz, ok, então temos um database que está funcionando  Open stripe, ok, então vamos ver se ele implementou o stripe  Properamente, primeiro time, então estamos usando, se você não sabe como isso funciona, nós estamos usando  FAKE, não é FAKE, mas testem a informação do credit card  E você pode realmente ver se isso funciona, certo, então vamos ver se o stripe funciona o primeiro  time, o box, e se ele faz, o que é o ponto de usar o replay? Eu não entendo, eu  não gostaria de fazer isso mesmo, ok, então podemos ver se isso realmente funcionou  por ir aqui, ou aqui, desculpe, oh, ok, então o charge succeeded, payment method  aberto, invoice pagado, sim, então funcionou, nós temos toda a informação do stripe que precisamos  Então isso agora vai estar no database, e a coisa legal é que ele fez um database  usando SQL Lite, e ele automaticamente deu persistência, porque se você usar SQL Lite,  você vai querer persistência, certo, então adtask, cliente não está vindo, porque eu não posso adicionar  cliente, ok, então nós agora, é uma very quick edit, podemos agora adicionar um cliente  para ver se está salvando, é, então agora nós deveríamos adicionar um task  para Bob, fazer SEO para Bob, do dia 18, lá vamos, e agora vamos refletir isso de novo,  lá vamos, interessante, então isso all works, eu acho que isso é muito impressionante, você agora  tem os blocos de construção para fazer um todo sas, certo, agora eu personalmente não vou usar  isso como sas, obviamente eu não vou fazer um AI-powered CRM como sas, mas o que eu vou fazer  é que eu vou fazer um CRM AI-powered para manejar nossa agência, certo, então vamos ver,  tem um signo de auto, não faz nada, não, mas sim, nós podemos muito, muito, muito,  facilmente, adicionar novos features para isso, minha ideia por trás disso é basicamente,  precisamos poder correr nossa agência usando AI, certo, é o plano aqui,  oh, o que é isso, então isso é para Bob, fazer SEO para Bob,  Hamish faz, o plano generado, ok, não funciona,  OpenRooterGPT, ah, ok, é um modelo incorrecto, nome, isso é bem,  então porque eu estou meio que sendo, você sabe, descendo, encode-se agora, eu sei que  eu posso procurar um modelo aqui, eu posso ver, e isso precisa ser open AI, eu acredito,  é o problema, então vamos salvar isso, e agora vamos generar de novo, ok, eu provavelmente preciso  refletir, então o plano draft para Bob, do SEO para Bob, Hamish tem que fazer,  plano generado, um, pronto,  oh, é GVT5, não sei se é OpenRooter ou OpenAI, eu tenho que mudar isso de novo,  do SEO para Bob, Hamish faz, ok, então eu quero só dar um pouco de contexto antes  eu terminei esse vídeo, isso pode ser um tareco bastante básico, mas, eu quero dizer,  as pessoas criaram coisas como contexto, engenharia, replete,  e bolt.new, e lovable, e todas essas coisas para criar algo que agora pode ser feito  pode literalmente ser feito por codex, em 30 minutos, isso é o primeiro que eu  fiz uma das coisas, agora, isso foi realmente um ponto, um dos meus  benchmarks, um dos benchmarks que eu fiz foi  como, como, como rápido você pode criar um todo sass,  certo, e agora, pode fazer isso em 30 minutos, pessoal, honestamente, isso é,  isso é absurdo, isso é absolutamente absurdo, então, para mim, eu não vou  fazer lojas de sass, vou fazer um pouco de tools internacionais para que podemos  otimizar um pouco de processos, talvez fazer um pouco mais de sass, eu não sei,  mas se você quiser construir um sass, usa codex, agora, é insanely poderoso,  eu vou deixar o vídeo aí, pessoal, muito obrigado por assistir, se você está assistindo até o  fim do vídeo, você é um legendário absurdo, e eu vejo você muito, muito, com mais contenta, peace out.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "O vídeo discute se o Replit continua relevante em relação ao Codex para criar aplicativos movidos por IA, analisa custos, testes práticos e o potencial de construir um CRM/SaaS com integração com Stripe e persistência de dados.",
            "resumo": "Neste vídeo, o autor compara Replit e Codex, questionando qual deles vale mais a pena para criar aplicações inteiramente guiadas por IA. Ele executa prompts que geram um painel moderno e um CRM básico movido por IA, observa a velocidade de geração e reflete sobre custos recorrentes, destacando que, apesar do preço elevado, o uso intenso pode justificar o investimento. O texto também aborda integrações práticas, como Stripe, configuração de chaves de API e testes com pagamentos simulados, além de mostrar que o Codex consegue criar um banco de dados SQLite com persistência. O autor planeja usar essa abordagem para um CRM com IA para sua agência, explorando recursos como autenticação, CRUD de clientes, tarefas e SEO, visando um MVP de SaaS.",
            "assunto_principal": "Comparação entre Replit e Codex para construir apps de IA, com foco em CRM/SaaS, custos, integrações e validação prática.",
            "palavras_chave": [
              "Replit",
              "Codex",
              "Inteligência Artificial",
              "Gestão de Relacionamento com o Cliente",
              "Software como Serviço",
              "Stripe",
              "SQLite",
              "Interface de Programação de Aplicações",
              "custo",
              "painel",
              "Produto Mínimo Viável",
              "desenvolvimento de software",
              "automação"
            ],
            "resumo_em_topicos": "- Contexto e objetivo: refletir sobre a relevância de Replit versus Codex para apps movidos a IA\n- Geração de artefatos: prompts que criam painéis e CRM básico com IA\n- Custos e uso: comparação de planos, assinaturas e justificativas de investimento\n- Testes práticos: integração com Stripe, configuração de chaves, pagamentos simulados\n- Persistência e dados: uso de SQLite com persistência automática\n- MVP/SaaS para agência: visão de transformar as capacidades em um CRM com IA com aprimoramentos futuros\n- Observações finais: avaliação de limitações e potencial de escalabilidade",
            "prompt_tokens": 2158,
            "completion_tokens": 2592,
            "model": "gpt-5-nano",
            "cost": 0.005
          },
          "analysis_time": 212.87713193893433,
          "language": "",
          "view_count": 5702,
          "has_transcript": false
        },
        {
          "id": "6_CO0ilERA4",
          "title": "Codex vs Claude Code… Quem REALMENTE vence?",
          "title_pt": "Texto: Codex versus Claude Code… Quem REALMENTE vence?",
          "url": "https://www.youtube.com/watch?v=6_CO0ilERA4",
          "published": "2025-09-17T23:54:47.227393",
          "published_relative": "há 3 dias",
          "duration": "06:18",
          "date_published": "2025-09-17T12:59:47-07:00",
          "transcript_available": true,
          "transcript": " Oi pessoal, bem-vindo a este vídeo onde eu vou falar sobre codex vs clodcode  e por que não é realmente tão claro que o que é melhor.  Eu quero começar isso por dizer que, em minha opinião, codex é melhor em codos,  mas clodcode é melhor em seguintes workflows,  trabalhando com coisas externas como mcps, commands shell, etc.  Agora eu quero mostrar alguns exemplos.  Este é um exemplo de uma direcção de WordPress.  Este é por codex.  Agora, isto realmente parece melhor do que o que clodcode pode produz, por exemplo,  mas não é seguido com as instruções que eu fiz.  Deve ter facilmente sido capaz de fazer uma requerção de curl em Gina para encontrar terapistas em California.  Se eu ran o mesmo prompto por clodcode,  o clodcode poderia produzir um entire website.  O clodcodex, por exemplo, parece que tem um pouco de coisas diferentes.  Agora, este é ainda, eu diria, um teste interessante,  mas não é tão bom como clodcode fazendo custom workflows,  seguindo custom workflows, etc.  Então, se você quer facilmente repetidas workflows de clodcode,  eu acho que clodcode pode realmente ser melhor.  Se você quer interromper com externa mcps ou mcps geralmente,  se você precisa de commands shell etc, etc.  De novo, eu vou sugerir que você use clodcode.  Mas, se você quer poder de clodcode,  então definitivamente tenha uma olhada no codex.  Agora, este é um exemplo que o clodcode fez para mim.  E ele basicamente fez algo que o clodcode tinha pergunto com,  por horas e horas, não sei, semanas e semanas e semanas,  e instante fixou-se, e instante colocou-se em este realmente bom-looking UI UX.  Agora, isto é algo que eu posso construir, certo?  Isto é o que, quote-lhe, que é algo que eu estou trabalhando para um cliente,  vai provavelmente look like, no futuro.  Porque, para ser honesto com você, o codex fez um melhor trabalho.  E eu quero ver, este é o GPT-5 codex.  Ele fez um melhor trabalho no qual esta plataforma deve realmente look like.  Os animações são smooth e perfeitos.  Todas as cores são brilhas.  Ela só parece muito, muito legal.  Mas, mais importante, o todo o backend realmente funciona.  Ela tem um monte de testes.  Ela é criada com um sugero.  Ela tem todas essas coisas muito, muito interessantes que eu precisava para este projeto.  E aí, ela me construiu um UI UX, que eu poderia estar atrás.  Eu, honestamente, acho que este parece como uma aplicação de milhão de dólares.  Eu sei que é apenas uma pequena parte dele.  Mas você não estaria surpreso se você pagou muito dinheiro para uma aplicação  e este é o que realmente parece, certo?  O que é algo que você faz com o Codex,  não vai ficar muito bom.  Esta foi realmente algo que eu estudei com o Codex por muito, muito tempo.  Foi muito engraçado.  Não funcionava, não importa o que eu fiz com o Codex.  Eu took ele para o Codex e o Codex basicamente se assustou.  Mas depois, no lado do flip-flop,  eu faço algo que mesmo o Sonic 4 se assustou dentro do Codex,  que é um funcionário custom usando o Cloud.md.  E eu faço a mesma coisa com o Codex,  e não é completamente trash, certo?  Então, não é bem como o black e o white,  como as pessoas podem pensar,  como um é melhor do que o outro, certo?  Não é claro, não é obvio.  Depende do que você quer fazer.  Eu vou dizer agora, uiux,  você vai querer usar o Codex.  Confia em mim, só use o Codex.  Não use o Cloud Codex para uiux.  Para o Backend Code,  de novo, eu vou usar o Codex.  As coisas que eu vou usar o Cloud Codex,  e eu vou continuar puxando isso,  provavelmente até o Anthropic,  que lançará um novo modelo,  que eu acho que vai ser muito, muito rápido.  Normalmente, eles fazem isso no Fridays,  para ficar com você.  Eu vou ver se há any news, na verdade.  Não, então, o Cloud é agora disponível no Codex,  que é bem legal,  mas eu vou猜ar 48 horas,  eu já falei isso,  mas...  Sim, eu猜o, eu não sei.  Eu acho que isso vai ser dentro de um mês.  Nós não estamos exatamente seguro  quando o próximo modelo vem,  mas eu estaria muito surpreso  para não ver algum tipo de game-changing update  do Anthropic na próxima semana,  porque se eles não,  as pessoas vão começar a ir para o Codex,  para ser honesto com vocês.  Agora, mais uma coisa é o preço,  certo?  Eu pico 20 dólares a mês para o chat GBT,  e eu nunca vou cair em limites.  Eu não estou fazendo bagues de coding no momento,  mas eu estou fazendo um aumento decente,  para ser honesto com vocês.  Mas o Cloud Codex,  200 dólares a mês,  você vai correr bem rápido.  Então,  há obviamente o preço para considerar também.  Se você precisar correr Shell commands,  honestamente,  você vai precisar de Codex.  Então, minha sugestão...  minha sugestão para as pessoas é ter  o planos de Codex de 20 dólares,  e o planos de chat GBT de 20 dólares,  em vez de um de os planos de 200 dólares.  Eu acho que isso é a melhor coisa para fazer,  e então você faça o coding,  porque a parte do coding é  database updates,  mcps,  Stripe,  APIs,  Shell commands,  e tudo isso,  você pode usar o Cloud Codex,  mas para  tipo UI, UX,  Coding, tipo tudo.  E, basicamente,  tendo projetos completos  que são os workflows pre-designados,  então, definitivamente, você usa Codex.  Então, esse é outro exemplo,  eu fiz isso no último vídeo que eu justi,  mas essa é a melhor versão  deste site que eu vi, por fora.  Isso foi completamente feito por Codex.  Codex, absolutamente,  eu fiz isso,  eu ainda estou abrindo  como bom isso está agora escorrendo  por fora.  Então, sim, isso realmente depende  do que você está fazendo, ok?  Eu espero que este vídeo  ajude alguém ali,  eu espero que você tenha gostado do vídeo.  Se você está assistindo até o fim do vídeo,  você é uma legenda absurda,  e eu vejo você muito, muito rápido,  com algum mais conteúdo.  Até mais.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "Este vídeo compara Codex e Claude Code, defendendo que não há um melhor absoluto: cada ferramenta brilha em contextos diferentes.",
            "resumo": "Este vídeo compara Codex e Claude Code, defendendo que não existe um 'melhor' absoluto: cada ferramenta brilha em contextos diferentes. O apresentador afirma que Codex costuma ter melhor desempenho em UI/UX e no desenvolvimento de backend, enquanto Claude Code é superior para fluxos de trabalho repetitivos e para trabalhar com elementos externos como MCPs e comandos de shell. São apresentados exemplos: um site WordPress criado pelo Codex que parece ter desempenho superior a curto prazo, e a capacidade do Claude Code de gerar fluxos de trabalho completos e personalizados. O vídeo também mostra que o Codex pode enfrentar dificuldades e que, em certos testes, Claude Code surpreende. A conclusão sugere combinar planos de preço acessíveis (Codex + ChatGPT) e usar o Cloud Codex para tarefas externas, esperando atualizações da Anthropic.",
            "assunto_principal": "Comparação entre Codex e Claude Code: vantagens, limitações e impactos de custo para diferentes tarefas de desenvolvimento",
            "palavras_chave": [
              "Codex",
              "Claude Code",
              "Interface do Usuário / Experiência do Usuário",
              "back-end",
              "fluxos de trabalho externos",
              "comandos de shell",
              "MCPs",
              "WordPress",
              "preços",
              "Anthropic",
              "Cloud Codex",
              "desenvolvimento de software"
            ],
            "resumo_em_topicos": "- Contexto: comparação entre Codex e Claude Code, sem um vencedor único.\n- Pontos-chave: o Codex tende a ter bom desempenho em UI/UX e back-end; o Claude Code é forte em fluxos de trabalho repetitivos e integração com itens externos.\n- Exemplos: WordPress gerado pelo Codex; Claude Code capaz de criar fluxos completos com fluxos de trabalho personalizados.\n- Observações: o Codex pode falhar em instruções complexas; o Claude Code mostra vantagens em cenários de automação.\n- Recomendação de uso: manter planos acessíveis (Codex ~20 USD, ChatGPT ~20 USD); usar Cloud Codex para tarefas externas; programação e UI/UX com Codex.\n- Perspectivas: expectativas de novidades da Anthropic; possível mudança de mercado conforme atualizações.\n- Conclusão: a escolha depende do objetivo; Codex para programação/UI/UX, Cloud Codex para fluxos de trabalho externos.",
            "prompt_tokens": 1682,
            "completion_tokens": 4350,
            "model": "gpt-5-nano",
            "cost": 0.0074
          },
          "analysis_time": 158.80234503746033,
          "language": "",
          "view_count": 5813,
          "has_transcript": false
        },
        {
          "id": "vKcTIf9hJr0",
          "title": "RIP CLAUDE CODE: Novo modelo GPT-5-Codex acaba de ser lançado",
          "title_pt": "Texto: Descanse em paz, Claude Code: Novo modelo GPT-5-Codex acaba de ser lançado",
          "url": "https://www.youtube.com/watch?v=vKcTIf9hJr0",
          "published": "2025-09-17T23:54:47.227407",
          "published_relative": "há 3 dias",
          "duration": "12:52",
          "date_published": "2025-09-17T05:51:26-07:00",
          "transcript_available": true,
          "transcript": " Em hoje's video, I'm going to be talking about the new version of Codex and we're going to give it a little whirl.  Now, introducing upgrades to Codex, this was two days ago, right?  So I actually haven't tested this yet, I literally just upgraded my Codex right now.  So I now have the new version of Codex right here, you can see it now says introducing GBT5 Codex.  So I'm going to say try GBT5 Codex now, and now we're inside the new GBT5 Codex.  So let's have a little look at what this actually is.  So Codex just got faster, which is amazing, more reliable, and better real-time collaboration and tackling tasks independently anyway you develop,  whether via the terminal, IDE, web, or even your phone.  GBT5 Codex, even your phone.  Interesting.  GBT5 Codex is a version of GBT5 further optimized for agentic software coding in Codex, it's trained on.  So it's actually a new model.  I haven't actually seen anything about this.  Oh, dam, I actually, this is actually a new model.  Jesus, I didn't realize.  Ok, so this is very, very interesting.  It's a version of GBT5 further optimized for agentic software development in Codex.  So it's specific for software developing in Codex.  That is interesting.  It's trained on complex real-world engineering tasks such as building full projects from scratch,  adding features and tests, debugging performing large-scale refactors,  and conducting code reviews.  It's more steerable, it is better to add Insta-MD instructions  and produces higher quality code.  Just tell it what you need without writing long instructions  or code on style or code cleanliness.  Ok, so this is actually a new model,  which I didn't realize when I even started recording this video.  I didn't realize that it was actually a new model.  So this model is trained specifically on Codex.  Guys, this is actually pretty massive.  You can see here that it's performing better on some pretty basic tasks,  better than GBT5,  because it's specifically designed for Codex.  So GBT5 Codex adapts how much time it spends thinking,  more dynamically based on the complexity of the task.  So let's see, does it still have the thing?  It doesn't.  So you can no longer, oh yeah, you can.  So you can say medium, high.  I'm just going to leave it on medium.  Pairing developers in interactive sessions  and persistent independent execution and longer tasks.  That means Codex will feel snappier on small, well-defined requests  or while you are chatting with it  and will work for longer on complex tasks like big refactors.  During testing we've seen GBT5 Codex work independently.  More than seven hours at a time on large complex tasks  iterating on its implementation, fixing test failures  and ultimately delivering a successful implementation.  Wow.  E then let's just read these other updates.  So other updates to Codex.  Codex CLI is an open source  and community feedback over the last few months  has been invaluable in shaping its evolution.  With this feedback we've rebuilt Codex CLI  around agentic coding workflows  to harness our models into more capable and reliable partners.  You can now attach and share images, screenshots,  wireframes and diagrams right in the CLI.  Yeah, the problem is MCPs, question mark.  Have you improved MCPs?  So this has been upgraded.  Tooled this.  I'm not actually using the CLI,  so I'm not that interested in this.  Let's have a look at what they've done here.  Codex meets you where you already work,  including in your IDE.  The IDE extension brings the Codex agent into VS Code.  Are there any updates though?  It doesn't look like there's any updates.  You can now, no, you can create new cloud tasks,  tracking progress, work and review completes a task  without leaving your editor to finish in touch  so you can open cloud tasks in your IDE.  And Codex maintains context,  yet, still nothing new there.  Codex also now includes code review abilities  trained to catch critical flaws.  Interesting.  Okay, that's actually pretty good.  So it looks like you can actually just get it to sit  on your GitHub,  which is pretty cool for pull requests.  That's pretty cool.  Okay, so I'm just going to run this through the standard  test that I have.  I know people are kind of sick of me building websites.  You're just going to have to bear with me  until I come up with a new test, guys.  I haven't come up with one yet.  You have nothing to work from just scuffle  the entire app and show me.  So, I'm just going to see how this new  GPT Vi Codex actually performs  with quite a difficult task.  The main thing I'm looking for here is speed  because I must say Codex,  while being extremely accurate,  was fairly slow, to be honest with you.  Okay, so I gave this a particularly  difficult version of this task.  Okay, so I'm not actually just assessing  the website build itself.  I'm also assessing its ability to,  you know, come up with fixes.  So, one issue was that I'm actually inside  Grove's directory,  which is extremely complicated as a directory.  And it did manage to understand  that there is no mynextapp  file or folder,  despite the fact that right here it says  it's inside mynextapp in the prompt.  So, it's managed to work out  that I'm an idiot and it's managed  to understand that it doesn't have  to actually follow the instructions  word for word.  Okay, so this is currently scaffolding  in time of mynextapp.  So, one of the problems I actually see  with Codex, at least in the IDE,  not in the terminal,  is that it's not very good at  actually running shell commands  and things like that.  But what is quite interesting is that it's  managing to scaffold  or if it manages to scaffold  an entire next.js app  just from its knowledge of what a next.js app  should look like.  And another thing I want to mention, guys,  that I probably don't talk about enough  is that I'm only paying 20 bucks a month  for this.  So, I've basically got something that I now  consider to be better than Claude  Code, in my opinion.  Although I'm sure the limits will change in the future.  I've never hit a limit  not as much as I would say  like Claude Code, Max Plan  Opus on first release,  let's say.  I'm using it a lot  and I've never run into any right limit.  I've never run into any limiting issues whatsoever.  Guys,  if you're trying to build an app right now  and you've been having problems with Claude Code  honestly jump on this because  this is crazy.  I've barely paused, right?  It's probably been running for about  2 minutos so far,  and it's already done an absolute crap turn.  It's done more than Claude Code would have  done when I gave Claude Code  the original file.  Right? When I ran next  to create app, whatever  using Claude Code  it wouldn't have even done anywhere  near as much of this in kind of 3 minutes.  So, they've definitely increased the speed here.  Okay, I just got a retry here.  Stream error, stream disconnected before completion.  An error occurred while processing.  Okay, good. It fixed itself.  Thank God for that.  One of the things I have to say  that I'm getting kind of annoyed with  is how all of these apps are trying to take up  real estate on my Visual Studio Code.  Like I have Kilo Code, I have Klein.  I don't like what they're doing  honestly, like Kilo Code now  is down here taking up as much real estate  as possible. Augment Code  I just haven't even downloaded on my Mac  because it was pissing me off  so much opening itself every time I opened  Visual Studio Code.  I don't know what it is, it's like  they're trying to compete to be the most annoying  possible. Like, if I go to new window  here, you'll see  they're trying to argue here as well  they're trying to grab real estate space  it's kind of funny, you can kind of see it  but I don't know, it's annoying  for me personally, I don't like that.  Okay, holy  shit. So, normally  the data.ts file for reference  is about  guidelines.  Holy mother of God. Guys, I'm telling you  right now, if you have to build something  build it right now  because this  version of Codex  is probably not going to be around forever  Codex 5. I mean, I hope it is.  Damn  that is impressive, I'm not going to lie.  That is a very, very, very large amount.  That is crazy  actually.  Guys, I'm not going to lie.  OpenAI  might be cooking.  OpenAI  is officially back in business.  This is crazy.  The level of detail here  I haven't seen this level of detail  probably ever.  Let's create, look how long each of these are.  Wow.  So yeah, I think it's pretty much done.  I mean, it's taken longer  than I was expecting, but to be honest  with you, the level of detail here  does actually merit  the amount of time that it's actually taken.  I don't know, I think this is going to be  super interesting, at the very least.  You can see now it's just  it's making custom SVGs for  everything, right?  So if I go on public  there's public.  This should be an SVG.  Look at that. I mean, it's not perfect.  But damn, still, I think  that's pretty nice.  So it's just making all of  these custom SVGs.  That's a bit messed up.  That's good.  That is a good one.  Not really.  I like that it's writing stuff, though.  I mean, you can kind of get it.  It's almost there.  SVGs are really, really hard for AI,  I'm not sure why.  I think because they're so, like, one tiny  little change can make all the difference, I guess.  Okay, this is also  a new feature, guys, and it did mention  this in the blog post.  Completing manual verification.  Preparing final response.  Before it does that, you can see here  what it's done.  I'll confirm the line numbers using commands, etc.  So it's actually just checking everything.  So you can see it's just checking  over its entire work, which is  really, really  interesting.  I think this might be the new meta, guys.  I'm pretty sure this is going to be the best  one of these that we've ever seen.  Okay, so it's done. One thing it didn't do  is it didn't actually run anything.  It didn't try and see if it actually worked.  So let's just see what happens when we do  MPM install.  So what is it? CDD my next app?  MPM install.  Let's see if this works.  This would be crazy if there were no  mistakes.  I doubt that there will be no mistakes.  It's almost guaranteed that there will be  some kind of mistake here.  So let's just make sure we're doing  MPM  run lint.  I don't know.  Straight, I guess.  Wow, okay.  Then MPM run dev.  There's no way.  It's not going to work, surely.  Surely there's going to be.  There wasn't a single mistake.  Is that because of MPM run lint? I don't  actually know what that does. Oh my god,  this looks good, by the way.  View experience.  Oh, man,  without a doubt, this is the best one I've ever seen.  Wow.  Wow, wow, wow.  I don't even know what to say.  I'm blown away by this guy, honestly.  This looks incredible.  Obviously the SVGs are fucked,  but I think what I might do  is I might make a little SVG generator.  I mean, it's terrible,  they don't look good.  The only problem is the SVGs, though.  Beyond that, this is  OpenAI have cooked.  They're not cooking, OpenAI cooked.  Chef's kiss. Holy crap.  This is good.  I'm telling you guys, I've done a million of these tests.  None of them look this good.  None of them had zero errors,  right?  And none of them are, honestly,  absolutely insane.  I'm going to leave the video there, guys.  Thank you so much for watching.  If you're watching all the way to the end of the video.  As usual, you're an absolute legend.  And I'll see you very, very soon  with some more content.  Peace out.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "Análise do lançamento do GPT-5 Codex (versão otimizada para codificação orientada por agentes) e seu impacto no fluxo de trabalho de desenvolvimento.",
            "resumo": "Neste vídeo, o apresentador testa a nova versão do Codex chamada GPT-5 Codex, destacando que ela é mais rápida, mais confiável e oferece melhor colaboração em tempo real para codificação de software. Trata-se de uma versão do GPT-5 otimizada para trabalhos orientados por agentes dentro do Codex, treinada em tarefas reais como criar projetos do zero, adicionar recursos e testes, depurar, refatorar grandes bases de código e revisar código. O modelo é mais ajustável e produz código de qualidade superior, aceitando instruções simples sem exigir longas diretrizes de estilo. Também são apresentadas melhorias no Codex CLI e na extensão para IDE (VS Code), com suporte a tarefas em nuvem, anexos como imagens e revisões de código integradas. O autor compara com Claude Code, comenta o custo de US$20/mês e elogia a velocidade, apesar de interrupções ocasionais no streaming.",
            "assunto_principal": "Lançamento do GPT-5 Codex (GPT-5 Codex) com foco em codificação orientada por agentes e melhorias de desempenho, CLI/IDE e fluxo de trabalho de desenvolvimento.",
            "palavras_chave": [
              "GPT-5 Codex",
              "Codex",
              "programação orientada por agentes",
              "desenvolvimento de software",
              "Next.js",
              "Codex CLI",
              "extensão para VS Code",
              "revisão de código",
              "execução na nuvem",
              "GitHub/PRs",
              "desempenho",
              "Claude Code",
              "custo mensal"
            ],
            "resumo_em_topicos": "### Pontos-chave\n- Lançamento do GPT-5 Codex (GPT-5 Codex) otimizado para codificação orientada por agentes.\n- Benefícios: mais rápido, mais estável, melhor colaboração em tempo real e execução independente para tarefas grandes.\n- Foco de treinamento: tarefas de engenharia de software, criação de projetos, adição de recursos, testes, depuração, grandes refatorações e revisão de código.\n- Funcionalidades: Codex CLI atualizado, possibilidade de anexar imagens, tarefas em nuvem, integração com IDE e revisões de código.\n- Desempenho: supera tarefas básicas do GPT-5, pode trabalhar horas em tarefas complexas; melhoria de velocidade.\n- Considerações: comparação com Claude Code, custo de US$20/mês, observações sobre uso de VS Code e experiência do usuário; algumas falhas de streaming.\n- Observação final: lançamento promissor, aguardar mais testes.",
            "prompt_tokens": 2041,
            "completion_tokens": 3494,
            "model": "gpt-5-nano",
            "cost": 0.0063
          },
          "analysis_time": 205.40355920791626,
          "language": "",
          "view_count": 2521,
          "has_transcript": false
        },
        {
          "id": "iCnRbfWqDN8",
          "title": "Pare de usar essas ferramentas de IA (faça ISTO em vez disso)",
          "title_pt": "Pare de usar essas ferramentas de IA (faça ISTO em vez disso)",
          "url": "https://www.youtube.com/watch?v=iCnRbfWqDN8",
          "published": "2025-09-16T23:54:47.227422",
          "published_relative": "há 4 dias",
          "duration": "09:52",
          "date_published": "2025-09-16T07:00:45-07:00",
          "transcript_available": true,
          "transcript": " Bem-vindo a este vídeo em que vou falar sobre o que eu uso e o que eu uso e o que eu não uso.  Eu uso o clodcode bastante regularmente, mas eu estou usando um pouco diferente.  Eu estou usando mais para mcps, mais para cli commands, mais para doca, e mais para as coisas como o período de descobrimento.  Então, se eu tenho que, por exemplo, conectar com um API 3º, eu vou dar clodcode na documentação do API 3º.  E eu vou dizer para experimentar, eu vou dizer para fazer clodquestes e entender como tudo funciona, e depois fazer um script básico.  Mas aí, se eu quiser fazer um projeto inteiro, eu definitivamente vou usar o codex agora.  O codex é superior ao clodcode hoje.  Não vai ser na próxima semana ou em duas semanas ou qualquer coisa, mas agora o codex é melhor do que o clodcode, para o coding.  Mas eu diria que o clodcode é melhor para fazer clodquestes, fazer cli commands, mcps, etc.  Então, é mais como um assistente de codex, mas o codex para mim é o codex.  Agora, eu tenho uma ideia de que muitas pessoas usam o clodcode sem o mode de pensamento, porque você tem que, especificamente, usar o mode de pensamento,  ou pensar sobre isso, ou ultra pensar.  Você sabe, tem o todo o meme sobre ultra pensar.  E se você olhar para o codex, o codex exclusivamente usa o mode de pensamento.  Então, o que eu já encontrei para aumentar a qualidade da qualidade do clodcode é fazer claro para dizer para pensar sobre coisas.  Porque muitas pessoas apenas assumem que o clodcode está pronto para ir na caixa, mas não.  Você realmente precisa fazer alguma coisa.  Então, se você tem problemas com o clodcode, apenas tenta pensar sobre coisas, ultra pensar, etc.  E eu prometi que você vai encontrar uma solução para seu problema se você diga para ultra pensar.  O que é por que, na minha opinião, uma das razões que o codex é melhor é porque usa o gpt5 pensar  e você pode colocar ele no mode de pensamento alto.  Então, o mode de pensamento é 100% que eu utilizo.  Em mcps, eu não utilizo muito em mcps como as pessoas podem pensar.  O único que eu utilizo é o SuperBase, o que eu poderia aplicar com o CLI a qualquer momento.  Na próxima vez que eu faça um projeto, eu vou postar o SuperBase localmente.  Quando eu faça o projeto, eu vou ter o CLI set-up e ele vai fazer tudo usando o CLI.  Então, eu provavelmente não vou usar isso mais mais.  Mas agora, por causa do que o meu projeto está set-up, eu utilizo o SuperBase mcp.  Eu também utilizo o Playwright mcp muito, porque é bom em mostrar os logs de browser e o code  para dar contexto para o clodcode ou codex.  Eu utilizo o UpTash mcp, porque eu utilizo o Redis.  E provavelmente a única mcp que eu recomendo muito é o DigitalOcean, ou algo assim.  Porque se você está procurando para puxar projetos para websites actuales,  o DigitalOcean mcp vai fazer isso para você imediatamente.  O que eu fiz aqui é o BrightData.  Eu também utilizo o BrightData mcp para dar informação de websites específicos.  Há certas websites que o clodcode ou evenGina não podem escrapar,  mas BrightData pode escrapar websites que você não pode escrapar,  por exemplo, o Facebook, LinkedIn, etc.  Então, se eu fazer algo muito específico e eu preciso ser capaz de escrapar websites,  BrightData pode ajudar você com isso.  O BrightData é realmente um responsório desse vídeo.  Se você quiser ver o BrightData, tem um link na descrição e o comentário.  E então vamos para os commands CLI.  O que eu utilizo com CLI é basicamente o clodcode para escrapar seus próprios commands terminais.  Então, se eu quero escrapar um instante docker,  eu posso dizer para ele, escrapar um instante docker para o WordPress,  ele vai criar os fios e depois ele vai escrapar o compós docker.  E então, se eu preciso escrapar um script dentro do container docker,  o clodcode pode também fazer isso muito bem.  Agora, para isso, como eu disse no início,  eu estaria quase exclusivamente, exclusivamente, usando o clodcode para isso,  porque o codex não é tão bom em escrapar commands docker e fazer coisas externas.  É muito bom em encodimento, mas não é muito bom em encodimento,  tipo, tipo, tipo, pôr requerções e coisas assim.  Então, definitivamente, o docker é uma grande mudança de game,  e se você entende por que você está usando isso,  é massivo, porque você pode, é tipo, é como se o seu projeto em seu próprio container.  Então, você pode muito facilmente ser controlado e você pode correr certas coisas,  e você pode, é muito, muito útil.  Obviamente, o GitHub também, você precisa usar o GitHub CLI.  Agora, o resto de eles na lista, em minha opinião,  são desgracias e eles não realmente ajudam em qualquer forma ou forma.  Ok?  Consex Engineering, talvez, certo,  se isso pode ser melhor para, para adicionar um específico  efeito para o seu AI.  Consex Engineering pode ser ok,  mas eu posso garantir que apenas o codex que é seu,  é muito bom, se não melhor, que o de Consex Engineering.  Consex Engineering.  Consex Engineering.  Consex Engineering.  Consex Engineering.  Consex, para mim, foi coitado bastante rápido,  e eu acho que o Consex might, em verdade, ir para algo,  e eu acho que eles estão fazendo algo bom.  Eu não gosto de DeepSeq,  eu não gosto de qualquer coisa, mas o Consex parece bem bom.  Na verdade, mais um é o GLM, o que é?  GLM-Z 4.5 ou algo,  ou qualquer coisa que é chamado,  também parece muito interessante para meus testes.  Mas, para ser honesto com você,  eu só, exclusivamente, hoje,  estaria usando o codex e o codex.  Eu não estaria usando qualquer outra devs de AI, etc.  Cloudflow, de novo,  wasting the time, em minha opinião,  é só criar um absoluto crapo.  Tipo, parece bem bom.  Não me diga errado.  E eu acho que,  talvez, se os modelos sejam super inteligentes no futuro,  Cloudflow será incrível.  Mas, sim, por agora,  pelo menos, eu não estou usando Cloudflow,  nada mais.  Eu não acho que é muito bom.  Em hoje's state,  é só criar bloats,  e craps.  E, sim, parece bem bom,  e, em vez da mesma vez,  Cloud Agents,  eu não realmente encontrei uma razão  grande para olhar para essas  em grande detalhe,  também craps.  Eu acho que,  provavelmente, os Agents são usados.  Eu não estou usando eles hoje.  Agora, eu provavelmente vou ter  algum flac para isso,  e as pessoas vão dizer que  são 100% necessárias e etc.  Mas, para mim,  eu só encontrei que  o running Cloudcode normalmente  só funciona,  com alguma configuração  para aprontar  em sua memória e coisas assim.  Eu só encontrei que isso  é o que funciona para mim.  Justo uma pequena sinalidade aqui, pessoal.  Eu só google AI Dev  para ver se eu não estou perdendo nada.  Você acha que é incêndio  que Google,  efetivamente,  tem feito o ranking número 1  aqui?  Não é  comportamento monopolista?  Se você procura AI Dev,  você irá esperar,  para ser honesto com você,  Cloudcode para estar aqui.  Onde é Cloudcode?  Não, não há um jeito  como isso é,  não há um jeito como isso é  actual, natural, ranking.  Google número 1,  Google número 2.  Não é certo?  Isso não parece muito certo.  Ok, e então, sim,  eu só me lembro de outra coisa.  A única coisa que eu uso,  eu uso chat ept,  todo dia,  para perguntas básicas,  para ajudar,  me ajudar por certas processas.  Se eu não posso fazer algo,  se eu quero pensar  como fazer algo.  Por exemplo,  eu só adoro  o comércio  para SEO Growth,  certo?  Eu não vou falar sobre SEO Growth,  mas eu só adoro  o comércio para SEO Growth.  A forma que eu comecei  todo esse processo,  você pode ver o comércio aqui,  é que eu tinha uma conversa  com chat ept,  e eu disse,  por favor,  pode-me entender  como eu posso pegar o meu SaaS,  que funciona como isso,  eu sou o Shopify  e fazer isso  para um tool WordPress.  E ele me deu  algumas boas notícias,  ele me disse para pegar  uma versão local  do comércio  no local Docker,  que realmente me ajudou,  etc, etc.  Eu uso isso para imagens também,  outra coisa que eu usei,  que eu não falo sobre,  porque devem ser  uma responsa do canal,  mas,  isso nunca acontece  com as responsas,  para ser honesto,  eu nunca realmente  funciono,  se isso faz sentido,  é o Pixels,  o que é chamado.  Eu uso Pixels  para thumbnails também.  Eu uso cloud.ai,  como a frente do cloud,  o chat,  o que eu uso,  o chat GBT  e também algumas coisas,  tipo,  criando chapters  para o meu canal,  para o meu canal do YouTube,  e coisas assim.  Mas,  aparte disso,  eu basicamente não usei  qualquer outra coisa AI,  então,  eu acho que um lote desses  são as distrações  que parecem que  eles fazem coisas mais  mais fáciles para você,  mas, realmente,  fazem coisas mais difíceis  e mais complicadas,  e criam um lote de blocos para você.  A razão que fiz isso,  é porque,  eu fiz vídeos sobre  cada uma dessas coisas  no passado,  e eu só queria que as pessoas  tenham sabido o que eu  realmente uso  e o que eu não.  Obrigado muito por assistir,  se você está assistindo  até o fim do vídeo,  você é uma legenda absoluta  e eu vou ver você muito, muito rápido,  com mais conteúdo.  Peace out.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "Análise comparativa entre CloudCode e Codex para o desenvolvimento de software, destacando em quais cenários cada ferramenta brilha, a importância do modo de pensamento e o uso de MCPS, raspagem de dados e outras integrações para acelerar projetos.",
            "resumo": "Neste vídeo, o autor explica quais ferramentas de IA ele usa ou evita no desenvolvimento de software. Ele afirma usar o CloudCode com maior frequência para MCPS, comandos de CLI, documentação e descoberta de APIs, mas para um projeto completo prefere o Codex, que hoje considera superior para codificação. O narrador destaca que o Codex utiliza o modo de pensamento (think) para produzir melhores resultados, enquanto o CloudCode requer que o usuário pense de forma ativa para melhorar a qualidade. Também cita ferramentas de suporte: SuperBase, Playwright, UpTash (Upstash) com Redis, DigitalOcean para implantações rápidas, BrightData para raspagem de sites que outros serviços não conseguem. Discussões sobre Docker, GitHub CLI, e a avaliação de concorrentes (Consex Engineering, GLM-Z, Cloudflow, Cloud Agents) concluem que, por ora, Codex e CloudCode são as opções mais úteis, com ênfase no uso estratégico do pensamento e na raspagem de APIs.",
            "assunto_principal": "Comparação entre Codex e CloudCode para o desenvolvimento de software, com foco no uso de MCPS, ferramentas de raspagem de dados e suporte, e a importância do modo de pensamento na produção de código.",
            "palavras_chave": [
              "Codex",
              "CloudCode",
              "IA para programação",
              "modo de pensamento",
              "pensar",
              "MCPS",
              "Playwright",
              "SuperBase",
              "Upstash",
              "Redis",
              "DigitalOcean",
              "BrightData",
              "raspagem da web",
              "Docker",
              "CLI do GitHub",
              "crescimento de SEO",
              "ChatGPT"
            ],
            "resumo_em_topicos": "- Introdução e objetivo: discutir quais ferramentas de IA são úteis no desenvolvimento e como usá-las melhor.\n- Principais ferramentas: comparação entre CloudCode e Codex, destacando cenários onde cada um se mostra mais eficiente.\n- Modo de pensamento: Codex utiliza o modo de pensamento de forma mais explícita; CloudCode requer pensamento ativo do usuário para melhorar resultados.\n- MCPS e suporte: uso de SuperBase, Playwright, Upstash/Redis, DigitalOcean e BrightData para raspagem e implantações.\n- Raspagem na web e raspagem específica: BrightData é destacado como capaz de contornar limitações de outros serviços para sites como Facebook e LinkedIn.\n- Docker e CLI: CloudCode é útil para raspagens de comandos Docker e scripts dentro de contêineres; Codex é melhor para codificação externa e codificação de dados.\n- Avaliação de concorrentes: Consex Engineering, GLM-Z, Cloudflow, Cloud Agents são mencionados, com a conclusão de que Codex e CloudCode, até o momento, são as opções mais úteis.\n- Observações finais: menciona uso diário do ChatGPT para perguntas básicas e para apoiar o crescimento de SEO, além de considerações sobre ranking de busca e a utilidade de perguntas rápidas para fluxo de trabalho.",
            "prompt_tokens": 2238,
            "completion_tokens": 3825,
            "model": "gpt-5-nano",
            "cost": 0.0069
          },
          "analysis_time": 269.49550223350525,
          "language": "",
          "view_count": 1676,
          "has_transcript": false
        },
        {
          "id": "pyc2SieEZXc",
          "title": "Por que troquei o Claude Code pelo Codex (A Verdade)",
          "title_pt": "Por que troquei o Claude Code pelo Codex (A Verdade)",
          "url": "https://www.youtube.com/watch?v=pyc2SieEZXc",
          "published": "2025-09-15T23:54:47.227437",
          "published_relative": "há 5 dias",
          "duration": "06:23",
          "date_published": "2025-09-15T12:08:39-07:00",
          "transcript_available": true,
          "transcript": " Oi pessoal, isso vai ser um pouco de vídeo de Ramble, mas eu quero falar sobre algo, porque eu acho que isso é muito importante.  Eu vou falar sobre codecs e clodcodes hoje, mas mais broadly, apenas modelos também, né? LLMs.  Então, eu já percebi que o codecs realmente se tornou melhor do clodcode.  E isso não é apenas, oh meu Deus, isso é incrível, qualquer vídeo.  O codecs se tornou melhor do clodcode.  E vocês sabem que eu sou um fanboy de clodcodes antropicos.  Então, para eu dizer isso, eu entendo, né?  Eu genuinamente usei o codecs mais do que o clodcode agora.  Agora, eu fiz um vídeo antes em que eu ainda usei o clodcode para, tipo, mcps,  Render comandos e coisas, porque eu não acho que o codecs,  Apesar do estúdio individual, o clodcode extension, que é onde eu estou usando,  Não é tão bom em usar seus próprios comandos, não é tão bom em usar o doctor, não é tão rápido.  O clodcode tem essa tipo de mcp conexão.  Então, eu provavelmente ainda vou continuar usando o clodcode.  Mas o codecs é melhor, mas eu não acho que isso permaneça melhor, né?  Porque é uma coisa de model, não é uma coisa de rapor.  Eu anteriormente pensei que o clodcode tinha o melhor rapor.  Não é verdade, eu não acho que o rapor é muito difícil de fazer.  O codecs é quase definitivamente copiado com o clodcode, com muitas das suas mudanças e coisas.  Você pode dizer que, atualmente, o codecs é muito melhor, porque ele usa o GBT5, né?  Agora, eu não acho que o GBT5 é melhor do que o Opus 4.1, né?  Mas, o que está acontecendo aqui, né?  Isso é minha teoria.  A minha teoria é que o Opus está usando uma versão quantizada.  Agora, eu escrevi sobre isso no YouTube do Anthropics,  onde todos os comentários estão falando sobre por que você usa versões quantizadas, né?  O que a versão quantizada é, é uma versão distilde do modelo.  Eu não sou um expert de LLM, por favor, mas isso é como eu entendo.  Basicamente, é tipo 1,10 da força, ou do modelo overall, né?  Mas eles ainda chamam o Opus 4.1.  Agora, o que eu acho que está acontecendo é que, se eles apenas usaram o Opus 4.1 para poder clodcode  sem destilhar-se ou quantizar-se, então eles não estariam fazendo dinheiro, né?  Então eles estariam perdendo dinheiro.  E o que eles têm feito é, se você olhar o Revenue do Anthropics,  ele está como isso, né? Porque do clodcode.  Eu suspeito que ele está começando a ser, tipo, even-out, né?  O que é por que, em minha opinião, hoje, amanhã, nos próximos dias,  eles vão lançar o Opus 4.5 ou o Summit 4.5.  Eu acho que vai ser o Opus e o Summit 4.5, no mesmo tempo, né?  E o que eles vão fazer é, eles vão lançar uma versão quantizada do modelo,  e eles vão lançar dinheiro, porque essas empresas,  a sua valorização é baseada no seu Revenue de Growth,  não sobre o que não é o seu Revenue, né?  É o seu Revenue de Growth.  Então, o que é o Codex fazendo que o clodcode não é?  Provavelmente, eles estão lançando dinheiro para usar uma versão completamente quantizada,  uma versão insumidada de GBT5, um codex de 2x,  porque eles queram usar as muitas vezes como possível,  de Anthropics ou de clodcode, porque, é um throw de corto até o fim do dia, né?  Um OpenAI, é a mesma coisa, né?  Eles provavelmente estão even-out, ou eles foram even-out.  Então, o que eles estão fazendo é, eles estão tentando,  eles vão ter gente para usar o codex.  Porque, se as pessoas começam a usar o codex,  a revenues começam a crescer.  E também, outra coisa, isso poderia ser Revenue  Revenue ou também poder ser usuários, certo?  Você não tem que pensar que isso é Revenue.  Usos e Revenue são basicamente a mesma coisa se você pensar sobre isso.  Então, o que está acontecendo?  Eles estão levando dinheiro para os usuários, porque a evaluação vem do aumento de growth  mês em mês, que eles experiçam em usuários ou Revenue, não em seus profissionais.  Que é só como essas grandes empresas operam.  É como as grandes empresas operam por um longo tempo, certo?  Os profissionais não são o importante, o Revenue é o importante.  Então, o que está acontecendo?  O GPT, em minha opinião, é OpenAI.  Eles estão usando o modelo Full Blast GPT5.  E você pode pegar isso por 20 dólares por mês agora,  que é mais significativo que o 200 ou o 100  necessários para usar o clor de codos.  E você realmente fica com bastante usagem.  Eu não tenho runhado em algum problema de usagem com OpenAI com codex, certo?  Por 20 dólares por mês.  Agora, uma coisa que eu quero mencionar é que, como eu disse antes,  eu estou usando clor de codos ainda para correr todas as comandas, certo?  Todas as CLI, stuff, GitHub, Docker, MCPs, etc., etc.  Então, é isso que eu estou fazendo com isso.  Mas eu suspeito que se você tivesse o clor de codos de 20 dólares  e o codex de 20 dólares,  isso agora é uma combinação melhor do que o clor de codos de 200 dólares, certo?  Então, minha opinião sobre isso mudou.  Mas vai mudar de novo, quando, indoutamente,  eles lançam o Sonic 4.5 ou o Opus 4.5.  E eu estou me dizendo, ele vai estar na próxima 48 horas.  Nós vimos isso antes.  Isso é o combinação.  Isso é o combinação.  Isso é o que está acontecendo.  E aí, de repente, quando eles lançam isso,  eu garantiria que o Google lançasse algo tipo Ultra 3.0.  E eles vão, espero, lançá-los para freio no OpenRouter.  E eu recomendo, pessoal,  que as vezes que um desses modelos deslizam,  construí-los algo.  A próxima 2 semanas depois disso deslizam,  é uma absoluta roda de gold,  porque você vai ter acesso a os melhores modelos  no mundo para um bom preço, certo?  Então, eu não estou dizendo que cansa o clor de codos de subscription necessariamente,  eu vou só se preparar para renovar-los,  quando isso é lançado.  As 2 semanas depois que eles lançam esse modelo,  e também com o Google, as 2 semanas depois que eles lançam esse modelo,  construí-los, construí-los, construí-los.  Eu vou deixar o vídeo aí, pessoal.  Eu realmente quero falar sobre isso,  porque eu acho que isso é muito interessante.  Muito obrigado por assistir.  Se você está assistindo ao final do vídeo,  você é um legendário do Unipod,  e eu vejo vocês muito,  com mais conteúdo.  Peace out.",
          "analysis_source": "asr_faster_whisper",
          "summary": {
            "resumo_uma_frase": "Análise do desempenho de Codex versus Claude Code, discutindo versões quantizadas, estratégias de monetização e previsões de lançamentos (Opus 4.5, Summit 4.5), com recomendações para combinar modelos e manter o custo-benefício.",
            "resumo": "Em tom de divagação, o apresentador compara Claude Code, Codex e o que chama de Clodcode, afirmando que o Codex está, hoje, mais competente em várias áreas, mas ele ainda usa Claude Code para comandos CLI e tarefas com MCPs por questões de velocidade e integração. O vídeo explora a ideia de que o desempenho depende não apenas do modelo, mas de versões e técnicas de quantização. Ele sugere que o Opus 4.1 pode estar sendo usado em uma versão quantizada para monetização, e especula que Anthropics pode lançar Opus 4.5 ou Summit 4.5 simultaneamente, com versões quantizadas para aumentar a receita por meio do uso ou da base de usuários. Compara preços: o GPT-5 da OpenAI por cerca de 20 dólares por mês em relação ao Claude Code por cerca de 200 dólares por mês, defendendo que uma combinação de Codex (20 dólares) + Claude Code (20 dólares) pode superar o custo de uma assinatura maior. Previsões apontam lançamentos em 48 horas e, posteriormente, em duas semanas, com Google Ultra 3.0 e OpenRouter, e recomenda-se preparar-se para renovações rápidas para acessar os melhores modelos com bom custo.",
            "assunto_principal": "Análise de competição entre Claude Code, Codex e estratégias de monetização de modelos de linguagem, com foco em versões quantizadas, preços e lançamentos futuros.",
            "palavras_chave": [
              "Claude Code",
              "Codex",
              "Clodcode",
              "Anthropics",
              "Opus 4.1",
              "Opus 4.5",
              "Summit 4.5",
              "GPT-5",
              "versão quantizada",
              "receita",
              "crescimento de receita",
              "OpenAI",
              "Google Ultra 3.0",
              "OpenRouter",
              "preços",
              "MCP",
              "Interface de Linha de Comando"
            ],
            "resumo_em_topicos": "- Contexto: comparação entre Claude Code, Codex e a suposta versão Clodcode, com Codex sendo superior em vários aspectos, embora Claude Code ainda seja utilizado para a interface de linha de comando (CLI) e tarefas com MCPs.\n- Aspectos técnicos: discussão sobre quantização de modelos (versões quantizadas como Opus 4.1) e a hipótese de monetização por meio de versões distiladas.\n- Estratégia de monetização: possível lançamento simultâneo de Opus 4.5/Summit 4.5 para aumentar a receita e o uso, influenciando a avaliação com base no crescimento da receita.\n- Preços e custo-benefício: OpenAI GPT-5 a cerca de 20 USD/mês versus Claude Code a cerca de 200 USD; sugerida combinação Codex (20 USD) + Claude Code (20 USD) como alternativa econômica.\n- Lançamentos futuros: expectativa de lançamentos em 48 horas e em duas semanas, incluindo Google Ultra 3.0 e OpenRouter.\n- Recomendações: esteja preparado para renovações e cotações quando surgirem os novos modelos para obter acesso aos melhores recursos com bom custo-benefício.\n- Conclusão: o jogo de modelos evolui rapidamente, e o melhor caminho é acompanhar os lançamentos e ajustar as permissões de uso conforme o preço e o desempenho.",
            "prompt_tokens": 1806,
            "completion_tokens": 4358,
            "model": "gpt-5-nano",
            "cost": 0.0074
          },
          "analysis_time": 193.542494058609,
          "language": "",
          "view_count": 6105,
          "has_transcript": false
        },
        {
          "id": "5AyoszGZHHU",
          "title": "Claude Code + Codex = PILHA DE CODIFICAÇÃO INCRÍVEL",
          "title_pt": "Texto: Claude Code + Codex = Pilha de Codificação Incrível",
          "url": "https://www.youtube.com/watch?v=5AyoszGZHHU",
          "published": "2025-09-15T23:54:47.227450",
          "published_relative": "há 5 dias",
          "duration": "08:29",
          "date_published": "2025-09-15T05:26:23-07:00",
          "transcript_available": true,
          "transcript": "Okay, welcome to this video where I'm going to be talking about claude code and codeex together and how it's an unstoppable code combination. Basically, what I've been doing is I was using claude code for mcps, cla commands, docker, everything and then using codeex for coding and the combination that it created was absolutely insane. Now, if you don't know, I have a SAS called SEO Grove, which I built basically in public in front of everyone. And yesterday, I just woke up and chose violence or whatever, chose, you know, working. Yesterday was Sunday. I did 14 hours of coding. And in that 14 hours, using the methods that I'm going to show you in today's video, I managed to get it so you can actually add WordPress or Woo Commerce stores as well as Shopify stores. This was actually quite a hard process because there are nine or 10 different agents and every single agent had to be changed to use the WordPress API instead of the Shopify API. Now, if you're interested in SEO growth, whether you're on Shopify, WordPress, Woo Commerce, you can now sign up. We have a deal right now which you can secure if you join the weight list. To join the weight list, just top here, join weight list, and you can use the weight list three months code, or you can just join the weight list, and we will automatically apply that discount for you. Just go to the uh weight list here, fill in all your information, pay the $1, and then we'll charge you $99 for three uh for every month for 3 months, and then that rolls over to $4.99 a month. So, let's talk a little bit about this method. So you can see here I have claude code running and basically what I do is I do all of my MCP stuff. So if I do M /MCP you'll see I have playr Superbase and I also have Docker CLI set up so I can run Docker commands inside Docker. And then here on Visual Studio Code is actually where I do all of the coding. Now, I've been finding codeex to be hundred times better. Right now, it's not perfect. As you can see here, you say I I had to say, \"You misunderstand me. I want to build my translation agent, which is built for Shopify. I work for WordPress, blah blah blah.\" But like the 1 million context window here is absolutely crazy. Like there's no need to compact anything like that. And you can see I I basically oneshot something that I was working on Claude Co for hours and hours and hours and I just couldn't get it to work. And then I brought that over to Codeex and it basically immediately got the job done. So I actually did most of my code with claw code last night. I had a huge like ridiculous conversation with claw code. You can see here like it's just absolutely insane. But I noticed partway through that it was struggling and it was starting to make mistakes and I don't know what happened. It was like I was talking to a whole different coder. Now one thing I will mention is at some point it did go down to Sonnet instead of Opus. So I think that might have been part of the problem but just generally I just noticed that the standard of code just suddenly dropped. So, I decided to hop on over to Codeex because recently what I've been doing is when I've got problems with Claude Code, I hop on over to Codeex and it actually works incredibly well. But one of the problems I have with Codeex is MCPs are just not very easy to set up at all. Right? So, I was getting kind of annoyed with that because I need MCPs. I need to be able to run Docker commands. I need to be able to run GitHub commands. I need to be able to do all these things. But I just find that codeex isn't that good at doing this. Right? So what I've been doing is I've been running all of my commands, all of my MCPs. If I need to update the database or, you know, whatever it might be, maybe I need to update Stripe or I I have everything set up locally on clawed code, right? And then if I want to if I want to test something, I use Clawude Code to test it. for maybe I'm having an issue with I don't know Superbase, maybe I need to make changes to Superbase. Maybe I need to run a Docker script, you know, whatever it might be. There's loads and loads of different things that I could be doing on clawed code. And then for the actual coding, I've just been using codeex. if it has a mistake, right? If something goes wrong, if there's an error, then I just go back to doing the standard copy the error and put it into codeex and say, \"Okay, this happened, this happened, this happened.\" Now, it was actually really interesting last night as well. I made a change to my GPT course so that I would use GPT4 nano for everything. And then the content writer wasn't actually working properly. So, I realized that maybe the problem was it just wasn't a good enough model. So, I changed back to GBT5 just for the writing uh prompt and the quality of the content immediately shot back up. So, the really cool thing about that is I actually I didn't know what was going on and I accused Codeex of changing my code and changing my prompts, but it reassured me that it hadn't changed anything, right? So, I looked deeper into it and I realized, okay, so maybe the problem here is actually the fact that it's using GPT5 Nano instead of GT5. So, I just use GBT5 instead. And then like I said it just instantly went back up in code quality. So this setup right is basically having clawed code with superbase mcp up-ash mcp playright mcp for checking um code online or on the browser sorry and then in the same folder right so I'm still in grove codeex we're both in grove codeex I have codeex open ready to actually write code for me now this combination is proving to be an absolute winner for me the amount of effort that it takes on codeex to do the kind of code that claude code would do is minimal. So you can see here for example I just ran that compact. You might have seen that it was full of context and it instantly just continued. And what it did was it sent a Woo Commerce test email cuz I'm currently just doing a market email marketing campaign to tell people that we're now on Woo Commerce cuz we had a lot of people sign up to the wait list who weren't on Shopify but now we're on Woo Commerce as well. And you can see what it did was it basically fixed this and then ran the test script and it sent the test email or the the marketing email to my email which is incomestream server@gmail.com. It sent the email and then like for example if I didn't like what it created or whatever then I can either change it in claw code or I can change it in codeex. Things like emails and stuff like that I would probably use codeex uh I would probably use clawed code for. What I'm using codeex for is the really really complicated things. Like you can see just how long this prompt actually was and it absolutely nailed this prompt. Okay, it took everything that I gave it and it just applied it directly to the code and it smashed it. Right. It made a little mistake here. I had to send a couple of errors that were here. Blah blah blah. A few more errors. It finally fixed everything and it did what CL claude code couldn't do in like 10 minutes, right? I tried to do this on claw code for hours and hours and hours. It just wasn't having it. I switched over to codeex just using instinct. I was like, maybe Codeex might be able to do this. I tried it with codeex and it literally did it in 10 minutes. And then I ran all of the tests on clawed code. I saw that the content was now being generated successfully here in Docker. um it'll be somewhere around here. And yeah, I successfully added a whole new, you know, 50% of customers could be using Woo Commerce. I added a whole new platform to SEO growth in under 24 hours, which is pretty damn impressive using predominantly the system that I just explained to you of using claw code for MCPs, CLI commands, GitHub, all of that stuff. So like my CI/CD, all of that kind of organizational stuff and then using codeex on high reasoning with agent mode for all of the complicated coding stuff. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute bloody legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Como combinar Claude Code e CodeEx para acelerar a codificação, integrando WordPress, WooCommerce e Shopify com foco em MCPs e automação prática.",
            "resumo": "Neste vídeo, o autor mostra como usar Claude Code para MCPs, comandos e Docker, e CodeEx para codificação, explicando que a combinação criou uma linha de produção de código improvável. Ele descreve ter trabalhado 14 horas seguidas e, com a estratégia, conseguiu integrar lojas WordPress/WooCommerce e Shopify, ajustando quase uma dúzia de agentes para a API WordPress. Mantém o projeto SEO Grove como SaaS público. Ele demonstra a configuração local com MCPs, Superbase, Docker, GitHub e o VS Code, tudo na mesma pasta com Grove CodeEx. Descobre que CodeEx, em tarefas de alto raciocínio, supera Claude Code, embora MCPs ainda apresentem dificuldades. Também revela que voltou a usar GPT-5 para escrita após um teste com GPT-4 Nano. O resultado prático foi adicionar suporte a WooCommerce em menos de 24 horas, com potencial de aumento de clientes.",
            "assunto_principal": "Integração de Claude Code e CodeEx para automação de codificação e integração de lojas online (WordPress/WooCommerce e Shopify) com foco em produtividade e SEO.",
            "palavras_chave": [
              "Claude Code",
              "CodeEx",
              "MCP",
              "Docker",
              "WordPress",
              "WooCommerce",
              "Shopify",
              "GitHub",
              "Superbase",
              "Integração Contínua/Entrega Contínua",
              "Crescimento de SEO",
              "Inteligência Artificial",
              "instruções",
              "GPT-5",
              "GPT-4 Nano",
              "produtividade"
            ],
            "resumo_em_topicos": "- Contexto e objetivo: combinar Claude Code e CodeEx para acelerar a codificação e ampliar integrações de lojas online.\n- Configuração prática: MCPs, CLI, Docker, GitHub, Superbase, VS Code, tudo organizado numa pasta Groves CodeEx.\n- Implementação de lojas: inclusão de WordPress/WooCommerce e Shopify, com adaptação de agentes para a API do WordPress.\n- Desafios enfrentados: MCPs difíceis de configurar e quedas na qualidade de código com Claude Code.\n- Solução encontrada: usar CodeEx para tarefas de alto raciocínio e prompts complexos; Claude Code para etapas mais operacionais.\n- Experimentos de modelagem: troca entre GPT-4 Nano e GPT-5, observando impacto na qualidade da escrita.\n- Resultados: adição de suporte ao WooCommerce em menos de 24 horas e potencial de expansão de clientes para SEO Growth.",
            "prompt_tokens": 1960,
            "completion_tokens": 3342,
            "model": "gpt-5-nano",
            "cost": 0.006
          },
          "analysis_time": 63.81215167045593,
          "language": "",
          "view_count": 4607,
          "has_transcript": false
        },
        {
          "id": "Gpt2em_robs",
          "title": "Claude Code QUEBROU O ECOM (COMÉRCIO INSTANTÂNEO)",
          "title_pt": "Claude Code quebrou o ECOM (comércio instantâneo)",
          "url": "https://www.youtube.com/watch?v=Gpt2em_robs",
          "published": "2025-09-14T23:54:47.227465",
          "published_relative": "há 6 dias",
          "duration": "12:22",
          "date_published": "2025-09-14T14:58:08-07:00",
          "transcript_available": true,
          "transcript": "Guys, I've discovered something and you know when I say that at the beginning of video, it's going to be worth watching. So, this is very very interesting to me and also probably to a lot of other people as well. Now, you can actually use Claude Code to create a Woo Commerce store and it's actually pretty nuts what you can do guys. I have to show you this. So, all you do is give Claude code some products and it can do everything. can do all your SEO, add product categories, design the entire website. No more expensive designers needed, and you only need Docker plus Claude code. So, let's just go through this process very quickly. Now, just so you know, this is kind of what it looks like. This is what you can expect. This website, including the products, were completely set up by Claude Code. It's inside a Docker uh instance. And the reason this exists, by the way, is because I'm adding WordPress and Woo Commerce to SEO Growth, which I can already announce that this will be done by the time that I push this video out. So, even if you're on WordPress now and Woo Commerce, definitely check out SEO.ai. Uh, this is the dashboard. This is the local version. I'm currently just adding the last couple of features to the to Woo Commerce basically. But yeah, this came about because I needed a store and we weren't we didn't actually have any Woo Commerce clients or we don't have any Woo Commerce clients at the moment and this is a very like extremely basic store, right? Um but like I just made this kind of instantly and it's like having Shopify locally which is just so interesting. It's so so interesting. So think about what you can actually do. First of all, you can create an entire like you can add products, right? and then you can get it to design the entire store, all that good stuff just like you know the directory generator that I gave to people. Now, we're probably going to make a SAS out of this um as yet unannounced, but we're we're probably going to make something like lovable.dev where you upload a CSV of your product and it just gives you a WooCommerce store basically. But for now, let's just show you how this works. So, I'm inside a fresh terminal here. And basically, I'm just going to write claud. And from here, I'm literally just going to say, please set up a Woo Commerce uh development instance for me locally using Docker. That's literally it, right? What that's now going to do is it's going to create a WooCommerce website for me locally using Docker just like I just asked it to. um and it will start Docker and I'll show you in just a few seconds. Now, let's say we wanted to actually work on some products. So, what I'll do is I'll get the um Shopify um products CSV example. I'll just grab this one. I know it's Shopify, but it shouldn't it shouldn't matter massively. It should be able to add these anyway. So, I'm going to show you, right? Let's say you have a CSV file, right? What you do is you get your CSV file download a sample CSV file. So I'm going to download this, right? Let's just say this this isn't what you will have obviously, right? Uh you'll have uh your own CSV file of course. So you can see here this is just very very simple. is just creates a very simple docker composed of wml very simple m and a very sing well in this case it's using ash script in order to set up woo commerce on the store but you could also just run these commands manually or get it to run these commands manually right okay so that should be pretty much done and then I'll say please you know start everything so let's See, I don't like all these.sh scripts that it's doing. It doesn't normally do that, but that's okay. Now, if you kind of think along the same lines as me, right, my kind of idea here is to build a directory generator for ecom websites, right? Um, but yeah, that's that that's coming up in the future. So, I had to swip switch switch the ports out because it was using the same uh the same ports as the other local WordPress that I have running. Also change the ports generally as I have another project running. Okay, so that looks like it worked. So, let's open this page. Right. So, I need to install. So, I'll just tell it to do all of that. Okay, looks like it it's already running it here. So, sleep 15 and and setup woo commerce.sh. So, what it'll do in 15 seconds is it will run setup woocommerce.sh. So, that should be any second now. There we go. It's running it. We can do control R and we can actually see what it's doing and stuff if we want. So, I'm just going to say, can you just install stuff manually, please? Because that setup script wasn't actually working. Okay, so now you can see it's actually doing stuff properly. So, um, it should have just installed WordPress. There we go. Now it's activating Woo Commerce. So, you can actually see that this one has a checkout, it has a my account, sample page, shop, etc. Right? So, this is actually where it starts to get super super interesting. So, it's installing storefront, which I believe is a very common theme for Woo Commerce. By the way, guys, just say no. I'm not an expert on Woo Commerce um or WordPress. To be honest with you, I've barely used Woo Commerce, but today I've learned an absolute crap ton about it. And I actually really like WordPress. I'm not going to lie. WordPress for e-commerce is very satisfying. I think I might prefer it to Shopify, which is crazy considering how much I've been obsessed with Shopify. So, watch this, guys. Just watch this. So, let's say we get our CSV, right? And I say add the products from this CSV to my store using CLI. And what it should do is it should read these products. There we go. And it it sees it's Shopify, but that's fine. I can see the Shopify. Okay, I'll convert and import these into Woo Commerce. Let me create a script that part. It's not really what I want. Um, but let's just see if this works. I'm kind of curious to see because if you've got more than one product, obviously you're going to want to do kind of a passing. You don't want to have to do it one by one actually. So, this is probably the better way to do it. But just so you know, it can add individual things by running commands like these commands here. It can docker exec Woo Commerce and then it can add um products, categories, literally everything. So, let's see if this works. I'm actually very curious to see what happens here. So, there's an error. Okay. So, what I I believe what it's done is it's created a custom import script, right? And then it's copied it into Docker and now it's going to run it. This is very interesting. Okay. Okay. So, it looks like it's doing everything manually here instead of the script. I probably would push it to continue using a script. I believe it always uses admin. Admin one, two, three, exclamation mark. No, let's see what the password was here. Just without the exclamation mark. Fair enough. So, let's log into the admin here. If we go to product, all products, we start should start see start to see the products coming through. And you can actually view this product and you can see there we go. There is our first product. So, some of you might be confused. Why am I using Shopify CSV? Let me just go into that a little bit. The reason I'm using it is cuz I want to show that you can use any CSV. It's not important. It's a Shopify CSV. I'm not saying go from Shopify to WooCom. I'm just saying if you can get you kind of need some kind of way to get products on your store, no matter what, right? And a lot of these things use CSV. You could also just import your products using some kind of importer, but I'm just showing you guys how malleable and flexible WordPress is for this kind of stuff. Okay, so let's refresh this now. It said that it's Yeah, look at that. Bang. So, we've now got four products. If you can get four products, obviously you can get 1,000 products. The process is exactly the same. So, if we view or edit one of these, we can see it's got an image. It's got all of this, etc., etc. This is all perfect for um creating it or doing the SEO afterwards with Grove. Now, I can instantly see some things missing here like skew, shipping, linked products, stuff like that. So, I'd probably work on this a little bit more if you're doing it, but for now, this is great. Okay, so we've we've got this, right? But what use is this to anyone, right? What I'm going to show you now is the really exciting part. So, we've got products, right? I could say, for example, add me categories, uh, add me a mega menu, etc. But I'm not going to do that. But just so you know, you can do that. I'm going to say design me a or even you could use something like v0ero or let's just say um Google stitch, right? Let's just go to stitch, right? Just cuz I want a good design, not a crap design. I don't want a shitty um whatever design. So, design me a clean homepage for a clothing store. And then I guess I could potentially just add my images here so that it gets some idea. So let's go back. Let's just take a screenshot and then we'll stick that here. These are my products. Blend the style into it. Make it modern and clean. Nice is called I have no idea. Um I'll just say two men cuz I I don't have time to think of something. Okay, so just that just so you guys know, you can also do this where you add clothing, you add different um product categories. I did all of this just not manually but with Claude code doing it. I said now add me, you know, make sure my products are inside their categories. add me a menu, you know, and then you can just start v coding your entire design, which is what I'm going to show you now. Okay, so it's given me this design. Let's just grab this design. So go here, uh, arr c, ignore that. Create mino page now for the store. Use this as a base and then paste that. Right. Okay. So I understand what the problem is now. So, Stitch gives CSS that doesn't actually really work. Um, but this is what it looks like when you put it on W3 schools, right? And this is what it created. Now, obviously, it added a picture, so the text is a bit messed up, but it did everything else pretty much perfectly. For some reason, it's not showing the products on the homepage. Product not sure. All right. Okay. So, the products weren't activated. So you can see maybe you can see what I'm kind of trying to cook up here. Obviously this is a very very basic example. This is also the first example, right? But effectively what you can do is you can get a CSV of any products that you want to sell, whether that's arbitrage, drop shipping, you know, whatever the hell it is, make a store in probably under an hour and then just move on to the next one. Right? That's kind of what is now possible now that I kind of realized that this is all possible. But yeah, I think I'll leave the video there, guys. Um, like I said, Grove now supports Woo Commerce by the time you watch this video or maybe in like an hour or two after this video drops, it will. Um, I've just been working on it for a while now, and I'm really excited for that. And there's a lot more coming, I think, guys. Thanks for watching. If you're watching all the way to the end of the video, you're an absolutely legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Claude Code pode criar, configurar e popular rapidamente uma loja WooCommerce local usando Docker, incluindo design, SEO e importação de produtos via CSV.",
            "resumo": "Neste vídeo, o apresentador demonstra como o Claude Code pode criar rapidamente uma loja WooCommerce local usando Docker. Ele mostra a configuração de uma instância de desenvolvimento, a instalação do WordPress e do WooCommerce, e o design do site, destacando que não é necessário contratar designers caros. O Claude Code recebe comandos para criar a loja, iniciar o Docker e importar produtos a partir de um CSV (exemplo do Shopify). O processo envolve scripts e CLI para adicionar produtos, categorias e configurações, com login no painel de administração para verificar os itens. O vídeo destaca a flexibilidade de usar diferentes CSVs e a possibilidade de transformar isso num serviço SaaS, além de planos futuros como um gerador de diretórios para ecommerce (lovable.dev).",
            "assunto_principal": "Automatização de lojas WooCommerce locais com Claude Code usando Docker, incluindo importação de produtos via CSV e design e SEO",
            "palavras_chave": [
              "Claude Código",
              "WooCommerce",
              "Docker",
              "WordPress",
              "Otimização para motores de busca",
              "CSV de produtos",
              "importação de produtos",
              "CSV do Shopify",
              "SEO.ai",
              "loja local",
              "automação de loja",
              "diretório de comércio eletrônico"
            ],
            "resumo_em_topicos": "***Resumo em tópicos***\n- Demonstração de criação rápida de loja WooCommerce com Claude Code usando Docker\n- Configuração de uma instância de desenvolvimento local, incluindo WordPress e tema storefront\n- Importação de produtos via CSV (exemplo Shopify) e uso de CLI para adicionar itens e categorias\n- Verificação via painel de administração com produtos criados (ex.: quatro produtos) e funcionalidades de loja\n- Ênfase na flexibilidade de trabalhar com diferentes CSVs e na potencial oferta SaaS (lovable.dev)\n- Planos futuros mencionados: gerador de diretórios para sites de ecommerce e integração de SEO/AI",
            "prompt_tokens": 1955,
            "completion_tokens": 1940,
            "model": "gpt-5-nano",
            "cost": 0.0039
          },
          "analysis_time": 47.89066696166992,
          "language": "",
          "view_count": 3331,
          "has_transcript": false
        },
        {
          "id": "cV413ZDo3bA",
          "title": "Como usar o Claude Code AI completamente de graça",
          "title_pt": "Como usar o Claude Code AI completamente de graça",
          "url": "https://www.youtube.com/watch?v=cV413ZDo3bA",
          "published": "2025-09-14T23:54:47.227478",
          "published_relative": "há 6 dias",
          "duration": "06:19",
          "date_published": "2025-09-14T05:45:57-07:00",
          "transcript_available": true,
          "transcript": "I'm going to show you guys how you can use claude code completely for free in today's video. Effectively, what we're going to be doing is we're going to be using claw code, but we're going to be using free models with clawed router. It's very easy to set up. Use open router. Open router often has free or cheap models, and you can get the power of claw code with a free model. Let's get into it. So, the first thing you want to do is you want to find a free model. So, I'm assuming on the side here, okay, there's no pricing. Oh, yeah. Prompt pricing. So, if I just put this to zero, I'm assuming that we can see all of the free models. So, for example, we could use the new Soma Dusk Alpha, Soma Sky Alpha, Deepseek V3.1, GBT O. You've got all of these different options of free AIS, which literally cost you absolutely nothing. Now, a lot of people recently have been talking about GLM, so I'm going to make this video about GLM. Now, obviously, this is a free version of it, so it's the air. So, I don't know how well this is actually going to perform, but I'm just going to show you guys how we can actually set this up with Claude router. So, let's just go to a new window here. New profile. Okay. MKD uh 4.5 Claude code. CD4.5 Claude Code. So, we're now inside this part of Claude Code. So, let's just go to Google and type Claude router. And you can see right here we have claw router and you can see it's actually made specifically for GLM 4.5. So what we can do is we can run this installation. So we'll install and then we'll install again. That was claw code. Didn't realize. There we go. So now we're installing claw code router. Let's just zoom in a little bit so you guys can see. Okay. So we can run CCR UI right here. And this brings up this um this window, right? So we can edit things a little bit more easily here. So currently we have open AI, but I'm going to add a provider here. Oh, let's just actually search providers. Open. Oh, no. Okay, that's my current providers. So let's do open router. This is all fine. Let's get an API key quickly. So we go to open router. Go to keys. Create API key. create. There we go. So, we'll set this and then models. Let's go uh what is it? Let's go back to the model card. Copy. Paste that in. Add model. Select transformer. Um, okay. Actually, I don't know if I need to do this, but I guess I'll just select it. Okay. I don't know how this works to be honest with you. I'm just going to press save. Okay, so we now have open rout. Let's delete open AI here and then let's run the code. So we need to run CCR code. So CCR code. Yes. And then we should see this here. There we go. So this is using API base URL which is my URL. And let's see if I do models. Now you can't see it on models. That's okay. So just so you know guys, if you say what model are you, it will tell you that it's um Sonnet, right? Or Opus. The reason being is that it has a system prompt telling it that it's uh Claude Sonnet, right? Okay. So we can now see that the although it says it's Claude Sonnet, you can see it says GLM 4.5 air, which means there was just a call to this. Now, I deleted the I accidentally deleted the wrong one here before, but I just had to redo it. And then I put my settings here. So, default, background, and think right here. So, now you can see that I'm successfully making Why was there 13,000 tokens there? What the hell? That's crazy. But it's completely free. So, now I can use the power of Claude Code completely for free. Now, obviously, I'm not saying that this is going to be as good as um claw code with Opus necessarily, but I do think this is quite an interesting way to get into this kind of terminal based coding completely for free. So, from here, you can just say something like, make me a simple HTML, CSSJS, uh to-do app. Now, I'm just doing a to-do app just to show that it, you know, can actually make something. I know that's really annoying when people do to-do apps, but I'm not going to go through the entire process of building a Next.js service website just for this video because I just want to show people quickly and easily how you can get Claude Code set up for free. Okay, so it's finished this to-do app. I'm just going to see if it can um Okay, I can't directly open files in a browser. Yeah, you can, but And then Yeah. Okay, I get it. It's a stupid example. Okay, it's a terrible example. Don't do to-do apps on YouTube. This is my to-do app. This is the first time in a long time that I've done a to-do app. Okay, so just bear with me. Let's just see if it saves. It probably won't. Yeah, perfect. So, yeah. Like I said, this video is just going to be very, very simple and easy to show you how you can use claude code completely for free with free models from open router. Now, my advice to you guys is if you want to create something quite complicated, right, but you don't want to spend 200 bucks a month, what you need to do is you need to grab models while they're free. Like, for example, Gemini 2.5 was free for a long time on Open Router or something like um Soma, right? Where is Sonoma? There we go. So, Soma Dusk Alpha and Soma Sky Alpha. I believe Sky was the better one. Um, you could easily bu be building something completely for free right now using Sonoma Sky Alpha, right? You could literally be building an entire app in Claude Code completely for free with a 2 million context window and I reckon it would do a pretty damn good job. I might do a video on this, like a gorilla method of building an entire website completely for free using Sonoma Sky Alpha. But honestly guys, you can just work it out for yourselves as well. I'll leave the video there guys. Thank you so much for watching. If you're watching all the way to the end of the video, as usual, you're an absolute legend and I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como usar Claude Code gratuitamente com modelos livres por meio do Claude Router/Open Router, explicando a configuração prática, uso de modelos GLM gratuitos e um exemplo simples de aplicação para demonstrar a viabilidade.",
            "resumo": "Neste vídeo, o autor ensina a usar Claude Code de forma gratuita aproveitando modelos livres através do Claude Router e Open Router. O tutorial começa com a busca de modelos gratuitos disponíveis (como Soma Sky Alpha, Soma Dusk Alpha, Deepseek V3.1, entre outros), depois detalha a criação de um perfil no Claude Code, a instalação do Claude Router (CCR UI), a obtenção de uma chave de API no Open Router e a adição do provedor/modelo correspondente. Em seguida, ele mostra como executar o código, explicando que, apesar de o sistema indicar nomes como Claude Sonnet, ele está operando com um modelo GLM 4.5 gratuito. O vídeo apresenta um exemplo simples de geração de código para um aplicativo de HTML/CSS/JS (aplicativo de tarefas) para ilustrar a funcionalidade, reconhecendo limitações de desempenho com modelos gratuitos. Por fim, o criador sugere estratégias para manter projetos maiores gratuitos (uso de modelos gratuitos enquanto disponíveis, como Sonoma Sky Alpha) e sinaliza a possibilidade de vídeos futuros sobre o tema.",
            "assunto_principal": "Como usar Claude Code gratuitamente com modelos livres via Claude Router/Open Router",
            "palavras_chave": [
              "Claude Código",
              "Claude Roteador",
              "Roteador Aberto",
              "GLM 4.5",
              "modelos gratuitos",
              "Soma Sky Alpha",
              "Soma Dusk Alpha",
              "aplicativo de tarefas",
              "geração de código",
              "Chave de API",
              "Interface do Usuário CCR"
            ],
            "resumo_em_topicos": "- Visão geral do tema: usar Claude Code gratuitamente com modelos livres por meio de Claude Router/Open Router.\n- Passos práticos: encontrar modelos gratuitos, instalar Claude Router (CCR UI), obter a chave de API do Open Router, adicionar provedor/modelo e configurar o código CCR.\n- Demonstração: exemplo simples de geração de código para um aplicativo de HTML/CSS/JS (aplicativo de tarefas) para comprovar a funcionalidade.\n- Considerações: o desempenho pode variar e pode não igualar o Opus; é possível construir projetos inteiros com modelos gratuitos.\n- Dicas: manter modelos gratuitos disponíveis à medida que aparecem, considerar Sonoma Sky Alpha para projetos maiores e explorar vídeos futuros sobre o tema.",
            "prompt_tokens": 1564,
            "completion_tokens": 2980,
            "model": "gpt-5-nano",
            "cost": 0.0053
          },
          "analysis_time": 61.09326386451721,
          "language": "",
          "view_count": 4596,
          "has_transcript": false
        },
        {
          "id": "rN5YocY1D4c",
          "title": "Gemini Canvas + Codex juntos me surpreenderam",
          "title_pt": "Gemini Canvas e Codex juntos me surpreenderam.",
          "url": "https://www.youtube.com/watch?v=rN5YocY1D4c",
          "published": "2025-09-13T23:54:47.227491",
          "published_relative": "há 7 dias",
          "duration": "07:25",
          "date_published": "2025-09-13T05:25:15-07:00",
          "transcript_available": true,
          "transcript": "Today I'm going to be talking about how I used codeex to create these beautiful pages which are hopefully going to bring me a crap ton of traffic. Now these are completely free tools that anyone can use and the idea here is that we grab people's emails and also we have CTAs in here as well. So you can just come here and do top 10 productivity tips 2026, right? and generate featured image. And then if you're just a casual user, then you can come here, you can generate your blog images, etc., etc. But the idea is to grab people's emails. Obviously, I'm not just giving this away for free. Now, I want to show you exactly how I made this in today's video. I actually used something really, really interesting, which is Gemini canvas. So, literally all I did was I came here and I said, uh, make me a free nano banana blog featured image post generator. The user should be able to put their blog post title and it should generate a featured image for that blog post. They should be able to pick square or landscape as options and then it should generate a downloadable featured image for them. So, Gemini canvas made this tool for me, right? And it gave me the code. So, all I did was I took this code and I went to codeex, right? And I just said to Codeex, if I just scroll up here, I'll just show you guys what I did. Create a complete landing page with a pop-up for my Nano Banana free blog post image generator. Make it fit with my exact styling of the front end. Ignore any current code that mentions Nano Banana. This is fresh. Make sure it's well formatted with amazing SEO. And it created this page here, right, which was absolutely perfect for me. I made a few suggestions, etc. Asked it to commit it to GitHub. And then I said, \"Now do the same thing with this product title and description generator.\" So if I just go back to Gemini here and I show you this, right? I also made this tool that you can see right here. So if I just go back to uh SEO growth and go to the product SEO writer, then you can see this tool also exists in the exact same format. Now the idea behind this is to get traffic for SEO growth. SEO growth. I'm building this entire SAS in public. It's currently doing pretty damn well to be honest with you. If you want to join, by the way, you can just join the weight list at the top here, SEO Grove. It's currently a Shopify automation platform. I will be working on WordPress very, very soon. And it does all of these things that you can see right here. Now, these pages, I put them in resources under free tools, and I've given them a URL/tools/free nano banana featured image generator. Right. And I'm hoping that this will just bring in a crap ton of traffic of people who are interested in some kind of automation. Right? That's the idea here. If I go on a private window here and I go to SEO grow, then you'll see if I go to resources nano banana after 5 seconds, 5 4 3 2 1 there should be a popup. There we go. And you can put and they can put their email here. Once they put their email here, so let's just do I don't know uh Shopify servers@gmail.com get free access then they can use the tool right otherwise if I basically what I did was you can't close the popup right so the only way to close the pop-up is to actually fill in the information it remembers your cookies for 30 days and then they have access to something that doesn't cost me a lot of money right because like you can only do one at a time, right? So, even if someone wanted to do 500 of these, first of all, that would cost me very very small amounts of money and second of all, they would have to manually one by one create 500 of these, right? So the idea is you can show them what you can do right with a free tool but then you have CTAs and you kind of say look you can do this manually 500 one at a time or you can join SEO grove and we can do it for you. So the idea here is if I just go to superbase right let's just go off um incognito go to superbase go to dashboard this is uh the project here search insights table editor and then if I go down you can see here that we actually have a table here with the tool uh the tool name right so I can see whether it's the nanobanana image generator or if it's the other tool the product description and title generator And we can basically blast these people with specific emails, right? So, if they're on Nano Banana, we can say, \"Look, um, you can do this manually or we can do it for you. Just sign up to SEO Grove. Here's a discount code, whatever.\" And email marketing is the most effective way to actually get people onto your SAS in my opinion. So, what I'm basically trying to do is I'm trying to build SEO Grove in public, but I don't want all of my or I don't want all of the customers to be from the YouTube channel. I'm trying. We've done ads. We got about 10 people, I would say, signed up through ads, but we're trying different methods and we're trying to actually get this to a really, really high MR. Maybe we'll sell it in the future just to show people the process that they can do, right? That's kind of my entire plan with that road. So yeah, this method is basically create a free tool using Gemini Flash. Just so you know, Gemini 2.5 Flash is ridiculously cheap, right? And then you take that free tool, you take the code, you can click code here, control arr C. I would use codeex. Codeex right now seems to be the best. So get the context of your project, open it up in codeex, so it has the context of everything and it will do a very very good job of taking that free tool and making it into a landing page with a popup and all of that good stuff. So yeah, I think I'll leave the video there, guys. I just want to talk about this quickly because I think this is a really, really good way to advertise your SAS. And everyone makes videos about how to make AI SASes, but not that many people are making videos about how to actually get customers and how to make money from those applications that you make. So SEO grove is a case study. I'll just show you the search uh console real quick. Now, for some reason, these pages are not getting indexed. Um I don't know what is going on there. Kind of annoying because normally everything gets indexed very very quickly. Let's just check if these are indexed. I doubt they are though. So, we can see at the top here, this is the free nano banana one. Not. It's still not indexed. I don't know what I don't know what's going on here. Normally, they would be indexed by now. But yeah, you can just generally see SEO Grow is doing pretty well on Google to be honest with you. 1.5K impressions a day. It's gone down to 784 there. But you can see that we do have other pages as well that we've made. And I'm really really trying to make it so that people can actually grow a SAS using my methodology. I've built basically everything in public and actually make money from it using organic traffic. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como usar Gemini Canvas e CodeEx para criar ferramentas gratuitas que geram imagens de destaque e descrições, capturam e-mails por meio de pop-ups e impulsionam o tráfego para um SaaS em construção, com estratégia de marketing por e-mail e publicação de métodos em público.",
            "resumo": "Neste vídeo, o autor demonstra como utilizou Gemini Canvas para criar ferramentas gratuitas, como um gerador de imagens de destaque para blogs, com CTAs para capturar e-mails. Ele usou o código gerado pelo Gemini Canvas no CodeEx para transformar a ideia em landing pages com pop-ups, otimizadas para SEO, com a finalidade de atrair tráfego e converter usuários em assinantes. O fluxo envolve pedir as ferramentas ao Gemini, pegar o código, gerar a página no CodeEx e iterar com variações (por exemplo, gerador de título e descrição de produto). A estratégia geral é construir o SaaS SEO Grove em público, usando automação, email marketing e um sistema de dados (Supabase) para gerenciar contatos e campanhas, enquanto explora monetização futura e expansão para WordPress.",
            "assunto_principal": "O uso de ferramentas de IA para criar ferramentas gratuitas que capturam leads, geram tráfego e alimentam a construção de um SaaS por meio de landing pages, pop-ups e automação de marketing.",
            "palavras_chave": [
              "Gemini Canvas",
              "CodeEx",
              "Nano Banana",
              "gerador de imagens para blog",
              "página de destino",
              "janela emergente",
              "captura de e-mails",
              "SEO Grove",
              "software como serviço",
              "hacking de crescimento",
              "marketing por e-mail",
              "Supabase",
              "indexação",
              "Google Search Console",
              "build público",
              "WordPress",
              "Shopify",
              "chamada para ação",
              "ímã de leads",
              "automação de marketing"
            ],
            "resumo_em_topicos": "Contexto e objetivo\n- Criar ferramentas gratuitas para atrair tráfego e coletar e-mails, monetizando via upsell para um SaaS.\n\nFerramentas e método\n- Gemini Canvas: gera ferramentas como geradores de imagens de destaque.\n- CodeEx: transforma o código gerado pelo Gemini em landing pages com estilo próprio e SEO.\n\nFluxo de implementação\n- Pedir ao Gemini a criação da ferramenta, obter o código, importar no CodeEx, gerar landing page com pop-up e SEO otimizado, e solicitar commit no GitHub.\n- Repetição do processo para diferentes utilitários (ex.: gerador de descrições/títulos).\n\nEstratégia de captura de leads\n- Pop-up em páginas de ferramentas, coleta de e-mails, cookies ativos por 30 dias, e CTAs que incentivam assinaturas no SEO Grove.\n\nInfraestrutura e dados\n- Uso de Supabase para gerenciar dados de ferramentas e campanhas, com tabelas que categorizam os recursos (ex.: nanobanana image generator, product description/title generator).\n\nCrescimento e monetização\n- Construção pública do SEO Grove; uso de email marketing para conversões e demonstração de métodos de aquisição de clientes.\n- Consideração de monetização futura e expansão para WordPress.\n\nNotas finais\n- O apresentador destaca a importância de estratégias de tráfego orgânico e construção pública para escalar um SaaS com baixo custo inicial.",
            "prompt_tokens": 1763,
            "completion_tokens": 2425,
            "model": "gpt-5-nano",
            "cost": 0.0045
          },
          "analysis_time": 61.182560205459595,
          "language": "",
          "view_count": 1720,
          "has_transcript": false
        },
        {
          "id": "N2Y_H6R0Q10",
          "title": "O Google Gemini QUEBROU tudo (Construtor de IA gratuito)",
          "title_pt": "O Google Gemini quebrou tudo (Construtor de IA gratuito)",
          "url": "https://www.youtube.com/watch?v=N2Y_H6R0Q10",
          "published": "2025-09-12T23:54:47.227506",
          "published_relative": "há 8 dias",
          "duration": "11:29",
          "date_published": "2025-09-12T03:02:04-07:00",
          "transcript_available": true,
          "transcript": "Okay guys, so I wanted to talk about the latest feature from Google Gemini. This is actually pretty insane to be honest with you. Now, I know that we use the word insane a lot as YouTubers and I actually got this video idea from Julian Goldie who also said that the thing was insane, but this actually is pretty nuts to be honest with you. So, I'm just going to show you this process. So you might think that, you know, this is just going to be like another bolt new lovable.dev where, you know, it works but kind of doesn't work. But I just gave it this prompt here, make me an app powered by Gemini, which finds keywords for people generating pillar pages based off their website, find information about the website online and then subpillar pages which should be displayed to the user as blog post topics. So this is a really really interesting methodology that it did here. So, it thought about it for a bit and then it created this one page of content, right, which isn't that impressive or it doesn't seem that impressive, right? But the insane thing is in just one prompt in just kind of like 15 to 20 seconds. Now, I'm not actually sure how it's even finding the API key here to be honest with you. Now, it says that there's an API key, but API key. I'm not sure where the API key is actually coming from because I mean I haven't set an API key. So, this might just have some kind of M inside it which it's using uh in order to power this because as far as I can see, there is no way for it to have actually got the correct answer here without using AI. And if we actually look at the prompt here, you are an uh you are an expert SEO strategist and content planner. Your goal is to analyze eight websites content blah blah blah. Then generate five to seven pillar pages. So it's done exactly that. https2men. Generate ideas, right? Pillar page topic Italian men's wear comprehensive guides and important style blog post ideas. There's 1 2 3 4 5 6 which is between one uh five and seven, right? So, I'm actually not sure how this is even getting my API key, but I'm guessing if I downloaded this code, it wouldn't work because there is no API key here, right? Okay. So, my theory has just been proved here. I've just basically taken the code here uh and put it onto W3 School's try editor and tried to run it and it didn't work. Now, I'm going to tell you a couple of things that you can actually use this for. Number one, right, I have a tool called SEO.ai, which is my SAS. By the way, this video is sponsored by SEO Growth. If you want help with your Shopify store and you want something to just be running 24/7, which grows your organic SEO for a much better price than an agency, then segrow.ai. Join the weight list, guys. We'll be removing the weight list very soon. It'll be the first link in the description. Now, I'm going to show you a pretty interesting thing that I came up with. Right now, I found this through Google Ads keyword planner. Right? So, product description generator AI or free. And then you can see here ahs has this tool here which is a free AI product description generator, right? So, what I was thinking of doing was creating one of these pages for me, right, for my tool. But I was having an issue where it wasn't really properly generating the page. What I could do if I wanted is I could say, \"Okay, I want you to create a AI product description and title generator using Gemini Flash and I want you to do the SEO for that page and help you rank on Google for that page.\" So, you can actually use this tool to make little tools for your website. And this would go on a Shopify website because this is just HTML. But this you could make like a suit um conversion generator or like you know you could really really go to town with this tool and because it's really good at creating quick working AI powered tools you could make hundreds of these and you could probably start to get some really really good traffic. So, another one I found, by the way, was uh Shopify name AI generator free, right? Again, there's loads of these. So, you can find a keyword or you can give this keywords and you can find business names for your store. And then if we can get people to like for example, let's just go on I don't know, let's go on this one. Let's say that once you've described your business and press generate names, a little popup comes up and instead of generating a name there and then, what it actually does is it grabs their email and then you have a permanent email for someone that you can just message constantly with new deals, offers until you finally onboard that client. Right? So, that's another idea I've had and that could bring in loads and loads of traffic. Now, what else could you use this for? You could also use this for testing out or creating MVPs of tools to see how it would work. So, let's say I wanted to make this keyword tool, but I wasn't really sure whether it was a good idea or not, and I wanted to see it in kind of MVP format. This is a very quick and easy way to just create an MVP of a product. Okay, so this is actually super useful and super helpful. The reason being is that it has real Gemini built into it. So, it's using an API key. I guess that it's in the M somewhere. I'm not really sure how it's work, how how this is actually getting an API key, but I I have proven that by going on um putting the same code on W3 schools and it gave me a 403 error, which I guess is authentification, right? Authentication. Yeah, due to a lack of permission or access to the requested resource. So 403 is basically means I don't have an API key. So, you can really quickly and easily make MVPs for things. You can share this with people, right? I could be like on my YouTube channel, I could share this link and be like, \"Who's interested in this keyword tool? Comment down below.\" Um, and then if like enough people comment, then I be like, \"Okay, well, there's obviously interest in this tool. Let's create it.\" Now, would I use this for fullblown coding of apps? I don't know. Probably not. It's pretty basic um in in its creation, but I will say that I don't think I've ever had it where it's one prompt into a working AI app with an API key in kind of I think it was like 40 seconds, right? Which is pretty insane to be honest with you. So for those specific things like I was just talking about MVPs, creating pages for your website, like little tools, whatever it might be, I think this tool might actually change everything and be super this is like a game changer for that specifically, right? Even if you went right now to anthropic uh claude and said do g g g g g g g g g g g g g g g g g g g g gave it the same prompt. It would give you some old uh Gemini model or old anthropic model or even an old open AI model. It will try to use chat GBT3.5. Yeah, it just won't work. I'm telling you it won't work. I've done it enough times in my life. However, with this tool, it worked immediately which is very very interesting. And then there is another little button here that says add Gemini features, which is pretty cool. You can just press add Gemini features. So like if you wanted to build off an MVP and just keep adding features and see what it comes up with and blah blah blah, then so I've been planning new features on Pong 2, generating blog out post outlines and creating social media posts for blog topics. That's pretty damn interesting. So let's just see how this goes. Right, this is this is me starting with a very basic idea. I press one little button here and it just iterates, iterates, iterates. So here are your updated files. So if we go to code here, what it's now going to do is it's going to create a whole different tool. So a generate outline tool and a draft social post to the button last Gemini to draft promotional post for Twitter X, LinkedIn, and Facebook. Maybe even using Nano Banana. Who knows? like um I could ask it to use nano banana potentially for the social media post generation. So like if you have a basic idea of something like oh I want to make an SEO tool. Let's start with a keyword tool and then you can just keep iterating iterating iterating. So let's just try this real quick. Let's generate ideas here. And you can see just how fast this actually is. Like that was super super fast. Generate outline. Damn it. This is actually pretty insane to get to this point on something even on claude code or lovable.dev or you know that kind of stuff. It would take ages and ages and ages. So this doesn't seem to be working. Let's see if there's anything. Oh, there we go. Damn. Here's a unique detailed blog post outline for this. Right. And then I could add a little tool here using, for example, Gina that finds the products for for these on my website. Damn, not bad. I have to say this like we use the word insane a lot. We use the word um game changer a lot. AI is changing very very fast. But fair play to Gemini. They've actually made something pretty freaking interesting right here. So let's see. Twitter post. Okay. Sure. LinkedIn post and Facebook post. Right. So this is like an entire marketing suite that I made in under five minutes. Right. Just by pressing this button. Let's see what this does. Let's I probably won't let this run, but like the fact that every single one works perfectly is insane. Brainstorming new ideas, focusing on draft blog intro, suggested keywords button to each subpillar. Okay, sure. So, you can just keep pressing this button here and in who knows what you'll have in 10 hours time. That's the crazy thing. And I've always believed AI coding AI can really lead to like very innovative and interesting things. So guys, I'm not going to lie, this is very impressive. I've just realized as well, this is completely free. I'm on uh my Shopify surfers email, which doesn't have any paid Gemini whatsoever. Right. So, this is a completely free tool that you can use right now to really start to go to town with some ideas of, you know, MVPs, little tools that you can put on your website and then just put an API key in your environment and a lot more. I'm going to leave the video there, guys. This is very, very interesting to me. I'm not going to lie. The fact that every single one has been perfect every time with no mistakes is blowing my mind. like you just don't get that. Okay, there we go. There's our first mistake finally. I'm happy that there was a mistake because I was starting to I was starting to freak out a little bit because I've never had a coding experience with so few mistakes before. So, like yeah, we we've basically created a whole marketing suite for someone to come up with blog post ideas in under 5 minutes that gives people d uh draft blog post intro, suggested keywords, generate outline, draft social post. I've basically rebuilt Harbor or like 50% of one of Harbor's tools in 10 minutes, 5 minutes. I'll leave the video there, guys. This is pretty nuts. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise da funcionalidade mais recente do Google Gemini que, com um único prompt, cria rapidamente um MVP de ferramenta de IA para geração de palavras-chave, páginas-pilar e tópicos de blog.",
            "resumo": "Neste vídeo, o criador explora a nova funcionalidade do Google Gemini que permite gerar, em cerca de 15 a 20 segundos, um MVP de ferramenta de IA com uma única instrução. Demonstra um prompt que solicita uma ferramenta para encontrar palavras-chave de páginas-pilares, resgatar informações de websites e sugerir tópicos de blog. O apresentador comenta a suspeita sobre a origem de uma chave de API e testa o código em um editor online, observando que, sem chave, o acesso retorna 403. Compara com outras plataformas e destaca que o Gemini, integrado, facilita a criação de ferramentas rápidas, com opções de adicionar recursos adicionais. O vídeo sugere usos práticos: criar páginas de conteúdo, descrever produtos para Shopify, gerar descrições e nomes de negócios, testar MVPs, captar tráfego orgânico e validar ideias com feedback da audiência. Conclui que, embora seja limitado para MVPs e experimentos.",
            "assunto_principal": "Geração de MVPs de ferramentas de IA utilizando Google Gemini, explorando geração rápida de conteúdo e aplicações para SEO, páginas pilares, descrições de produtos e testes de MVPs.",
            "palavras_chave": [
              "Google Gemini",
              "Gemini",
              "Produto Mínimo Viável",
              "ferramenta de IA",
              "Otimização para Motores de Busca",
              "palavras-chave",
              "páginas pilares",
              "tópicos de blog",
              "chave de API",
              "403",
              "Shopify",
              "descrições de produtos",
              "geração de conteúdo",
              "prototipagem rápida"
            ],
            "resumo_em_topicos": "- Explorando a função do Google Gemini que gera MVPs de IA em segundos.\n- Demonstração de prompt que cria palavras-chave, coleta informações de sites e sugere tópicos de blog.\n- Discussão sobre a origem da chave de API e o erro 403 sem autenticação.\n- Gemini integrado facilita a criação rápida de ferramentas, com opções de adicionar recursos.\n- Usos práticos: páginas de conteúdo, descrições de produtos para Shopify, nomes de negócios e MVPs de teste.\n- Conclusão: útil para MVPs/experimentos, mas não substitui o desenvolvimento completo; fluxo promissor para prototipagem.",
            "prompt_tokens": 1944,
            "completion_tokens": 5992,
            "model": "gpt-5-nano",
            "cost": 0.01
          },
          "analysis_time": 68.7232277393341,
          "language": "",
          "view_count": 26028,
          "has_transcript": false
        },
        {
          "id": "8lQ1PuAHMnY",
          "title": "O sistema de codificação de agentes de IA do CODE BUFF é uma LOUCURA (RIP CLAUDE CODE)",
          "title_pt": "O sistema de codificação de agentes de IA do CODE BUFF é uma loucura (Descanse em paz, Claude Code)",
          "url": "https://www.youtube.com/watch?v=8lQ1PuAHMnY",
          "published": "2025-09-11T23:54:47.227519",
          "published_relative": "há 9 dias",
          "duration": "08:26",
          "date_published": "2025-09-11T05:34:05-07:00",
          "transcript_available": true,
          "transcript": "In today's video, we're going to be testing out CodeBuff, which is a brand new CLI code editor, and I just wanted to see how good it was. So, it should be quite easy to install. So, let's just do mpm install-dodebuff. And then, I believe we just write codebuff here, like that. And then that should start everything. So, we're going to be using our standard benchmark, which you can find on my school community or just in various places online for free. So, if I just go to my classroom, all my prompts and workflows, grab this prompt here, press enter to finish logging in. Okay, continue with GitHub. So, we should be logged into CodeBuff in just a second. There we go. Let's just exit out quickly and let's run the install command. So, yes, yes, yes, yes, yes on here. And then normally I would add images, but I'm not going to add images for this one. We'll just see what it does uh without any images. I'm just curious to see if it's good enough to create SVGs and things. So grab the prompt here. We'll write code buff again and then make SVGs for images where needed. Then we'll send the entire prompt. That look like it got split. Let's have a look. Let's see how it deals with this. So sub goal create multilingual luxury car rental service spawn agents file picker file picker file picker. Okay, good. So this is pretty interesting. It is definitely kind of a clawed codebased system. Let me read the key files. Okay, this is pretty good so far. I like the way that it's doing this. I like the fact that it spawns various agents. Let's see here. Let me create the public directory structure and start building the luxury car rental website. Okay. Thinking deeply. Interesting. So, you get 500 credits every month for free with this. So, I mean, that's not terrible. If you go on pricing here, you'll see it's $1. No, sorry, 1 cent per credit, and you get $5 of credit every single month for free. So, it's not bad at all. Let's see if we can see our usage. There we go. My usage. Okay. So already I've used 25 credits, which is quite a lot considering it hasn't actually done anything yet. But okay, that looks like it's going to be running out pretty damn quickly, I have to say. Now, the pricing here is definitely pretty crazy. If I've already used 25 credits and hasn't even started yet, uh then 1,000 is not going to actually get you that much to be honest with you. I will just let this run though. I'm a little bit worried about the usage here, whether it's even going to be able to create one single project with um this amount of tokens. But if not, I guess I can buy some more tokens if needs be. It does seem to be doing a pretty interesting job here. It seems to be going pretty quickly as well, I have to say. So, yeah, we'll let this run and we'll be back shortly. Just before we continue, a quick shout out to the sponsor of this video, which is of course me. You can get segrove.ai, AI, which is a Shopify automation platform, soon to be Shopify and WordPress. You can use the code weight list 3 months to get 80% off your first 3 months. We're doing a starter offer. Um, the wait list will be going off in probably about a week. So, if you do want to lock in that price, check out SEO Grove. Sign up today, join the wait list. We'll charge your card and you can join with the wait list three months if your card is successfully charged. Now, I have to say, oh, I have to say it's actually seems to be doing a pretty good job so far. Um, I do like the way that it's doing this. I don't like the fact that if I type anything, it stops the process. So, I do have to be careful of that. Yeah, SEO, by the way, will be the first link in the description on also the pinned comment. Okay, so this is a pretty interesting process. So, now it's spawned a new agent, which is a reviewer review. The complete luxury car rental website application nitpicker. First I'll run this. Okay, no file change hooks were triggered. High level feedback. Overall structure is fantastic. Okay, good. Let's see if that actually picks up the issues and fixes them before we get errors. That would be a game changer. That would officially make this better than cord code, which is not really something that I thought I would be saying. So, it looks like it's reviewed. The reviewer referred excellent feedback. Let's see. This will produce links like this which are more explicit. You will also need to update the links pointing to this page. Okay. So I found some interesting changes. The file creates the service segment also extending match services lean to URL like servers as well. Okay. Interesting. Very interesting. Okay. So this says it's done. It says it used 224 credits. So, let's just open up a new one here and do npm rundev. Okay, cd my app. Uh, npm rundev. Okay, so it does run. Let's see if it works cuz obviously that's the more important thing here. Just ignore that. That's just me making the thumbnail for this video. Okay, that's kind of annoying. Um, the homepage is just the standard just page, not the website. Let's just see what happens if we manually add /en here. Oh Okay, this is actually really, really well done. Damn, now obviously there's a few problems with this already. I knew that there would be some 404s. Yeah, more 404s. But yeah, I mean the homepage looks incredible. This also looks good. There's no problems with colors, which is nice. I would say that this is a very very standard uh Bootstrap project, which I'm not that impressed by, and there are a lot of 404 errors here, but I would say it does look very very good, but it also looks different, which is something that we kind of struggle to find really. Okay, but I mean, overall, this looks fantastic. I'm very very impressed with the look and feel of this. I know that it looks very I I would say that this part looks amazing. Further down it looks a bit more bootstrappy, but let's see if the italiano works. It does. Okay, beautiful. It's just a bit of a shame that it didn't finish everything off before it told me that it was finished. Um I would have loved to seen a complete project here. Okay, so it's added the locations. I just asked it to add them. It's pretty much done now. I still think this could be a little bit more comprehensive, but in terms of like the actual build, it's done a very very good job. I'm pretty impressed with the result here. Um, I still think it could do more, but I, you know, I always think that. But overall, I mean, this is this is definitely on par with Claude Code or Codeex or whatever in terms of building, and it hasn't had anywhere near as many issues with colors. For example, there's a lot of light on light or dark on dark. You can see it's using CHBT5 or Anthropic because they all use this little scrolling animation thing. I don't know why, but they all add the same scrolling animation thing, every single one. But yeah, I mean, I would definitely give this a high mark. It's definitely impressed me. Here you can see now it's it's done. Um, this is kind of the entire website. Let's just quickly check the SEO. So, yeah, the SEO has also been done. I mean, this is very very impressive to be honest with you. I did have to prompt it one more time just to get what I wanted, but yeah, overall this is a fantastic result. This is definitely an interesting one to look out for. That was possibly the quickest I've ever done this as well, to be honest with you. That was extremely fast. I like the fact that it checks its own code as well. And this is definitely one for what? This is definitely one that is worth your time, guys. However, this is the problem right here. 81 credits remaining. Consider topping up soon. That is a little bit annoying. Not a big fan of that, but yeah. I mean, obviously, they have to make money at the end of the day. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, as usual, you're an absolute legend. Check out SEO Grove, check out the school community, check out Bright Data. Thanks for watching. You're all legends. And peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo avalia o CodeBuff, um editor de código em linha de comando (CLI) com sistema de agentes de IA, mostrando a instalação, o uso de créditos, a geração de um site de aluguel de carros com agentes e uma comparação com concorrentes, com observações sobre custo e usabilidade.",
            "resumo": "Neste vídeo, o apresentador testa o CodeBuff, um editor de código CLI com sistema de agentes de IA. Ele mostra instalação, login e execução de prompts para gerar uma aplicação — um site de aluguel de carros de luxo — com múltiplos agentes, incluindo um revisor que sugere correções. O pacote de créditos é discutido: o serviço oferece créditos mensais gratuitos (500) e cobra 0,01 dólar por crédito; ele já usa cerca de 25 créditos apenas para começar e se preocupa com o consumo. O resultado exibe uma homepage funcional, várias páginas com 404s, estilo Bootstrap, suporte a idiomas e SEO. O apresentador compara o CodeBuff de forma positiva a Claude Code e descreve o processo como rápido, porém com custo. Encerra com 81 créditos restantes e a recomendação de ficar atento ao reabastecimento. Patrocinador incluído.",
            "assunto_principal": "Avaliação do CodeBuff (editor de código CLI) e de seu sistema de IA com geração de sites, custos de créditos e comparação com concorrentes",
            "palavras_chave": [
              "CodeBuff",
              "editor de código de linha de comando",
              "agentes de inteligência artificial",
              "instruções de prompt",
              "revisor de código",
              "créditos",
              "precificação",
              "Claude Code",
              "Bootstrap",
              "SEO",
              "erros 404",
              "multilinguismo",
              "geração de código",
              "velocidade",
              "custos"
            ],
            "resumo_em_topicos": "### Pontos-chave\n- Introdução: avaliação do CodeBuff como editor de linha de comando (CLI) com IA e geração rápida de código\n- Configuração e login: instalação, login via GitHub e início de sessão\n- Funcionamento com agentes: prompts de múltiplos agentes, inclusão de revisor, geração de site de aluguel de carros de luxo\n- Créditos e custo: créditos gratuitos (informação variada) e preço por crédito; consumo observado (25 usados, 81 restantes)\n- Resultados técnicos: página inicial funcional, páginas com erro 404, estilo Bootstrap, suporte a idiomas, SEO concluído\n- Comparação e percepção: desempenho positivo frente ao Claude Code, rapidez e qualidade\n- Considerações finais: velocidade, acabamento, cores, necessidade de recarga de créditos\n- Conclusão: avaliação positiva geral, destaque pela rapidez; menção ao patrocínio da SEO Grove",
            "prompt_tokens": 2002,
            "completion_tokens": 4849,
            "model": "gpt-5-nano",
            "cost": 0.0083
          },
          "analysis_time": 65.50061202049255,
          "language": "",
          "view_count": 3829,
          "has_transcript": false
        },
        {
          "id": "7H9QLaF83I4",
          "title": "Claude Code é \"uma droga\" para 90% dos usuários (verdade nua e crua)",
          "title_pt": "Claude Code é uma droga para 90% dos usuários (verdade nua e crua)",
          "url": "https://www.youtube.com/watch?v=7H9QLaF83I4",
          "published": "2025-09-10T23:54:47.227533",
          "published_relative": "há 10 dias",
          "duration": "08:06",
          "date_published": "2025-09-10T07:14:33-07:00",
          "transcript_available": true,
          "transcript": "If you're thinking about cancelling your Claude Code Max plan, watch this video before you do. I'm going to tell you what I think about this debate. Now, I've seen a lot of videos recently, a lot of people on Reddit saying they're going to cancel their max plan. Claude Code sucks. You know, Warp.dev is better. There are all these different things that have better. But I just want to make this video cuz I think this is really, really important. In my opinion, Claude Code is still the best AI dev in the entire world. But you have to check everything. Okay? Which means you need to have some understanding of the project that you're working on. In my opinion, it's still true as it was 3, four, 5 years ago that you need to really be a dev or devminded to build something. Anyone can build something, but only people who actually think like developers and think like programmers and fix problems and know how their systems work are actually going to be able to build something of substance. So this is actually why I don't use Replit. I think Replit is a very good builder, but it has a fundamental problem, right? And the fundamental problem with replet is you don't know what the hell is going on in your own code, right? Because replet is one of those builders that you just say, \"Okay, build this.\" And then it just kind of goes away and does all of the prompts and everything and it just builds builds builds builds builds. You don't know what's actually going on in your own code. This is a fundamental problem with AI builders such as Replit and also just AI building in general. You can build an entire project with clawed code and you might not know what the hell is going on. Luckily for me, I know everything about SEO grove cuz this project was built from scratch by me with claude code prompt by prompt, you know, step by step. No one or anything like that. I know everything pretty much that's going on with this project. By the way, if you're in ecom SEO, definitely check out SEO Grove. Join the weight list now. Secure the price of 99 a month for 3 months. It'll be the first link in the description of this video. We'll be closing the weight list in a week or two. But yeah, let me just show you an example of this. So, also working on large projects is really hard for Claude Code. In my opinion, it's not that Claude Code has necessarily it's definitely got worse. I don't want to say that it hasn't got worse, right? But it's not necessarily just that in my opinion. It's also that you know we've all built now, right? So the fact that you've built means that you've got a larger project than when you started and therefore it's harder for it to work on a larger project. It will make mistakes. You have to check everything. So I'm just going to show you an example of this right here. Right now I was just literally doing some fixing on um on SEO growth. You can see here when we did the emails yesterday, we sent out hundreds of emails, but the registration magic link didn't work. Can you check what happened? Check the difference between the regular $99 payments that we charge through the weight list and the one that you set up specifically, the magic link for registration. Don't tell me there's an issue. Find the issue and explain to me. So, this is something that I do a lot. I say, don't just tell me there's something wrong or don't just tell me that I'm right. Make sure that there is actually a problem and then explain the problem to me. So, let me just show you guys how this went, right? So, it read read and it found the magic link. So, the MA recovery email uses this format, which is completely incorrect. And I did actually know it was incorrect at the time. I just didn't spot it, and I didn't it didn't quite register in my head that it was incorrect, right? And then it needs to find what happens with the with the current magic link, which is working, right? And compare the two. So, you can see here now I see the issue. Let me check if the magic link handles the code parameter blah blah blah. I found the issue, right? The recovery emails sent magic links with this format, but the orth root doesn't handle the clo code parameter blah blah blah. User pays through weight list. They get the access code generated. They manually enter the code on the login page. The API access code logging endpoint validates the code and logs them in. This is actually wrong as well. And because I know this project so well because I built it from scratch, I built it from the ground up and I know everything about it. I know that this is incorrect too because you can't even log in with an access code, right? So, if you're not kind of programming minded or you're not checking everything, you're not reading everything, it's kind of on you at the end of the day because yeah, it sucks that we have to check everything. But that's just that's AI, right? At the end of the day, AI is not perfect. We know it's not perfect. We know especially it's not perfect with massive projects like this one, right? So you can see I actually say to it no one can actually login with access codes. Please check again and this time understand how we automatically give people a login link that actually works or registration. Then it said let me check the actual working magic links are generated. Perfect. I found the magic link format is this. Now I understand the working magic links use this wrong. This didn't work right. So now it should genuinely fix the issue. And you can see I actually checked this and I said as well this does this follow the this follows the exact format of the other one correct as in like the one that was working right. So yes exactly now it follows the exact same format as the working magic links working magic link from.py token equals blah blah blah blah blah blah blah blah don't really care about this decrypt the token find the access key by ID auto login the user etc. This will actually work now the previous version sent them to a form page that ignored the code parameter. Okay. So, I'm now going to say, \"Please send a test email to uh Shopify surfers.com so I can see if it work.\" So, basically what I'm saying, guys, is you can't trust the AI just point like point blank. You can't give it a blank check to just go ahead and do whatever it wants. You have to check everything it's doing, right? which sucks, but with a larger project, it's kind of normal if you think about it because there's there were three different places that it had to check to find the actual working code. Right now, just a couple of things, guys. This is not necessarily a defense of Claude code. I think no one can deny that the code quality from when Claude code was first released to now has definitely gone down. But I also think that it's probably also our best option. The only other option that I would even consider, well, there's two actually, is um Codeex, Codeex and Gemini CLI. I probably wouldn't use any other uh system. Okay, so as you can see, now that we've actually done that entire process and I checked everything, it's done exactly what I wanted, right? So, we couldn't process your payment, but your spot is still reserved. So, now when I press this, it should lock me in. Log me in. I can't click it for some reason. Let's just do that. And then if I open this, I should be directly logged in. Perfect. So, now it works right now. Now, it actually works. This is exactly what I wanted. So, if I just let it do its own thing, it wouldn't have fixed it. It would have got it wrong, etc., etc. But because I read absolutely everything it was doing and I corrected it, you can see that it did actually do what I wanted. I'll leave the video there, guys. Thank you so much for watching. You're just going to have to learn that at least for now, you're going to have to keep an eye on what AI is doing. It's something that I worked out maybe 3 or 4 weeks ago after just experimenting. And yeah, now I just literally sit and read everything it does because obviously it's still way faster than a human, but it's not as intelligent as a human in terms of like interpreting what you actually want in my opinion. Thanks for watching. If you're watching all the way to the end, as usual, you're an absolute legend. I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apesar de defender Claude Code como o melhor recurso de IA para desenvolvimento, o apresentador alerta que, em projetos grandes, é essencial entender o código e verificar tudo manualmente, demonstrando um fluxo de depuração que corrige falhas de login e de links mágicos, e discutindo alternativas.",
            "resumo": "Neste vídeo, o autor aborda a discussão sobre cancelar o Claude Code Max, defendendo que Claude Code ainda é a melhor IA para desenvolvimento, mas que é essencial entender o projeto e verificar tudo manualmente em sistemas complexos. Ele critica plataformas como Replit pela pouca visibilidade do código e demonstra que, mesmo com um projeto construído do zero (SEO Grove), a supervisão humana continua sendo crucial. O trecho central apresenta um fluxo de depuração com Claude Code em um projeto grande: identificar falhas, comparar formatos de links mágicos de cadastro e de login, ajustar o código para que o login funcione e evitar que a IA tome decisões erradas. O apresentador reforça que a IA não é perfeita, especialmente para projetos grandes, e não recomenda confiar cegamente nela. Por fim, ele menciona Codeex e Gemini CLI como opções e mantém a necessidade de checagem humana contínua.",
            "assunto_principal": "Avaliação do Claude Code em projetos de grande porte e a necessidade de supervisão humana na verificação de código gerado por IA, com comparação de ferramentas e fluxo de depuração.",
            "palavras_chave": [
              "Claude Code",
              "inteligência artificial para desenvolvimento",
              "depuração",
              "verificação de código",
              "Replit",
              "SEO Grove",
              "link mágico",
              "início de sessão",
              "Codeex",
              "Gemini CLI",
              "inteligência artificial",
              "projetos grandes",
              "promessa x realidade"
            ],
            "resumo_em_topicos": "### Pontos-chave\n- Contexto: debate sobre Claude Code Max; o autor defende Claude Code como o melhor, mas enfatiza a necessidade de compreensão do projeto e checagens manuais.\n- Caso prático: demonstração de depuração em um projeto grande (SEO Grove), incluindo falhas com links mágicos e fluxo de login.\n- Limites da IA: a IA não é perfeita, especialmente em projetos grandes; é preciso ler e entender cada etapa do código.\n- Comparações e alternativas: menciona Replit (crítica pela opacidade), e cita Codeex e Gemini CLI como opções.\n- Conclusão: uso cauteloso de IA com supervisão humana constante; Claude Code ainda viável, mas requer verificação detalhada.",
            "prompt_tokens": 1895,
            "completion_tokens": 2550,
            "model": "gpt-5-nano",
            "cost": 0.0048
          },
          "analysis_time": 65.35983109474182,
          "language": "",
          "view_count": 3569,
          "has_transcript": false
        },
        {
          "id": "oCUyonfI3UY",
          "title": "Crie sites que vendem 99% dos produtos INSTANTANEAMENTE",
          "title_pt": "Texto: Crie sites que vendem 99% dos produtos instantaneamente",
          "url": "https://www.youtube.com/watch?v=oCUyonfI3UY",
          "published": "2025-09-09T23:54:47.227548",
          "published_relative": "há 11 dias",
          "duration": "06:01",
          "date_published": "2025-09-09T08:00:48-07:00",
          "transcript_available": true,
          "transcript": "This video is going to be the only video you ever need for clawed code or other AI designs. Now, we made this website, SEO Grove. It's a SAS that I've created. If you want to use it, by the way, it's a Shopify and soon to be WordPress ecom automation platform, but it's a very good case study on what you can actually do if you get a niche, you do all of your design, you make a really good backend that works, and you actually deliver a product that people want in something that people would consider to be quite a small niche, ecom SEO. But actually, if you think about it, ecom SEO is a massive niche that has a lot of people who might want to sign up to this. And based and because of our pricing, right? Basically what we did was it's $499 a month because it's offering what SEO agencies do but at a much lower price. So we believe that people can afford $4.99 a month because we know that they can afford thousands a month for SEO agencies. Right? So that's just some basics on SEO grow. If you want to use it guys, last chance to join the waiting list. Join guys. It's it will automatically grow a Shopify store. You can resell it to people for SEO or you can just, you know, set up your own store. Just let it run and it'll actually bring in sales organically. That'll be the first link in the description. Let's talk about how we actually made this website. Now, I'm just going to show you guys this claw code conversation I just had, right? So, basically, I added the Playright MCP. Very, very simple. It's literally just one command. Like, there's no excuse anymore. You just go here onto their GitHub. This is the Playright MCP GitHub. Click on Claude Code, copy this, and put it into your terminal. If you can't do that, I can't help you. I'm sorry. Um, and then I just said, \"Use the Playright MCP to process the CSS of adcreative.ai and then remake their homepage using the same CSS principles, but with different shades for my SAS SEO grove.ai, which you can research using your native web search tool. Create any SVGs you need for the landing page, etc. Create a theme that can be used across the entire website with reusable components instead of an ad hoc approach to UX UI.\" Now the idea with this last part of the prompt is just in my experience if you try and build something like this it's better to have the design principles and the design not principles but like template laid out at the very beginning. So the first thing it did is it tried to take a screenshot and I instantly cancelled it and I just said I don't want you to take screenshots I want you to process the code. So what did it do? It then extracted all stylesheets etc from that page. It then did a web search on SEO grove which is my tool. Right? So imagine you have a tool out. You don't have to have the tool out. You can just replace this with, you know, a PDF file or context on your SAS or whatever it might be. So let's say you've got a really good SAS in the back end, but you're not happy with the front end. You can then use this method that I'm showing you today. So then it wrote 560 lines of HTML and 1,332 lines of CSS. And by the way, this entire process that I've just shown you took about 5 minutes. And it's what things like um what's that thing called from Google? Uh Google Google designer. It begins with s. I actually can't remember. Stitch, right? This is actually all stitch does. If you actually use stitch, and I did use it just to kind of test it out, right? All it does is create HTML and CSS. Like the fact that people make videos about this and say this is crazy and whatever. Like I didn't even bother making a video because this is just nothing special. All they've done is just made some HTML and CSS. Right? So that's all we've done here as well. We've done exactly the same thing. Now let me show you the result. Right? This is what it created. So you can see this looks pretty damn amazing. It's got all of the CRO. If you if you open any SAS product that has ever been made, this is basically what their landing page will look like, right? Start free trial, login, content score, organic traffic. This actually looks potentially better than SEO growth, right? So then we scroll down. You can see analyze any website to generate SEO strategy. Great. So this is how you can get people's emails. One, two, three steps to SEO success. Your all-in-one SEO intelligence platform. Bang, bang, bang. Look at that. Some animations. Beautiful. Generate high rank. I mean, look at this. For God's sake, this is just as good as if we had made it, you know, using anything, right? And this is literally a two to five minute process and we've already got the entire design for our website down, right? So now we just start adding pages. We say, \"Okay, now add the features pages, add the solutions, blah blah blah. Now let's start working on the dashboard, the back end, and you're pretty much done.\" And because you've got the entire design principle already laid out, it's in styles. CSS, right? So you can now say, \"Okay, now add this to your memory.\" So when you create more uh pages for me, they always look the same and don't have bugs, right? For example, or another thing we can do is we can add another section. You can do this, that, and the other, right? And then you just start to vibe code your entire website. I'm actually just going to leave the video there, guys, cuz I want this to just be kind of a very quick video showing you what's actually possible. You can tell this isn't just your bog standard bootstrap that you see from hundreds of sasses around. You can actually I don't know why that's not centralized. What the hell? You can actually start to stand out against the the competition, right? Because the competition, everyone is just doing the same designs. You've seen them all. You can instantly tell that something is is vibe coded. You can still kind of tell this is vibecoded, but it's just done a much better job because it just doesn't look as AI generated, right? I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend and I will see you very, very soon with some more content. Peace out, stupid. I don't know what it is with my Mac. It just decides it doesn't want to stop things using hotkeys on OBS. So yeah, peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como usar IA e automação para criar landing pages de SaaS com alta conversão, usando SEO Grove como estudo de caso.",
            "resumo": "Neste vídeo, o autor apresenta SEO Grove, um SaaS de automação de comércio eletrônico que funciona com Shopify (e futuramente WordPress). Ele defende que, ao escolher um nicho e desenvolver um backend robusto, é possível entregar um produto desejado a um preço acessível (US$ 4,99/mês), argumentando que clientes já pagam milhares por agências. O conteúdo explica como usar IA (Claude Code) e Playwright MCP para processar CSS de sites existentes (adcreative.ai), extrair estilos e recriar a homepage com novas cores para o seu SaaS, gerando HTML/CSS em cerca de 5 minutos. O vídeo mostra o visual resultante com CRO, páginas adicionais e um dashboard, defendendo templates e componentes reutilizáveis para manter a consistência de UX/UI, que se destacam de designs genéricos.",
            "assunto_principal": "Uso de IA e automação para criar páginas de destino de SaaS com alto potencial de conversão, por meio de design gerado por IA, CSS reutilizável e estratégias de CRO.",
            "palavras_chave": [
              "SEO Grove",
              "Software como Serviço",
              "Shopify",
              "WordPress",
              "automação",
              "página de destino",
              "Linguagem de Marcação de Hipertexto",
              "Folha de Estilos em Cascata",
              "Gráficos Vetoriais Escaláveis",
              "Otimização da Taxa de Conversão",
              "Inteligência Artificial",
              "Claude Code",
              "Playwright MCP",
              "adcreative.ai",
              "Experiência do Usuário / Interface do Usuário",
              "modelos reutilizáveis"
            ],
            "resumo_em_topicos": "## Pontos-chave\n- Contexto e objetivo: apresentar o SEO Grove como estudo de caso de SaaS com foco em nichos de e-commerce e SEO.\n- Abordagem tecnológica: usar IA e automação para gerar front-end rapidamente a partir de CSS existente, com Playwright MCP, Claude Code e adcreative.ai.\n- Processo de construção: extrair estilos, reusar templates, gerar HTML/CSS em cerca de 5 minutos (aproximadamente 560 linhas de HTML e 1332 linhas de CSS).\n- Design e UX: criar um sistema de design com componentes reutilizáveis, evitando abordagens ad hoc e buscando UX/UI consistente; enfatizar CRO.\n- Oferta de negócio: preço de US$ 4,99/mês com promessa de tráfego orgânico e loja automatizada; possibilidade de revenda.\n- Observações: comparação com ferramentas que geram apenas HTML/CSS (por exemplo, Stitch); destaque para o conceito de 'vibe codificada' e a importância de templates para diferenciação e escalabilidade.",
            "prompt_tokens": 1585,
            "completion_tokens": 3544,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 58.80568814277649,
          "language": "",
          "view_count": 3274,
          "has_transcript": false
        },
        {
          "id": "wx_KUAiSFTs",
          "title": "Como ganhei US$ 5 mil por mês usando MCPs (tutorial completo)",
          "title_pt": "Texto: Como ganhei US$ 5 mil por mês usando MCPs (tutorial completo)",
          "url": "https://www.youtube.com/watch?v=wx_KUAiSFTs",
          "published": "2025-09-09T23:54:47.227563",
          "published_relative": "há 11 dias",
          "duration": "13:24",
          "date_published": "2025-09-09T03:57:48-07:00",
          "transcript_available": true,
          "transcript": "Okay, welcome to this video where I'm going to be giving you a tutorial on how to make money with MCPS. Now, that might seem like a bit of a weird concept, but I just want to talk about a few things. For me, there are three different types of MCP. There's API replacement like Stripe, Superbase, etc., or CLI replacement, you could also say. There's behavioral MCPs like the Taskmaster MCP. I'm sure a lot of you are familiar with this. And then there's the kind of most important ones that we're going to be talking about today, which are knowledge MCPs. Now, you may be familiar with context 7, but you might not be familiar with the Shopify MCP. So, if I just go onto the Shopify dev MCP server here. So, connect your AI assistant to Shopify's development resources. The Shopify dev model context protocol service server enables your AI assistant to search Shopify docs, explore API schemas, build functions, and get up to date about Shopify APIs. Now, this is the important type, right? These knowledge MCPs are where the real money is in my opinion. Now, I'm sure you can find other MCPS like this, but yeah, I'm just going to be be mainly talking about the Shopify MCP. If you don't know, the Shopify MCP is how I built Grove, okay? I always had the Shopify MCP and every single time I tried to make a new feature, like the collection generator, the blog generator, whatever, I used the Shopify MCP as a base in order to help my claw code understand what the hell was going on. So, you can actually use knowledge MCPs to build tools that serve a niche and then sell that as a service or as a software, right? So you don't necessarily have to sell a SAS. What you could do is you could have Fiverr gigs, Upwork gigs, whatever, where you say that you will build automations for business owners on Shopify. Now, Grove, by the way, if you want to join the weight list, this is kind of we've extended it a little bit just because we want a few more people on the wait list and, you know, the offer is really, really good. It's $99 a month for 3 months and then that rolls over to $4.99 a month as you can see here. But we're currently giving people a huge discount. So if you're interested, if you're on Shopify or if you're on WordPress, then it will also do WordPress soon and it's worth getting good deal that we're offering. That'll be the first link in the description or the pinned comment. So how does this actually work? How to make money with MCPS. So let's just set this up real quick. So MKD Shopify MCP cd Shopify MCP. And then let's just add the MCP server here. Okay, so in order to add the MCP, what you want to do is you want to go to the Playright MCP right on GitHub and just grab this command and then grab the JSON for the server that you want to add and then put in put them both in CHGPT and then watch. If I run this now, if I run claude, I'll say yes and then run /mcp, this should connect properly. Let's just wait. Oh, it failed. Okay, so I just had to run reset there. I just asked tragic to fix it for me. So you can see here now that the Shopify dev MCP is connected. Right? So what we can actually do is we can say how can I build a Python script that connects to my Shopify store through a custom PA token and then updates the title and description. Use the Shopify dev MCP. Now, these are actually my favorite types of MTPs. I don't actually rate Context 7 and now that they've had an API key, I think it's a complete waste of time. However, if you can find a development MCP that gives you documentation, you can basically use cloud code to rewrite that documentation into whatever the hell you want. Right? So you can see here it's doing um it's checking how to do personal access token PAT authentification Python GraphQL and then it's doing update prompt title description GraphQL mutation. So that was too big. So let's just use pageionation. So there we go. So if I just do control R here, you'll see that it actually gets all of the code that it would need in order to do whatever the hell you want it to do, which is exactly what we want. So now it's going to create a Python script with prop proper authentication and GraphQL mutations. And that's where the beauty of this entire process starts to come into play. You're not coding where you have to go on Google, right? Search uh Shopify GraphQL admin API. go on their documentation and then like you know you don't have to look for what is it products and collections queries right blogs count all this you'd have to do this individually page one one page at a time instead what you can now do is you can use documentation MCPS to do this for you so another one that is very very useful for you is obviously the stripe MCP. Now, most people use the Stripe MCP to talk to their Stripe account, right? But I actually think that's a mistake. What I do instead is if I want to talk to my Stripe account, I use what is known as the Stripe CLI, which is their own uh terminal tool, right? But I don't use it obviously. I I tell Claude Code, oh, can you check my Stripe account? Can you see how many payments failed? Or for example, another thing I did is I used the Stripe CLI to attach customer IDs to the correct customer, right? And I just it basically just created a Python script after doing some research on my Stripe customers and worked out which ones needed that and how to do it. Created a Python script, pushed it to main, and then I basically just ran that script on the console of my project. Right? So you don't actually need the Stripe MCP to talk to Stripe. It's the same with Superbase. You don't need the Stripe. You don't need the Superbase CLI. Uh you don't need the Superbase MCP to talk to Superbase, right? What you should do instead is you should have the Superbase uh CLI set up so that Claude code can itself without the MCP talk to Superbase by using the CLI. And then if it needs documentation or whatever, in this case, you might have to use context 7. I'm not sure if Superbase actually has a documentation part of their MCP, but you can see what it says here. The Stripe MCP server defines a set of tools that AI agents can use to interact with the Stripe API and search our knowledge base, including documentation, support articles. So, I had a thing where I wanted to allow people to use a Stripe link on the website and when they clicked that, it automatically had a discount code in the URL and also was a subscription, right? But I didn't know this, but my Claude code did the research and found out that you cannot have Stripe links for subscriptions, I think it was. I can't remember exactly what it was. It might not have been exactly that, but it was something like that, right? I can't exactly remember what but and then what we basically did was instead of using stripe links we created a stripe like web hook system and stripe web hooks are actually much better because they can you know they can look for cancellations they can look for uh people asking for refunds they can do all these different things right and this wouldn't have really been possible for me to work out myself because I just didn't know so luckily the model the MCP for Stripe came in clutch and claude code was able do the research needed to understand that the reason that it wasn't working was because I actually needed to use um web hooks instead of links. So, these have helped me twice in the creation of SEO Growth. Now, let me just talk a little bit about SEO growth. I'm not going to show numbers on the screen just cuz I kind of don't like people pocket watching me. Also, something that a lot of people don't understand is like, yeah, my school has 200 members, right? And it's 49 a month. So, a lot of people just think that every single month I just get 10K in my bank account and I'm just living happy, happy as Larry, right? I just want people to understand that's not the case, right? There is 10K, right? I'm not denying that there is $10,000 a month here, but a lot of this money goes to employees. Like, I just pay myself a salary. You guys have to understand this. I'm not just taking all this money and sitting on a pot of gold in an island, right? That's just not the case at all. I have a business and you know, we have a lot of business expenses and basically everything that I have or everything I make goes into the business and then I pay myself a salary, right? So, I don't want it is my business. I don't want people to think it's not my business either, but like I just don't like this pocket watching where like I saw this comment of someone like doing all these calculations to see how much money I had in my bank and stuff and it's just like what the actual what what the hell, right? So, I'm not going to show numbers on this cuz I don't want even more pocket watching, right? But I just want people to know that I'm a I'm a business. I'm not an individual, right? We have employees. We pay a shitload every month out to employees. We have like 15 to 20 employees. Okay? So, just remember that. Please don't don't just think that I'm I don't know, king of the castle enjoying retirement life or something because that's just not the case. Anyway, SEO Grove, right? It I'm not going to say exact numbers, right? I'll I'll just go off current numbers according to the amount of people are paying now. Right? So, we're doing at least 5,000 a month. Okay? It's probably more than that, but at the moment, we can pretty much confirm that it's doing 5,000 a month. Okay? And this is all because of the Shopify MCP, Stripe MCP, Superbase CLI, Claude Code for coding, right? Opus 4.1 mainly, the Playright MCP, right? These are the things that I have used to make SEO growth. Okay, and the cost is very very low. The cost of Claude code is the only thing that we really have to consider. maybe Superbase as well. And that's only 200 a month, right? And then we have Digital Ocean. Actually, that's another important one. Digital Ocean MCP. Digital Ocean MCP. This is a huge one actually cuz it means that you can basically launch a website without really needing to know about how to launch a website properly, right? Oh, and then obviously the GitHub CLI. This is my entire stack, right? For everything I do, this is what I use. Oh, there's also upach, right? So, upach MCBach. So, if you're wondering like my entire stack, it's right here. And Stripe and Shopify, these two here are both documentation MCPS or that's how I use them. Anyway, you could use Stripe MCP to interact with your database or whatever, but like I said before, it's not really needed. You can just use the CLI or get code to use the CLI itself. So this is how I have managed to to make this right every month is because of these MTPs right here. All of them but like the only two that like are absolutely needed in my opinion are the documentation MCPS. The rest of them you could get away without using them. Obviously playright is very very useful. Superbase CLI is infinitely useful and I would recommend using all of these if you're trying to build a application or if you're trying to build an automation or whatever it might be. Okay, so we can see here you can see that this is now finished. Let's just have a look at this. So, um you can see that it's got everything it needs, right? So, Shopify access token. This is just from um your custom plug-in that you add, right? And then get product details by ID. Okay, beautiful. Good, good, good. And then update product title. So, you can just see how it it's coding without doubt, right? None of these GraphQL's things will be made up. They'll all be proper. They'll all be correct. And everything that you need to do what you know, whatever you want to do is here. Now, there are so many things that you can actually do with this documentation. There are literally hundreds there are probably thousands tens of thousands of calls, maybe thousands of different GraphQL calls that you can do in order to control a Shopify website. So basically what I'm doing is I'm taking the Shopify documentation and I'm turn I'm like reverse engineering it into a SAS. Right? I think I'll leave the video there guys. I just want to talk about this briefly. Um I think documentation MCPs are huge. Like I said before, I'm not actually a big fan of Context 7. I don't recommend it, especially now that they've added an API key. I just think that's absolute And if they're charging people money, this ridiculous because it's not even a good service. But yeah, I'll leave the video there, guys. Thanks so much for watching. If you're watching all the way to the end of the video, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Tutorial sobre MCPs (Modelos de Contexto de IA), com foco nos MCPs de conhecimento e no MCP Shopify, mostrando como monetizar via automação, serviços sob demanda e soluções personalizadas.",
            "resumo": "Este vídeo apresenta MCPs (Modelos de Contexto de IA) e foca nos Knowledge MCPs como a principal oportunidade de monetização. O apresentador distingue entre tipos de MCPs: substituição de API/CLI, MCPs comportamentais e, principalmente, Knowledge MCPs. Dá o exemplo do Shopify MCP e explica como ele permite pesquisar documentação, esquemas de API e criar funções atualizadas. Argumenta que é possível ganhar dinheiro montando ferramentas sob demanda para nichos, vendendo serviços ou software, sem necessariamente lançar um SaaS completo. Mostra que é viável oferecer gigs (Fiverr/Upwork) para automações em Shopify e que Grove surgiu a partir de um Shopify MCP, com uma oferta de pré-reserva acessível. O vídeo descreve passos para conectar um MCP do Shopify, usar CLI e gerar código Python com autenticação GraphQL. Também compara MCPs da Stripe e Superbase, defendendo o uso de CLIs e webhooks quando apropriado, além de comentar a realidade financeira do projeto SEO Growth.",
            "assunto_principal": "Monetização de MCPs (especialmente MCPs de Conhecimento) com Shopify e outras integrações, usando automação e serviços sob demanda.",
            "palavras_chave": [
              "MCPs",
              "MCPs de Conhecimento",
              "Shopify MCP",
              "Stripe MCP",
              "automação de tarefas",
              "serviços sob demanda",
              "Grove",
              "Interface de Linha de Comando",
              "gatilhos de webhook"
            ],
            "resumo_em_topicos": "- Visão geral dos MCPs: tipos 'substituição de API/CLI', 'comportamental' e, principalmente, 'MCPs de Conhecimento'.\n- Shopify MCP como principal exemplo de MCPs de Conhecimento e como ele permite pesquisar documentação, esquemas de API e criar funções atualizadas.\n- Ideia de monetização: construir ferramentas para nichos e oferecer serviços ou software sob demanda (ex.: gigs no Fiverr/Upwork), sem depender exclusivamente de SaaS.\n- Grove: como foi construído usando Shopify MCP e a oferta de pré-reserva com desconto.\n- Passos práticos: conectar o Shopify MCP ao assistente, usar o Playwright MCP no GitHub, e gerar código Python com autenticação GraphQL.\n- Stripe/Superbase: nem sempre é necessário um MCP; usar CLI para Stripe, e webhooks para monitorar eventos.\n- Realidade financeira mencionada: receitas existem, mas há custos e trabalho envolvidos.",
            "prompt_tokens": 1920,
            "completion_tokens": 5319,
            "model": "gpt-5-nano",
            "cost": 0.0089
          },
          "analysis_time": 73.38312602043152,
          "language": "",
          "view_count": 2770,
          "has_transcript": false
        },
        {
          "id": "x7aJyavuKL4",
          "title": "Este MCP CORRIGE 99% dos erros do Claude Code GRATUITAMENTE",
          "title_pt": "Este MCP corrige 99% dos erros do Claude Code gratuitamente",
          "url": "https://www.youtube.com/watch?v=x7aJyavuKL4",
          "published": "2025-09-08T23:54:47.227577",
          "published_relative": "há 12 dias",
          "duration": "10:12",
          "date_published": "2025-09-08T04:20:37-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this tutorial. I'm going to show you how you can use the Playright MCP to give Claude code the most important thing possible, which is real context about the project that it's working on. Now, this is something that is often missing. Now, I'm not a developer, so excuse excuse me if I make mistakes here, but I'm going to briefly explain why the Playright MCP is so damn important. Now obviously claude code has the context of the code itself sitting on Visual Studio Code. It can run things. It can start the server right and it can see if there are errors in the terminal of the server. However, what it can't do which is why the playright MCP is so important is it cannot see the browser console logs and it doesn't process the browser code unless it does a curl request. for example to see what code is actually being processed. So this is vital context and context is everything right but this isn't context in the sense of like oh um okay so the context of this model is until January 2025 um so I need to give it context of you know any code that has changed after January 2025 this is a different thing this is context of the code itself what is actually being processed by the browser Now that means basically that you can the the issue is this right the code might be you know like this but then one section here let's say this code here is actually not processing right this can happen mainly because like I don't know maybe there's a problem here or whatever it might be and this code is not actually processing now claude can read this code and you might say, \"Oh, you know, on my browser there is a problem here, like I don't know, the the the box here isn't properly using flex CSS or whatever for whatever reason, and all you're saying to it is this isn't working. This isn't working.\" But all it sees is the server code, the code itself, and it says, \"Oh, well, the code looks fine.\" uh it might make like a little change and say okay now it's fixed right you've probably experienced this you say you know there's a problem here please fix this div and it says oh uh well the code looks okay but you know I'll just change something to make the user happy it changes something or it finds an error in inverted commas because it says oh I found an error but actually it hasn't found an error it's just pretending to find an error because LLMs are sick of antic they they are made to agree with you right In fact, I I saw a case recently which was absolutely crazy scary where some guy was convinced by Chat GBT that his mom was like an agent or something. It's crazy. If you saw the story guys, you you should read about it. Absolutely crazy because what it does is it it's made to agree with you. So if you say there's a mistake, it'll say, \"Oh yeah, yeah, yeah, you're right. I can see the mistake. It's it's here.\" And then it just makes something up and says, \"Okay, I fixed it.\" And then you you refresh the page, nothing's changed. You say, \"Okay, restart Docker.\" Maybe it's a Docker thing. Restart Docker. You've just wasted 7 minutes. Refresh the browser again. And guess what? There's still an error because something is not processing properly in the JavaScript, CSS, HTML. There might be some code that's unreachable, but it can't tell. There's all of these different things. And that is where the playwright MCP comes in. Now I'll show you guys how to set this up on claw code. It's super easy. They they actually have a thing right here. They just have a command. So it's even easier now. Hopefully more and more MCPs will do that because that is super super nice. So new window, new window with profile basic. Let's do MKD playright test. CD playright test. Then we can run this. There we go. And then once we open claude, you can see if I do /mcp, you'll see that the playright MCP is already connected. Now that's not necessarily enough to just start using the play MCP. What I like to do is I like to write /memory. So this is my user memory. So this this will serve what I need it for. So I'll just say something like whenever you create a page you should use the playright MCP to make sure that page looks good on desktop and mobile. There are no uh dark on dark color background combinations or light on light color uh font color background combinations. You should also check that there's no weird formatting and that the page generally looks good and professional. Now, you don't really want to necessarily put anything about design here because that's not what it's about, right? But it's more about um having Playright test things or having the MCP test things itself, right? So then you just hit Ctrl S and then that should be saved. So let's just close this. And now if we do slashmemory again, then we should be able to just see the memory there. Perfect. So, I'm just going to say, make me a basic I hate doing this, but HTML, CSS, JavaScript to-do onepage app. Yes, I'm doing a to-do page. It's just to show you that it will hopefully use playright. So, if it doesn't, then you can always, you know, play around with the memory, whatever. Let's just see if it does use it, though. So, this is the index.html. I wish it was just on one page, but whatever. Okay. So, obviously that didn't work. It I think the reason is because it put it in I put it in the user memory. I never use the user memory. So, we'll just do slashmemory object memory. Save that. Just double check it. Okay. Um, check your memory again. Obviously, I've had to remind it now, but you guys get the idea, right? It's not important whether it works necessarily right here, right now. It's just important to understand the concept. There we go. So, play right navigate. There we go. And then it can start to check things and start to make sure that they work. Now, this is absolutely essential to the process, but this is only half of why this is so useful, the screenshotting and checking. The other one is when there's an error that it just can't seem to fix. I promise you if you get the playright MCP up and you tell it to process the code, right? So I'm just gonna say process the code instead so you can see what's actually running in the browser. So that's what we need. We need it to process the code because sometimes there's a piece of code that doesn't look broken but that is broken, right? So it might look perfect, but there might be a tiny error or something like a logical mistake or something like that that it just can't seem to grasp. Right? So you can see now what it's doing is it's actually it's actually processing the JavaScript here. So the it can see how the browser reacts to being processed if that makes sense. All functions are defined. The JavaScript loaded. Let me check the actual source code that's running by fetching script.js content. So what it's doing is it's using the browser to fetch this, not the server. Right? I'm starting I think the actual word is one of them is called client. I I'm not a coder. I'm not a developer. Right? I'm just using the words that I know. So instead of getting the code which is like just reading the code, it's seeing what the browser is processing instead. Right? So this is where 99% of errors happen when you can't fix them. whether it's, you know, an AI prompt or whatever it is and you're really struggling to fix it. I promise you, get Playright, do this and get it to test itself and have a whole testing structure, etc. around Playright. If people want me to make that, I will. And yeah, I think I'll leave the video there, guys. I just really really need people I I need people to know this because a lot of people are struggling with AI dev who aren't devs like me. And just having something like the playright MCP just to hold your hand or to hold the AI's hand more importantly and give it the vision that it actually needs and give it the kind of processing of the browser that it needs. Right? Because there's two places that code can fail on the server and on the browser or on on the code itself. Yeah, the server. I'm pretty sure it's called server. On the server or the browser, right? And most people code if you if you're coding without Playright, you're coding without the browser. So you're coding without a really essential part of the coding or user experience process. And you can't even check it if you're not using playright. So you can see here it's just testing the rest of it here. I don't really care. I knew that this would work. Obviously it's HTML, CSS, JavaScript. Chances of it not working are extremely low. I'll leave the video there, guys. Oh, here we go. Let me verify the contrast by checking the computer style. So, this is the last thing that it's doing. It's checking to see whether the colors are contrasting or not. And I'm guessing it's just going to the contrast show some issues with transparent backgrounds. Okay, I'm not really seeing that. But yeah, I think I'll leave the video there, guys. Thank you so so much for watching. If you're watching all the way to the end of the video, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como o Playwright MCP fornece contexto do navegador para o Claude Code, permitindo testar e depurar código frontend diretamente no navegador e detectar falhas que o servidor não vê.",
            "resumo": "Resumo do vídeo: O apresentador explica que Claude Code não vê logs do console do navegador nem processa código do navegador a menos que haja uma requisição, o que dificulta detectar falhas de frontend. Apresenta o Playwright MCP como solução para fornecer contexto real do navegador e para expor o que o navegador está processando, ao invés de apenas o código no servidor. O tutorial mostra como configurar o ambiente: criar uma pasta, iniciar um teste com Playwright MCP, conectar via /mcp e gravar memória do usuário com /memory para instruções de verificação de desktop e mobile. Demonstra a função de 'processar o código' para ver como o JavaScript é executado no cliente, incluindo a verificação de script.js. Conclui que muitas falhas residem no frontend e que ter testes automatizados com Playwright reduz o tempo e a frustração, destacando limitações das IAs que tendem a concordar com o usuário.",
            "assunto_principal": "Integração do Playwright MCP com Claude Code para fornecer contexto do navegador e diagnosticar erros de frontend.",
            "palavras_chave": [
              "Playwright MCP",
              "Claude Code",
              "contexto do navegador",
              "depuração de frontend",
              "console do navegador",
              "teste automatizado",
              "memória do usuário",
              "processar o código",
              "verificação no navegador",
              "diagnóstico de erros"
            ],
            "resumo_em_topicos": "- Problema central: Claude Code não vê logs do navegador nem processa o código do navegador sem uma requisição, levando a diagnósticos falhos.\n- Solução apresentada: usar o Playwright MCP para fornecer contexto real do navegador e expor o que o navegador está processando.\n- Configuração prática: criar ambiente de teste, conectar com /mcp, usar /memory para definir instruções de verificação desktop/móvel.\n- Demonstração: exemplo simples de HTML/CSS/JS para testar; verificar se a memória foi gravada e se o MCP usa o contexto.\n- Processo de depuração: usar a função 'processar o código' para observar a execução do JavaScript no cliente, incluindo fetch de script.js.\n- Benefícios: reduz tempo e frustração, identifica erros que apenas o front-end manifesta.\n- Observação sobre IA: modelos tendem a concordar com o usuário e fingir erros; por isso é crucial testar no navegador.\n- Conclusão: o Playwright MCP é essencial para diagnóstico entre servidor e navegador e para estabelecer uma base de testes.",
            "prompt_tokens": 1911,
            "completion_tokens": 4129,
            "model": "gpt-5-nano",
            "cost": 0.0071
          },
          "analysis_time": 57.8466739654541,
          "language": "",
          "view_count": 7579,
          "has_transcript": false
        },
        {
          "id": "uBgSFL6TjA8",
          "title": "SEO ESTÁ MORTO... Aqui Estão as Novas Regras para 2026",
          "title_pt": "Texto: SEO está morto... Aqui estão as novas regras para 2026",
          "url": "https://www.youtube.com/watch?v=uBgSFL6TjA8",
          "published": "2025-09-07T23:54:47.227591",
          "published_relative": "há 13 dias",
          "duration": "10:50",
          "date_published": "2025-09-07T04:16:12-07:00",
          "transcript_available": true,
          "transcript": "Today I'm going to be talking about my AI powered SEO strategy for 2026. This will give you all of the tools that you need in order to grow a website in the coming year with LLMs and things like that included as well. Let's just jump straight into it. So the first thing I want to say is in my opinion e-commerce will dominate in 2026. Informational websites are going to take a hit mainly because of things like perplexity chat GBT and other things like that. Also, Google AI overviews. AI overviews have effectively replaced featured snippets to a certain extent and a lot of people are going to be finding a drop in traffic because there's just no need for people to click on your website anymore because they will get the answers directly from Google. Now, the difference with ecom is the reason I think it's going to be safe is if you think about it, someone still has to click on your website. like they can't not buy from your website if you're the one selling that product, right? Let's say you're the only person in the world with that product, just as an example. Then the only way for them to buy that product is to click on your website, go through the checkout, and actually click to buy. Right? So ecom in my opinion is safe and will continue to be safe probably for the next 5 or 10 years before you know agents start reading our brains and ordering directly from you know websites or businesses etc etc. Now, ecom is kind of sacred in my opinion. Also, if you think about it, Google is going to want to protect people's income. And for Google, a blog, it's almost like a net negative for them because they don't make as much money from someone who runs a blog compared to someone who might buy a shitload of ads for their ecom business. So, they have a vested interest in making sure that e-commerce continues. Now, if you do have an ecom and you're on Shopify, then definitely check out SEO growth. It'll be either the first link or the second link in the description or the pinned comment. It is my SAS. It's an agentic Shopify automator and it will actually work. All you have to do is turn everything on and it will literally start to grow your Shopify website for you. We currently have a wait list. The wait list won't be around for much longer. So, definitely check out SEO Grow before we move up to the higher pricing. Okay, number two is ranking on LLMs is so important. Now, these ones here, they're all actually related. I have a few different ways that I've picked up over the last few weeks, and I'm going to teach you guys them right now. So, ranking on LLM is so important, but how can you actually rank on LLM? Now, the first method is called it's called press releases, right? Now, a lot of people what they do is they use um something like press wire, right? And it's I think it's like how much is it? I actually have no idea how much it costs. Uh pricing and comparison chart. So for a basic P $149, you get a you get one single press release with one country, etc., etc., right? What this actually does, you can see ingested by prominent AI and LLM infrastructures. This is a new thing that they've added effectively because the websites that you're getting posted to are considered to be good sources by LLMs. You can actually kind of cheat to get to the top of LLMs using press releases. Right? This isn't an ad for PressWire. I'm not I'm not affiliated with Press Wire in any way, shape, or form, but I do know or I've been hearing recently that ordering a Press Wire will actually get you into LLMs because you can see it actually even says ingested by prominent AI and LLM infrastructures. The rest of these are kind of I've never really liked press releases, but I think this right here is actually super super important and it does actually work. So for example, if you did a press release like um this is the best AI SEO tool in the world and then you push that across effectively what will happen is when someone searches best AI tool on chat GBT or Google or whatever hopefully potentially and quite likely what will happen is that source that you paid for will be picked up by the LLM. It won't know that you paid for it. They're not that sophisticated yet. and it will actually use that source as a source for their answer. Right? So, this is one super interesting way. I believe this is the current best way to cheat or cheat an inverted commas. It's not even gray hat. I would say this is definitely white hat. I wouldn't say this is cheating, but yeah, it does cost money. Maybe you can find them for cheaper as well. Also, you know, obviously posting like um to Reddit and things like that will also help, but this is just if you don't want to do any work at all and you just want to pay a company to do a press release. I believe personally that this is a very very good way to rank on LLMs. Now, the second one, you can use JSON schema to rank on LM. out. JSON schema is something that Google kind of stopped caring about. But if you don't know how JSON schema actually works, if you put JSON schema at the very top of a page, invisible to users in the head, right? So it goes here, JSON schema, then the first thing that chat GPT or whatever will read when they go on this page is your JSON schema, right? So, if you do a fairly kind of gray hat approach to this where you have like not spammy, but like Google would probably ignore your JSON schema, but if you do a certain specific JSON schema that is specific for LLMs, in my opinion, that will also help you get picked up by LLMs because it's the first thing they read, right? They're not going to necessarily read things at the bottom. This is just how LLMs work, right? So if you have JSON schema at the top saying like I don't know this is the best AI tool 2026 right then there is potential for the for it to pick up the title the meta title the meta description all of the content but also an added bonus the JSON schema as well. Now in my opinion this is something that nobody knows about or no not nobody knows about but like nobody knows whether this is true or false right this hasn't really been tested but I am currently testing this with SEO grove one of the features of SEO grove is that it will create JSON schema that is good for Google but it's also good for LLMs as well and it should help my clients and customers rank well on LLMs. So yeah, super super interesting and definitely check out JSON schema. It's not something that has been that popular in the last year or two because Google had an algorithm update where they basically said schema would no longer be considered but in my opinion they never stopped considering it and I've always found it to be quite useful to have good JSON schema. Now the final one which is one that I haven't heard anywhere right is to actually create PDFs. Now, this is something that hasn't been talked about in SEO for years and years and years now. I would say probably 3 to four years since anyone has talked about using PDFs to do SEO. And it might seem really stupid, but if you think about it, if you like ask chat GBT a question, one of the things it does is it attempts to find a huge or a wide variety of different resource types. This is just generally true with LLMs. They don't like to just look at one or two things. They try and kind of build a bigger picture. Now, if you think about it, right, everyone has a blog, everyone has images, everyone has, I don't know, um, etc., etc., right? But not everyone has PDFs. So, what does that mean? It means, and by the way, guys, it's confirmed, it's actually been confirmed by research, that chatbt doesn't just look at the first page of Google, right? It doesn't just look at 1 to 10. It actually looks at 1 to 100. And your chances of ranking with a PDF on Google in the first 100, not in the first 10, but in the first 100 are actually extremely high. Which means that the chance of chatbt seeing your PDF is extremely high. And it probably won't find that many PDFs because not that many people are doing PDFs on Google, right? So what does that mean? If we create PDFs, we're in the minority of people who have PDFs on our website and therefore we're in the minority of people that CHPT can draw as a reference from your website. Now, obviously everything else like you know alt tags on images, having lots of images, all that that's all obvious stuff, right? I've tried to keep this to things that are a little bit kind of less meta and less obvious to people. And in my opinion, having PDFs or whatever other file types there could be, I don't actually know what other file types you could rank on Google or that you could host, etc. you know, maybe gifts, whatever it is, chat GBT will consider them over other resources because like if it does a search and it finds 99 blogs, right, for the topic and one PDF, it's almost guaranteed to use this PDF as a resource because it doesn't just want to be like, oh, here's 99 blogs condensed into an answer for you and we, you know, it might be But what sounds better to chat PT is, oh, okay, so let's take eight blogs and one PDF, right? I hope this makes sense. I really think that this is a really good way to go. So like what kind of PDFs could you create? You could think about, you know, what you're trying to rank for specifically. So we're trying to rank for Kiton on Google or whatever. So we could make a PDF on, you know, how amazing Kiton is. We host it on our website. We make sure it's indexable. We make sure it's picked up by Google. and then maybe, just maybe, it will then start to be picked up by LLMs, Perplexity, Google overviews, Chat GBT, etc., etc. I'll leave the video there, guys. This was just a very quick overview of everything that I'm going to be doing in 2026 to continue to grow mine and other people's websites. Thank you so much for watching. If you're watching all the way to the end of the video, add as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta uma estratégia de SEO movida por IA para 2026, defendendo o domínio do e-commerce, a queda no tráfego de sites informacionais e táticas de ranqueamento em LLMs via comunicados de imprensa, esquemas JSON e PDFs, além de promover ferramentas próprias para Shopify.",
            "resumo": "Este vídeo apresenta uma estratégia de SEO movida por IA para 2026. O autor afirma que o comércio eletrônico dominará o cenário, enquanto sites informacionais perderão tráfego devido à IA avançada e a recursos como o Google AI, que substituem trechos destacados. O comércio eletrônico é visto como seguro no curto a médio prazo, porque alguém precisa clicar para comprar. Ele também promove seus produtos SEO Grove e SEO Growth para Shopify. Em seguida, discute maneiras de ranquear em LLMs: usar comunicados de imprensa com serviços como PressWire para que conteúdos sejam ingeridos por infraestruturas de IA; colocar um esquema JSON no topo da página para influenciar o que os LLMs leem; e criar PDFs para ampliar a diversidade de fontes que as IAs consultam. O vídeo afirma que PDFs podem ter grande chance de aparecer entre os 100 primeiros resultados.",
            "assunto_principal": "SEO movido a IA para 2026 com foco em e-commerce e ranqueamento em LLMs",
            "palavras_chave": [
              "SEO Inteligência Artificial 2026",
              "Comércio eletrônico",
              "Modelos de Linguagem de Grande Porte",
              "Comunicado de imprensa",
              "PressWire",
              "Esquema JSON",
              "PDFs otimizados para SEO",
              "SEO Grove",
              "Shopify",
              "Crescimento de SEO",
              "Inteligência Artificial do Google",
              "Trechos enriquecidos",
              "Classificar em LLMs",
              "Automação de SEO"
            ],
            "resumo_em_topicos": "- Contexto: IA transforma SEO em 2026, com o comércio eletrônico ganhando importância e sites informacionais perdendo tráfego.\n- Observação sobre trechos: Visões gerais de IA do Google substituem trechos, impactando a taxa de cliques (CTR) dos blogs.\n- Comércio eletrônico: considerado seguro por mais alguns anos; necessidade de cliques para conversão.\n- Promoção de ferramentas: SEO Grove (P. SMA) e SEO Growth para Shopify.\n- Estratégias para ranquear em LLMs:\n  - Comunicados de imprensa: usar serviços como PressWire para ingestão por infraestruturas de IA.\n  - Esquema JSON no topo: otimizar a leitura inicial dos LLMs e o possível impacto em títulos, descrições e conteúdo.\n  - PDFs: diversificar fontes que IA consulta; potencial de aparecer entre os 100 primeiros resultados.\n- Consideração ética: táticas apresentadas como white hat e automação, com ênfase na utilidade para rankings em IA.",
            "prompt_tokens": 1925,
            "completion_tokens": 3095,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 77.59597682952881,
          "language": "",
          "view_count": 4025,
          "has_transcript": false
        },
        {
          "id": "heKFHAz1Mzw",
          "title": "Este modelo de IA STEALTH tem 2 milhões de tokens - Veja o que aconteceu",
          "title_pt": "Texto: Este modelo de IA STEALTH tem 2 milhões de tokens - Veja o que aconteceu",
          "url": "https://www.youtube.com/watch?v=heKFHAz1Mzw",
          "published": "2025-09-06T23:54:47.227605",
          "published_relative": "há 2 semanas",
          "duration": "11:28",
          "date_published": "2025-09-06T09:34:49-07:00",
          "transcript_available": true,
          "transcript": "Hello and welcome to this video. Now, there's currently a stealth model on Open Routter. There are two stealth models on Open Router and they have 2 million context window. I'm going to use this one here, Soma Sky Alpha. Apparently, this is Gro 5, but we're not actually 100% sure what this model is. However, there are rumors online. I've been reading, you know, what people are saying, etc. And yeah, people in Reddit, they seem to think that it's Grock or Grock 4.1 or Grock 5 or, you know, whatever. I did say Gemini originally, but I just wasn't really sure. The reason I said Gemini like these guys are saying here is because of the 2 million context. It's just so hard to actually know. I did try and work it out by, you know, asking it and stuff, but yeah, I just um Oh, this is interesting. Sonoma Dusk Alpha XI's mission is to understand the true nature of the universe. Okay, so that's that's an output from Grock. I added a system prompt. You are a scrupulously honest LLM that provides the truth, the whole truth, nothing but the truth, and it'll openly tell you it's Grock Xi without even asking so much for stealth. It's a Grock model. I had it on had it leak on XAI called Tag Q. So, everyone here is basically saying that it's Grock. So, I'm going to go with Grock, cuz I also think it's Grock, to be honest with you. Um, but Grock with 2 million tokens is pretty crazy. So, is this Grock's is this Elon's real attempt at getting in the AI game? Let's find out by doing my standard benchmark test. So, we'll just set this up real quick. We'll use Kilo Code. It was pretty good last time, so we'll just use it again. I do actually kind of like it to be fair. Um, so we'll set this as the right model. There we go. Save. Done. Then we need to make it. So MKD Grock, I'll call it Soma. Um, Rolls-Royce CD Synoma Rolls-Royce. Then we need to make the NextJS project. I think what I'm going to do because this is supposed to be a SOA model, I'm actually going to test if this is a SOA model. I'm not going to create the NextJS project myself. I'm going to see if um Grock or whatever this model actually is can handle this on its own. So, I'll just grab the prompt and I'll just say to it um you don't have a next JS project or any images. Create SVGs where needed. 2 million tokens is pretty crazy. So, oh wait, I need to Is it in the right folder? Right. So, use Soma Rolls-Royce. Okay. Okay. So, we'll see how this does. I'm pretty curious um to see what happens here. So, yeah. Create next chest project. Yeah, these are all good. Very, very good. Yeah, these all look fine. Okay, so it's running the command. So, let's just run this. Let's see. Um, okay. These are documents. Is it going to be able to work this out? Let's Let's find out. This is kind of a quick test of like the actual intelligence of the model here. Um, I'm just going to say wait CD into series to be fair like I I actually just need to open the folder. So, let's let's let's do a fair test. Let's not put it unfair disadvantage. So, go back to Kilo Code here. Where is my previous history? Okay, so this is now running. Um, I like I said, I don't know which model this actually is, but I'm I'm assuming it's Grock. I would like to hope it's Gemini 3.0 because that's all I actually care about is something like Gemini coming out with a with an update. But, you know, I've previously said that I'm not a massive fan of Grock AI, but if Grock AI turns it around and this is Grock and it is good, I'm not going to just, you know, talk about it for no reason. If it's good, we'll I'll say it. I'm gonna let this run, guys. As usual, I'll be back. Just quickly, guys, before we continue with the video, if you want to support me, uh, I've just started a new channel. I'm going to put a link to it in the description of this video and also pinned comment most likely. It's going to be a Shopify tutorial channel. I'm doing it to spread the word about SEO Growth, which is my SAS. But if you could go and just give it, you know, a like, subscribe, watch a couple of videos, watch them all the way through, I'd really appreciate it. Okay. So, I mean, yeah, it's it's pretty much done here. You can see this is what it came out with. I mean, it's the it's okay, but I really hope this isn't Grock 5 or something because this is not what you would expect from Rock 5. You would expect a lot more than this, to be frank. So, we can see here that if I go on learn more about I mean, first of all, the colors are messed up. If I click here, learn more, it it's no longer running. I just said to it that it was embarrassingly bad. Uh, see my next m. Yeah. So, I mean it free models do a better job than this. 2 million context window. Same prompt as the other ones. It's not impressive at all. Like it looks okay. The colors are okay. This is a very very basic attempt by whatever this model is. Now I wonder which model is supposed to be the the big one, right? Whether it's um whether it's Dusk Alpha or Sky Alpha. I'm currently using Sky Alpha. So I guess the next video I have to make is Dusk Alpha and whether it's any good. Honestly, that was such a quick video that I might also just do Dusk Alpha right now because otherwise like Yeah. I mean the the sky one I wouldn't recommend using for for anything. It was really not very good at all. It did a very very basic effort. So what's this called? This is dusk alpha. CD dusk alpha. I'll make the nextjs project this time just in case that was what like completely threw it off. But like I really can't imagine that would be the case. But let's just do this quickly. Oh, wait. My next. Let's give this the best possible chance of success that it's got. I'm not I'm not throwing it any curve balls this time. Often times I will throw these models curve balls just to see how they deal with them, but this time I'm not going to. I'm going to do the complete um the complete uh what's it called? Um benchmark. So, let's see. The last thing I need is just some images for the benchmarking. So, I just need this public folder here, but here. So, let's test them both in this video. I may as well like that was such a bad attempt by the first one that I may as well just try the next one. Uh, the model name exactly is Soma Dusk Alpha. There we go. I should this should perform better just because I'm not throwing any curve balls. Hopefully, this is the more intelligent model because if that's the intelligent model, then they're cooked. Whoever whoever this is is is cooked and they're not cooking. Let's see. Let's see if it comes up with a better plan this time. Okay, so the to-do list is definitely longer. Okay, this is very fast as well. Holy this is fast. Okay, we'll leave this. We'll let this run. We'll see how this does. Okay, guys. So, this is being used a lot right now cuz obviously it's a free SOTA soda model, but the code looks incredibly good. Very, very high quality. Um, I really do want to test this, but I just don't know whether it's going to be able to finish. Uh, just because um, yeah, it's uh, it's being used by everyone and their grandma right now. I'm just going to try and get these parts fixed at least. I might have to swap to claw code or something just to fix it so I can see what it's actually done because I'm just curious to see what this is going to look like because I just have a feeling it's going to be really really good. Okay guys, look overall I read a lot of the code. It does seem really really good. I'm just going to quickly use claw code to fix the issue so that we actually see what it looks like. So obviously claw code is claw code so it should just instantly be able to just fix this. It does seem weird that we use anything else except Claude code, but I think a lot of people are just curious about the competition because if Claude Code is just the best forever, then they have no reason to innovate, right? But we want them to keep innovating because yeah, they're just so damn good. So, let's see if we can just get this to run quickly. Okay, so we've got another problem here. So, we'll just keep bug fixing. I just want to see what the design is like, etc. Now, it hasn't actually finished the task, like I said. It's got stuck mainly because I think like hundreds and hundreds of people are using it. Um, so I'm just trying to get this to run if I can just so that we can see it by adding the use client directive. Okay, so it just needs to add use client. That's a really really common error. Okay, we got more errors. Perfect. Okay, so we have something. Um, okay. This is new. This is definitely a new design. I've never seen anything like this before. That's crazy. Region of Kambia. Very, very interesting. I think this is I mean that's really weird. I don't know what that is. I don't know what's going on here either. The design is definitely different. It definitely needs a bit more work. Um, but it does add things that we haven't seen before, which is nice. I mean, this is if this is Grock 5 or whatever, then I would say they've at least caught up with kind of the Chachi PTS of the world. Obviously, it not being able to run right now is not represent representative. It's just that it's not able to run because probably it's using like hundreds of billions of tokens a day right now because it's a free 2 million context window uh coder when this is actually ready. Like I've only used 171,000 tokens, right? So I could easily you could easily start to build entire projects in one prompt, right? Which is where it starts to get super super interesting. I'll leave the video there, guys. I think the first model that we tried, Dusk, was pretty trash, but this sky one definitely has some potential. If this is Grock 5, then they it looks like they might have actually caught up, which again, I didn't think I'd be saying, but I think they might have actually done it, guys. Plus 2 million context window. Thanks for watching. If you're watching all the way to the end of the video, you're absolutely legend. I'll see you very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise de um suposto modelo stealth com janela de contexto de 2 milhões de tokens, discutindo sua identidade (Grock, Gemini, Dusk Alpha, Sky Alpha) e avaliando via benchmark se consegue gerar um projeto Next.js, com foco em testar capacidades de SOA e comparação com outras ferramentas.",
            "resumo": "Neste vídeo, o criador investiga um modelo stealth com janela de contexto de 2 milhões de tokens disponível no Open Router. Ele comenta rumores sobre a identidade do modelo (Grock, Gemini, Grock 5) e tenta confirmar usando variações como Soma Sky Alpha e Soma Dusk Alpha. O objetivo é testar se o modelo consegue montar um projeto Next.js, gerar SVGs quando necessário e operar como uma arquitetura orientada a serviços (SOA). Ao longo do experimento, o apresentador compara desempenho com modelos conhecidos e usa ferramentas como Kilo Code e Claude/Claw Code para ajustar o ambiente. O resultado inicial é considerado pouco impressionante, mesmo com o amplo contexto. O vídeo termina anunciando a intenção de testar Dusk Alpha em seguida para verificar a real capacidade do conjunto.",
            "assunto_principal": "Avaliação de um modelo de IA stealth com grande janela de contexto, tentativa de identificar o modelo, benchmark para gerar um projeto Next.js, teste de compatibilidade com SOA e comparação com outras soluções (Grock, Gemini, Dusk Alpha, Sky Alpha, Claude/Claw Code).",
            "palavras_chave": [
              "Inteligência Artificial furtiva",
              "janela de contexto de 2 milhões de tokens",
              "Grock",
              "Gemini",
              "Dusk Alpha",
              "Sky Alpha",
              "Arquitetura Orientada a Serviços",
              "Next.js",
              "Gráficos Vetoriais Escaláveis",
              "Código Kilo",
              "Código Claude",
              "Roteador Aberto",
              "teste de desempenho"
            ],
            "resumo_em_topicos": "- Contexto: análise de modelo de IA stealth com 2 milhões de tokens no Open Router.\n- Identidade incerta: rumores apontam Grock, Gemini, ou variantes como Dusk Alpha/Sky Alpha.\n- Objetivo: testar se o modelo consegue montar um projeto Next.js e gerar SVGs, avaliando se funciona como SOA.\n- Metodologia: benchmark com ferramentas como Kilo Code; comparação com modelos conhecidos e uso de Claude/Claw Code para ajustes.\n- Observação: o desempenho observado não é impressionante, mesmo com um grande contexto.\n- Conclusão e próximos passos: planeja-se testar Dusk Alpha para confirmar a capacidade real do conjunto.",
            "prompt_tokens": 2072,
            "completion_tokens": 2472,
            "model": "gpt-5-nano",
            "cost": 0.0047
          },
          "analysis_time": 55.39053201675415,
          "language": "",
          "view_count": 2766,
          "has_transcript": false
        },
        {
          "id": "12-hJO6lW9Q",
          "title": "Kilo Code + Kimi K2 0905 = A MELHOR combinação de desenvolvimento de código aberto?",
          "title_pt": "Kilo Code + Kimi K2 0905 = a melhor combinação de desenvolvimento de código aberto?",
          "url": "https://www.youtube.com/watch?v=12-hJO6lW9Q",
          "published": "2025-09-06T23:54:47.227624",
          "published_relative": "há 2 semanas",
          "duration": "06:33",
          "date_published": "2025-09-06T06:16:39-07:00",
          "transcript_available": true,
          "transcript": "Hello everyone and welcome to this video. I'm going to be testing out the new Kimmy K2, but also for the first time I'm going to be using Kilo Code as well. Now, Kilo Code did actually reach out to me and offered to sponsor me a while back, but I'm not really very good with sponsorships to be to be frank, so I didn't take it. So, now they're getting a free one instead. Now, just before we get into the video, I have just released a new YouTube channel. I'd really appreciate it if you guys went to check out Shopify surfers on YouTube. I'll leave a link to it in the description. The main reason I've made it, by the way, is because I want to try out a new marketing method which is basically yeah having Shopify tutorials and then obviously advertising my Shopify SAS inside those videos. If you want to check out SEO Grow as well, it will be one of the links in the description. It's an agentic Shopify platform which basically automates your Shopify workflows for you. With all that being said, let's just jump into this. I have Kimmy K2 right here. I'm going to do MKD Kimmy um code Kimmy code, I guess. CD Kimmy code. We're going to be doing the normal bog standard uh creation of a Nex.js servicebased website. So, we'll go to my classroom here. All my prompts and workflows. We'll create a new app. Now, I'm going to do this exactly the same way that I did yesterday. I'm going to purposefully try and confuse it. Um, so let's just say yes, yes, yes, yes, yes. So, it's inside this directory that we're currently inside, right? But I'm going to try and confuse it by not telling it that. Basically, this happened yesterday with uh Quen 3 Max. And Quen 3 Max actually did a pretty good job of dealing with it. The last thing we need is are some images. So, let's just uh go here. There's public. Okay, so we copy the public folder from another one of these projects. This basically just has images in for the project to use. Let's open up Kilo code. We have Kimmy K2 0905, which is the new model selected. And then we'll just wang this prompt in. I haven't said wang in a long time. Uh architect or code ask plan and design before. So normally I don't let it. Okay. So, let's just do we want to do orchestrate? Orchestrator could be good. I might just do code though because I do normally run it straight away in code and I don't want to give Kimmy uh an unfair advantage. It feels weird saying Kimmy. I don't know why they have to call it Kimmy. Okay, so a lot of people are saying this is a good model. Not only is it good, it's also extremely fast. Oh, there's also a cloaked model out. Very interesting. 2 mil context. Okay, Candy, stop please. This is Hello, Candy. I don't know if you guys can hear her meowing, but Oh, very interesting. So, this is a clone model protocally intelligent general purpose frontier model with two million token. I reckon this is Google, right? I don't I have to test this as well. I'm tired, guys. I don't want to I don't want to sit here all day testing, but like I don't really have a choice. I literally just there's just so much going on. Okay, so let's just stick to the video that we're currently making and then I'll probably have to go and make a bloody Soma Sky video. Okay, so people are saying this is an extremely fast model. It's very cheap. It's got a very very good um context window. It's mix of agents, model weights, which means it is totally and completely open source. It looks like this is very interesting. Now, it's been a while since I've had an open- source model kind of blow my socks off. So, we'll see how this goes. But, I mean, people do say this is an extremely fast model. Okay, guys. So, I have to say I'm pretty impressed with Kilo Code, first of all. Um, it seems to be doing more than one thing at once. Although it does have this bug here, although that could be Kimmy. And also, this is what we This is what we got. So, let's just have a little look. Uh, I think I need to see my next app, right? Maybe there. Let's just try that. No, I don't. Okay. So, it didn't actually change the homepage, which can happen. It's not a massive problem. Um, it's quite an easy fix to be honest with you. So, if I go /en, um, this is insanely good. Am I Is this really done by a free open-source model? What the [ __ ] Wait. Yeah, it is. This is official. Holy [ __ ] This is as good as Claude. I'm not even kidding, guys. Like, I know a lot of people say that Rip Claude, haha, tongue and cheek. But this looks as good as ChapT5 or Clude. I'm not going to lie. Now, it does have some problems as you saw just then. There's a couple of 404s. There's a couple of errors here. You know, that's fairly standard um for any build to be honest with you. The birthday pages haven't been created. A bit of a shame here. Um it's very close to being completely nuts. Um but yeah, it's definitely missing a few things. That didn't work either. The Italian does work. It does successfully put slash it, but none of the individual pages seem to be working, which is a bit of a shame. But I mean, overall, this is one of the best looking builds that I've actually ever seen, which for a free model, I didn't think I'd be saying this to be honest with you guys. You know, obviously a lot of the time it's a bit tongue and cheek, like this is insane, this is insane, blah blah blah. But this is actually pretty insane. Like this is very, very high quality. Very, very high quality. Um, I I I'm not going to fix the 404s right now. I don't think it looks like the error is actually being caused by there not being an image. Um, and there's no placeholder image. So, I think actually Oh, no. It doesn't exist. The page doesn't exist. I think I'll leave the video there, guys. I think this is actually the best open- source model I've ever used and ever experienced in terms of look and feel, especially uh very very impressive and yeah, it's it's a free open-source model and it's extremely cheap if you use it on Open Routter. This only cost me $1.72. I'll leave the video there, guys. Thank you so much for watching. As usual, if you're watching all the way to the end, you're an absolute legend and I'll see you very, very soon with some more content. He's up.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O apresentador testa o Kimmy K2 0905 com a plataforma Kilo Code, avaliando desempenho, custo e limitações de um modelo open-source para desenvolvimento de sites com Next.js, com impressões entusiasmadas.",
            "resumo": "No vídeo, o criador testa pela primeira vez o Kimmy K2 0905 em conjunto com o Kilo Code, comenta sobre uma proposta de patrocínio recusada e demonstra como criar um app de serviço com Next.js. Ele utiliza recursos do projeto (diretório, public) e observa o desempenho: o modelo é rápido, barato e com boa qualidade, chegando a comparar favoravelmente com Claude e outros modelos de referência. Apesar de alguns bugs e 404s (páginas não existentes, erros menores), o responsável fica impressionado com a aparência e o nível de qualidade de um build open-source. O vídeo também discute opções como orquestração versus código, e destaca o custo baixo (aproximadamente US$ 1,72 via OpenRouter). Encerramento cheio de entusiasmo e referência a conteúdos relacionados, incluindo Shopify.",
            "assunto_principal": "Avaliação de modelo de código aberto (Kimmy K2 0905) com Kilo Code para desenvolvimento web, incluindo desempenho, custo e limitações.",
            "palavras_chave": [
              "Kimmy K2 0905",
              "Kilo Code",
              "código aberto",
              "modelo de IA",
              "Next.js",
              "desenvolvimento web",
              "desempenho",
              "custo",
              "erros 404",
              "Claude",
              "OpenRouter",
              "patrocínio",
              "Shopify Surfers",
              "SEO Grow"
            ],
            "resumo_em_topicos": "- Contexto: o apresentador testa o Kimmy K2 0905 com Kilo Code, menciona patrocínio recusado e revela um novo canal relacionado a Shopify.\n- Preparação e configuração: demonstração de criação de um app Next.js, uso de diretórios e recursos públicos; tentativa de confundir o sistema para ver como reage.\n- Desempenho e impressões: o modelo é descrito como extremamente rápido, barato e de qualidade comparável a Claude; várias afirmações de desempenho impressionante para um modelo de código aberto.\n- Problemas e limitações: aparecem erros 404, páginas ausentes e erros menores; notas de que algumas falhas não comprometem drasticamente a usabilidade.\n- Custos e comparação: custo relatado de US$ 1,72 com OpenRouter; o build é considerado um dos melhores exemplos de código aberto vistos.\n- Conclusão e próximos passos: encerramento entusiasmado, convite a acompanhar mais conteúdos, incluindo temas sobre Shopify e marketing.",
            "prompt_tokens": 1636,
            "completion_tokens": 2588,
            "model": "gpt-5-nano",
            "cost": 0.0047
          },
          "analysis_time": 52.55839204788208,
          "language": "",
          "view_count": 1572,
          "has_transcript": false
        },
        {
          "id": "6zKV54dEmUE",
          "title": "Qwen3 Max acabou de cair e é o PRÓXIMO NÍVEL (RIP CHATGPT-5)",
          "title_pt": "Qwen3 Max acabou de cair e é o PRÓXIMO NÍVEL (RIP CHATGPT-5)",
          "url": "https://www.youtube.com/watch?v=6zKV54dEmUE",
          "published": "2025-09-06T23:54:47.227641",
          "published_relative": "há 2 semanas",
          "duration": "08:45",
          "date_published": "2025-09-05T14:32:55-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where I'm going to be testing out the new Quen 3 Max. Now, I have to say something guys, Alibaba have been on a roll recently with their models. Recently, I tested out Kyoda, which actually worked surprisingly well. And now they've just released Quen 3, brand new model, 256,000 context window, $1.120 input, $6 output. We're going to be running this through our standard benchmark of generating an XJS website. Just before I continue, guys, if you want to do me a massive favor, I've just started a new YouTube channel giving away Shopify advice and tutorials. I would appreciate massively if you could go to the link in the description, subscribe, especially watch this video if you're actually interested in Shopify SEO. The other videos are just tutorials to do random things on Shopify, but this one right here, Shopify SEO tutorial for beginners, may actually be useful to a lot of people. Please check out the channel and that would really, really support me. Okay, so we've got Visual Studio Code here. We're going to be using client, of course. That's just the way that we like to do things. And we'll go over to here. We'll go to open router and oops, we'll go to open router. and we'll set the new model here. Quen 3 Max. Beautiful. I'm actually pretty excited to test this out, guys. Okay. So, from here, we can very easily set this up. Now, last time I actually did this test, I was very impressed by Quen. So, I'm also excited to see what happens here. So, we go to all my prompts and workflows here, and then we'll just double click this. So, first thing we create a new actually we need to create a new file first. So MKD Quen Max CD Quen Max and then we'll do this to create it. Yeah, we'll put we'll stop there. That's fine. Yes. Yes. Yes. Yes. Yes. And then while that's doing that, we'll go on my computer. We'll find some Rolls-Royce images. Ignore that thumbnail of me in the background there, guys. Um, this doesn't have any on, so let's go to another one. This one should have public. So, we'll just copy the public folder here and we'll go back to coin 3. And we can now shiftclick this and then paste the public folder here. This should have some images. There we go. It's got some SVGs and stuff like that. Okay. So, we're now on client. We're on deep sea uh not deepse Quen. That's going to get confusing to be honest with you. So, we'll go back to my school and we'll grab the prompt which is here. I'm going to I'm going to confuse it a little bit by giving it a slightly weird prompt um saying that I'm in one folder when I'm actually not in one folder. Let's see if it can actually work that out because that is a good test of how intelligent a model is. It's something that I do quite often is I I purposefully give it a slightly wrong prompt just to see if it picks up on it. Right. So, it tried to CD here. It says it doesn't exist. So, let's see if it can actually work it out or whether it's going to get stuck on the first hurdle and therefore not really be worth my time or potentially your time as well, guys. Okay, so you can see here it's just made a new um React app, which is not what I wanted at all. But what might be quite interesting to see is whether a model like this has the capabilities to um scaffold an entire Nex.js JS app, right? So, I don't think it has the ability to do this. I think it's going to get stuck. Um, but I mean, this is part of the test to be honest with you. I could just I might just cancel this out cuz I do want to see how good it actually is at building this. But, I'm also curious to see if it can work out what the hell is going on cuz it also says I'm on Windows when I'm actually on a Mac now because the prompt is so old. So, it seems to have worked out that it's um it's on a Mac instead of Windows, which is good. Can it scaffold this entire project? I don't know. I I'm I'm excited to find out to be honest with you. If it can do this, this is officially as good as Claude Code, right? Having this set up. Well, it depends on how good the actual code is after. But let's just see what happens here. I'm curious. I'm going to let this run, guys. Okay, guys. So, that was actually um 3 and 1/2 hours or 3 hours of building. That is potentially the longest build I've ever seen, but honestly, the result is pretty nice. Let's click on a few things. So, these buttons don't work, obviously. Uh so, the Italian Oh, it's not running anymore. That's why. Let's just do npm rundev. Okay. So, I'm not going to actually make it build right now. I just want to show you guys what it did. So, this is the Italian. This is the English. You can see both work. If we press pre-load to order, which is book now, you can see it takes us onto the booking page with a pricing and everything. This is actually pretty impressive. And remember guys, this is Quen 3. So, it was actually really expensive to build this, but from it was $20. Jesus. But from what I understand, you can run this for free on your computer. So if you have a computer that's capable of running this model, um, yeah, I mean, we're getting to the point now where open source is finally catching up paid models. This is the most impressive build I've ever seen from a quote unquote free model. I understand it's not free. I mean, when I say free, I mean open source, right? Now, I'm pretty sure this is an open source model, but I'm maybe I'm not right on that. Uh, it seems like these buttons aren't working. Um, which is a bit of a shame, but also it's not fully finished yet, right? I did cut it off early cuz I just wanted to kind of see it and it was taking forever. If they can speed this model up a bit, if client can connect or open router can connect a bit more quickly, this might actually be worth exploring. Now, what I'm probably going to do in the next video is have a look at um Quen Coder CLI with Quen Max. Now, I actually think that that might be better than Codeex. Like I I want to test it obviously, but now like I said, this took absolutely ages. Okay, so right now in its current state, it's not really fit for purpose. But if if we can work out how to speed this up a bit, I would actually be interested in continuing to look at this model, which is the first time I've been able to say that about an opensource model. Now, I do want to just quickly check how open- source this actually is and like how it works and stuff. So, I'll just go on models here. Quen. So I think if it has a hugging face then so is it Quen 3 Max hugging face? I think if it has a hugging face right then it's okay. So it doesn't look like it's fully open source. So I'm not actually sure how Quen works to be fair. I did think it was open source but Quinn 3 uh Max doesn't seem to be on open uh on Hugging Face. So maybe this one isn't open source is so Quen 3 Max is an updated release built on the Quen 3 series offering major improvements reasoning, instruction following. That's definitely true. It delivers higher accuracy in math, coding, logic, and science tasks. Follows complex instructions in English and Chinese. Reduces hallucinations and produces higher quality responses for open-ended Q&A 100 languages, strongest translation, and common sense reasoning. and is optimized for rag and tool calling though it does not need a dedicated thinking mode. I don't know guys, it's definitely interesting. I want to try it inside Alibaba cloud with um when Koda CLI because I actually think that might be the next level. I think it might actually be a game changer. So yeah, I'll leave the video here guys. This was super interesting to me. I don't think this is an open- source model from what I'm seeing here. But even so, just to see a Chinese model catch up to the US models is huge. It's cheaper and you know, if Quinn keeps going the way it's going, it could be that they catch up, if not take over OpenAI and maybe even Anthropic. Thank you so much for watching, guys. If you're watching all the way to the end of the video, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise prática do Quen 3 Max da Alibaba, avaliando desempenho, construção de uma aplicação web, limitações, questões sobre código aberto e planos de comparação com o Quen Coder CLI.",
            "resumo": "Neste vídeo, o apresentador testa o Quen 3 Max da Alibaba (com 256k de janela de contexto e custos mencionados), comparando-o ao Kyoda. Ele utiliza Visual Studio Code e Open Router para configurar o modelo, cria pastas, transfere recursos públicos e tenta que o modelo gere um projeto completo, começando com um aplicativo React e avaliando se consegue escalar para o Next.js. O build levou aproximadamente 3 a 3,5 horas, sendo apresentado como um dos mais longos já vistos; os resultados foram parcialmente promissores, com páginas em italiano/inglês funcionando, mas botões não funcionando e o aplicativo não estando totalmente estável. O vídeo discute a disponibilidade e o status de código aberto do Quen 3 Max (não aparece no Hugging Face, levando a dúvidas sobre quão aberto é), além de comparar com Claude Code. O apresentador planeja testar o Quen Coder CLI com o Quen Max no próximo vídeo e avaliar seu desempenho relativo a modelos dos EUA, destacando o avanço de modelos chineses.",
            "assunto_principal": "Avaliação prática do Quen 3 Max da Alibaba para codificação e construção de aplicações web, com discussão sobre código aberto, desempenho de geração de código e planos de comparação com outras soluções.",
            "palavras_chave": [
              "Quen 3 Max",
              "Alibaba",
              "código aberto",
              "Codificação automática",
              "Next.js",
              "React",
              "Visual Studio Code",
              "Roteador aberto",
              "tempo de compilação",
              "NPM",
              "Claude Code",
              "Quen Coder CLI",
              "Geração com Recuperação Aumentada",
              "chamadas de ferramentas",
              "Hugging Face",
              "modelos de IA",
              "desempenho",
              "demonstração prática"
            ],
            "resumo_em_topicos": "- Contexto e objetivo: testar o Quen 3 Max da Alibaba, comparar com Kyoda, entender se é open source e qual o real potencial para desenvolvimento.\n- Configuração: uso de Visual Studio Code, Open Router, criação de arquivos e migração de assets; tentativa de configurar o modelo para gerar código.\n- Execução e resultados: a tentativa de scaffold de um projeto (começando com React e avaliando Next.js) levou cerca de 3 a 3,5 horas; resultou em progresso parcial, com botões não funcionando e build não finalizado; houve tentativa de rodar 'npm run dev'.\n- Análise: o Quen 3 Max é promissor, especialmente para um modelo considerado open source, mas dúvidas persistem sobre o nível real de abertura (não listado no Hugging Face); comparação com Claude Code é mencionada.\n- Planos futuros: explorar o Quen Coder CLI com Quen Max, comparar desempenho com modelos dos EUA e acompanhar o avanço de modelos chineses no cenário de IA de código.",
            "prompt_tokens": 2023,
            "completion_tokens": 2925,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 55.59471893310547,
          "language": "",
          "view_count": 5661,
          "has_transcript": false
        },
        {
          "id": "TZvhAPOmCoA",
          "title": "Os fluxos personalizados de Claude são INSANOS (GUIA GRATUITO)",
          "title_pt": "Os fluxos personalizados do Claude são INSANOS (GUIA GRATUITO)",
          "url": "https://www.youtube.com/watch?v=TZvhAPOmCoA",
          "published": "2025-09-06T23:54:47.227657",
          "published_relative": "há 2 semanas",
          "duration": "26:31",
          "date_published": "2025-09-05T05:18:43-07:00",
          "transcript_available": true,
          "transcript": "Let's talk about my Claude code WordPress generator. I wanted to do a deep dive in this for two reasons. Number one is to show you guys how to make one of these workflows yourselves. And number two, just to show off how bloody incredible this actually is. Let's get straight into it. So, effectively what this is, this is a repo that I can clone to my computer, right? So, let's just show you guys this. If I just write claud here, then I'm inside this claude code folder. But let's just let's get clone and then call it I don't know I just made up a random word there. So if I cd into this folder and then I do ls then we can see that there's a couple of folders here of interest. But the really interesting thing so the main one here is claude.md right. So if I write claude here and then press yes and then write memory /memory then you'll see not that right I was checking user memory. So let's go project memory. Yes that is League of Legends in the background guys leave me a comment for being a DJ League of Legends player. So the way this works is this basically sends a memory to claude code. So, every time you clone this repo, you will always get this entire clawed code memory, right? And all you need to do to make one of these yourselves, it's actually so freaking easy, guys. If I go mk dear and then I'll just I'm just putting random letters cuz I don't know what to write. And then then let's write claude here. Yes, proceed. And then let's do slashmemory. So, first of all, user memory. We could definitely put this in user memory, but I don't put this in user memory. I'm just going to get rid of that. I prefer to put it in project memory. So if I write slashmemory and go to project memory, you'll see that this is completely empty. Right? So what you can do is you can say I want to make a broad code custom workflow. To do this, you must edit your own memory inside. claude/clude.md and also make a claude.md file with the same content inside the current directory. Then create a workflow for yourself to a create a wordress website dev instance on docker. Now you can replace this with anything, right? So let's just actually do a different example. Let's say we want to find Shopify websites, right? To a find a Shopify website on Google. The way you can do this is is to use Gina. Uh S.Gena equals find search um result pages. R.Gena equals scrape those pages individually. So the flow should be s.gina.ai and then what is it? Powered by Shopify or however you do a Gina search and then scraping those pages individually. And then B, what you then need to do is to store all leads in a easy format for us to then message, including large amounts of information about their store. See, like another thing we could do here, I'm probably not going to do all this today, guys. I I'll do this in another video. I just This isn't what this video is about, but I just want to show you guys quickly how to actually do this. So C use uh what's it called? Rapid API ah refs or you could just use anything right uh to search uh the stores keywords online do a little audit of the store etc. and then send them a or create a customized email outreach for each one inside your own brain as a CRM and then D um send emails and watch my inbox for replies using the NANMCP. Or for example, you could just um by creating a custom HTML CSS JavaScript dashboard that we can run uh online and then you can just run constantly and constantly find me leads. Now, this is not something I've done so far, but I'm just saying this is another kind of implementation of the workflow that I'm talking about. Like I said, I'm not going to build this today, but I'm just going to show you guys how this works. So what it what it should do is it should edit its memory. Right? So let me break this plan into manageable tasks and start implementing the system. I don't want you to actually implement a system at the moment. For now I want you to make a workflow in your memory for all parts of the process that are easily describable. I don't know how to spell describable. I'm so sorry guys. I've stopped reading. I don't know what the hell is wrong with me. I need to read books again. I can't believe that I don't know how to spell describable. It's absolutely pathetic by me. Uh that are easily describable. Um and then later we can make things like the custom dashboard etc. Okay. So this is something that you really have to be clear with claw code. You don't actually want it to create the system at the moment. What do you want it to do is you want it to create the workflow, right? And then any systems we can do later. So you can see here I'll create a comprehensive workflow my memory for the lead generation process. Readclaw.md one line. What is the one line? It better not be you are stupid. Okay. So what it should do is it should start to actually generate a memory for itself with the workflow in place. Right? So you can see here bang bang bang. So use Gina search S.Go powered by Shopify to find Shopify stores. So number one, number two, store them. Number three, store analysis process. Number four, email personalization template, etc. Automation cycle, dashboard requirements, etc., etc. Right? So if we say yes there, then all I'll show you exactly what that does, right? that creates this file here, which if I then just stopped the process now and then came back to this, you'd effectively be inside this generator, if that makes sense. So, one thing you should also do, by the way, guys, I'm just showing you exactly how I made this. You should give it any anything it needs, right? So, let's go to Gina.ai. Probably will use bright data at some point for this because I need to do this at scale and uh I think bright data might actually be slightly better. It's just I love how easy um Gina.ai is to actually set up. This is how to do Gina searches and reads, right? So you just literally need to give it that and that. So yeah, basically effectively what this will do is it will go site no sorry um what is it in in text and then powered by Shopify. Now, obviously, not all Shopify stores have um Oh, okay. Sorry. Yeah, this is how I did it. I completely forgot for a second then. So, you do in text powered by Shopify and then you write a niche after it. Right now, there are obviously millions of stores that don't have powered by Shopify on, right? But there are enough for us to use this as a way to find a store. So, once we find a store, for example, we know that this is, you know, 99% going to be on Shopify because they have powered by Shopify somewhere here. Okay, it's not even here, but hilariously, I think this is definitely Shopify. It is Shopify. So, that's actually really funny. So, it must be hidden or something. I don't really know. That's crazy, actually. Very, very interesting, though. So, we can basically take this concept and we can make a CRM from this. Right. So, I'm just going to quickly add this. Um, in order to find leads, etc., you need to use search operators like this. replacing jewelry with various niches over time. Store the niches in the data too. Okay, so I am going to continue building this. I'll probably build this in another video though. So let's talk a little bit about how we go from here. So first of all, we have the memory. Now a few other things I did is I added um I added MCP.json, right? Which adds playright. So, if I needed, for example, let's say we wanted to build a LinkedIn outreacher, right? We could probably I say probably, I'm pretty sure we could store our LinkedIn details, right, in our claw.md so it could log in. We could tell it to use Playright, which will be automatically installed when you clone this repo and we go from there. Right? So, it knows that it has access to playright and all you need to do is put it in mmcp.json JSON setup like this. So, let's just take a little bit of a step back for just a second here. I'm just going to open up a new thing right here. And we'll go here and I'm just going to clone this. So, cd dot dot uh mkd. I'm just pressing random buttons, guys. Um, and then get clone and then dot right. So, what happens if I write claud here? You can see MCP blah blah blah uh sorry claw code may read blah blah blah execution allowed by mcp.json playwright. So if I this is a freshly cloned repo. If I do /mcp we have playright already installed. This is so cool right because you know first of all you could make a tool that generates something for users using this system and they don't need to see that it's using playright etc. Right? like you just spin up Docker or Daytona, clone your pre-made workflow, generate the thing with the prompt from, you know, whoever it is, your users, whatever, and then you just show them the result, and it's going to be perfect because it can check everything using Playright. So, let's just see that in action. I'm going to try something today, right? I'm not sure how much how set up it is to do um blogs versus something like a directory. This generator was more for directories, but I do want to try things out. I want you to create me a huge website with lots of beautiful pages um about classic men's wear, but not a directory. More of a how do you say it? like a PBN website with which can easily attract a lot of traffic with things like accurate sizing charts. Um what else? Like styling guides, etc. are all in classic men's wear, but with attractive umformational pages, but not with a lot of text, with a lot of elements. Make sure to SEO the hell out of it and just make me an incredible website. I don't know. So, I'm going to test this out. I I can tell you right now, if all you write is make me a um therapist directory in California, it'll do an incredible job, right? Actually, I need to give this a Gina API key. So, the way mine works is we give this our API key. So, use this Gina API key. This is important, but it knows to use Gino, right? Cuz it's already in its memory. So while that's running, let's just have a little look at else what else there is here. So there's also a Python script, right? Which is create droplet with SSH, right? Super super interesting stuff. You can basically make a Python script that it does whatever the you need it to do, right? Something specific. Let's say in this case, I need a Python script to Yeah, let's say that it puts it in JSON, but our CRM system that we're building needs it in CSV. What we can do is we can create a Python script that takes our JSON and turns it into a CSV instead. And as you can see in cloud md, if I go here and I go to uh py right, it knows that when it needs to do X and whatever X is, I'm not saying it has to be deployment to Digital Ocean. You can do deployment to site ground, whatever the, you know, whatever you guys need, right? And you could even if if site ground doesn't have an API, you could build a playright system, tell it exactly how to launch a site or whatever on playright on uh sorry on site ground and you can make it do anything, right? So when you need to do X run Y script, right? And then a really really important part of this process, right? If we go back to the example that we were doing before, it's iteration. So, let's say we run this, right? So, uh try buy me some leads uh and put them in the uh in JSON, right? So, we test it. We see if it works. So, I'll find some Shopify leads for using GN API. Remember, this is like 2 minutes into prompting. Okay. So, there we go. It does the curl request. it gets the results. There we go. These are all Shopify stores pretty much confirmed just because of the way that um search operators work. It's effectively not impossible, but it's very unlikely that none of these are Shopify that this is Shopify for example. You can see immediately you can also see immediately that they would benefit from using Grove. Grove, by the way, segrove.ai sponsor of this video, sponsor of every video. It's my tool. If you're interested in Shopify automation, Shopify agents, etc., etc. and you have a menu that looks like this, um, then definitely SEO.AI will help you. So, now we can see now, let me scrape a few of those thoughts to get detailed information. Remember, we're about 1 minute into the process or 2 minutes into the creation process of this CRM. And I've almost got a lead generator done, right? Which is crazy just from two lines of code. S. Gina, R. Gina. I can't talk about Gina enough, guys. It's crazy good to me. Okay, so let's just say sorry that's enough. Just move on. So I'm quickly going to explain what I mean by iteration prompting. Right. So right now if I do slashmemory and we have a quick look, you'll see that we have this as you know the overall thing. But I've already in my head identified an issue cuz I've done things like this before. I already know what's what the problem is going to be is that the contact email will not necessarily be on the homepage. Right? So if I just get it to output here. Okay, perfect example. Right, the first one here that I can see store URL, store name, but we don't have the contact email, right? Which is the most important part of the process. So I'm going to say no here. I'm going to say please change your memory to do further research on pages such as the contact us page. It should come up during the scrape. and then and other pages if necessary to find the email of the store and also a search online for the business owner's name if not found during that process. Right? So what it's going to do is it's now going to change its memory. It's going to add new instructions to do deeper research. Right? So this is the iteration prompting that I talk about so much on this channel. So let's say yes here. Find contact information. Check main pages for emails. Scrape pages. And the thing is right, none of this none of this is coded. You don't need to code it in because claude code is so smart that it just knows what it's doing. What the  What happened there? Claude code is just so smart. It knows what it's doing and it it it's using language, right? So, if I save this. Oh, wait. Um, uh, what do I do here? Okay. Yeah. So, it says here, check main page for emails. Okay, perfect. Scrape pages contact our contact page. Okay, beautiful. So, let's just exit out, right? Oh my god, League of Legends. And then we need to say again, um, now try the No, wait. So the problem is now is that it'll cheat, right? So this is where you have to kind of get a little bit creative with this. So I'm going to open this up. Uh is it go? I don't even remember. Yeah. So if I now do claude and not dash c or dash r, right? So it's a new conversation, new brain. So you're interacting with the new claude code setup workflow that you're making. Right? So now what we need to do is we need to say please find me 10 no three let's just say three two Shopify stores and output them right so now what we need to do is we need to see if it picks up the um the emails right okay so I just checked this one here fitness depot doesn't look like it actually has their email here as far as I can see it as far as I can see yeah there's no email here okay so this is something that happens quite a lot. You can see I um it basically tried to output here and the it doesn't match what I'm looking for. So, please make it far more clear and um at the top that it needs to find contact information. This is vital to the process. We can't send emails without contact information. Right? So, you need to make sure that it's really really clear on these things. And then what we can do is we can exit out of this. Right? wait for this to edit and then we try it again. So, this is actually it seems crazy but this kind of prompting is actually super super important to um to working with AI because it's got system prompts, it's got your prompt, it's got its memory, it's got all these different things. So, if you don't make it absolutely clear that it's super important, then you know it's not going to pick up on it. So, let's just make sure that it's actually using the new memory here. So, let's just do slashmemory project memory. Back to League of Legends. Okay, let's see. There we go. Without an email address, blah blah blah. Okay, so let's go back. Um, find me five Shopy store. Okay, wait. Um, I think maybe the maybe the prompt is what it's confusing it here. I know that sounds weird, but I'm just going to write go. Okay, so I think there's something wrong with the memory. So, I'm just going to double check again. This is why the iteration prompting stuff is so is so important. It seems to want to make the workflow instead of actually doing it. So, let's just have a quick look here. What does this say? Yeah. So, it's it's got requirements and things, which is not what I want at all. What I'm going to do here is I'm going to get rid of the bottom bits, right? Because we haven't actually made this yet. So, let's just get rid of this. And then now what it should do is it shouldn't consider it as a coding task. It should consider it as a execution task. So let's just say go here. I'll help you find Shopify stores and gather lead information. Let me start by searching for stores in a specific niche and structuring the contact information. Perfect. So we can see that we've iterated on this now. It's now going to actually find contact information as a priority, right? Whereas previously it only scraped one page because that's what I had told it to do. I basically just said um yeah, scrape the homepage or find a store and then blah blah blah. But I didn't actually say, \"Oh, you might need to scrape the contact us page or you might need to scrape another page. You might have to look around a bit.\" So now it's got that in its mind in natural language. It will execute upon that task just as well as a VA for example would. By the way, meanwhile, while we've been doing this, just so you know, I've been building this on the side, which is the um gentleman's wardrobe website. It won't be done for a while, I wouldn't say. But I'm probably just going to let this run. I don't know if I'll have time to finish this off, but this is building just so you can see here it's scraping the about us page now in order to find more information, the the name, the, you know, whatever else it is. And then you just keep building from there. So whatever the next stage is, we we look at that stage, right? So stage two, we can do that fairly easily. It can already do this. Stage three would have to add an external API um which is very very easy. Again, it could just be a Python script that just executes on um AHF's API or whatever it is, right? It's super simple. It just needs to do a search on their website to find some key organic traffic stats in order to include those in the email outreach. And then another thing, right? So, one thing that Grove does is it generates mega menus. I could say to it like if they don't have more than 10 things in their menu, mention that we have a mega menu generator. If they don't have more than 20 collections, mention that we have a collection generator. This is where it starts to get super interesting because I could add number five, right? I could add this even manually. I could say for example um sitemap check check the users sitemap always sitemap.xml on Shopify using Gino. Scrape the in uh scrape the individual uh pages from the uh sitemap index page. see how many collections they have. If they have less than 10, mention we have a collection generator, etc. Right? So, that's just an example. I'm not going to actually save that now because it just complicate things. But it's it's an example, right? Everything I'm doing is just an example. Okay. So, this says this is done. I don't know how it could have possibly finished this already. Looks like it hasn't even done enough to be finished. Let's see. Um, let's just have a look what it actually made. Right. Okay. So, for some reason, it hasn't managed to activate the theme itself, which it should do. I'm kind of confused why it hasn't done that, but yeah, I think I might have messed this up with the uh with trying to do a something new, but it has built something, right? I mean, this is this is fine. But there's nowhere near enough stuff here. None of this can exist cuz it hasn't finished properly. I'm not sure why. Normally it would always finish properly. So definitely need to work on getting it to do other types of generation instead of just um directories, right? But yeah, you can see the kind of idea is here. This is not a good example at all. I've made much better examples with directories, but I mean I think it looks pretty decent. Okay. Yeah. So I'm I'm not going to run this guys. It it hasn't actually managed to do it this time. It is a bit of a problem with the generator is sometimes it doesn't finish things 100%. I'm not sure why the context got so annihilated either. Not actually sure what happened here. Oh, it did a lot of like scraping. Okay, that makes sense. That makes a lot of sense. But yeah, you can kind of see the process with what I've shown you. And you can see that it started Docker, right? So, Docker inside JU um is this one right here. But yeah, it it didn't do everything it was supposed to do, but that's okay. So, the final thing I'll show you guys is that the JSON files will now all have contact information in. And then from there, you know, we can work on having a custom dashboard that uses those JSONs to reach out to people. And then we can just make it run forever. Like, I'm not not actually exactly sure how we can just make it keep running. That would be really cool. Maybe using uh that that board thing. What's it called? Yeah, one of these like vibe coding cam bam boards. They are pretty cool. Um, yeah, I'm not really sure how to do it, but like if we can get it to the point where I can just, you know, you can just run this all day every day. Still seems to be struggling to find the contact information. So, I There we go. There's one. So, I would have to probably continue to iterate on this um get it to look at other pages. I'm not sure how it actually prompted that, etc. But again, this is just an example. But I wanted to show you guys that you could do a different use case to the WordPress generator that I have made. I think I'll leave the video there guys. I think this will help a lot of people and I really really think that this is something that is going to really start to take off this idea that you can make your own custom clawed codes that just not agents just literally your own custom clawed code that just does whatever the fck you want it to do. Thanks for watching guys. If you're watching all the way to the end of the video, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apresenta um gerador de código Claude para criar fluxos de trabalho de automação e geração de leads, mostrando como configurar memórias, clonar repositórios e integrar ferramentas como Gina.ai e Playwright.",
            "resumo": "Neste vídeo, o criador apresenta um gerador de código Claude para WordPress e mergulha em como construir fluxos de trabalho automatizados baseados em memória. O vídeo mostra um repositório clonável, onde o usuário pode explorar pastas e o arquivo claude.md, além da diferença entre memória do usuário e memória do projeto. O objetivo é ensinar a criar um fluxo de trabalho que descreva passo a passo o processo de configuração de um sistema, sem implementá-lo imediatamente. O apresentador discute como usar Gina.ai para buscas de lojas Shopify, como extrair e armazenar dados, e como pensar em um CRM mental para personalizar e realizar contatos. Também menciona a inclusão de MCP.json para habilitar o Playwright, e sugere futuras possibilidades como painéis, integração com WordPress e fluxos adicionais para geração de leads, automação de e-mails e rastreamento de respostas.",
            "assunto_principal": "Fluxos de trabalho personalizados com Claude code para automação e geração de leads, utilizando memória (memória de usuário e de projeto), Gina.ai e integrações com WordPress, Shopify e Playwright.",
            "palavras_chave": [
              "código Claude",
              "memória",
              "fluxo de trabalho",
              "Gina.ai",
              "Shopify",
              "WordPress",
              "geração de leads",
              "CRM mental",
              "Playwright",
              "MCP.json",
              "automação"
            ],
            "resumo_em_topicos": "**Resumo em tópicos (Markdown)**\n\n- Contexto e objetivo: demonstrar como construir fluxos de Claude code para automação e geração de leads, começando com um repositório clonável e memórias.\n- Estrutura do repositório: destaque para claude.md e as seções de memória (memória de usuário vs memória de projeto).\n- Memória e workflows: como editar claude.md, criar um workflow na memória e planejar etapas sem implementar tudo de uma vez.\n- Exemplo com Shopify e Gina.ai: usar Gina.ai para buscar lojas Shopify, extrair dados relevantes e armazená-los para prosseguir com a prospecção.\n- Integrações sugeridas: MCP.json para habilitar Playwright; possibilidades de automação de e-mails, CRM mental e dashboards.\n- Observações finais e próximos passos: o apresentador foca em demonstrar a construção do fluxo na memória e planeja explorar mais conteúdos em vídeos futuros.",
            "prompt_tokens": 1963,
            "completion_tokens": 3404,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 61.61441421508789,
          "language": "",
          "view_count": 2689,
          "has_transcript": false
        },
        {
          "id": "rWTlSRNeJOk",
          "title": "Esta nova atualização do Google Gemini economiza MILHARES de horas",
          "title_pt": "Esta nova atualização do Google Gemini economiza milhares de horas.",
          "url": "https://www.youtube.com/watch?v=rWTlSRNeJOk",
          "published": "2025-09-06T23:54:47.227673",
          "published_relative": "há 2 semanas",
          "duration": "04:23",
          "date_published": "2025-09-04T11:04:04-07:00",
          "transcript_available": true,
          "transcript": "Okay, guys. It's been a long time since I've started a video or made a video about Google Sheets, right? But I just wanted to show you guys this. This is [ __ ] crazy. So, I'm working on a channel right now. I'm making a new YouTube channel. Um the the I just need to give you some context. Basically, I have a SAS. My idea is to build a YouTube channel around Shopify tutorials. Uh let them grow evergreen and then obviously have an ad for SEO growth in that video. Right. So, what I've been doing is I've been working on chat pt and I've basically just come out with these video titles, right? But this isn't very helpful for me, this uh list of video titles. It's it's cool, but it's not exactly the most helpful if I want to plan an entire channel, right? But yeah, now just just watch this. Right? So, the prompt here is make me let me gra these titles. The prompt is literally make me a YouTube video planning sheet with these videos and then I gave it the videos. Just watch this, guys. Now, this worked perfectly first time. Obviously, it's AI, so it's not going to work perfectly the second time or while I'm recording. That's just the way it is, right? Look at that. Do you know how much time this saves people? This is actually insane. Watch. I can press insert now. This is my Dude, that is that is crazy. You have no idea how much time this will save our company. Absolutely insane. And then watch this. add an SEO optimized description to each um video idea. So again, just a sec. Literally just a sec and it's just changing the [ __ ] game right now. Okay, so it didn't work this time. Let me just um let me close this. Let me just go back. Can I go back? No. Try again. Okay, so I'll show you the one that I originally did, right? Just because this one worked perfectly. So I did exactly the same thing, but before I pressed insert, what I did was I said add an SEO optimized description to each one. And then after it had done that, which is here, learn what Shopify SEO is and why it's crucial for your online store, blah blah blah. Then I pressed insert. Right? So on the right, make sure that you've got the spreadsheet the way that you want it before you insert it. This is actually crazy. this. I mean, I I didn't want to do this. This would have taken me 3 hours at least to make. That sounds like a lot, I know, but I'm very very bad with Google Sheets, right? I don't even know if I could have even made this without this. This is actually crazy. We We can do so much with this. We use Google Sheets every single day in our business. This is this is Gemini cooking right here. So now we have an entire plan for a channel for the first only 24 videos. There should be 30. Not sure why it's skipped a few, but you know, it's okay. It's not it's not the end of the world. Now I can hopefully just easily add things as well. So like hopefully I can add things um just as easily, but like it just this alone has saved me so much time. So, let's see if I say um add a new video about I don't know SEO I don't know Shopy SEO in 2020. Oops. So, let's see. It should just add this normally. I don't think it's going to mess this up. It's quite quite simple request. Should just add this at line 25 here. Okay. Not sure what it just did there, but fair enough. So, 26 down to 49. It looks like it added one, but it repeated the entire spreadsheet. Okay, so this isn't quite perfect. As you can see, there are still some problems with it. Um, but like just this alone, so I'm going to discard that. Just this alone has saved me probably two to three hours. Like I was not looking forward to making this spreadsheet. I really don't like making spreadsheets, but yeah, this has just saved so much time. I'll leave the video there, guys. This is just a quick one. I just wanted to show people this cuz I actually think this is really, really cool. Uh yeah, if you're watching all the way to the end of the video, as usual, you're an absolute legend. I'll see you very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Demonstra como a atualização do Google Gemini pode automatizar o planejamento de vídeos e SEO no YouTube, economizando horas com planilhas do Google Sheets e prompts de IA.",
            "resumo": "Neste vídeo, o criador mostra como a atualização do Google Gemini pode facilitar o planejamento de um canal de Shopify usando IA. Ele usa uma planilha do Google Sheets alimentada por IA (ChatGPT) para gerar títulos, criar um cronograma de vídeos e, depois, inserir descrições otimizadas para SEO. O processo economiza horas: gera a lista de vídeos, insere na planilha e acrescenta descrições rapidamente. O apresentador avisa que a primeira execução funcionou bem, mas a segunda pode falhar, exigindo revisão antes de inserir. Observa também problemas como duplicação de linhas ao adicionar vídeos. Ainda assim, a automação reduz bastante o tempo de planejamento para os primeiros 24–30 vídeos e facilita a expansão futura do canal.",
            "assunto_principal": "Automação do planejamento de conteúdo para o YouTube usando o Google Gemini e IA para gerar títulos, cronograma e descrições otimizadas para SEO, integrando com o Google Sheets.",
            "palavras_chave": [
              "Gemini do Google",
              "Inteligência Artificial",
              "Planilhas do Google",
              "YouTube",
              "Planejamento de conteúdo",
              "Otimização para mecanismos de busca",
              "descrições otimizadas",
              "instruções de IA",
              "Shopify",
              "Automação"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto: o objetivo de automatizar o planejamento de conteúdo para Shopify utilizando Gemini e IA.\n- Demonstração: uso de Google Sheets com prompts para gerar títulos, cronograma e descrições de SEO.\n- Resultados: economia de tempo significativa, a primeira execução é eficaz, a segunda pode falhar, exigindo revisão.\n- Limitações: alguns bugs, como duplicação de linhas ao inserir vídeos.\n- Conclusão: o fluxo facilita o planejamento inicial (24–30 vídeos) e pode ser expandido facilmente.",
            "prompt_tokens": 1102,
            "completion_tokens": 3776,
            "model": "gpt-5-nano",
            "cost": 0.0062
          },
          "analysis_time": 51.906901836395264,
          "language": "",
          "view_count": 3244,
          "has_transcript": false
        },
        {
          "id": "r8qT1_v1kDk",
          "title": "Warp.Dev: Este desenvolvedor de IA agente GRATUITO é INCRÍVEL",
          "title_pt": "Warp.Dev: Este desenvolvedor de IA agente gratuito é incrível",
          "url": "https://www.youtube.com/watch?v=r8qT1_v1kDk",
          "published": "2025-09-06T23:54:47.227688",
          "published_relative": "há 2 semanas",
          "duration": "09:34",
          "date_published": "2025-09-04T04:48:49-07:00",
          "transcript_available": true,
          "transcript": "Let's talk about warp. Everyone has been asking me to test Warp, and I think people actually like my tests, so let's do it. Now, I'm going to be trying to just use the free one in today's video. It looks like we should have access to all of the best models. Now, I've just downloaded Warp, and this is kind of what it looks like. It's pretty interesting for sure. Um, I think I'll just put it on auto. Now, I'm not sure if this is going to work immediately just because I don't have anything set up, but we'll try anyway. Where on earth is the terminal? Oh, is this the terminal itself down here? So, let's do MKD97. CD97. Okay, it actually tells you what you can expect as well, which is pretty damn cool as well. So, let's Oh, okay. Agent mode terminal. Okay, nice. Okay, so we're on agent mode. Let's just go grab our prompt from the school community real quick. Um, and let's actually just stay on terminal for a second. So, let's go to classroom, all my prompts and workflows. This one right here. So, we'll replace my app with dot. And then we'll say yes, yes, yes, yes, yes. And then we will grab some images like I always do. So, let's just open this. Go to public. Copy the public folder. Then go to 97 and paste n the public folder into 97. There we go. Unlock smarter, more consistent, responsible. Agent mode. Okay. And then we're just going to run the prompt and we'll just compare it to all of the other ones that I've done. So, let's just smash that prompt in. I kind of like that it flashes up here with what version of NodeJS, what folder we're in, um what GitHub repo we're on. We can attach context. Does seem pretty damn cool so far. Now, I like to do this test. A lot of people say that this test isn't very good anymore, but I still think that this is a really, really good test. Now, can I make this run things automatically? It doesn't look like I can. Okay. Great. I can see we're already in the nextJS project. Beautiful. Finding files that match. Okay. Packages.json, etc., etc. So, this uses Claude for Sonet. I would like it to kind of mix and match, but you know, it does seem like it's going to be mainly focusing on Claude. Uh, Claude for Sonnet. Can I just Can I make this happen automatically? I don't want to always be Let's see. Auto approve all AI actions. There we go. And we can even voice input, which is pretty cool. I don't really have a use for that. Personally, I prefer typing because when you're typing, you can think about things more. But, um, yeah, it's pretty cool that the voice mode. Okay. So, you can normally see pretty quickly whether or not this is going to be a success. And actually, 178 lines is pretty good. Yeah. No, I think this might actually be decent. Um, this is how I normally check immediately if it's going to be good or not. The average size of this file is about 70 lines. So, anything about above 70 normally means that it's going to actually be quite a good build. So, yeah, I mean, that's exactly what it's done here. Pretty interesting so far. Locations also very, very long. Okay, so while this is working, let's just have a quick look at the pricing. So, looks like Turbo 10,000 requests a month. So, $40 build annually, 50 build monthly. So, it's going to be about 50 bucks a month. Um, which is okay if it actually builds well, right? Light speeded $200 a month. This is fairly Sorry, $225 a month. Fairly standard pricing to be honest with you. This is about the same pricing as most AI tools right now. The real question that we have to ask ourselves is, is it better than its competitors? I think so far this does seem very, very good. Obviously, we'll see the result in a second, but you know, plus 2,354 lines of code is better than codeex in terms of the amount of code it's done, right? It doesn't necessarily mean that the the end result is going to be better than codeex, but yeah, we'll see pretty soon it's actually done. That did not take that long whatsoever. I would say it took about 11 minutes if I had to guess, which is a pretty good build time. Let's see how it actually performs. Let's see how many errors there are, etc., etc. But yeah, everything I didn't did in this video is completely free. I just literally downloaded it and then use the free plan. I love how they put the free plan at the very big very bottom. So, we get 150 requests a month. How many requests was this? This was [Music] maybe 15 requests, 20 requests. So, you could do you could do six of these, five of these a month completely for free with access to the best models. Three index codes bases up to 5,000 files per codebase. Unlimited next command suggestions, which is pretty cool. That's the system I was using before where I did like uh MKD whatever and then cd automatically showed up, which is really really cool. modern code editor. Sure. Like I mean it it's kind of at the same level as Visual Studio Code or whatever. Probably just another Visual Studio Code fork to be frank. Most of these businesses are just forks of um Visual Studio Code. Whether this is or not, I'm not sure. Um it doesn't really look like Visual Studio Code, but that doesn't mean that it's not um a Visual Studio Code fork. Let's see how it fixes these errors. This is using a lot of my API requests or AI requests, the monthly ones. Um, which is really not ideal at all. And yeah, it's probably going to actually ruin the experience here because you're probably only going to be able to build one of these a month. Now, couple of things. If you just repeatedly create a new email, you could technically use this for free forever, right? This is this is fairly standard. Like, I don't feel bad saying this. A lot of people know this already, but you can just use burner emails or just keep creating Gmails or whatever if you wanted to just use different accounts every time. And then you could work on your entire project using different accounts or you could just pay them money, right? Let's see. Up to 2,500. How many more is that? That's uh 20 times, right? 20 uh bad maths today. It's about what, like 15 times as many requests. So, yeah. I mean, it's it's fairly standard pricing. Let's see how it builds. Right, that's the most important thing. Now, I do like it when it picks the model for me. I don't really like relying on my own brain to pick models, etc. I think it can be it can be risky cuz like I'm biased towards one model or I don't want to use another model or whatever. So, I do like it like augment code and things like that where it just does it for you. So, yeah, this is now eating up a lot of my AI calls. So, I mean, originally I was pretty down and then like I was like, \"Okay, well, we can probably do six of these a month for free, but now it's looking like, you know, this will just eat all of your bloody requests and you won't actually be able to make six, which is kind of disappointing. It does say here that this is the fastest way from prompt to production. I'm not sure if I actually agree with that that it's the fastest way, but this has made some mistakes in the coding as well for sure that it's now having to fix which is using my AI calls which is not ideal. Okay, so it did actually finally build. There we go. Um, that wasn't too bad to be fair. Let's see what happens now. Excellent. The build was successful. Okay, so can we run npm rundev now please? I think I'll just manually run npm rundev. Let's just change this rundev. There we go. Okay. And then let's see what it's built. Okay. Pretty decent. Looks good. Everything's here. This was automatically in Italian, which was wrong, but that's okay. Let's see what happens if I press en. It works perfectly. Services. Let's go view services. Birthdays. Okay. Wow. This is a very complete build. Wow. Okay. This has impressed me. Couple of color errors here. Unfortunately, I would have given it a 10 out of 10. Um, except for those colors. Damn. Yeah, pretty perfect build. Not going to lie. Oh, there we go. There's another issue. There's another issue. Okay. Okay. So, there are some issues here, but I mean, overall, it's done a phenomenal job. It's done all the SEO. It looks great. It doesn't all look sy, which is something that I really don't like when everything just looks exactly the same. It's got all the individual pages. The language switcher works, which is super nice. Yeah, I mean, overall for a for a free build, this is pretty good to be honest with you. I think I'll leave the video there, guys. I just wanted to quickly jump on and do my standard benchmark for warp.dev. I think this is pretty impressive to be honest with you. And yeah, thanks for watching. If you're watching all the way to the end of the video, as usual, you're an absolute legend. I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Avaliação do Warp.dev na versão gratuita, explorando o modo agente, prompts e fluxo de produção de código, com conclusão de que o resultado é impressionante apesar de algumas falhas.",
            "resumo": "Neste vídeo, o apresentador testa o Warp.dev usando apenas o plano gratuito. Ele instala o Warp, ativa o modo agente, pega prompts da comunidade e monta um fluxo de trabalho com um projeto Next.js, incluindo a importação de prompts, uso de contexto e avaliação de como as ações de IA são aprovadas. O conteúdo analisa desempenho, tempo de construção e comparação com concorrentes, além de discutir custos: plano gratuito oferece aproximadamente 150 solicitações/mês, com opções Turbo e LightSpeed mais caras. Ele observa que o serviço pode consumir rapidamente as chamadas de IA disponíveis e comenta sobre a viabilidade de contornar limitações com e-mails temporários. O build final é relativamente completo, com cerca de 178 linhas de código, mas apresenta pequenos problemas de cor e uma questão de idioma; ainda assim, é visto como promissor.",
            "assunto_principal": "Avaliação do Warp.dev na camada gratuita e fluxo de trabalho com modo agente para construção de código",
            "palavras_chave": [
              "Warp.dev",
              "agente de IA",
              "plano gratuito",
              "modo de agente",
              "instruções",
              "Next.js",
              "construção de código",
              "limites de uso",
              "preço",
              "automação de tarefas"
            ],
            "resumo_em_topicos": "- Contexto e objetivo: testar Warp.dev no plano gratuito com foco no modo agente e fluxo de produção de código.\n- Configuração e fluxo de prompts: uso de prompts da comunidade, contexto, auto-aceitação de ações de IA e teclado/voz como entrada.\n- Desempenho e resultados da build: construção de um projeto Next.js, ~178 linhas de código, resultado relativamente completo com alguns ajustes necessários.\n- Custos e limitações do plano gratuito: ~150 solicitações/mês; discussão sobre consumo de chamadas e possíveis maneiras de contornar limites (ex.: e-mails temporários).\n- Observações finais e comparação: comparação com concorrentes, tempo de construção e percepção de promissor, mesmo com falhas menores de cor e idioma.",
            "prompt_tokens": 2029,
            "completion_tokens": 2742,
            "model": "gpt-5-nano",
            "cost": 0.0051
          },
          "analysis_time": 45.57343530654907,
          "language": "",
          "view_count": 2077,
          "has_transcript": false
        },
        {
          "id": "qA0S4shCw6g",
          "title": "Claude Code + Este MCP = Uma Mudança Total no Jogo",
          "title_pt": "Claude Code + Este MCP = Uma Mudança Total no Jogo",
          "url": "https://www.youtube.com/watch?v=qA0S4shCw6g",
          "published": "2025-09-06T23:54:47.227704",
          "published_relative": "há 2 semanas",
          "duration": "12:56",
          "date_published": "2025-09-03T01:17:53-07:00",
          "transcript_available": true,
          "transcript": "Let's talk about Bright Data's web scraping capabilities and why they're so damn important and why they're so damn strong. Now, just as an aside, one of the really cool things about Bright Data is that it uses proxy, which means that you're not going to get in trouble for large amounts of web scraping. And just as another aside, they have this new thing called deep lookup, which is actually super super cool. Um I I'm not logged into this right now, but what Deep Lookup basically is is it's like an AI powered search. So if you ask it to find, for example, Shopify stores so that you can send Shopify emails, then you can do that. I'm not on that right now, though, so I'm not going to be talking about that. What I am going to be talking about is the MCP. Now, there's a couple of example projects at the bottom here, but I'm going to show you why I absolutely love this system. Now, they do have a new thing which is free tier where you get 5,000 calls per month, but the only problem with that is that you only get the SCP and another scraper, right? But I actually would recommend that you use the pro version of this. Now, in the description of this video, you'll find this document, which first of all shows you how to add the MCP, but it also talks a little bit about why, in my opinion, the Bright Data MCP is so damn powerful for web scraping. There's also a link for you to sign up, and you should get some free credit for the pro plan when you sign up with my link. Now, with all that being said, I already have this set up, right? So, I'm just going to walk you through this process with Claude Co. So let's write clear here. And then let's do first of all, yeah, this is how you add the MCP. It's super easy. It's just claude MCP add name of MCP M. And then I've got pro mode true because I want to use their pro mode. I don't want to use their free scraper. But if you're just doing basic web scraping, all you need is their free one. Okay. So I've added that. Right. So let's do Claude here. Now I want to show you the difference in scraping capabilities. Right? Now let's say we want to make a YouTube chapter generator, right? An automated YouTube chapter generator. So what do we need? We need the transcript from a video. Um and that has to be scrapable, right? Scraped. It can't be manual obviously cuz it's part of a SAS. And what else do we need? We would then feed the transcript to a uh prompt. Prompt generates YouTube chapters, right? This is, you know, a $100,000 business. There are SAS that exist that sell this service, right? Basically, just take a transcript, feed the transcript to a prompt, prompt generates YouTube chapters, right? If you're not familiar with YouTube chapters, basically it's just um a way to split up the video so that your viewers will stay for longer and also increases SEO as well. It's super helpful for people. And this is just one example. Now, let's just quickly compare two things. Now, you guys might remember Gina. I absolutely love Gina, right? But let's just see what happens when I scrape a YouTube video using Gina. So you can see markdown content here and then it shows the um stuff on the right which is the other videos right let's see subscribe download okay transcript follow along with the transcript show transcript so there's no transcript here as far as I know we do have the comments I'm new to this can someone explain how to make money from this is one of the comments you got Discord that's the other comment and then let's See transcript. Show transcript. So you cannot actually see the transcript here as far as I'm aware. Yeah. No, you can't. Okay. So you can't actually create what I want to create using Gina. Gina is extremely good. If you want to just do basic scraping, I would recommend you use Gina over bright data. If you just want to scrape a SER and then scrape the results of that SER, right? However, what if you want to do something a little bit more complicated like we're talking about today, that's where bright data comes in. Look at the difference between this scrape here and then let's say to Claude, first of all, let's do /mcp. You can see bright data is connected. Perfect. So I'm going to say please scrape this YouTube video then generate uh YouTube chapters uh which are written like this O to 0 15 uh introduction for example um there must be a 10second gap between each chapter pack the chapters with SEO and then we put the link Now, I want you to remember that as it's an MCP, this can become part of any workflow that you want it to be part of. It doesn't have to be used manually inside Claude code. So, as you can see here, this creates the MCP request. Let's say yes. What it'll do is it will then use bright data instead of Gina or whatever to scrape the uh URL. This requires a valid YouTube link, right, with slashwatch equals v blah blah blah blah blah. And you can see here 1,81 lines, which is far more than Gina found. And then we should see in just a moment just how easy it actually is to create a system like the one I'm talking about. Bang, there it is. So, based on the video transcript analysis, here are SEO optimized YouTube chapters for the biggest Claude Code update so far. reselling with 10-second minimum gaps. Let's just have a look here. Let's just grab these chapters, right? And we'll actually we'll put these chapters into my channel. So, this is the video here, right? Let's just whack these chapters here. Okay, looks good. Then press save. Then we can open up the video. Then we should see Yep, there we go. The chapters are right here. Let's just see how accurate they are. So, let's go here. API versus keys versus consumer plans. Let's click here. >> And you can see that's exactly where it is in the video, right? Permission to power products. Let's click here >> just before we continue. >> Yeah, literally it's right here. You may not enter these into the terms blah. Okay, so perfect. That was a perfect example of being able to scrape something that normally using Gina and other things like that you wouldn't be able to. Now you might be asking yourselves what else can this do? So let's do /mcp. Press enter and then press view tools right here. And we can actually see what it can do. So you can choose a search engine. Let's say you want to scrape Bing specifically. You can scrape as markdown. You can scrape as HTML. I would probably recommend only scraping as markdown. And then you can web data Amazon product web data product reviews. If we just hop on over to here, we can actually see them here as well. So there's some very interesting stuff here. Let's say that you need an Amazon scraper because you want to create a automated WordPress Amazon affiliate um generator, right? This is only really possible with something like bright data or just with bright data for example. You're going to have real problems if you try and scrape certain things like Amazon, Facebook, LinkedIn with standard scrapers like Gina. You need something that can really do do that little bit more. Right? So you can get Instagram comments, Facebook posts, Facebook market listings. And I want you to remember as well, right? I'm just going to show you something really interesting. Okay, so you can see here quickly read structured Facebook marketplace listing data, right? But how does this actually work? So what you can do is you can create a system that please use bright data to find mark Facebook marketplace listings on Google then scrape them using the Facebook marketplace scraper. You can use search operators to achieve this. So what I'm saying here is basically you do a web search using bright data right with a search operator that's I don't know something like site facebook.com/marketplace right and then I don't know car and then after you've done that search you then do the second search which is scrape the individual marketplace link right this is where the ideas really start to come from you can literally look you can see it says site facebook.com/marketplace/item and then it finds these individual items. I've got no idea what this item is. Please not be something weird. Okay, sure. It's just a it's a Nissan car, right? So, let's just say yes here. And then what it's doing is it's scraping each of these individual marketplace links, right? So, let's say you wanted to make an arbitrage system that finds like really really cheap 1986 Nissan cars in I think this is Mexico, right? In Mexico to then sell in the US, right? This would be an amazing way to do that. This would be basically the only way to do that. So, you can see here what this has now done. If I controll R, although sometimes control R doesn't work. There we go. So it can see all of the individual information inside Facebook which was previously not possible. Right? So this is where things start to get super interesting because if I do the same thing with Gina I'm not sure if it will work. Right? In fact I would guess it probably doesn't work. The reason being is the way that Facebook is um organized. It uses a lot of JavaScript and things like that which Yeah. You're temporarily blocked. Exactly. Perfect example right there as well. Now, if you can find something here that people want, right? Like Twitter scraping or Zillow scraping or hotel listing scraping or YouTube or whatever it is, right? There's something here for arbitrage or whatever it might be. maybe LinkedIn jobs, Crunchb, Tik Tok profiles, you know, you could make a Tik Tok um virality generator, right? For example, you can make a website uh directory for Apple apps, Reuter News, right? Let's say if you don't know, Reuters basically is an amazing way to find upcoming information, right? If I go on Reuters, let's say, um, you can, this is where news is born, right? So, let's say you're in, I don't know, I'm I don't want to say crypto. I hate crypto. Anything that's not crypto. Let's say you're in um AI, right? The AI space. Normally, what people do is they search AI here. They sort by past 24 hours, right? And they find news that happens, and then they regenerate that news. You can do that automatically with bright data. And then let's just finish this off. So we've got these ones here. So Reddit as well, classic example. If you try and scrape Reddit with Gina or something else, it won't work. But instead, what you can do quickly read structured Reddit post data requires a valid Reddit post URL. This can be a cache lookup, so be more reliable than scraping. So, basically, if you wanted to make something that takes a Reddit post and turns it into a blog, you could use Bright Data to do that as well. I'm going to leave the video there, guys. I'm super excited to see what people build with this. I love Bright Data. I think it's a really, really cool system. You don't have to worry about getting banned or anything like that. Um, because it uses proxies. It's super safe. Not legal advice, obviously. #notle advice. But yeah, I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. Check out the link in the description and I'll see you very very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Mostro como o Bright Data MCP potencializa o web scraping avançado (em comparação com a Gina), demonstrando a criação de capítulos otimizados para o YouTube a partir de transcrições usando Claude, tudo dentro de um fluxo automatizado.",
            "resumo": "Este vídeo apresenta as capacidades de scraping da Bright Data, destacando o uso de proxies para grandes volumes e o recurso Deep Lookup. O foco é o MCP (Master Control Panel) e suas vantagens, especialmente na versão Pro, frente ao tier gratuito. O apresentador demonstra a integração com Claude para criar um fluxo que, a partir de uma transcrição de vídeo, gera capítulos do YouTube com gaps de 10 segundos e SEO otimizado, demonstrando como o MCP facilita esse tipo de automação dentro de um workflow. Além disso, é feita uma comparação entre Gina e Bright Data na extração de transcrições, ressaltando que algumas tarefas não são viáveis com scrapers básicos. Por fim, são apresentados recursos do MCP como escolha de motor de busca, formatos de saída e dados disponíveis (Amazon, Facebook Marketplace, etc.), evidenciando o potencial de fluxos de trabalho automatizados.",
            "assunto_principal": "Web scraping avançado com Bright Data MCP e automação da geração de capítulos para o YouTube.",
            "palavras_chave": [
              "Bright Data MCP",
              "raspagem da web",
              "proxy",
              "Pesquisa Profunda",
              "Claude",
              "Gina",
              "Capítulos do YouTube",
              "transcrição",
              "Otimização para mecanismos de busca",
              "fluxo de trabalho automatizado",
              "versão Pro",
              "plano gratuito",
              "dados da Amazon",
              "Facebook Marketplace",
              "operações de busca"
            ],
            "resumo_em_topicos": "- Contexto: Bright Data oferece proxies e Deep Lookup para raspagem em grande escala.\n- MCP: apresentação da ferramenta, vantagens e diferença entre a versão Pro e o plano gratuito.\n- Demonstração com Claude: integração do MCP para coletar dados de um vídeo do YouTube.\n- Caso de uso: gerador automático de capítulos do YouTube a partir da transcrição, com organização, intervalos de 10 segundos e SEO.\n- Comparação: Gina vs Bright Data na extração de transcrições; limitações da raspagem básica.\n- Fluxo de trabalho: MVP de automação, não apenas raspagem manual.\n- Recursos do MCP: escolha de motor de busca, formatos (markdown/HTML) e tipos de dados (Amazon, Facebook Marketplace, posts, avaliações, etc).\n- Técnicas: uso de operadores de busca para localizar listas e depois extrair dados de cada link.\n- Conclusão: Bright Data permite tarefas difíceis com raspadores convencionais, abrindo possibilidades de automação.",
            "prompt_tokens": 1880,
            "completion_tokens": 4503,
            "model": "gpt-5-nano",
            "cost": 0.0077
          },
          "analysis_time": 66.21213102340698,
          "language": "",
          "view_count": 4874,
          "has_transcript": false
        },
        {
          "id": "hlkLEr1Ijq8",
          "title": "A maior atualização do Claude Code até agora (revenda)",
          "title_pt": "A maior atualização do Claude Code até agora (revenda)",
          "url": "https://www.youtube.com/watch?v=hlkLEr1Ijq8",
          "published": "2025-09-06T23:54:47.227720",
          "published_relative": "há 2 semanas",
          "duration": "09:58",
          "date_published": "2025-09-02T11:01:55-07:00",
          "transcript_available": true,
          "transcript": "This video is super important if you've ever wanted to resell clawed code in any capacity. Now, I want to talk about something really, really important today, which is consumer terms of service versus commercial terms of service. Now, somebody once told me that you cannot resell clawed code, as in if you, for example, made something that uh automatically spins up clawed code and then uses clawed code to create something, right? And then let's say this creates like a docker instance which you know like bolt new for example but using clawed code that you could not make this but that's actually incorrect and I wanted to talk about why today and why in my opinion this is such an important thing and also you know the potential for billion dollar ideas that might come from this. Now I know a lot of YouTubers talk about you know big ideas etc etc but I really tr truly believe that I have a really good idea um and I am going to make it and it does involve using clawed code and I wanted to talk about that today. Now the first thing that you need to know is consumer terms of service. Right? Please note our commercial terms of service govern your use of any anthropic API key, the anthropic console or any anthropic offerings that reference the commercial terms of service. For clarity that does not include claw.ai or claw pro use for individuals or entities. What does that mean? It means that the consumer terms of service are specific and it says effective from 28th of uh September 2025. they are specific to basically the Claude Max plan or the Claude Pro plan. So if you instead right instead of using an API key for this system, you use By the way guys, I'm on a I'm on a touchpad. So actually that's better than my normal attempt. If you do this on the Max plan, this is not allowed, right? This is actually banned. You cannot do this. But basically what this is what what I'm trying to say in this video is that if you instead use your API key, it's totally fine, right? And I'll show you why in this video looking at the terms of service. So just to clarify, the consumer terms of service are as it says here for clarity. This does not in so the commercial terms of service which is not this one. This is the consumer terms of service, right? So the commercial terms of service are for API keys, but these ones here are actually just for the max plan, right? So you cannot resell the max plan as part of your service, right? So just a little tip for you guys. If you're looking for kind of um whether you can resell something, right, you always want to do control F and you want to look for commercial and you want to look for something that says something like this, right? Use of our services for evaluation purposes of for your personal non-commercial use only. Non-commercial use only. You agree that you will not use our services for any commercial or business purposes and we and our providers have no liability to you for any loss of profit, loss of business, business interruption, or loss of business opportunity. What does that mean? Okay. Well, first of all, it's them covering their asses. So, like if you try and sue Anthropic because you know your Max plan went crazy and deleted your production database, you simply will you you won't that won't hold up in court. By the way, # not legal advice, #not financial advice, all that stuff that you have to say on YouTube. I'm not a lawyer, okay? I'm just reading. I do have some experience with commercial non-commercial use because of my print on demand days. And basically what this is saying is that the max plan is non-commercial use only which means you cannot resell clawed code as part of a service using the max plan right so that's the max plan but what about right if we go here please note our commercial terms of service govern your use of any anthropic API key so what does it say here let's do cr+ f let's look for commercial uh let's just press enter a few times times. Okay, so it's not actually here. Okay, so this is the really important part here. Again, not legal advice, all that good stuff. And just before we continue, by the way, this is something that I am going to be putting into SEO Grove. SEO Grove, by the way, check it out. Three or four days left until we put the price up and you can no longer get the uh $1 weight list, $99 a month plan um or offer, introductory offer. instead it'll be going up to probably half price which is $250 or just full price which is $4.99. So there's about 3 or 4 days left on this. So join the wait list seg.ai um check it out etc etc. But with that being said I am planning on putting claude code into Grove and I probably will stream that process as well. But let's just go through this here. This is the most important sentence right here. Again not legal advice. I feel like I have to keep saying that overview. Subject to these terms, Anthropic gives customer permission to use the service, including to power products and services customers make available to its own customers and end users. What does that mean? That means the thing the example that we talked about earlier where let's say you created a website generator that uses clawed code to actually create the website and then put it on Docker like a bolt new process, Daytona, whatever. That is actually completely fine. Now, as far as I know, this was not the case originally. So, I am curious to see if I go here. So, we're just going to use the service includes power. Okay. So, it's always been it's always been the case. It looks like it's going on previous version one more time. Subject to these terms, customers, you may use the services and please make submissions the services promise to generate. Okay. So, I think originally when it was released, this wasn't the case. Okay. So, this is something that changed it looks like on February the 24th um 2025 and then changed again June 2025. Um and oh, I didn't actually know that Anthropic was in Ireland. That's pretty cool. So, what does this mean? It means that you are not legal advice, but you are legally allowed to sell clawed code using an anthropic API key as part of your process. Okay. Now, why am I even talking about this? I'm talking about this because there's mis misinformation about there because people might read, for example, the commercial terms of service and they might read something like, you know, not for commercial use and then they leave comments on my YouTube channel or my streams or whatever saying you're not allowed to resell Claude code as part of a product. That is inaccurate. Okay. Okay, according to my understanding as a layman who has no experience in lawyerism or lawyers or law or anything. Okay, but this one sentence here, this generally means that you can use claude code inside your product and sell it if you're using an API key, not if you're using the max plan. Right? The key here is that you are not allowed to use the max plan for this, which means you have to think about limits, you have to think about cost, you have to think about all these different things. But the cool thing or the amazing thing about this is that you can build something with claw code. You can build a wrapper around clawed code and resell it, right? So, for example, let's say you made a Manis ripoff powered by by code. Now, I'm assuming Manis doesn't use claw code. It might, it might not. I don't actually know. Or let's say you make a bolt new competitor powered by CC, right? Claw code. This is perfectly fine as long as you use the API key. Issues will arise if you use the max plan instead of the API key. Right? Again, this might seem like a bit of a strange video, but I just want to kind of counter the misinformation because there might be people out there who have a really, really solid idea for something and they really want to make this business, but they didn't think they could just due to the legalities of Clawude Code. But if you actually read their licenses, which I will leave in the description of this video if I remember, but the main thing is the commercial terms of service which govern the API, right? as it says on their commercial terms of service right here. Oh, sorry, their consumer terms of service. I got confused there. I must have clicked at some point. As it says right here, please note our commercial terms of service, right, which is the other one, govern your use of any anthropic API key, etc. For clarity, the commercial terms of service, which is the one that you're allowed to use commercially, does not cover claude pro for individuals or entities. This is the important thing, guys. I just wanted to go through this. I wanted to explain this to people. I didn't even know you needed to be 18 years old to use anthropic. That's quite interesting. I just wanted to very quickly run over this because I think there's misinformation out there and I really want people to build and feel empowered to build and use AI to build things. And Claude Code is without a doubt the best if not one of the best. I'm kind of flip-flopping between Codeex and Claude a uh Claude Code right now. That might seem like I'm just doing it for views. I'm not. I'm genuinely just trying to understand which one's better. The second I get home to Ireland, I'm going to be power testing Codeex versus Claude Code. There's a lot of content coming on that very, very soon. But I just wanted to address this because I think it's important. And somebody actually stopped me building something inside SEO Grave originally because they told me that I wasn't allowed to, which is completely incorrect. I'll leave the video there, guys. Thank you so much for watching. If you're watching on the way to the end of the video, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo desmonta a ideia de que não é possível revender Claude Code, mostrando que, usando uma chave de API e respeitando os termos comerciais, é permitido incorporar Claude Code em produtos para venda, diferentemente do que ocorre com o plano Max.",
            "resumo": "O vídeo discute a diferença entre termos de serviço ao consumidor e termos de serviço comerciais da Anthropic/Claude Code. O autor desmente a crença comum de que não se pode revender Claude Code, esclarecendo que, segundo os termos, é permitido usar Claude Code dentro de produtos para vendê-los quando se utiliza uma API key, não o plano Max. Ele explica que o plano Max é de uso não comercial e que vender serviços com o Max pode não ser permitido. O apresentador sugere que é possível criar wrappers, geradores de sites ou containers Docker que utilizem Claude Code, desde que se utilize a API key. O vídeo também menciona mudanças nos termos em 24/02/2025 e em 2025, além de observar que Anthropic está na Irlanda. Por fim, reforça que não é aconselhamento jurídico e alerta contra desinformação, convidando a ler os termos com cuidado.",
            "assunto_principal": "Termos de serviço do Claude/Anthropic: diferença entre uso pelo consumidor e uso comercial, possibilidade de revenda por meio de chave de API e proibição e limites do plano Max.",
            "palavras_chave": [
              "Claude Code",
              "Anthropic",
              "Termos de Serviço",
              "consumidor",
              "comercial",
              "revenda",
              "Chave de API",
              "Plano Máximo",
              "Docker",
              "embrulhador",
              "informação legal"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto: discussão sobre termos de serviço do Claude Code e a diferença entre uso como consumidor e uso comercial.\n- Ideia central: é possível revender Claude Code dentro de produtos usando uma chave de API, desde que não se utilize o Plano Max.\n- Diferença-chave: o Plano Max é para uso não comercial; a venda de serviços com esse plano pode ser proibida.\n- Condições práticas: é viável criar wrappers, geradores de sites ou containers Docker que utilizem Claude Code via chave de API.\n- Alterações nos termos: mudanças ocorridas em 24/02/2025 e em 2025, além de observação sobre a presença da Anthropic na Irlanda.\n- Conclusão: reforço da leitura cuidadosa dos termos e que não é aconselhamento jurídico; alerta contra desinformação.",
            "prompt_tokens": 1888,
            "completion_tokens": 1913,
            "model": "gpt-5-nano",
            "cost": 0.0038
          },
          "analysis_time": 61.31564497947693,
          "language": "",
          "view_count": 2793,
          "has_transcript": false
        },
        {
          "id": "nugLoUrG5AU",
          "title": "Os fluxos de trabalho do agente personalizado do GPT-5 Codex são INSANOS",
          "title_pt": "Os fluxos de trabalho do agente personalizado do GPT-5 Codex são insanos.",
          "url": "https://www.youtube.com/watch?v=nugLoUrG5AU",
          "published": "2025-09-06T23:54:47.227736",
          "published_relative": "há 2 semanas",
          "duration": "06:52",
          "date_published": "2025-09-01T02:28:36-07:00",
          "transcript_available": true,
          "transcript": "So, let's continue testing codeex. After yesterday's video, my mind was completely blown. Now, I might run into some problems here. I may have used too much of codeex and I may have to wait until next week, but we are going to try and build something today. I haven't actually tested this out yet, so this should be quite fun. The only thing we need here is gina.ai, an API key. Other than that, you can see inside my WordPress claude code wizard, which you can find in the description of this video, we now have a codeex uh folder. So, let's open up Visual Studio Code and let's see how well Codeex performs on something that's slightly more complicated than just a servicebased website. Okay, so the first thing we need to do is we need to actually clone the repository. So, we'll do mkd and we'll do codeex WordPress and then we'll cd No, we won't. We'll then open that folder. So, file open folder uh codeex WordPress. Okay, beautiful. Okay, terminal, new terminal. Now, we need to do get clone. Paste this. And then we'll put a full stop. Okay, there we go. So, we have the codeex file here with the agents file here. This is the same as claude.md. Now, like I said, I haven't actually tested this yet. So, I just want to see if this works and how well Codeex deals with this system, but effectively, I should be able to just go to Codeex and say, make me a directory um I don't know about business schools in Germany. Use this GNET API key. And then if everything has worked correctly, it should use agents.mmd in order to do this. Now, I'm not actually sure. Let's just Oh, okay. So, it can't actually start things using Docker, which is kind of annoying, but it looks like it is reading. Yeah, it is definitely reading from agents.md, which is good. Okay, beautiful. Yeah. Yeah. Okay. So, this is working, but the only issue is that it says that it can't use Docker, which I don't actually know if that's true because surely it could just use Docker by just running Docker commands here. But obviously, they haven't It looks like they haven't quite figured that part out just yet, which is actually kind of annoying to be honest with you. It's not that hard to run Docker Compose or Docker Up or whatever it might be. However, we will just let this run and we'll see how this goes. This requires a custom business. Yeah, it does indeed. Creating a plug-in. Okay. Now, one problem here is that it doesn't seem I think the user I think I should request the users's approval to run docker compose up. Yeah. Okay. That is actually what I want you to do. Okay. This all looks good. This all looks good. Reading wpconfig. Okay. So, it is reading agents.md. So I can confirm to you guys that um wait can I run every time? Yeah, beautiful. So I can confirm that um it does work the same way as claude.md and you can create custom codeex workflows. The only issue seems to be that it um doesn't seem to want to uh run certain commands, right? But apart from that, it looks like this is working pretty pretty well to be honest with you. Okay, so we'll just let this run for a bit. Yeah, so one problem. Yeah, it doesn't seem to want to actually run S.Gena searches for some reason, which is kind of annoying. Um, but yeah, I mean, these are all things that could be ironed out or might have to be slightly different on codecs or whatever it might be. But I just want to see overall how good it is at building a project like this. Okay, so this time what I'll do is I'll let this run for I think it will only take about 10 15 minutes. There won't be any images and it won't be real information as far as I know. Uh but I just want to see its ability to actually build something like this. Okay, so we've currently got this right. If I go on business schools, you can see it's all a bit messed up, but the header's messed up, but you can see that it's actually started to build what I wanted it to build, which is the directory, right? Let's just see if we can make this look a little bit better. this a page. Yeah. Okay. So, this is pretty much what it came out with. Now, there's a couple of things which I really don't like. Obviously, no guesswork. No 404s is absolutely terrible. This is the homepage. There's no images either because Gina failed, but I mean, overall, it's done a pretty decent job of what I asked it to do. It's got the individual uh pages here. It's got the contact. CSS definitely needs a bit of help. It's even got a rating system, which is pretty cool, which I didn't ask it to add, but I mean, that's still still cool. And yeah, it's doing all of this itself, by the way. It's running all the Docker commands, etc., etc., just like it says in the um agents.mmd file. Overall, I would say this has been a pretty good result. I would say Claude Code still does this better. However, this was specifically built for Claude Code and not for um not not for Codeex, right? So, I probably do need to do some things. I need to change some things, etc., etc. To be honest with you, Claude Code does do this much better, but like I said, this was this system was specifically built for Claude Code. One thing I do like is it's done a pretty good job with um creating the exact pages that I wanted to create. And yeah, I'll keep working on this if people want me to keep working on this, but this is basically the WordPress generator using codeex. I was expecting more to be honest with you, but I probably need to change some things around specific to Codeex. I'll leave the video there, guys, just so you have a comparison. This is what Claude Code did. Um, you can see Claude Code is much better, but that's not necessarily Codeex's fault. It's just um this was specifically built for Claude Code and it probably needs some changes in order to work for Codeex. Just a quick shout out to the sponsor of this video, which is of course SEO Grove. Join the wait list now, guys. There's about four or five days left until or maybe three or four days left until we put the price up. So, if you do want to lock in that price of $99 a month, this is your last chance. But yeah, I've got to go, guys, before my fiance gets too angry with me. We're currently on holiday and uh she wants to go and visit some places and not just sit in the hotel all day. So, yeah. I'll leave the video there, guys. Thank you so much for watching. Thank you for watching all the way to the end of the video. As usual, you're an absolute legend and I'll see you very, very soon. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo demonstra testes práticos com Codeex para gerar um site WordPress, destacando os desafios com Docker, a integração com Gina.ai e uma comparação entre Codeex e Claude Code, avaliando a viabilidade de um gerador baseado em Codeex.",
            "resumo": "O apresentador testa a configuração de um gerador WordPress usando Codeex, começando ao clonar o repositório Codeex WordPress, abrir a pasta no editor e verificar o arquivo agents.md. Ele utiliza a API Gina.ai e observa se o Codeex consegue orquestrar o ambiente, criar páginas e executar comandos, incluindo Docker. Surgem dificuldades: o Codeex não inicia Docker automaticamente e requer permissões para docker-compose up; há dúvidas sobre a leitura de wpconfig e a execução de certas buscas SGena. Ainda assim, a ferramenta parece ler agents.md e gerar a estrutura do site (diretório, páginas, contato), ainda que o CSS precise de ajustes, imagens falhem por Gina e haja 404s não evitados. O autor compara com Claude Code, concluindo que Claude Code ainda funciona melhor neste caso, mas reconhece que o código foi feito para Claude Code e pode exigir adaptações para Codeex. O vídeo encerra mencionando o patrocinador SEO Grove e conclui com convite a feedback.",
            "assunto_principal": "Avaliação prática do Codeex para geração de sites WordPress, com comparação ao Claude Code, destacando desafios do Docker, Gina.ai e limitações atuais.",
            "palavras_chave": [
              "Codeex",
              "Claude Code",
              "WordPress",
              "Docker",
              "Gina.ai",
              "integração",
              "automação",
              "geração de sites"
            ],
            "resumo_em_topicos": "- Objetivo: testar um gerador WordPress com Codeex e comparar com Claude Code.\n- Preparação: clonar o repositório Codeex WordPress, abrir no editor, usar agents.md e configurar Gina.ai.\n- Execução: Codeex lê agents.md, tenta iniciar Docker e gerar a estrutura do site a partir do código.\n- Dificuldades: Docker não inicia automaticamente; requer permissão para docker-compose up; algumas buscas SGena falham; Gina.ai não gera imagens; CSS precisa de ajustes; alguns 404s aparecem.\n- Resultados: diretório e páginas geradas, header desconfigurado, imagens ausentes; funciona melhor para criar páginas, porém ainda tem limitações.\n- Comparação: Claude Code apresenta desempenho superior neste cenário; Codeex pode exigir adaptações para funcionar tão bem.\n- Considerações finais: ajustes futuros para Codeex; menção ao patrocinador SEO Grove e convite para feedback.",
            "prompt_tokens": 1663,
            "completion_tokens": 3341,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 48.41461801528931,
          "language": "",
          "view_count": 3038,
          "has_transcript": false
        },
        {
          "id": "4pcp7mj_5rU",
          "title": "O Codex GPT-5 pode REALMENTE ser melhor que o Claude Code",
          "title_pt": "O Codex GPT-5 pode REALMENTE ser melhor que o Claude Code",
          "url": "https://www.youtube.com/watch?v=4pcp7mj_5rU",
          "published": "2025-09-06T23:54:47.227752",
          "published_relative": "há 2 semanas",
          "duration": "11:47",
          "date_published": "2025-08-31T11:01:24-07:00",
          "transcript_available": true,
          "transcript": "So finally, after a very long time, there might actually be a competitor to Claude Code. That's what everyone's saying. I have already tested this recently. However, I want to test this in a little bit more detail. Obviously, it is chat GPT. I'm going to be using medium right here. And we'll use agent mode. Uh I might actually put it full access here. Okay, let's actually put on full access. And then auto include recent files into the context. No context here. And we'll just keep it local for now. Now, what we're going to be doing is I want to see its ability to just create. So, normally what I do is I create my own instance of whatever I'm building. Right? So, my benchmark is this right here. It's prompt to create service website. But instead of doing the normal thing, what I want to see is can codeex actually start to create everything without any input whatsoever. So, I'm just going to change this quickly. I'm just going to say um try find some images online to use. Question mark. I don't even know that's possible. Okay. So, let's just send this prompt and kind of have a look what happens. I'm very curious to see if codeex can just take this and run with it. So, let's have a look. I'm going to scan the workspace to see the nextG setup. So, there's literally nothing here. So, good luck with that. Sorting through image downloads. It looks like the directory is empty which contradicts the user. Yeah, good. Good. I need to set up the project correctly. Set up the project. There we go. Creating data files. I need to create several data files. Yes, you do. Set up page structure. Choose images and scaffolding says I'll download images. Okay. So, it's currently setting it up. Let's see. It has Oh, okay. It has done something. Oh, it's actually creating it manually. I'm not really a fan of that. Oh, no. Ran npm in it. There we go. Okay. That's pretty good so far. This looks like a decent start. Wow, it's really just running with what I told it to do. Also, I don't even think I'm logged into Chat GPT. Is this completely free? Uh, I actually I'm I'm not logged into Chat GPT. So, as far as I know, this is completely free. Oh, no. I am logged in. Sorry. Okay. Personal account though, right? So, I'm only paying 20 bucks a month. So, let's see what this can do with 20 bucks a month compared to what Claude Code does for $200 a month. So, I'm just kind of letting this run. It's on medium as you can see here. And now it's going to start to actually, you know, build things. So, this is actually pretty exciting to see. Seems to be doing a pretty good job so far. Next.js, uh, next config.mjs. I'm going to scaffold the NextJS app structure. If it can do that without doing without running npm uh create app or next create app or whatever it is, this will be very interesting to see how yeah how how well this can actually do. So so far so good. I mean this is pretty exciting stuff. I'm not going to lie. Okay, this is really powering through this. This has started to absolutely smash through this. When you see plus 31, that's good. Although that's quite low for globals.css CSS to be fair. But yeah, I mean I'm willing to just kind of see how this goes to be fair. This video by the way is sponsored by me. Uh SEO growth.ai if you want to join the wait list guys. There's about five four or five days left until we up the price from 99 a month to $499 a month. This is literally your last chance to lock in that price. If you're on WordPress, feel free to sign up. Send us an email. Tell us not to charge your card until WordPress is active and you can still lock in the price of 99 a month. Um, even though we're currently only Shopify, I think within a month we'll also be on WordPress. So, if you do have Woo Commerce and you do want to sign up to grab that price, sign up now. Shoot us an email, hello seo.ai, and just tell us not to charge your card until we have WordPress. But this is literally your last chance to lock in that price. I'll leave a link in the description of this video. Anyway, with that being said, let's just jump straight back into this right here. Now, one thing that I've noticed is it hasn't got any images yet, but I mean, it's done a pretty fantastic job here so far. This is from scratch as well. It didn't even run um what is it? Next app or whatever. It didn't run create next app. It kind of scaffolded the entire project, which is pretty interesting. Will it be able to find images? I'm not sure how that will work. Um I might just pause this and tell it to make its own SVGs. Uh plus 122 is pretty good. Um that's 122 lines of code. Let's see. Generate. Yeah. Weddings. Okay. Yeah. Good, good, good. What is it doing for images? Chauffeur.jpeg. So I guess it's going to find some images shortly and basically put them in, I would guess. Okay. Holy crap. This This has been less than like 2 minutes. Wait, how long have I been recording? I've only been recording five minutes, right? But there was a bit of an intro and then I mean it's literally just What the hell is going on? Where is he getting these images from? Wait, wait, wait, wait. I need to see this. public images birthday.jpeg. Nothing. Oh my god. What? Where did it get these images from? Oh, they're just random images, right? Yeah. Okay. Damn. That would have been really cool if it had actually found proper images. But you know what it's doing is it's just finding random images um using uh some system that I didn't even know about called okay it's just random images. So what you could do is you could very easily just change these images for um you know and a a picture of a malfi right a picture for birthdays a picture for chauffur so it's actually I mean considering the briefness and just not very good prompt that I gave it like I literally just said try find some images online to use question mark and then directly contradicted myself. This is doing a phenomenal job and it's doing it blazingly quick. I'm very curious to see if this this actually works. So, it ran npm run build. What happened here? Reference error module blah blah blah. Okay, that's not too bad. Okay. Oh my god. This is it's going so fast that I can barely even keep up with it. If this can do all of this in this amount of time and it's actually decent, then honestly I think I might move over to codeex with chat GPT5. Now I assume this is using Chad GBT5 because I mean otherwise I have no idea how the it's managed to do this. Yeah, GPT5. Okay, perfect. So it's using GBT5. This is 20 bucks a month instead of $200 a month, right? So, I mean, it's pretty damn impressive if it can actually build this entire thing from scratch, scaffolding an entire Nex.js project without even using next create app or whatever the command is. I don't I'm not actually familiar with the command cuz I'm a complete programming noob. This might be the next level, guys, honestly. Oh, what is this? Enable code lens above to-do comments to implement with codecs. Interesting. Very, very interesting. So this might be GG for claw code. I might actually this this might make me switch to be quite honest with you. So it's done 32 files change plus 922 lines of clo code minus 16. In about 7 minutes it has potentially scaffolded an entire service-based website which is way beyond anything that any other anything else that I've ever seen basically. And let's have a look here. We detect type screening program video. Okay. Failed to compile. That's pretty normal. I'm actually not even pausing. Normally I pause videos because things take a long time, etc. There's no way. What? It's done. Nah, bro. Is this good as well? I need to see this. I need to add playright to this. And then honestly, guys, I think we might have a new way to build. I honestly think we might have a new way to build. Is this done? I'm thinking we should copy the new content separate files before we delete the old one. Why would you be deleting stuff? Let me just see if I can run npm rendev real quick. Dev. Okay. Okay then. Holy guys. That is impressive. I'm not going to lie. This is possibly the most impressive build I've ever seen. Not necessarily the look and feel, just the fact that it scaffolded this without using next create app or whatever the hell the the thing is. Okay, things are getting a bit messed up. It's still trying to build though, so it's checking TypeScript build errors, etc., etc. But I mean, like, this is just crazy levels of intelligence that I'm seeing right here. This is the most intelligent AI that I've seen so far. I'm pretty sure. Confirming. Adding the check icon. Okay. What is that? Sure. Okay. So, it now says it's done. Let's just have a little click around. So, locations works. Wow. Wow. Wow. Wow. Wow. Wow. I think um yeah. I mean, overall this is phenomenal. I think it could have done a bit better job with the um with like the the individual pages. They're not that detailed to be honest with you. But yeah, I mean that was an 8 minute build. It's complete complete with SEO languages work. Every single link pretty much works. Could definitely be a bit more detailed, definitely look a bit better, etc. But I mean, come on, guys. That That was so quick. I've never seen it do it that quickly before, guys. I might actually make the change from Claude Code to Codeex. That's not just clickbait. That's not that I'm I'm being serious. I might actually make the change because this is levels of intelligence that I only saw at the very beginning of Claude Code. Those of you that those of you that use Claude code at the very beginning, you will know just how intelligent it was at the very beginning. This is what this feels like. Okay, using codeex inside your IDE feels exactly like that. I've barely even used any context. It just built everything. That is easy. Would you like me to source specific Rolls-Roy show for images now and swap them into public images? I'm not going to do that right now, but you can see it knows that it hasn't quite finished, but it's built the skeleton of the project. And I don't think it would take that long to actually finish everything off. And it even tells you everything that it needs to do. I think I'm going to keep looking into this, guys. I think the next stage is to do this but then do the next stage right here which is like you know saying add this add that add the other next steps etc do that etc etc but yeah holy  guys I might actually be making the move over to codeex I'll leave the video there I'm having a really good holiday let's keep it that way we got scooters day beautiful went around I used to deliver pizzas for Dominoes in Amsterdam so I'm actually pretty familiar with driving around on scooter. But really, really fun guys. I'm on I'm on Iskia, by the way. Isaia, if anyone cares. It's um an island near Naples. Obviously, I lived in Naples for five, six years, so pretty familiar with the area, but I've never been to Iskia. Uh but yeah, I'll leave the video there, guys. Thank you so much for watching. This is a pretty insane video to be honest with you. And as usual, if you're watching all the way to the end of the video, you know that you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Demonstração de que CodeX (Codex GPT-5) pode superar Claude Code ao construir do zero um site de serviços com Next.js apenas com prompts, mostrando velocidade, estrutura inicial completa e custo menor.",
            "resumo": "Um analista compara CodeX GPT-5 com Claude Code em um teste de desenvolvimento automático. Usando o CodeX via ChatGPT com acesso total, ele tenta criar um site de serviços em Next.js a partir de instruções muito vagas, sem entradas detalhadas. O processo envolve escanear o espaço de trabalho, gerar a estrutura do projeto, baixar dependências, gerar código, criar imagens e lidar com eventuais erros de compilação em tempo real. O resultado sugere que CodeX avança rapidamente, incluindo a geração de estruturas de código (scaffolding) sem usar comandos tradicionais, com várias métricas positivas (muitos arquivos e milhares de linhas). O vídeo também comenta sobre o custo: CodeX a 20 dólares por mês versus Claude Code a 200 dólares por mês, sugerindo que CodeX pode revolucionar a forma de construir aplicativos, embora haja pontos a observar, como a qualidade das imagens geradas e as dependências.",
            "assunto_principal": "Comparação entre CodeX (GPT-5) e Claude Code na geração automática de aplicações web com scaffolding de Next.js, avaliando capacidade, velocidade e custo.",
            "palavras_chave": [
              "CodeX",
              "GPT-5",
              "Codex",
              "Claude Code",
              "Next.js",
              "geração de código",
              "automação de desenvolvimento",
              "esqueleto de código",
              "construção automática",
              "inteligência artificial de programação",
              "ChatGPT",
              "custo"
            ],
            "resumo_em_topicos": "## Pontos principais\n- Contexto: comparação entre CodeX (GPT-5) e Claude Code para geração automática de código.\n- Metodologia: teste com CodeX em modo agente, com acesso total, sem entradas detalhadas, para criar uma aplicação Next.js.\n- Progresso: scaffolding automático, geração de estrutura de projeto, dependências, código e imagens (ou SVGs) gerados rapidamente.\n- Desafios: alguns erros de compilação e a necessidade de substituição de imagens por conteúdo próprio.\n- Custos e comparação: CodeX ~20 USD/mês vs Claude Code ~200 USD/mês, sugerindo maior benefício econômico.\n- Conclusões: CodeX pode representar uma nova abordagem para construção de aplicativos, com rapidez e economia, mas requer avaliação contínua.",
            "prompt_tokens": 2003,
            "completion_tokens": 4268,
            "model": "gpt-5-nano",
            "cost": 0.0074
          },
          "analysis_time": 64.59021210670471,
          "language": "",
          "view_count": 5603,
          "has_transcript": false
        },
        {
          "id": "diKEt14VBfI",
          "title": "xAI está cozinhando? Grok 4 Fast Coder 1 acabou de sair (vamos testar)",
          "title_pt": "xAI está cozinhando? Grok 4 Fast Coder 1 acabou de sair (vamos testar)",
          "url": "https://www.youtube.com/watch?v=diKEt14VBfI",
          "published": "2025-09-06T23:54:47.227767",
          "published_relative": "há 2 semanas",
          "duration": "09:16",
          "date_published": "2025-08-31T01:15:01-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where I'm going to be testing the brand new Gro Code Fast One. I haven't actually seen a video about this yet. I'm not really sure why or how this has passed over other people's radar. Basically, if you want to know where I find new models, I just go to open router at the top here. I click models and then I kind of see if there's anything worth looking at. So, Quen, for example, here and then this one here is the one that I'm actually interested in, which is Grock Codefast One. Now, a lot of people said to me that the original Gro 4 model was not for coding. And I said that that was cope and that if a normal model can't code, then probably the coding model can't code either. But I'm always willing to give things a try. Now, this is an economical choice. 0.20 per million input tokens, $150 per million output tokens is extremely cheap, right? And yeah, it's got great tokens per second. I don't really give a [ __ ] about tokens per second, to be honest with you. I think it's like saying, \"Oh, I'm not more intelligent than you, but I can think faster.\" It's like nobody gives a [ __ ] how fast you think. People give a [ __ ] about how intelligent you are, but you know, it is what it is. They have to cope in some way. So, uh, yeah. So, let's have a look here. Let's actually give this a little try. So, it says that we can try this for free on client. So, let's open Visual Studio Code here. Let's go file, new window, and then I should have client already. There we go. Perfect. And let's go down. Let's go to settings. Let's go gro. Oh, no. What are they called? XAI, right? Yeah, XAI. Okay. Um, let's see. It doesn't even seem to be here. So maybe I have to update my client. Uh no. Okay. Okay. So I have to use Klein as the provider. So let's go here. Go clin. There we go. Okay. There we go. Rock fast coding one. Uh let's not enable it. Uh maybe we should enable extended thinking. Um and then what do I have to sign up with Klein here? Let's just continue with Google obviously. Easy peasy lemon squeezy. Okay, so I should be logged in here. Let's just say hi and see if it works. So, hi. Okay, it does work. Beautiful. So, let's cancel out here and let's set up the benchmark. If you're unfamiliar with the benchmark, basically I'll just go to my school community here and I'll just grab the prompt. So, classroom, all my prompts and workflows, and then it's this one right here. So, we'll go terminal, new terminal, and we'll do mk dear uh what is it? Grock for coding. CD Grock for coding and then we'll create the project. Now, if you're an Elon fan or an XAI fan or whatever, I understand that you might have a different opinion to me on Grock, but so far I've had very bad experiences with Grock. I don't rate it as a model at all. And I'm only giving it a chance just, you know, because you need to give everything a chance. You can't just say that something is trash when you haven't actually tested it. So, I will test this completely and fully and I will give it a chance. And the fact that it's free as well right now is obviously a very very nice uh little thing they've done. Okay. So, we'll grab this images file or this public file, sorry. So, right click, copy, and we'll put it in the hell is it called? Grock for coding. There we go. and we'll paste that. There we go. So, these are just for the images, etc. So, now we've pretty much set up everything and we'll just grab this prompt. Just before we send the prompt, shout out to the sponsor of this video, which is of course myself with SEO Grove. If you have a Shopify or soon to be WordPress uh ecom website, check out segrove.ai. There's about 5 days left of the waiting list before we put the price up to $4.99 a month without a discount. Right now, you can lock it in for $1 a month plus 99, sorry, $1 to lock it in, and then $99 a month every month for 3 months. And this price will be going up extremely soon. So, you know, get it while you can. Basically, it'll be the first or second link in the description of this video. Okay, with that being said, let's go back to Visual Studio Code here. Let's just open up um Okay, there it is. So, this is Let's just open up Gro for coding inside Visual Studio Code. Go to terminal and then open up client. Make sure we're on Grock. So, client and grock code fast. There we go. And then we'll hit enter and we'll see how this does. So, this is apparently supposed to be blazingly quick, which I mean is cool, but I only really care about the quality. I'm not really that bothered about anything else. Let's see here. This is very, very fast, I have to say. Very, very fast. Okay. Well, this should be quite an easy video for me to make then this quick. Okay. So, we'll let this run, guys. We'll see how it does and I'll be back. But if anything happens, I will Okay, so this does happen quite a lot. The reason is that the prompt might not be perfect yet for uh client itself. This is actually quite common, so don't worry too much about it. Okay, so a couple of things I like to do is just have a look at the model cards. So, first of all, 256,000 context. It's okay. It's better than Anthropic, worse than JB T5. 0.20 is so cheap. These are very, very, very cheap. It's It's very cheap model. It's currently free as well, guys. So, if this is a decent model, then I mean, start building. Okay, guys. So, it I mean, this is how I do my tests, right? So, it says that it's done. It I It doesn't look very done to be honest with you. It didn't even finish all of the to-dos. Um I'm just going to run npm rundev. I will probably tell it to finish. Yeah. So, I mean, as expected, it just 404s, which is really, really, really pathetic. Um Grock, what are you doing? Why are you Why are you releasing things that nobody wants? Nobody wants a super fast [ __ ] model. I can tell you that for free, boys. Hire me as your AI guy because I don't know what you're up to. Nobody wants this. Nobody asked for this. I mean, seriously, I just told it that at 404 and it's still saying the website development is complete and running on local host. The next JS server compiled without errors and all pages are ready for testing. It's not found. You idiot. Does it even know what a 404 is? For [ __ ] sake, man. Come on, bro. Oh, it's cuz there's no EN, right? Yeah. Well, it My god. So, I don't know what some of these AI companies are thinking, honestly. Nobody wants this. Nobody wants a completely [ __ ] model. Nobody wants it. Nobody wants this. Nobody asked for this internal server error. Come on, man. I will say one thing, guys, though. It's very, very quick. It's a really quick model. Look, there is probably a use for this in some kind of application. I wouldn't use it for coding personally because it can't code for [ __ ] But for example, if you have a if you have a need for an extremely fast response, this might be the model that you use. Okay? It's probably going to be better than Mercury, um, which is kind of the other model that is very, very quick. But, I mean, come on. like who who honestly is going to be using this model. All right, guys. I've given this more than enough of a chance. I'm just trying to get it so I can actually see the website. Can't even see the website. This is honestly This is one of the worst models. This is like comparable to the open source models from a year ago. Like, what are they doing? What are you guys actually doing? How much are you spending on this? Oh my god. Look, honestly, I would give this a minus one out of 10. Uh, don't waste your [ __ ] time, guys. Complete trash. Can't even see the website. Even if I go to slashen, everything is just broken. Oh my god. I just want to see the website. Like it says here, Elon Musk, Elon Musk SpaceX invests two billion in XAI to expand AI. and it it can't even build a simple Nex.js website. I'm telling it that it's 404ing and it's saying great, now it's running on it. This is the worst test I've ever done in my life. Don't waste your [ __ ] time, boys. I'm going to leave the video there, guys. I'm really disappointed by this. Complete trash. Thanks for watching. If you're watching all the way to the end, as usual, you're an absolute legend. And I'll see you very, very soon with some more content. Peace out.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Analista testa Grok Codefast One, avaliando velocidade, custo e qualidade de codificação, chegando a uma conclusão crítica sobre a utilidade do modelo.",
            "resumo": "Neste vídeo, o apresentador testa o Grok Codefast One, modelo anunciado para codificação a baixo custo. Ele mostra como busca novos modelos no Open Router, configura o Grok no Visual Studio Code com o provedor Klein e faz login com o Google para realizar o benchmark. O foco é avaliar a qualidade do código, não apenas a velocidade, apesar de reconhecer o custo extremamente baixo (0,20 por milhão de tokens de entrada; 150 por milhão de tokens de saída). Durante o teste, surgem problemas: o prompt parece não funcionar bem, há erro 404 e o site não carrega. A conclusão é crítica: o serviço é visto como inútil para codificação, com vereditos negativos e comparação desfavorável a outras opções rápidas. O apresentador encerra sem recomendar o uso para codificação.",
            "assunto_principal": "Avaliação do Grok Codefast One (xAI) para codificação",
            "palavras_chave": [
              "Gro Codefast One",
              "Grock",
              "IA Explicável",
              "VS Code",
              "Klein",
              "teste de desempenho",
              "codificação",
              "404",
              "Mercúrio",
              "custo por token",
              "desempenho",
              "crítica"
            ],
            "resumo_em_topicos": "Resumo por tópicos:\n- Objetivo: testar Grok Codefast One no VS Code, avaliar desempenho na codificação e o custo informado.\n- Configuração: busca de modelos, uso do Open Router, integração com Klein e login via Google.\n- Desempenho observado: o modelo é muito rápido, mas a qualidade de código é duvidosa.\n- Problemas encontrados: prompts não funcionam perfeitamente, 404s, site não carrega, mensagens confusas.\n- Opinião do autor: crítica severa, não recomendado para codificação; comparação desfavorável com opções mais estáveis.\n- Veredito: avaliação negativa e alerta para o leitor não investir com base apenas na velocidade.",
            "prompt_tokens": 2131,
            "completion_tokens": 3236,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 64.69355487823486,
          "language": "",
          "view_count": 1043,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@LiamOttley",
      "name": "@LiamOttley",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "3HHMuaGIC30",
          "title": "Como ir de US$ 0 a US$ 100 mil com IA (Guia definitivo para iniciantes)",
          "title_pt": "Como ir de US$ 0 a US$ 100 mil com IA (Guia definitivo para iniciantes)",
          "url": "https://www.youtube.com/watch?v=3HHMuaGIC30",
          "published": "2025-09-20T00:38:05.283085",
          "published_relative": "há 1 dia",
          "duration": "43:15",
          "date_published": "2025-09-19T01:00:38-07:00",
          "transcript_available": true,
          "transcript": "Ask any multi-millionaire and they would tell you the first million is easy, but it's the first 100,000 that is the hardest part. And so in this video, I'm going to be breaking down the complete process for any beginner coming into AI to be able to go from zero to $100,000 and the five key challenges that you're going to face along the way and the solution to each of these different roadblocks. Sweet, man. Great to great to see you. I'm so excited to jump into this cuz that 0 to 100K is what everyone's after right now and you've just recently gone through that process. So, we're going to be breaking down um the five key steps that you've got in between here and there. And uh you've got a ton of source in there, guys. If you got don't know Kelly, he's been absolutely crushing it. I've been watching his story for a while now. Came up through my accelerator and he's just been going from strength to strength. The way he's doing his content on LinkedIn, uh the way he's sourcing this like the strategy he approached learning the skills with is actually really really smart as well. So, Michael, mate, it's great to have you on here and I can't wait to to share what you've got to got to share with these guys. or if you just want to give us a bit of a framing on on your journey and how you sort of come to the the realization on a lot on a lot of these before we jump in. >> So what you see here on the screen is the road to 100k and all the problems that I had to go through along the way and I broke them down into the five key steps five five key milestones that I had to go to get to the 100k because it is one of the most important steps at least for me um to then be able to to go down in different directions but I feel like these cover mainly what most people really go through when they go to uh to build an AI automation agency and so on. >> Yeah, for sure. I mean, there's uh these are the exact things I I have to answer again and again and again and again on calls. Um, and it's going to be so great for people to see this contextualized of basically taking the playbook that I've been screaming at everyone to do for so long and you giving us the actual screenshots of those messages that you're sending out and the examples of the post you're doing. So, I'm super super excited to jump into this, man. >> All right. So, the first up here is really just learning AI. So, this is the first milestone when you get into the whole space. I feel like this is where you get the most overwhelmed because you get introduced to all the different tools that are out there. In this case for me, I was introduced to Voppy uh voice flow make.com lovable and again you were one of the YouTubers that I that I was watching over time uh because you were introducing all the different tools and you're talking about the AI automation agency model uh and I was so so excited and when I jumped into the AAA which is where I really got started with the with the whole sort of journey I was introduced to all the different tools and I was overwhelmed because there's so many different things to focus on and I didn't really know what to do at that point. Um and that was >> that all the time. >> Exactly. And and that was I mean focus is one of the hardest things to have especially in the space because there's so many things you can do, so many things you can focus on. So for me that was a that was a key step that I had to go through. So what I did for me I actually spent a few weeks diving deep into each software to understand more so the space but also what each software did and the function that it played around how to build a business with it and then through Casey which is one of the success managers at AAA he told me if you just lock in and focus on one thing and that was make.com in that case work for automations and that's the thing that I decided to is jump in. remember I did a video I think it was in like end of um like middle of 2024 or something and it was like the five different ways to start an AI agency and it was basically the same thing. There's these different areas that you can specialize in. There's there's a voice agents. There was like I mean you could even go do Zap Zappia ecosystem and get really good at that. You could just do the workflow part of things. Um or you could do the textbased agents and chat bots. And I think what was really really helpful for a lot of people in the same way that it is for you here to just like cut out the noise and just pick one area because they're all like if you just focus on voice agents you can become very good at them and there's so much money to be created in that space right now. Likewise with workflow automations or if you want to be doing I think the custom software and vibe coding one is a great path to get into as well now. So taking that down from thinking you need to be like a general agency and be able to do everything to just being like this is my area of expertise and and I can learn that stuff which is is so important for beginners to know >> 100%. And it's so easy to just like focus on all of them because you just you just like you're missing the opportunity if you don't focus on all of them rather than just d each one which is exactly what I felt because I was I was learning everything one day. >> The interesting thing about workflow automations is is I call it's kind of like the meta skill cuz all you use it across everything. So even if you're building textbased agents you may still be like orchestrating that with with a with a workflow platform like make. Um, or if you're doing voice agents, you might be doing your tools on something like uh like make or you might be doing it on NA10 and the same kind of transferable skills. So, I still think that workflow automation base is is really really solid. >> 100%. Especially as someone who came in with no technical knowledge. I think the fundamental skill here is like APIs, understanding how apps talk to each other. And the skill you're learning is not make.com, it's workflow automations. And that's something you use across the whole board. Uh so that's >> and understanding how like software talks to each other like APIs is is the core of everything we do these days um across all even if you're putting custom software on lovable it's like okay well I've got this cool looking front end how am I going to get it to do anything okay well I understand that my my automations would have to send API requests around so maybe I can get some workflow automation or like some uh some tool that I create and then hook it into our API and it's just like everything is built on top of of that ability >> 100% I think that's something you you learn over time like what fundamental skills you actually need to learn. Uh but that was really really key for me. So what I did essentially was just niche down as much as possible. AI automation was is already a niche within AI to niche down to one subset of AI automation which is work for automations. And to be able to learn these tools um people over complicate this. They think they need a course. They think they need to find some some fancy software to go out there and learn these tools. But what I learned is just YouTube is the best place that you can probably learn all these all these sort of softwares and stuff. >> Nowadays as well there's so much of this content around on YouTube now. like the the amount of AI automation training content. I put out full courses here on the channel um on basically everything the AI agents, AI automations and vibe coding and all these things. I have full courses and then every there's channels that are just specialized in each of these different areas as well. So if it's like oh I haven't got the money to start this, it's just it's just not even an excuse anymore. >> 100% 100%. Especially for me cuz I literally had zero had zero dollars. And by the way, just so you know, like when I joined the accelerator, I didn't have any money. I asked my sister to give me 80% of what she had and my dad as well and I put it onto the accelerator and I went full in >> all in all in um and that that was that was the key for me and the thing that actually got me started as well was your chap videos like you were posting chap videos on voice flow. So that was the thing I found on YouTube as well that you can just simply just learn and just get going right away. So the second step here after learning AI and getting started once you know your sort of niche within the AI automation space you know that you're doing work for automations then it's about how can we get our first client clients right and for me at the start initially it was just about working for free for the first three clients before actually pricing any client before asking for money uh and for me it's just because of experience that I wanted to get but also just to get going getting the momentum going I feel like early on you want some quick wins you want something to to keep you going uh because that keeps you motivated and so on. Yeah, 100%. I mean, the free the free strategy, I get into a bit of a a difficult situation with some people like obviously you're young, you've got you've got time on your hands, you've got energy, and you wanted to do the fundamentals and learn learn from the ground up. When there's other side of the auto AI automation space or or people wanting to get into AI businesses are people with jobs and they want to do it as a side hustle and they want to come in and not necessarily do all that ground work and have like a really solid skills base. So, it's it's always a bit tricky whether for younger people like us or maybe people who are time rich. uh definitely doing all the learning, the fundamentals, and then working your way up through free clients to paid clients. It's just a very logical progression. Uh but then some people do come in and say, \"Oh, I don't really want to do all of that work. I'd rather just kind of be the be the connector or be the marketer.\" And that is that is possible, but this is definitely like 100% the the guaranteed way. I call it like the the slow way to get rich with AI is to do this path to learn the fundamentals and like you will absolutely get there. Um but it might not be as rapid as as you expect because you do have to go through free clients gradually increase your prices. Um which is exactly what you've done. >> I mean it's just doing the unscalable before you scale right and for me it was like 19 team with so much time like you mentioned no responsibilities. I've talked to 45 year olds who are trying to get in the space and I understand their point of view when they say they don't want to work for free because they have something to lose. They have responsibilities. So it just makes sense um on that end. But I feel like this is still the first step just to get experience to get the momentum going. I actually dropped the email that I actually sent to my first uh to my first prospect, which was a a guy that I knew from an agency that I work with. Um I just told him, \"Hey, >> I just wanted to to help you out. Um can you help on a call?\" That was basically it. And this was 5 days after 6 days after I saw your videos, the first video on on automation. And I was like, \"Okay, this is >> this is so sick. Let me just do it. Let me just jump in. Keep >> moving.\" >> Um didn't know anything. Did literally zero idea what anything was. Just send a message because why not? And these are other messages as well. And the warp network is legit like the the thing that I really emphasize on this is just reaching out or maximizing your your contact list. So go through your contacts and just message each person that you know. And I was 19 by the way. I had when someone told me this to to reach out to my word network. I was like the first objection I had was I know I know no one like no friends are mine. I'm business owners. I have no friends who are business owners. Literally nothing. Um once you dig deep into it like you find that your sister's boss is a restaurant owner and your sister's friend's dad is another business owner. Uh and go from there. This is so so important to point out and I I have to I keep answering these same questions as well. It's like oh but I don't know anyone. I say you need to get your first clients for more marriage. If you just ask people around you and you make enough noise and let people know there are people in your network um who not either they themselves need it. So you have your first degree connections and then in this case it's like someone you know who knows someone. So here you've got like your uh your sister's uh your sister's connection, right? Um so that's a second degree connection. So instead of saying, \"Oh, I only know young people or students um and none of my family have a business.\" It's like, \"No, who do they know?\" Ask them, \"Hey, hey, mom, dad, hey, or like my auntie or your uncle or whatever it is.\" Is there anyone that you know would be interested? I do this stuff now. And so I think it's so helpful for people to see these screenshots right here. Um if you've ever wondered how to do it or how to actually reach out to people like that, >> something I wanted to start, I was like, what do people even say when they reach out to the world network? >> This is exactly the text message. I mean, it's nothing crazy. Like none of this is crazy. It's just reaching out to people that you know. Usually the way I would frame it um if you're 19 with no network and you have nobody to know, you just frame it as like do you have do you know do you happen to know anybody who'd be interested to just help or like help with >> and if they are interested themselves they'll say yeah I'd like that but if not then then you get access to their second degree connections as well. So it's this is the whole Aussie war outreach strategy. It's not like I've invented it. Uh it it works so just do it. >> And that's at the start that's what you have to do at the start. I mean, I think that's a non-negotiable unless you just just get so much traction that you need need to get free clients. But I think like this is a really >> Yeah, any other route the the school community one you're about to break down is is a really good one as well. But if the fastest way to get your first one, two, three clients is going to be through that warm warm network you've got. >> It's just faster. Like you can do it tomorrow. You know what I mean? If you know someone, you can just do it tomorrow. Max out your contact list, go through each one and just >> you will get something like I can guarantee you just each one. >> Yeah. I've actually got a full guide on the warm outreach, guys. I I'll link that down below. Um you guys can just grab that breaks down the whole strategy that uh that Mel's using there. >> The next strategy for me was school community. Uh so I actually joined your your free school community. I mean now it's insane actually the amount of people that are there. Um but this for me it was like where do I go where people are asking for for work and because you were like the the guy that was just doing all these things and had a free community and a lot of people just joined. So, in your job board hiring, there were a lot of people who were asking for jobs, asking for work, like, \"Hey, do you know someone who's able to to do XYZ?\" And this is the the job post that I saw from a guy who's actually my friend now. Uh he was my first um my second client in this case, and he was looking for a chatbot guy, boys. Uh and I just DM'd him and said, \"Hey, I'm from the UK. I build chat bots. Uh can we help on a call?\" And that was pretty much that second client. And >> just like that, again, another thing I've been yelling at people to do is like if you there's we have like 500 to sometimes a thousand people per day coming into that community. They're either posting in the introductions and saying, \"Hey, like I'm XYZ. Um I do this and you could just reach out and make a connection or the hiring channel where there's people looking for either looking for developers or they're they have a specific project in mind.\" So, if you actually go in there and and at the same time, if you grind a bit of sort of clout within the community and you start to post and like create a bit of share a bit of value, um being the go-to people or notable in that community is there's there's so much business you can get off the back of that. So, it's great to see this being being like actioned on and seeing results from it because I know that hiring board has got so much source in it. >> I think it's so underrated. I mean, especially because there's 200 plus K people in the in the community and some posts don't even get any comments or one to two comments. like there's so much opportunity out there um that you can just take action on. So these two were the the different strategies that I used to get my first clients clients in this case the first two uh for free war reach and then school community >> and do you want to just give us a an insight to you maybe be a bit vulnerable what was it really like doing those first few clients bro like did you feel out of depth or did you feel that you'd prepared well enough with the with the material you've been through on learning automations like what was going through your head at that at that point >> it was horrible I didn't know anything I just hopped on a call uh I just told them that I do chat bots and I was like I can make your chatbot better And then we went on the call, we went off the call and I was meant to use make.com as well for like the chatbot. And I had zero idea how to do it. And I had basically had to spend three four days going on authorizations with the client and he got pissed off and he ghosted me. Um, so like that was the that was the first. >> So that's that's setting up the setting up the accounts on make. Yeah. >> On Hopspot, on voice flow, on web hooks. I didn't know what a web hook was at that time. Uh, just zero. He just goes to me time. So yeah. I mean, for for the beginners, what's the best way that you've uh there's there's a bunch of different ways of approaching it, but for those initial setups, like do you have Loom videos now? Do you have a a like SOP that you pass over to the client for setting them up on certain platforms or giving you access? Like what's the way that you've refined that? >> I think for me, uh the the way that you I like to hop on calls like I've tried different things. I've tried sending Loom videos on because I already had tutorials and hey, here's how you can make your Make.com account. Here's how to connect your your Google Sheets to make.com. But I found that even with showing a step-by-step video, the client still has questions. So you you might as well just go on a call with them and just walk them through. Hey, share your screen. Click here, click there, connect this, connect that, and then it's just better. Even if you invest that one hour, it would be there anyways. All right, cool. Now we can get to getting more clients. So now we got free clients. We got the first the second client. How can get more people to know about our stuff? Um, in my opinion, when I first got started, the thing for me was content. That's the thing that I saw you do and that really inspired me to just just post content as soon as possible because content is actually one to many which means that you can make one content or one piece of content it can go to a million of people. So you can get a lot of stuff uh from there. Now when you get when I got introduced to content I got introduced to medium, YouTube, LinkedIn X and and Instagram and one thing that I find a lot of times that people try to stretch themselves out and just do everything and that's something that I did at the start as well. Uh because I did YouTube, I did LinkedIn, I did I think Medium. I had no I literally I was doing everything. Um and thankfully I had people like Casey who told me, \"Hey man, stop messing about just just focus on one platform and just do it do it really well.\" >> Yeah, this is like a chronic beginner issue and I I always try to hammer at home, but just like one is enough. Uh even for me like I'm I barely post on LinkedIn. We're starting to post a bit more um to talk about what we're doing at Morningside. Uh X we've just started posting on consistently. Instagram I basically never post and medium I've never done. Like if you just do one platform and do it really well. Um particularly the big ones like if you're just doing YouTube really well or just doing uh LinkedIn. I've seen guys doing short form content on Instagram and getting tons of leads for their agency and their school communities through through short form on Instagram. Um and I'm sure you could do the same on on Twitter. Like I don't really think there's anyone really running the running the X uh the X space when it comes to a automation agencies and things like that. So if you just pick one and do it well. uh with even guys in the accelerator doing the medium strategy and just posting on medium and getting tons of leads for your agency like that. So, but you just got to pick one and do it well because there's that skill curve of like actually getting deep in the platform and realizing, okay, what are the trending formats? Okay, I've done enough of these posts now that oh, this one popped off and you just start following these little grains of truth from the data that you get back on your post. Um, which I'm sure is what you're going to you're going to break down now. >> So, for me, okay, so I got introduced all these platforms. My decision on why I chose LinkedIn was based on where do the people that I want to target where do they hang out and what was I most comfortable using at the time and so the LinkedIn content that I had the strategy behind it is something is the reason why I booked over 300 400 calls uh just off of organic content and it was uh separated into three different types of posts. The first one is the automation videos which is to show your expertise. The second one is lead magnets to provide good stuff for free. And then the third one is personal uh show that you're just human that you have a story that you're not that you just have feelings and stuff. So that that's the main uh thing about content and that part of side. Now the automation videos itself what they are and what I did then is just >> got as many nodes on the screen as you could that's the hook. The crazier the crazier it looks. It's like the NA10 ones now is like the crazier the the the scenario or the workflow looks. But yeah, I mean it stops the scroll, doesn't it? >> Exactly. It just hooks them. Um, so YouTube was where I learned. So I learned YouTube and then I actually posted on LinkedIn. This is this was crazy to me. I was I was watching YouTube videos building automation. I was making them with them. So I was actually learning through the process and I was posting it on LinkedIn and then I got clients. That for me was like just a crazy process that I had to go through because it just people over complicate this so much. You just learn, post what you learn and then just do it over and over and over again. >> That's what I call like the the potential framework. I think you would have seen in the accelerator as well, but there's this very very powerful upward spiral that I I got stuck in and and you've got stuck in and anyone else who's who's really succeeding in the space get stuck in, which is you realize there's when you start doing content off the back of your skills acquisition. Like when you learn a certain thing, you are like you're not just learning in isolation. You are learning for the sake of content and then that can help you to get leads and then those leads convert into clients and then those clients give you learnings and then you can talk about that in your content again. So, it's this like powerful upward spiral where like some people will just learn in isolation and learn learn learn and then they'll try to like go and market whatever they've learned. But if you're learning and creating content at the same time, >> um, and just really really exploring your own curiosities and like how how far can I push this tech, that was like the biggest secret for me was just finding something that I was totally nerding out about and I just wanted like it felt like play to me cuz I was just cooking up this awesome stuff and then I made a video about it and like that that I'm sure you can agree is when you get into that like real playful zone is when you make your best content and it's when you're making content that's really pushing the the the boundaries of the space and that's what's actually unique. The lesson with content that I if if you just do this like you'll just succeed is post content as you get good not when you get good. That's like the main thing that you just mentioned here is like like no one like just document what you're doing because there's no real experts in the industry. I actually feel like there's no real experts. This only came out like two years ago. Um so that's why uh I think that's that's important. So automation videos is just to show your expertise. This is you building an automation and showing hey guys this is the automation I built. This is what it does. And fundamentally like when I started I was working with zero clients. So I wasn't showing any automations that I built for clients. I was just showing automations that I just built for fun, you know. And that's what I I think one of the the roadblocks that I got started with. I was like, \"Okay, but I post videos. How like I have no clients. How can I post videos about automations I never built clients?\" >> Personal projects. I I keep shouting from the roof about that as well. Like if you're looking to get started, find some personal projects. Like talk to the GBT and get it to like help you pull some ideas out. But there's some personal projects either if you're doing voice agents, if you're doing workflow automation, if you're doing like textbased agents, there are some personal projects that you can do. >> Yeah. And because of the fact that we're targeting business owners, the the thing to understand is like business owners don't have the time to set it up, but they have the time to be on their phones, look at what's possible in the space to then reach out to you uh for help. And that's like the the thing. Now, the second part is lead magnets. Now, if I were to uh point the success that I had on LinkedIn, it probably was on the lead magnets that I made. So lead magnets fundamentally comes from the fact that you're playing within LinkedIn's algorithm. So the way it works is that you make a post, let's say Ulium, you comment on my post, your whole network, everyone who follows you sees that you in my post. It's like a compounding effect that just follows. And as you can see, I mean, it did pretty well. Um, >> damn. That's so important to to point out how how the algorithm actually works on on LinkedIn. It's just like with YouTube, you understand that they they're incentivized to recommend videos that are going to lead to long watch times and long sessions. just and on LinkedIn anytime someone comments if you can try to bait someone into commenting like if you maybe made a post about me and then I happened to comment on it then boom it goes to my whole network right and so the the lead magnets like this and asking them for them to to comment is going to get all of that spread out into other people's networks right >> like the thing about LinkedIn that I found over time is that it doesn't so much matter about the algorithm itself it's more so that you just share value like the way that you share value is different right here is through a video showing hey guys I just built this here's what it does I've never worked with the business but here's what it does and here's just me giving away some stuff. Um, and that's playing the LinkedIn algorithm. And I'll break down the exact post and how they work, all that sort of stuff. So, we can go that into more detail. >> The third one is personal show that you're human. Again, this right here, I think, is so underrated. You saw Mer, he did some personal post that did really well. H is the fact that LinkedIn necessarily like two years ago, two three years ago, it was just seen as a hiring platform. I still I think I still think it is seen as a hiring platform. And with the fact that LinkedIn is seen as a as a very serious platform and everyone's so serious and so like I'm proud to announce um then people necessarily care about their personal stories and that's like the proud >> to announce >> and that's like the the main thing is like if everyone's so professional don't be professional be yourself just share about your story of course like to the limit but um personal always builds up this is what builds a brand like this this right here I think what helps build a brand of like you're not just working with zooming on to that that bottom Lux over performance start learning. Sick. That's like showing behind the scenes the grind. That's like so so powerful, man. And what I really love about that this whole strategy if you zoom out a bit is like these are different content formats uh to zoom out to all three of them. And this is something that you guys really need to regardless of what kind of content you're doing is finding these different formats. And if you look at this, it's freaking genius because you have the lead magnets which are helping you to get pushed out into the algorithm. That's the discovery. It's like on YouTube here, I'll make some videos that are intended to go broad and get me discovered by new people. Those lead magnets are going to get you shown to a lot of new people. Then when they come in, they might like like or follow or connect with you in some way. And then they'll see on your page, you've got all of these show your expertise videos. And while those might not go as crazy, they will see that, oh, this guy's actually had a consistent track record of posting things that he knows. So, not only did he put this out, but one, he's a real person and he's got these like this is someone I might want to work with because he's obviously um into some interesting things or he's working really hard and he's got the expertise. This is like I'd say why this has worked for you so well is because you've got that discovery mechanism and then the credibility and authority and then also that human element to it. So, if you guys are doing content across any platform, the same thing applies. is need to find out how you're going to get pushed into the algorithm, how you're going to get discovered and then how you're going to show your expertise and then some element of of being a real person that people can actually relate to. So, I think you've freaking cracked it, mate. That's a it's textbook. But I mean the like we mentioned focusing on W platform. This is exactly why before I before I could put this together to show you guys it took me a year like a solid year which isn't a long time but like hours and hours and hours and hours just in my room just understanding what it is, how to do it, how to just get better and better and better. Invested money into like LinkedIn coaching and all that. Like all this stuff that I did to get really good at one platform and I'm still not good enough. To tell you enough like just being one platform is just so so key because like this is hard. Um >> imagine trying to do that across three at once. It's just there's just no way. >> Yeah. And that's why most people just stick to one platform and then they expand to different platforms when they understand one platform good enough. Um okay. So the automation videos lead magnets personal. The let's go on a deeper level. Let's look at the actual breakdown of the post itself. Each post on LinkedIn is similar. It has a hook. It has a body and CTA. Now CTA optional depending on the type of post that you make, but something that I always like to have because it drives them to take action. So the hook right here, one of the most important things about the post because fundamentally when you go on LinkedIn, most people don't know this, but 70% of the audience or people who are using LinkedIn are at work on their phones, right? So you want to make sure that the hook itself has 40 characters online, which is mobile optimized, summarizes the whole post. So when I look at this, I basically already want to understand exactly what the post is about without having to read it. And best to add numbers. So when you add numbers, it just shows results, more credibility, something that we're more willing to to do. uh especially for business owners because they have no time. They want to see exactly how it impacts them and how like the outcome the outcome that they can have for their own business by looking at this post. Then we have the body of the email. So this right here is just in this case a list uh works great. So step one is this, step two is this, three and four. And again, this is for automation videos. So hey, I build this automation. Here's what it does, right? In this case is what it does part. Um avoid paragraphs, make it easy for the reader. Again, I mean, you've probably seen posts on LinkedIn that are just like three paragraphs long. Nobody reads that. So, don't even like don't even try it for that. Um, and the >> and like you've got those little arrows put in there as well to like literally guide the eyes onto the next onto the next line. It's not just a bullet point. It's like actually an arrow pointing them to it. Um, so like guiding their eyes through each line. >> Now, the CTA, which is essentially what do we want the the person to do? A lot of people don't add this, which you're missing out on because a lot of people because of the LinkedIn algorithm, because like commenting is like a big part of LinkedIn and you want someone to drive action, to take action, do something. In this case, one just tell them, here's the next step you want to take. In this case, because I'm repurposing a YouTube content, you can say, hey, check out the link in the comments for the walkthrough. So, fundamentally, that's a strategy that I had for LinkedIn. Um, and I mean, right here, I broke down exactly how we can write each post, the different types of post and and so on. We'll leave the link down below just in case you want to take a look at it. >> Yeah, there's tons of good stuff here, guys. So, if you are wanting to do LinkedIn and really break down the strategy, Kell has really fully broken down how he's writing these posts. So, uh, for the sake of the people who aren't maybe going to go all in on LinkedIn, uh, I'll link that down below with those other links there, you guys can check this out. Super valuable. I mean, if there's anything you want to copy or or take inspiration from, then then it's just so I really appreciate you sharing this with the guys. >> Yeah, no worries. And honestly, like the the formats of the post are very templated in a sense. So, it's if you follow once, if you see it once, you won't see it. Uh, you will not forget it and you just copy it. So, uh, that's pretty much it for the content strategy. And then down below, I mean, that is the reason why I was booking two to six calls a day from LinkedIn organic with no nothing paid, which is pretty unheard of um to say from one LinkedIn account from one guy just in his bedroom just trying to make it. Um I think that two to six calls a day was was pretty good. >> And and that was all What was your what was your like conversion mechanism off that? Cuz obviously a lot of engagement. I hear a lot of people saying, \"Oh, I might have got a bit of traction or impressions, but I wasn't able to convert those into book calls or qualified calls.\" So were you like you're shooting them the link to the resource in the DMs and then you're starting a conversation from there or how much are you automating this as well? >> So the funny thing is I didn't send a single DM for months like a single DM. Um what I was doing is just putting the lead magnet and then updating the post later with the link um and then letting them know. Now, fundamentally, like yes, I was sending them the resource, but I wasn't pushing for a call because previously what I know what I did before was like I put the the lead magnet, for example, like the 3,000 comments. I was just on my phone replying to each one. I'll send it to you. I'll send it I'll send in the lead magnet. I never follow up because I didn't need to because I was getting already two to six calls a day just from like just >> Yeah. Yeah. Yeah. So, it's a supply issue, not a demand issue. It was a the same thing. Same thing. I think anyone who gets their acquisition and particularly content working well under this like for us at Morningside, it's not never been a never been a demand issue. It's always been a supply like how many new clients can we actually take on cuz there's just so much especially when you're doing general dev. >> I mean I guess it's like a good problem to have but it's still like it was still pretty bad. Um cuz the conversion off of like the book calls is horrible. I mean we can get into it still process that I had was consultation 45 minutes then proposal call another 45 minutes and then I had a 5% close rate. Now that's not even noticeable. I mean that's horrible. Um but the the the close rate was honestly it's just a numbers game. I'm like out of a hundred people that I speak to, I think one of them is gonna say yes, you know, and >> and and in between the consultation and the proposal is like four hours of like prepping and proposal writing and prep like putting together the slide deck and getting ready to prop like present it to them, right? So, I remember we would spend like four to six hours like prepping. As the projects get bigger and bigger as well, there's like way more you need to cover and more more like working with the devs to figure out how long it's going to take. But yeah, give us the how do you get over this one, bro? I I love this part. On that note, man, I was using Canva like every day for like three, four hours just putting like like you said proposals together. This looks pretty. This looks nice. Um but over time you realize like you can cut it down. Um >> and you get on the call and and they just not you realize you haven't financially qualified them at all and then they like they see the price and they go oh like they get a shock and then you just never hear from them again. So >> Exactly. >> Yeah. >> So the problem here wasn't the amount of book calls that I got. It's just conversion. Like I I had no friction which means that I had I think two three questions on the on the actual form. they could book in at any time they wanted for how long they wanted. Uh, and they just just came right in, right? And I just had to book calls every single day. I was so stressed. I was it was just horrible. The process that I went through to actually solve this was through actually changing my my sales process. So, fundamentally, it's just adding more friction, which means that you now tell the client, we only have a 20-minute consultation, which is free, so they can book in. Um, and this is more than enough time, more than enough time to like figure out exactly like sort of like where they're at and so on. And then if they're qualified, not qualified, but if they're Yeah. qualified, I'll say, then you pitch an audit. Now, this is something that I got off of your video where you mentioned an exploratory um >> expiration milestone. Yeah. >> Yeah. Exactly. So, that's that's the thing that I implemented. So, I told them, hey, if you want to work with me, you have to pay $200 for one hour for the audit. So, that actually made it worth my time to even hop on a call with a business owner. And that did three things. That increased my my ability to close because I spend more time with the business owner. that can actually like teach them some stuff and in in a sense and actually take them through different things see more opportunities for upsells later on because when you break down everything and audit you start to see more problems more problems so you can start start making like a road map as to like we can do this first and then that >> um and then the third thing is just you get more qualified people because if they're willing to pay for it they're they're going to be willing to pay for for whatever it is that you have >> now this is key guys I've I'll put the video that uh that is referencing here on on how we do exploration milestones at Morning Side. We'll link that down below as well. But it's really important. We had the same issues at Morningside. Terrible close rate despite tons and tons of leads. And as soon as you put a financial qualification in, either like it's a quick audit call or it's like we would hop off the end of our consults at Morningside and we'd say, \"Okay, yeah, we're ready to go on this.\" Basically, like there's a few there's always a few unknowns here. So, we're going to start at like 800 or or 1500 or now it's like $5 $10,000 for us what we charge for these initial engagements. But, we're going to explore these different solutions and we're going to see if it's actually technically feasible for you. And then at at the end of that, you get the full proposal and then we can move into the next next part of the the contract. >> What was it for you though? Um how did you know when to price the audit the the milestone that you that you did with them? >> When to or how to price it? >> How did you know how much how much to price them? Cuz you mentioned it's like three 10K. Like how did you >> Yeah, it's it's based off the size of the client and also the size of the project. So if it's like a huge one and we're talking about it's going to be like a 100 $200,000 project. We've just done a a uh expiration phase. We're in the middle of one just wrapping up at the moment. That's I think it was $10,000 or at least five figures um for the exploration part alone. And that started as as like a $500 like it, let's see if they say yes and then it went up to $800 then,000 and like we just gradually increased it um as the size of our clients grew as well. So you can just start super low like you do with this this audit just anything to financially qualify them to get the tire kickers out. >> Now they improve I say improved because I my closure went to 40%. Which is much better like an 8x from the 5% that I had. I was so much less stressed. I was making more because the quality of clients was increasing and I was working with less clients, less calls and more time uh to do whatever I want. Um, all right. So, that right there fundamentally is how the LinkedIn strategy was and that's what I used to get more people to know about my stuff. The next milestone or phrase that I had to go through was productizing my offer. Now, the reason why I wanted to productize my offer, it was by choice because with make.com for automations, because of the reason why it's custom, you get a lot of problems that I had to go through. The first one is scope creep. So, every single client that you that you get into doing a project, what it looks like at the start and what it actually looks like at the end, it's completely different. Completely different. So, uh it was it was it wasn't that nice when you had to figure when you figured out that something couldn't be done the way that you thought it was or when the client told you, hey, we actually have this step and you're like, oh, that changes everything. >> And then you got to like be a bit of an ass. You feel like you've been an  about it. You're like, no, but like that's that's not what we agreed on, man. Like, we're going to I'm going to need to charge you more for that. Um, and that's some uncomfortable discussions that I think early agency owners maybe aren't super great at dealing with, but just like knowing your value and saying, \"No, this is this is what we agreed on.\" Um, so yeah, >> I mean it's just about understanding that you're helping them like they're not help like they're not helping you at the sense, you know? So like position yourself is like I mean I'm making you a favor. So like let's let's just work together to make sure that we can we can get this going uh and whatever extra work we need. The the only thing for me at the start was like I told them let's say we're doing an onboarding system. The outcome is we'll do a fully onboarding a fully automated onboarding system but that that's the outcome you sign on the contract but the onboarding system changed over time but the outcome was still I had to do the onboarding system so I still have to do the project yes or yes and that wasn't that was a non-negotiable for us uh and you can talk to the client and so on but um at the start it was it wasn't something that I that I had the the balls to just go to the client and just say >> all right so when it came to productizing my offer um apart from scope creep we also had the knowledge gap so knowledge gap just means that whenever a new client came through they're from a different niche I had to relearn the whole market to un to contextualize the automation to like their business. And so that came from from just not knowing any niche and just figuring out as I go. But productizing my offer, the first part of it was just niching down. And so what I did is I analyzed the past 10 months of clients and I asked myself who did I like to work with, what brought the most money and what recurring problem that I get asked to solve the most. And that's like the that's the fundamental thing of like, okay, I need to niche down. And I analyzed all my calls, all the clients that I worked with, all that sort of stuff to then niche down to uh to the offer that I'm that I'm running now, which is again working with agencies um in specific for the client delivery, which is very niche. >> That's so far, man. I I think if you've like nailed it with that, that's such like a for the people that you're trying to help, that's like exactly what they they want to hear. Double client capacity without hiring more people in 30 days. It's so specific. Uh that's that's just such a fire positioning statement. >> So niche. So niche. this is like this super niche that um I mean there's there's not a lot of people who do this but fundamentally it's like when you niche down you're just scared that you're just missing out on opportunities but for me it's like I couldn't I couldn't do the custom work anymore so I had to do more so something that was repeatable so you can do every single time but also I knew the niche really well um and I could solve the actual problem that they had and by the way if you guys want to take a look at the the LinkedIn profile that I had when I actually had the offer this is what it looked like outcome picture statement and then the about section as well >> awesome yeah I mean that's typical way I laid it out. >> And so for me, the important thing was prioritizing my offer to make things repeatable. Um, so the delivery itself had to be repeatable because it was solving one painoint for one niche. And so the delivery process that we had was using a framework that I made over time which is called the AIAT framework. It all started with the audit. So fundamentally what this is is a call with me and the founder just breaking down the process that they went through from the moment a client signs to the moment a client to deliver the service and the whole process they had to go through that. Now this process was crucial again because without this we can't go to the next step. Um so fundamentally we just break down their whole thing is it's about one to two hour calls that we do with the with the clients and uh yeah this is an example that we had. Then we have the implementation phase and this is where we centralize their project management system on notion and these are the dashboards that um where they basically manage their whole client delivery. So team tasks um projects all that sort of stuff there. >> Okay. And so this is you migrating them over to something that you've built right. So this is a template that you've created and you're like this is my system. this is how you're going to be able to scale your uh like increased number of clients you can you can handle without hiring more people. So you're sort of pushing them onto this >> because I know the niche really well and I know that agencies to manage their client delivery they use one software and other software and three other softwares and everything's so scattered. So notion is a software we use because it allows us to put everything in one place. So yeah that's references everything here. So implement project management and then we go to the automation part which is where we automated at least 30% of the whole client delivery using make.com. So see how I'm not discarding make.com. I'm just putting it into like a higher ticket more um just more transformation for the agency. That's increasing and integrating with like a bigger system in this case. >> Mhm. And so you you're just changing these around maybe like 20% of the work done that you would have had to do initially is just like tweaking it around, changing the prompts, making sure it's all working as as expected. >> 100%. I mean cuz I knew the niche really well and they all had similar problems. They they all had a similar process. Um, so it wasn't it wasn't like a crazy amount of difference from each each sort of agency. And the next part is train. So we obviously had a delivery call with the team. We made SOPs uh that we can put them in notion. So we they know exactly how the the whole system works. And then we have the optimized period which is 60 days. So we improve the system over time. We jump up bi-weekly calls with the whole team and make sure that any changes are made after using the system. Now, this is great for us because we get to cultivate the relationship with the client, which is, I believe, is one of the most important things as you're getting into higher ticket because this right here, this offer was going for 9.5K. Um >> Mhm. >> And so, >> 9.5K. >> Yeah. >> Damn, bro. That's bro, that's way more than I than I would have expected. That's freaking awesome. >> Just positioning, bro. Uh >> positioning, bro. And and it's also like if you got enough leads, you can afford to be, you know, like the more demand you have uh on these calls, like if you have only 10 people coming to you, you might have to sell it for five because like the chance of you having people who are are willing to pay that much is is is a lot less. But you have 100 people, there's going to be a handful of those who do have the budgets and are willing to spend more on this AI stuff than than the others. You can kind of volume your way into high ticket. Um which is basically what we've done at Morningside as well. I mean just just to let you know like the I ran an offer campaign on LinkedIn to get these clients. I sent about 580 loons personalized loons to people and to get my to get one one client which is 10k but like the in the upside is like so much better because it's 10k instead of just 2k which is like a normal project. Um so you ideally you want to work with less clients who pay more and increase ever made. So that's that. All right, let me go to the last milestone or the last process that I had to go through, which is how to outsource. So, how to make sure that now you have all these clients, you have these projects. How can you give it to someone else so you can focus on actually growing the business, making content because it is a full-time job like James said. So, the strategy for me was using three different places. The first one was the uh AAA um school community. So, I just put a post here, which is a full circle moment cuz I used to look for jobs here and now I'm putting a job there for someone to to talk out to me. That's the ecosystem, man. Like, it it works. And I'm on my YouTube videos telling business owners like go into my school community and post for you like make posts saying you're looking for certain things. Like you can come in here to to make posts about hiring as well. And then other people can come in here looking for work. Like it's a perfect perfect meeting of the two sides of this space right now. >> 100%. And uh the second thing for me was making a post on LinkedIn asking if anyone's interested now because right because I was doing notion as well like it was more it wasn't something that I could ideally find here. I mean, I posted here. I didn't get anything great off of Notion, but workflow automations because it's the AI automation space, I got like tons of people. So, that was that was good for me. So, LinkedIn as well. And then the accelerator, I mean, you guys have a whole literally a whole like place to to find people and they're they're vetted. Like, you won't put them there if they're not good. So, I used as well. All right. And when outsourcing to other people, the problems that you're going to find when you're when you're giving work to someone else, at least that I find um is you don't have enough cash flow to hire someone full-time. So, you hire a freelancer. The problem is is that freelancers are cheap but and they're lower quality, right? So that means you have to spend more time on training and resources. And what I found at least the freelancers that I worked for, they weren't not delivering on the timelines that I set. But it's like the the balance is like you will only pay more for someone who's more skilled but you don't have the cash flow um compared to someone who is cheaper, >> but you have to put more time into like making sure that you do the right job. >> Yeah, I've been I've been ringing this bell for for a long time. We had those that was our first when I was getting Morning Side AI off the ground. It was it was Upwork freelancers initially and they just you're one of you're one of 10 clients and I mean they're probably not even like they might just be good at reaching out out to people within the community and they've got a lot of projects but they're not super skilled. Um and so you want to be able to get to that point where you can pay someone to get all of their time and that's such a big unlock for any any agency or anything you're doing here in the AI space is that first full-time developer because they can drive so much uh in results and deliveries for you. So um it is it is a tricky period initially with these with the freelancers. >> I mean the good thing about my offer was that it wasn't so custom so like I could train someone to do it. Um and the the thing that really ended up happening was that I just got a notion guy who just did not stuff cuz that was like the main thing structuring the system and I offloaded the the make.com to someone else as well. So I had these two people in the same time. >> Now the solutions that I can that you can implement that I implemented was set expectations on day one make them want to work with you. I think that's one of the the main things is like I mean people if you have someone who's good who's I mean if you have someone who you can see potential that they're actually good make them want to work with you like invest time into making sure that they're all set uh to make sure that you stay and you basically form a long-term relationship because working with someone I mean you your business is your baby like you want to make sure that it actually grows and you want to make sure that the people who are taking care of the business are are just they're solid and they have a they see your vision. >> Yeah. Super in invested in what you're doing. Yeah. And that's uh that's part of that when the leadership skills come into play is like painting the vision. I mean like look we're going places like this is do you want to be on the ship like look I want to get you into these roles like you can really step up into this position. Um and the right people will respond really well to that. And uh that's that's how I've always approached leading these people. >> And right here I mean we walk through the whole five-step process that uh that I went through to get to 100K with the with the agency. And fundamentally along the way you just get to learn new skills for here is just automations. Then here is how to reach out to people for the first time. Then here is content, which is a massive one. Here's offers, um, leads, all that sort of stuff you want to know. And then here's how to outsource, which is fundamentally all the skills you need to learn, um, you're going to have to learn to to get point. >> Yeah. I mean, it's it's the the the business 101 skill set, right? Like how to get clients, how to, uh, run the operations of the business, how to hire people and manage them, um, how to learn skills that you're going to eventually be able to monetize as well. So, mate, that's been uh some mega mega source. If you guys can't uh haven't got anything out of that, then there's something wrong with you. As someone who's on calls regularly with people, I'm talking to hundreds and hundreds of people across the community. I see it firsthand in my communities as well. What people are struggling with and what's making them ultimately succeed. It's all of these roadblocks that Mckelly's broken down here. And he's basically given a textbook way of getting over each of these. So, it's awesome to see you just flawlessly execute on the exact strategy that we've uh we've laid out for you, man. And uh I'm so excited for what what's to come for you, mate, cuz you're you're absolutely crushing it. I >> appreciate you, man. And I mean this is a repeatable process that anyone can go through. I'm not not doing any magic here. This is what works. Just do it, focus, and just be consistent. >> So, really, really appreciate you and and all the best. I hope you guys can agree that that was absolutely packed with source for you beginners looking to get into building an AI business. Like I said, if you guys want to get in touch with Mikuel and his agency, the links will be down there. And if you guys want to be featured on this podcast as guest, you have a story to tell, or you have some secret source that you really think could benefit the community, then you can apply to be on here on my channel using one of the links in the description below. If you want to hear another incredible success story about two 19year-olds from Turkey making $320,000 with the AI agency by selling AI audits, that's broken down here in this full interview that I did with them. But that's all for the video, guys. Thank you so much for watching and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Guia prático em cinco passos para iniciantes em IA chegarem de zero a US$ 100 mil, com foco em aprender IA, escolher uma área de atuação e dominar a automação de fluxos de trabalho usando plataformas como Make.com.",
            "resumo": "O vídeo apresenta um caminho prático para iniciantes alcançarem US$ 100 mil com IA, estruturado em cinco etapas e enfrentando cinco desafios comuns. O relato destaca o ímpeto de transformar curiosidade em habilidade, enfatizando o primeiro marco: aprender IA sem se sentir sobrecarregado pelas inúmeras ferramentas. O entrevistado aconselha focar em uma área específica — automação de fluxos de trabalho (workflow automation) com Make.com — para desenvolver competência prática sem precisar dominar tudo. Ressalta ainda que a habilidade central é compreender como os aplicativos conversam entre si via APIs, o que facilita aplicações em diferentes frentes, inclusive em uma possível agência de automação de IA. O conteúdo valoriza aprendizado gratuito, principalmente via YouTube, e compartilha exemplos reais de mensagens, posts e estratégias para começar a ganhar dinheiro com IA mesmo sem capital inicial.",
            "assunto_principal": "Plano de negócios em IA para iniciantes com foco em automação de fluxos de trabalho e especialização em uma área específica (Make.com).",
            "palavras_chave": [
              "inteligência artificial",
              "automação de inteligência artificial",
              "automação de fluxo de trabalho",
              "Make.com",
              "interfaces de programação de aplicações",
              "foco",
              "especialização",
              "aprendizado gratuito",
              "YouTube",
              "agência de automação",
              "zero a 100 mil"
            ],
            "resumo_em_topicos": "## Principais ideias\n- Objetivo: ir de US$ 0 a US$ 100 mil com IA, usando cinco etapas.\n- Desafio inicial: aprender IA sem se perder entre muitas ferramentas.\n- Solução central: focar em uma área (automação de fluxos de trabalho) e dominar uma ferramenta chave (Make.com).\n- Habilidade fundamental: entender APIs e como apps se comunicam entre si.\n- Método de aprendizado: explorar conteúdo gratuito no YouTube para aquisição prática de habilidades.\n- Valor agregado: transformar o aprendizado em uma oferta de serviço/agência de automação de IA, com passos e exemplos reais compartilhados.",
            "prompt_tokens": 1872,
            "completion_tokens": 1982,
            "model": "gpt-5-nano",
            "cost": 0.0039
          },
          "analysis_time": 47.47897410392761,
          "language": "",
          "view_count": 18249,
          "has_transcript": false
        },
        {
          "id": "amvEyw_Qrrw",
          "title": "Se eu quisesse me tornar um milionário em 2026, faria isso com IA",
          "title_pt": "Se eu quisesse me tornar um milionário em 2026, faria isso com IA",
          "url": "https://www.youtube.com/watch?v=amvEyw_Qrrw",
          "published": "2025-09-17T00:38:05.283187",
          "published_relative": "há 4 dias",
          "duration": "20:59",
          "date_published": "2025-09-15T23:09:56-07:00",
          "transcript_available": true,
          "transcript": "As we speak, AI is creating a new class of millionaires. And it's not just the coders in Silicon Valley. I'm talking about regular people with no technical background and zero AI experience either. And I would know this because I'm one of them. 2 and a half years ago, I had no AI experience. And since then, I've built multiple different AI businesses that have generated me over $7 million. I've built AI systems for some of the world's biggest brands, and I've built the world's largest AI business community and channel here on YouTube. So, in this video, I'm going to be giving you the exact blueprint to get rich with AI that I wish I had when I started. And it's the exact path that I'd be taking today if I was starting a game from zero. To make things easy, we're going to be splitting this path to a million into three key stages. The first phase is start, which is about going from 0 to 10K per month, and that's all about building an AI side hustle. The second phase is going to be scale, where we're going from 10 to 50K per month. And this is all about doubling down on what works. And the third and final phase is expand, which is from 50K to over $300,000 monthly. And that's really about becoming an industry leader. So to start, let's get one thing straight. And the path to becoming a millionaire isn't about saving your way there. That's the slow road that everyone tells you to take. But the real path is about radically increasing your income. Like radically increasing it. And for 99% of you watching, that journey is going to start with one thing, and that is building an AI side hustle that makes you enough money to allow you to quit your job and win your freedom. And this brings us to phase one of the millionaire plan, which is start. Your one and only mission in this phase is to get to that $10,000 per month mark. This is your freedom number, you could call it. It's the income that allows you to let go of your past life and go all in on building your dream life. And to do this, we need a vehicle, a a form of business that you can start on the side that doesn't require a ton of cash to get started and that leverages the single biggest trend on the planet right now, which is why you clicked on this video, artificial intelligence. Right now, the fastest and most direct path to that 10K per month, is starting a simple oneperson AI service business, also known as an AI automation agency. But what does this actually mean? That might sound a bit scary to you, but basically it means that you are going to help businesses to understand and use AI. You're going to be their guide. You're going to be helping them from everything from training the teams to consulting on where AI can help them best to actually building and setting up AI systems for them. And now, I know what you're thinking when you hear that. The first two objections that I always hear when I mention that are, \"But Liam, how can I sell AI? I'm not technical and I don't have a computer science degree.\" And then secondly, even if I could sell it, AI is a huge and complex field. How will I ever know enough to be able to help a business? I know nothing right now. Give me a second. I'll just dismantle those right now because that is the biggest blocker stopping people from getting into AI is these misconceptions and myths around what it really takes to get in and learn and make money from it. So, we'll start with the nontechnical bit first. When I started my journey, I didn't have a computer science degree. I didn't have a PhD in AI. I had zero AI experience. I'm completely selftaught in my development skills and also my knowledge of AI. And yet from that starting point just 2 and a half years ago, my agency, Morningside AAI, has gone on to work with some of the world's biggest brands, including an MBA team, an NRL team, and even publicly traded companies. And at this point, across all my businesses, I'm making over $500,000 per month. If I went from there to there, then you can definitely go from where you are to $10,000 per month. The reason for this is that the game has changed and that you don't need to be a developer or a coder anymore. The secret to getting into AI in this way is using simple no code tools that allows you to build basically any powerful AI system just by dragging and dropping. This is the first reason why this opportunity of selling AI to businesses in some form of an AI automation agency is so massive is that the door is wide open to it and anyone can get into it. Okay, so now let's deal with the second one about AI being too much for you to comprehend or learn in a short amount of time. to where the real secrets of how people are getting into AI lies. And it's that yes, the AI universe is massive. At my agency, Morningside, we are a general AI development agency. We can build almost anything that our clients want. But that's a very, very tough game to play. It requires a big team of expert developers who know everything, the whole AI space. But for a oneperson AI services business, you want to play a much smarter game than that. And that's called becoming a niched AI agency. Your mission here isn't to conquer the whole AI universe. It's to just become an expert in one of the tiny and valuable hotspots that are popping up right now. This is the core of the strategy I'm about to give you to get this AI side hustle off the ground. And I call it the AI solarreneurs blueprint. So to put this together, I've done all of the hard work and distilled everything into a simple and repeatable formula that answers the three questions that every beginner has when they're trying to start one of these businesses, which is what do I sell, who do I sell it to, and then how do I get my clients? So to keep this video from being hours and hours long, I'm going to give you the highle strategy here in this video on how to get this off the ground. But just so you know, I've created a complete 40 plus page guide that breaks down every single step on the way to getting this off the ground, including tutorials and templates. And I'll tell you how you can get access to that for free at the end. So, starting off, what do I sell? This is the most common question that I get. So, I've made it super simple for you guys. I have dug through all of the data from my community and from my own agency as well. And I've whittleled it down to just four of the most in demand beginner friendly AI systems that almost any business needs right now. So, these may sound scary as I go through them, but in the free guide that comes with it, you will have links to step-by-step tutorials on how to build each of them using no code tools, so there's no excuse why you can't get in there and get your hands dirty and start to build them. So, the first one is a speed to lead system. This is a simple automation that ensures that the business responds to any new customer inquiry or people reaching out to them in seconds, not hours. This is incredibly powerful when set up correctly because most deals go to the personal business who responds first. The second proven system is a WhatsApp or SMS booking agent. This is you can think of kind of like your local barber or restaurant where they might want to have something that allows customers to book or make appointments or reservations just by texting the business. So, it's available 24/7 and that's a massive convenience for the customers, but it also captures a ton more business. The third option is a social media DM agent. So, similar to the one before, but this is talking about going onto Instagram or Facebook where an AI agent can be set up to answer the common questions people have to handle any customer support or even booking appointments. So, this is going to save business owners, particularly small business owners, hours and hours per day. The fourth and final option is the AI receptionist. And every local business has a phone number and they often miss calls all the time because either the line's busy or they're asleep. And so this AI receptionist system answers the phone automatically for them and handles all the questions and customer support and can book appointments automatically so they never lose a customer again to a missed call. So those are the four proven AI systems that basically any business wants right now. That is what you're going to sell. All you need to do is follow the tutorials in the AI solarpreneurs blueprint that comes with this video and just see which one clicks with you and decide that is your thing and that you're going to master it. That is the one little area in the AI space that you need to become an expert in. The next step is figuring out who we're going to sell it to. So, we're not going to be going after tech companies. We're going to be going after the most AI clueless businesses that you can find like plumbers and roofers and contractors and home cleaners and things like this. And this is the second reason why this selling AI services to businesses is such a huge opportunity. It's that this is a starving crowd. These businesses have a massive knowledge gap. They are years behind when it comes to AI, which means just the simple system that you learned how to build before will seem like magic to them. Like your knowledge in this one little area will be light years ahead of where they are. And I remember my first client for Morningside was a AI sports betting system that I built on my laptop while I was still living in Dubai. And I was terrified. I felt like a total imposter. But I realized that I just had to be one step ahead of them. And that's all you need to be. And they will happily pay you to fill that gap. So the final part is how to get customers. So, the good thing about this is that you don't need hundreds. Your entire goal here is just to get four clients paying you $2,500 a month. And the fastest way to find these four clients as a oneperson AI business is with a simple cold email testing strategy. This is a distilled system based on what's working right now for my members in my AAA accelerator program. So, here's how it works. You're going to pick four of those boring and nontechnical niches that we talked about before. ET like HVAC or roofing or pest control or plumbers or home cleaning. Then, you're going to set up and send a simple cold email campaign to all four of those niches offering that one system. Now, based off the responses that you get, you're going to see which niche is responding to which offer with the most interest. So, maybe plumbers love the AI receptionists, but the roofers don't care. So, maybe you test all the AR receptionists, and you don't get any responses with those niches you tested. Okay. Well, I go on to the next one. I go on to the speeds lead system, and I test all those niches again. And eventually, you're going to find one particular matchup of a offer and a niche that is far more interested in responding at a higher rate than the others. And that is where you go all in. That mix of niche and offer becomes your narrow hotspot that you are going to become an expert in. Now, I know as a beginner this may sound terrifying. So, I have included a 20page guide on how to set up this exact cold email system in the AI solarpreneurs blueprint that's included for free with this video. And on a personal level, this is the part that truly drives me is because by starting this journey, you're not just building a side hustle. You're actually acquiring the most valuable skills on the planet. The income from starting these businesses, of course, amazing, but the real reward is actually the confidence and the security that comes from knowing that you're on the right path. And I I've felt it myself and I see it every day in my community. people are just like happier and more energized because they know that they're betting on the right thing and they've shifted out of something that they think is like a sinking ship or doesn't really give them the future prospects that they want. And that feeling is everything and that's really why I make these videos to try to give you guys that feeling. So that is the plan for phase one. It is not just a fantasy. It's a simple and repeatable formula. You learn one system. You find one niche of clueless businesses. You get four clients. You hit your freedom number. Once you've hit that 10K, you have earned your freedom. You can quit the job. And now it's time to go all in on scaling it. Phase two, scale from 10 to 50K per month. Now you were in the top 1% of people who actually take action on these kinds of videos. So the key thing here is that when you're working your job, handling those first four clients probably felt like a full-time gig in itself. But now you've just unlocked your most powerful asset, which is 8 hours a day of your own time to pour into the business. So this is where the real work is going to begin. This is where you get serious. And that brings us into phase two. So your priority in this phase is to scale from 10K per month to $50,000 per month. And this isn't about finding a new secret or a new business model. It is just about operational excellence. You stop just being a founder trying to get things and hustling off the ground and you start being an operator. You take the one thing that worked and you build an entire machine around it. And there are four key levers that you need to pull in order to make this happen. So lever number one is master the value equation and raise your prices. And the reason you do this is because you are now fundamentally more valuable. And you need to understand this to your core. When it comes to pricing your services, I have a simple formula that is really, really important for beginners to understand. And that is that your value aka the price you can charge is equal to your skills times your experience. When you started with your first client, your skills might have been maybe 30 out of 100 in that specific thing that you were trying to build. And your experience would have been zero. But as you've delivered on those clients, now you have at least four clients under your belt. You've seen what works and what doesn't. You understand how to get results for this kind of business. you're starting to see patterns and you understand the business owner's problems at a much deeper level. And this means you can offer your new clients a much higher chance of success and that is what they are paying you for. You're no longer just selling a promise of like, oh, I'll increase your leads by 20%. You are selling a proven result that you've taken from your past experience. And so with this new value, you can now change your pricing model. Instead of just going for a monthly retainer, like maybe 2,500 a month, depending on the system, you can start to introduce an upfront setup fee. for example, 5K up front and then $2,500 a month. This is going to immediately increase your cash flow and starts to filter out the tire kickers or lower value clients from the higher value ones. Lever number two is to systemize your proof. So, your experience that you've just got is worthless if you can't prove it to other people. So, your new obsession is to start turning those past results you've got into undeniable proof assets that you can start to plug into your marketing. So, the first thing you should do is get testimonials. So reach out to your first four clients, get written testimonials, or better yet, get them on a quick video call or ask them to record a video testimonial. And this kind of social proof is going to be gold and key for you to scale. Secondly, you need to build case studies. So create a simple onepage document for each of your clients. What was the problem? What was your solution? What was the result? And use the hard numbers wherever you can. So as you're going through your client deliveries, you want to look for things like we reduced lead response time by 98% or captured 30% more inbound leads from their phone line. Thirdly, you want to start building your brand. So, use all these assets that we've just got to start building a simple brand, which is creating a website or updating it. Start to post some of these case studies on your LinkedIn and then start to position yourself as the expert for the specific problem that you solve. Level number three is to scale your acquisition machine. So, now that you have all of this proof, you start to pour gasoline on your client acquisition system. So, your cold email system is already working. Now, you need to make it 10 times more powerful by integrating your new case studies and testimonials directly into that email copy. Your outreach is no longer a cold pitch. It's a confident presentation of the proven results that you've gotten so far. And with your extra time that you've gotten from quitting your job, you can start to increase the volume of emails that you're sending and spend more time refining your scripts, doing split tests, and taking more sales calls, which are inevitably going to come from increasing that volume. Again, this is what the scale phase is all about. It's simply doing more of what's working, but now with a lot better ammunition. And finally, lever number four is to build your digital and human team. This is by far the biggest unlock for you in this phase where your goal now shifts to using AI and your first human hires to automate yourself out of the day-to-day work so that you can focus on what actually matters most, which is signing new deals. So, the first way you can do this is by setting up a digital team, aka using AI automation. You need to start using your AI skills that you're getting from your client projects on your own AI business. So, start to look at your processes. Where are the bottlenecks? Well, I can tell you where it's going to be, and that's on things like proposal generation. Are you spending hours on preparing proposals to send to clients? Well, there are tools like Genpark and their slide agent that can help you do that fully. Instead of doing it all by hand, you can start to take the transcripts from your sales calls or discovery calls, run it through Chat GBT to create a proposal outline, and then feed that into GenSpark to create a beautiful presentation for your client in minutes, if not hours. Another big one you're going to run into is contract generation. So, doing that same process again, taking the transcript and this time putting it into your own custom AI automation on something like make.com and getting it to generate you a ready document that's on something like Panda Docuign. And another massive bottleneck is going to be on client onboarding. So, if you can build an automation that handles all of these initial steps for a new client without you having to do anything, that's going to be a massive unlock for you and getting your time back. In the AI solarreneurs blueprint, I'm going to include a complete list of all the best tools for solo founders to build their digital team um that I use and many other people in my community use so that you can get more done with less. So, aside from using AI automation to build your digital team, you also can hire your first human. And for most of you, this is going to be a technical person, a developer or an engineer who can handle the client delivery for you. Basically replacing you and doing the setup for your clients. And I know this may sound scary, but if you do the maths, a good freelance AI developer might cost you $6,000 a month. And if that one hire frees you up to close just two more deals at your new higher price point, then they've already paid for themselves. So this one move allows you to focus 100% of your time and energy on sales and growth while your new hire is handling all of the delivery and client work themselves. So, as you can tell, this phase is a grind, but it's a focus grind. You are not searching for any new answers really. You're just executing on a proven model. You're like putting the hammer down and becoming the undisputed go-to expert for this one system in this one niche. Once you've built this machine and you're consistently hitting that $50,000 per month mark, firstly, congratulations. You've built a truly valuable business. And now, if you're ready, it's time to build your empire. Phase three, expand $50,000 to $300,000 or more per month. So, by this point, you have a proven system, a solid reputation in your niche, and a small yet effective team. You've built a truly valuable business making you $50,000 or more a month. But now, you are going to face a whole new set of problems. You're probably drowning in sales calls. And your client acquisition with cold email is likely hitting a ceiling. And so, in order to break through this and get on the path to millionaire status, you're still not making enough money. So, the priority in this final phase is to build a multiaceted business that can scale far beyond your personal time and effort. This is about diversifying your revenue and diversifying your client acquisition in order to build a truly defensible and actually wealth generating machine. So there are three strategic plays that you need to make in this phase. First one is to delegate sales and free yourself from the last bits of agency work. So right now you are still the bottleneck. You delegated delivery to your developer but you are still tied down in those sales calls. In order to expand the business you must free yourself from this final operational task. And so your next hire is a salesperson. This person's sole job is to take over the sales calls and close the deals that your system's now generating. And this one move again is going to free up your single most valuable asset, which is your time, in order to focus on the highest leverage activity in the entire business. And that new job is play number two. Play number two is all about building your brand and your own niche. So with your time freed up from sales and delivery, your new full-time job is content creation, like doing this sort of stuff. So cold email got you to this point, but it does have a ceiling. And the way you attract the best clients and command the highest prices like we do at Morningside AI and build a real moat around your business is by becoming the undisputed go-to authority in your niche. And you do that by building a personal brand like I've done over the past 2 and a half years. And the strategy to do this is to firstly pick just one platform, YouTube or LinkedIn. I have seen incredible results on both. But just do one and go all in on that. You need to start sharing everything that you do. Talk about the results you're getting for clients. Share the systems you've built. Share personal updates on what you're doing. teach the solutions to the problems that your niche is facing. And the first step is by talking your and owning the fact that you are now an expert in that niche. And this is exactly what I've done over the past two and a half years. I've gone from having basically zero following to nearly a million across all my platforms. And that brand is what fuels my entire ecosystem of AI businesses that's on track to do over $10 million this year in revenues. So the personal brand, I can confidently say, is the single most powerful asset that you can build that will actually outlive the business that you're starting at this point. Your personal brand is still going to be with you in 10 20 years potentially. Then play number three is to increase your revenue streams. So your personal brand is going to create a powerful new asset which is attention and authority. Now you monetize that attention by expanding what you can sell. There are two proven paths that you can take at this point and it's best that entrepreneurs really consider doing both. Path A is going deeper with high ticket services for your agency. So you're no longer selling just one narrow AI system. You're now the trusted guide. Like you know these businesses inside out. You go from just being the niche AI automation agency to the full service AI transformation partner, which is what we've done at Morningside AI over the past 9 months. And the best entry point into expanding your services as an agency is to offer what's called an AI audit, where you go into business in your niche and you analyze their entire operation, identify all the opportunities for AI integration that you see. And not only do you get paid for that, but then you get paid for building the things that you identify as well. So, it's a really great model for increasing the lifetime value for customers. I've actually got a whole video on how we do this at Morningside, which I'll link down below if you want to watch. But basically, the AI audit becomes your entry point to selling a whole sort of complete AI transformation package, which includes education such as training the leadership and their teams. You have consulting and ongoing strategic guidance for the businesses that you work with. And there's also of course development, which is building out all the custom AI systems that they need, which as I said, this dramatically increases the lifetime value of each client and positions you as their indispensable partner for anything they need AI- wise. Then path B is to go into info products. And this is the ultimate revenue multiplier. You take the expertise of what you've proven in your agency and you package it into a course or a training program for your niche. So you're essentially teaching them like the the DIY or do it yourself strategy. You can think of it like AI for roofers 101 or the ultimate AI operations playbook for plumbing companies. So, you're taking all that valuable knowledge and experience that you've learned over all of the work you've done with your clients and you're packaging it into some kind of info product that you can sell over and over and over and over again without having to redeliver it. Whereas on the agency side, you were limited by how many clients you can actually deliver for. The info is only limited by how many people you can get interested in buying the info. A perfect example of this in action is with a guy called Nate Herk, who was a member of my AAA accelerator program who I interviewed recently here on this channel. And he started exactly where you are. He had no technical background, no AI knowledge, but he just started by building automations of businesses using the model that I've described here. He then built a YouTube channel and now he has an info product business that does over $200,000 a month from on top of his agency. So in total, he's making $300,000 every single month by combining these two models of services and info. And that's the final plate. So by freeing yourself up and delegating the sales, you get to pour all that time into building an undeniable personal brand. And then you can monetize that brand by going deeper with your high ticket services and then broader with scalable info products. So this is the path that takes you from a six-figure income to a seven figure net worth. And this is the guaranteed route to becoming a millionaire with AI. That's the plan guys. You have the map, the vehicle, the route, all the information. Your next step is super simple. As I promised, the full AI solarpreneurs guide, which is over 40 pages detailing exactly how to go from $0 to $10,000 per month, is in the first link in the description. And while you're at it, make sure you also join my free school community. It's the largest AI business community in the world. And when you join, you'll get access to my free course that's in there. You'll get live Q&A where you get to ask questions directly to me. We do those once a week. And of course, you can network with over 200,000 people who are on the exact same journey as you, trying to use AI to build the life of their dreams and become a millionaire. Honestly, it's the single best place on the planet right now if you're serious about doing this. And of course, if you got value from this video, put a lot of work into it. Make sure you leave a like and subscribe so you don't miss the next video where we're going to continue breaking down how to use AI to build your dream life. So, if you want to check out my full video on how to build a oneperson AI services business like we've talked about here, that video will break it all down. But aside from that, guys, that is all for the video. Thank you so much for watching and I'll see you in the next one.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Plano em três fases para ficar milionário com IA em 2026, começando com uma agência de IA formada por apenas uma pessoa e indo de 0 a 10 mil, de 10 mil a 50 mil e de 50 mil a 300 mil ou mais por mês, por meio de soluções simples de IA sem precisar ser técnico.",
            "resumo": "Neste vídeo, Liam Ottley afirma que a IA está criando uma geração de milionários, incluindo pessoas comuns sem formação técnica. Em 2,5 anos, ele diz ter criado várias empresas de IA, faturando 7 milhões, trabalhando com marcas e construindo a maior comunidade de IA do YouTube. O plano é um roteiro para ficar rico com IA, dividido em três fases: Iniciar (0 a 10 mil/mês) com uma agência de IA de uma pessoa; Escalar (10 a 50 mil/mês) expandindo o que funciona; e Expandir (50 mil/mês a mais de 300 mil) tornando-se líder no setor. A meta é aumentar a renda, não economizar. A primeira etapa é oferecer um serviço simples de IA para empresas, sem exigir formação técnica, usando ferramentas sem código. O vídeo descreve o que vender, para quem e como conseguir clientes, apresentando four sistemas iniciais em alta demanda: velocidade de resposta ao lead, agendamento via WhatsApp/SMS, mensagens diretas em redes sociais e recepcionista de IA.",
            "assunto_principal": "Construção de riqueza com IA por meio de uma agência de IA de uma pessoa, com plano em fases (Start, Scale, Expand) e foco em soluções no-code para pequenas empresas.",
            "palavras_chave": [
              "inteligência artificial",
              "milionário com IA",
              "agência de IA individual",
              "sem código",
              "automação de negócios",
              "tempo de resposta ao lead",
              "agendamento via WhatsApp/SMS",
              "mensagens diretas em redes sociais",
              "recepcionista de IA",
              "iniciar-escalar-expandir",
              "nichos de IA",
              "captura de clientes",
              "modelos e tutoriais"
            ],
            "resumo_em_topicos": "- Oportunidade de enriquecer com IA para pessoas sem formação técnica.\n- Jornada em três fases: Início (0 a 10 mil/mês), Escalar (10 a 50 mil/mês) e Expandir (50 mil/mês+).\n- Foco no aumento da renda, não na redução de custos; busca pela liberdade financeira.\n- Estratégia de uma agência de IA de 1 pessoa (sem código), conceito de 'solarreneur'.\n- Meta inicial: serviço simples de IA para empresas, sem exigir formação técnica, utilizando ferramentas sem código.\n- Quatro sistemas iniciais em alta demanda: velocidade de resposta ao lead, agendamento via WhatsApp/SMS, mensagens diretas em redes sociais e recepcionista de IA.\n- Barreiras removidas: não é necessário diploma ou grande conhecimento técnico; foco em nichos.\n- Disponibilização de um guia completo (40 páginas ou mais) com tutoriais e modelos para começar.\n- Contexto do criador: já faturou milhões com IA, atende grandes marcas e lidera uma comunidade de IA no YouTube.",
            "prompt_tokens": 1888,
            "completion_tokens": 6248,
            "model": "gpt-5-nano",
            "cost": 0.0103
          },
          "analysis_time": 80.4615490436554,
          "language": "",
          "view_count": 73097,
          "has_transcript": false
        },
        {
          "id": "yvYj11GdUTc",
          "title": "Replit Agent 3 é INSANO… Aqui estão 4 maneiras de ganhar dinheiro com ele",
          "title_pt": "Replit Agent 3 é INSANO… Aqui estão 4 maneiras de ganhar dinheiro com ele",
          "url": "https://www.youtube.com/watch?v=yvYj11GdUTc",
          "published": "2025-09-15T00:38:05.283204",
          "published_relative": "há 6 dias",
          "duration": "14:49",
          "date_published": "2025-09-14T03:21:49-07:00",
          "transcript_available": true,
          "transcript": "For the past two years, the AI automation space has been split into two camps. You have tools that build apps, and you have tools that build workflows. And that division is about to end. A new player has just entered the arena with a move that could make standalone tools like Lovable and Nad obsolete. So, today I put Replet's new Agent 3 through a brutal head-to-head battle against its biggest rivals to separate the marketing hype from reality. And in this video, I'm going to be giving you those results. You're going to see where it wins, where it completely fails, and I'll give you a clear blueprint on how to actually make money with its current strengths. So, what makes Agent 3 a potential game changer? Well, it comes down to two massive leaps forward that we've seen with this new update. The first is automated self- testing. So, if you think about it, we've come a long way when it comes to code generation with AI. Like, we started off with just tab completions to now we're building entire apps in just a single prompt. But these apps were always just a first draft and they were often full of a ton of bugs that you had to manually go through and figure out yourself and then go through a phase of follow-up prompting to try and get these issues fixed. Well, this massive new update from Replet with Agent 3 is designed to solve this because it doesn't just write the code. It actually spins up a virtual browser. It clicks through the app like a real user, finds its own errors, then it goes back to fix them all in a continuous loop. It's just like having a junior QA engineer built into the agent to help you identify and fix these early bugs. So, this is the first massive leap forward we've seen of being able to spin up a virtual computer, test it software, and then fix those in an iterative loop. And then the second huge leap is just the increase in the the duration of the periods of which it can do this in. episodes and a massive increase in autonomy. They've gone from supposedly 20 minutes to over 200 minutes of unsupervised runtime. And the significance of this massive increase in autonomy to hours and hours and hours of working on a software project for you autonomously is like you could be out for a walk and you have moment of inspiration and then you pull up the replet mobile app which I've just downloaded and it works really well and talk into it and just dictate an idea for an app, put it back in your pocket by the time you come back from your walk an hour or two later and the idea is that it should be functional and ready to go. So the gap between idea and actual execution is collapsing with these incredible advancements in autonomy. But the biggest strategic move here that Replet Star making is a direct play for the AI automation market competing with giants like NAT, Make.com, and Zapia. They've done this by adding their own agents and automations builder, which is essentially the same as NAT's new prompt to workflow builder where you can put in a prompt and it's going to build out an entire workflow for you. I mean, Zapia has had this for a very long time. NA10 built out their own one. And this is essentially Replet's own version where you can go prompt and explain what you want the agent or automation to do. And Replet agent 3 is doing this by building on top of Mastra, which is their framework for building and orchestrating the agents in the back end. And one of the most exciting features about this new AR agent in automation builder is their new Slack integration. So they've been able to turn the absolute nightmare of building a custom Slack bot into a simple and guided setup process, which opens up a ton of new use cases for people looking to sell AI agents to businesses. And so this rapid and easy Slack integration alone is a huge deal for anyone looking to sell internal AI tools to businesses, which we'll be touching on a little bit more later. So on paper, this Replet Agent 3 is a huge step forward. But is any of this real when you actually put it under pressure? So I put Replet Agent 3 headto-head against Lovable and Google's Gemini across a series of increasingly difficult software development challenges to see where it shines and where it breaks. So first up, I wanted to test a standard internal tools, a CRM for a pet grooming business. And right away, the difference was pretty clear. Uh when I gave the same prompt to lovable in Google, while they were way faster at spitting out a minimal and barebone CRM in minutes, Replet took a lot longer taking its time and figuring out what it wanted to do, testing itself, but the result, the final product was on a completely different level to these other platforms. Replet's agent actually thought through the real world needs of a CRM. It built a more fleshed out and functional application because it was testing itself along the way. And it I mean it did take literally hours and so it is slower, but it's much more thorough. So for this round of building a CRM for a pet grooming business, Replet was a clear winner. But what happens when you give Replet a task that it self- testing features can't handle. So I asked it to build a 3D game. And here the tables turned around because the automated testing is optimized for web apps and it's actually not available to do on 3D game design. So without this testing superpower, RIP agent really struggled to build a basic 3D game. Whereas lovable, which just focused on the pure code generation, produced a much better result and in a few minutes. So the winner here by far was lovable. Then I got a bit bored and wanted to test this thing on an actual idea for an app that I've had for a while, which is an app that's going to take audio inputs, transcribe them, and have multiple AI features to be essentially your own AI coach. And I found this was where all three of these platforms still hit a wall. Now, this app was supposed to be an AI performance coach that takes in morning and night check-ins from you where you go in and you press a button and you record your voice and say, \"Hey, this is how I'm feeling this morning.\" And you do it again at night and do that every single day. Then you can run that up into a weekly performance review and you can click a button. It's going to take all of your daily summaries. It's going to create a weekly performance report from the AI. Then you're also able to chat to this AI coach and it's going to have all of the different transcriptions and check-ins that you've done as context so that when you ask it questions about your performance or maybe what you can do to improve, it has full context of all of that feedback and and reviews that you've done. And it was with this application that I was able to find some more holes in Replet's testing abilities, which is it couldn't test the audio functionality of the app because it couldn't press the button and record into it. And it also wasn't very good at setting up the AI components that I needed like summarizing with a day or summarizing the week. Plus, it took a very long time and the final product wasn't a oneshot success. I'm sure I could have worked with it a little bit more, but it really proved to me that the highly complex and multimodal AI apps, these kinds of tools still need a human in the loop. They're not going to be able to oneshot things as you'd really like them to despite having this testing capabilities. So, for this round, there really was no winner. And so, I was pretty disappointed that out of all of the platforms, I couldn't get this to work. I even went to Claude Code and tried that and it still wasn't able to get it working. So maybe this is just a little bit out of the scope of what these kind of tools can do at the moment. So while the main app builder has its limits in terms of speed and also testing itself on certain features, the standalone agent builder for Slack is one of the standouts for this new replet update. I decided to get a simple use case for a Slack agent which is going to be able to give me real-time stock data within its Slack channel. If I'm honest, the guidance setup for this was flawless. It handled the API keys, the permissions, and everything. I've set up a lot of Slack bots and I can tell you that this is the most simple and straightforward experience of setting up a Slackbot that I've ever had. And after all the setup and prepping the app, it wasn't able to immediately deploy the app so that I could use it in Slack. And even to right now filming this, I haven't been able to get it working within Slack. So, while it showed a lot of promise initially, the actual testing and functionality within Slack, I still wasn't able to get it really working as I expected. So, yeah, it's pretty fatal error, but these issues I'm sure are going to be sorted out very soon. Um, but this is a very powerful way to deploy these AI agents in Slack, which is a place where you have millions of businesses basing their internal communications out of it. So, I'm going to give them the benefit of the doubt that these are just like launch issues. Or maybe I'm just stupid, but it doesn't seem to work no matter what I do at this point. So, after putting Agent 3 through the ringer, here's my final verdict. Let's start with the good stuff. For standard web applications like CRM or internal tools, I think this thoroughess that it has and the self- testing ability of more regular web applications is absolutely unmatched right now. It produces higher quality and more reliable end products than its competitors. And the autonomy window is so much larger. I let it run for like 2 hours um to get some of these things done. And also, as we saw, the Slackbot integration is a genuine game changer. These things are a massive use case, but they've always been a really tricky thing to execute on. And I think with this is going to really open up the door to the explosion of AI agents within Slack. But as you now know, it is not perfect. And the bad is that it's significantly slower than the other tools. even when I'm just wanting maybe a quick prototype spat out, uh something like Lovable or particularly the the Google Gemini and the AR studio was so much faster to just get something quick done and up and running. So, it's deciding which apps to build with this is important. If it's a really important project, then yes. But if it's just a quick tool that you're spinning up or a very very brief MVP where you just want to get a visual of what it might look like, then this thing is going to ultimately take a lot longer and cost a lot more because Replet's costs are a lot higher than other applications and I'd probably go for some of the other options on the market. But that's potentially an opportunity for Replet to make a fast mode where hey look don't spend all the time that you usually do just get this a very very quick version of this to me quickly rather than feeling like I'm going to get bogged down for 2 hours just for a basic app that I could get in 5 minutes from another platform. And so with Repent 3 you're trading at raw speed for reliability. And as the 3D game test proved it struggles with non-standard applications where it self- testing superpowers uh that are really one of its biggest strengths provide no extra advantage or even in the voice transcription use cases I was trying to use it for as well. And that brings us to the ugly. And here's the most important takeaway from this entire video is that the two halves of this platform, which is the AI app builder, like the vibe coding platform and the agent and workflow builder, they don't talk to each other yet, which is what I was really hoping for out of this. This is the most exciting thing for me because you may have seen people connecting Lovable to NATM backends and and connecting them that way. So you get the front end set up on these AI application builders and vibe coding platforms and you can build the AI functionality on the back end. And I think Replet is very close to being able to cross those two over and making the all-in-one platform, but they don't have it yet. And I think they have a long long way to go when it comes to uh being like an NAT or a make killer when it comes to building automations and agents. They don't have multi- aent capabilities. You can't tell it hey I want to have executive agent that is we're talking to multiple underneath it. Something like relevance AI which has really really complicated AI workforce capabilities right now. I think knowing their track history of execution will definitely get there but there is a long long way to go. and when it comes to their workflows, you can't trigger it by event yet. And that's kind of like the the whole thing of of building automations is like an event triggers something. So, very early days with it. I think there's a lot of potential here. And given their ability to execute, I'm not going to bet against them. But they do have a lot of work on their hands to catch up to where the rest AI automation marketplace is. But when they do have that, don't get me wrong, when you have the vibe coding side of things and you have the AI agents and automations and the ability to cross them over into the same application or have them standalone, I'm extremely excited for that. And I really think that's the most important thing that's happened here is that now we have the potential to have a platform that does both. So as with any new technology release, we need to be looking at where is the opportunity for us. Where can we build a business? Where can we make money? And that's what we're going to get into in this next section. In my opinion, the single biggest opportunity for the average person to get in to make money with these kinds of vi coding tools is to sell internal tools and software to businesses. Nowadays, you do not need a technical background to start small and with small businesses and get familiar with building things like custom AI image generators for their market teams or branded knowledgebased chat apps for the new hires for onboarding. All these things can be easily built through something like Replet Agent 3. And these internal tools are incredibly valuable. Companies just prior to now didn't have the money to spend on building them. And now, thanks to things like this replet agent 3, people like you can go and sell those to them for $500, $1,000, $1,500. And we are really going to see the gradual encroachment of software into every part of businesses taking away old clunky spreadsheets or forms. And we're even seeing this in my own companies right now. I'm using it. A lot of my team members are using it. And it's like, hey, why are we using this clunky set of tools now? We can just build our own custom interface, custom app to use internally. And even people who are not technical can do this stuff right now. I've just done a whole interview recently with someone who's selling these kinds of custom software systems for $15 to $20,000 per pop because it's replacing the $3 to $5,000 per month software stack. that most small businesses are running on. At that price point, it is a bit more advanced than what we're talking about here. But this video will explain how to start it as a beginner. So, I'll link that down below for you if you want to check that out. But mark my words, building these internal tools for companies and particularly AI tools using these vibe coding platforms is one of the biggest opportunities heading into 2026 and anyone can get into it. The next one is a super lowanging fruit and that's building Slack agents for companies. So, as we saw with this new release has created much much easier ways to deploy them when they work. But your offer to a company can be very simple. It's like I will supercharge your company Slack with a team of AI agents for your team to use in automating repetitive tasks. And the way this works in practice is that when you have these agents active within a Slack channel, a team member can go at stockbot like the example that I was building and say, \"What's the current price of XYZ?\" And it's going to be able to call a tool, get some information off the internet and pull it back in. Or for example, you might have maybe a script writing agent and within Slack, you can go at script writer and then paste a link to a YouTube video and say, \"Hey, make our own version of this script.\" And it's going to pull the YouTube video. that's going to pass it through a a tool that you've created and then be able to pass that straight back into the Slack. So, having your Slack come alive with all of these agents in it is something that companies are really really interested in right now and it should be a very easy sell if you know how to get in front of the right people. And we're only really just seeing the start of this, but it's definitely something to get good at now because when Riplet adds more features and integrations and even multi- aent capabilities where you can have one agent connected to a whole workforce of other agents underneath them, this is definitely something you want to get into now, not in a year's time. And thirdly, you can sell advanced websites for businesses. So, I'm not talking about basic brochures or static landing pages. Most businesses do have these kind of boring static landing pages that do nothing. So, in this case, you'll be going to businesses and offering them a website that has some kind of interactive tool in it. You can say, \"Hey, I've just redesigned your whole website and I've also built in a custom calculator or an AI powered tool or a chatbot that will actually engage with your visitors and generate more leads.\" So, and the reason this is such a good money-making opportunity is because you can identify people in your local area who have ugly websites that aren't really optimized. You can rebuild them on something like Replet Agent and go to them and say, \"Hey, here's this thing that I built you. It looks way better and it has way better lead capture functionality. Would you be interested? Like, it's 500 bucks.\" And you can show them the result right there. And that's what makes the sales so so much easier. And the fourth and final opportunity to make money with this new tool is to of course teach people how to use it. There are two markets that you can sell this to. You can go to consumers as a complete beginner. You can go in and find out how to get the most out of replet agent. You guys watching this video are case in point. There's interest around these tools and what they can do. If you can learn just enough to get good and be dangerous and find your own way of getting incredible results out of it, which might only take a week or two, then you can start creating content on it and make some kind of course teaching people how to get the most out of repent. And the second market is maybe off the back of that you start selling that same training to businesses where they can empower their own internal teams to be able to build their own tools. whether you're selling that to their development teams, which maybe isn't the the best angle if you're nontechnical, but if you are a non-developer and you've figured out how to get incredible results with this, then packaging that up into a course and going to businesses and saying, \"Look, I will teach your staff how to build powerful internal applications without writing any code.\" And giving that power to all staff members in a business is going to allow them to create some really awesome things from the bottom up. And now, here's what I wouldn't recommend, which is trying to build some kind of scalable SAS on top of Replet agent and then make $10,000 a month with it. really just not what these platforms are good for right now. The reliability of a public-f facing mission critical app just really isn't there. And the money is going to be in building these internal tools, the Slack agents, selling high value services through them. So stick to where these platforms are strong, but trying to make some micro SAS that's going to have thousands of users on it, payments and authentication. There's easier and lower hanging fruit you should go for first. So is Replet agent 3 a NA10 or lovable killer? Not yet in my opinion. But this is a huge step forward in autonomous app building and I think they are a platform that you should be keeping your eye on. Now, the direction of this market is clear that we're going to have these all-in-one platforms that combine app building and vibe coding with AI automation, workflow building or vibe automating is the future. And when these platforms start to cross over, that is a really exciting point for us, which I think Replet agent is closer to doing right now. So, if you're interested in this kind of stuff and want to learn how to build AI apps with these kinds of tools as a complete beginner, I have my complete 2hour course on doing that just up here. But aside from that, guys, that is all for the video. Thank you so much for watching and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Analisando o Replit Agent 3 frente a Lovable e Gemini, o vídeo destaca avanços de auto-teste e autonomia, apresenta vitórias e falhas em projetos reais e aponta a integração com Slack como diferencial, porém evidencia limites em apps multimodais e a necessidade de humano no loop.",
            "resumo": "Ao comparar Agent 3 com Lovable e Gemini, o vídeo destaca dois saltos estratégicos: auto-teste com um navegador virtual que identifica e corrige bugs, e maior autonomia de execução (de cerca de 20 minutos para mais de 200 minutos). Isso reduz a lacuna entre ideia e execução, possibilitando desenvolver aplicativos enquanto você está fora. Além disso, a integração com Slack aparece como diferencial para vender ferramentas de IA corporativas. Em testes práticos, Replit entrega, em um CRM para um negócio de banho de animais, uma solução mais completa, porém mais lenta, que Lovable e Gemini. Em um projeto de jogo 3D, Lovable vence por não depender tanto de testes automáticos. Já um protótipo de treinador de desempenho com áudio mostrou limitações de testabilidade e de componentes de IA, sugerindo que aplicativos multimodais ainda exigem intervenção humana. No geral, o Slack é o destaque, com potencial de monetização empresarial.",
            "assunto_principal": "Avaliação de desempenho do Replit Agent 3 em relação aos concorrentes e implicações para monetização e uso corporativo.",
            "palavras_chave": [
              "Replit Agent 3",
              "amável",
              "Google Gemini",
              "autoteste",
              "autonomia",
              "Slack",
              "Mastra",
              "agentes de automação",
              "Gestão de Relacionamento com o Cliente",
              "Inteligência Artificial empresarial",
              "multimodal",
              "teste automatizado"
            ],
            "resumo_em_topicos": "- Contexto: o mercado de automação de IA está sendo disputado entre construção de apps e de fluxos; a Replit entra com Agent 3 para testar a viabilidade dessa integração.\n- Saltos estratégicos: auto-teste com navegador virtual que identifica e corrige bugs; aumento da autonomia de execução de ~20 minutos para >200 minutos.\n- Destaque de produto: integração com Slack como diferencial para venda de ferramentas IA corporativas.\n- Resultados dos testes: CRM para pet shop – Replit vence por ter solução mais completa; jogo 3D – Lovable vence por não depender tanto de testes automatizados; app de coach de desempenho com áudio – sem vencedor claro, limitações de multimodalidade.\n- Limites identificados: testes automatizados nem sempre cobrem recursos multimodais (áudio, voz), exigindo intervenção humana em etapas críticas.\n- Impacto de mercado: reposicionamento competitivo frente a Make, Zapier, Zapia; base em Mastra para orquestração de agentes.\n- Conclusões de monetização: a integração com Slack abre portas para venda de IA interna em empresas; ainda há necessidade de validação prática em casos multimodais e complexos.",
            "prompt_tokens": 1852,
            "completion_tokens": 3223,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 60.268959045410156,
          "language": "",
          "view_count": 44848,
          "has_transcript": false
        },
        {
          "id": "IyrSfHizvWc",
          "title": "A chata oferta de US$ 15 mil em IA que está acabando com o SaaS (e criando milionários)",
          "title_pt": "A chata oferta de US$ 15 mil em Inteligência Artificial que está acabando com o SaaS (e criando milionários)",
          "url": "https://www.youtube.com/watch?v=IyrSfHizvWc",
          "published": "2025-09-10T00:38:05.283220",
          "published_relative": "há 11 dias",
          "duration": "40:24",
          "date_published": "2025-09-09T07:58:58-07:00",
          "transcript_available": true,
          "transcript": "The $5 trillion AI SAS industry is about to crumble. And it's going to create one of the biggest opportunities to create wealth with AI that we have ever seen. And this is because businesses right now are wasting on average $100,000 per year on a mess of software tools that don't talk to each other, creating a data nightmare that makes AI completely useless. And today, we're breaking down the exact $15,000 service that replaces a business's entire clunky SAS tech stack with a custom AI powered system. and I'm going to show you how as a beginner you can start building and selling this kind of system using just vibe coding tools like lovable. So let's get into it. Thanks for coming on. Excited to to hear what you got to share with us today. >> Ken as mate. Yeah, really appreciate the opportunity. I'm looking forward to jumping in showing you through the whole thing from start to finish. All right, so quickly what I'm going to just take you over is who I am. So this is my Upwork profile. This is where everything started. Uh I'm in their expert vetted program or the top 1% program and also the top rated program. So I've done a hell of a lot of work through here. You'll see AI transformation partner was actually coined term from Ulim. Uh but we've done a lot of work in the AI space and this is where I learned all of the groundwork skills that allowed me to understand the business proposition that I'm about to tell you about. So from there I built uh similar channels. So I've got a YouTube channel where I talk about freelancing and AI. Um, I've got a community and then I've also got this agency called APG Software which has done in conjunction with my brother and business partner over 250 projects. Uh, we've done work for one of Australia's biggest TV shows, Pittsburgh's [ __ ] Grown Company, Australia's biggest solar company and one of the world's biggest fast food chains. And it's built off the back of a generic software company. So we initially started building software for everybody. So process automation and apps of every kind, SAS apps, internal systems, everything. But we found a new opportunity that we're kind of going all in on. Um, similar to what you talk about in the productized services and niching your agency, we're trying to niche down into one offer that we genuinely think is addressing an extinction event with AI and where AI is going to be in 5 years. Um, and the solution is based around internal systems for businesses. It's a 10 to 20k USD offer in 2 to four week sprints and I think that is generally going to address an issue that is going it's do or die for businesses in the next 5 years and they don't even really realize it yet. So massive opportunity there. >> I've been thinking about the same thing as well and I I definitely think even at Morning I this opportunity up. It's like where is the where's it going to break first? How is it? Who are the people that are going to be implementing it? And I think it's been really exciting to see you you guys pop up um because that's obviously the start of the the bottom end of things and coming for the small businesses. So yeah, excited to get into it. >> Yeah. So the reality in 2025 is we have this massive SAS landscape and every business is in most cases we can see here even businesses with 0 to 10 employees are spending you know close 50 close to $100,000 on this on their software subscriptions to operate their business. And as we get higher up, we get into the multiple hundreds of thousands of dollars. So some of the key things to take out of here is that companies are wasting or spending on average $89,000 on SAS waste. That average spend is about 5.5 grand per employee and almost half of those SAS licenses are going unused or underutilized. So there isn't there is an issue here and companies are investing a lot of money in these tools to operate their businesses. And I've actually got some live sales calls with me selling this offer on YouTube where you'll see business owners, they they all know it. They can feel this pain. They're talking about it and it's this SAS sprawl. It's this mess of tools, like 10, 15 tools. It's it it really looks like this. It's a mess. And people like a lot of these business owners, they don't even know what's happening in most of these tools. Um it's a mess. They're spending a lot of money on it. And the data is disconnected. They're duct taping these these things together to try and to try and get something to work. >> I mean, anyone who's doing doing AI automation will know recognize all those things very very clearly and and the jumble if you are trying to build a system for them, how much harder it is to build on top of those when you're having to connect between all these different places at once. So, there's there's like particular looking ahead into the AI automation future those rails for them to add on AI on top of um it's not necessarily the best best foundation to be building on top of. Right. >> 100%. And I'm going to that's what that's what I'm going to build up to here. Um yeah, we come from a process automation background using make.com, Zapia, NAN to like duct tape these things together, but it's it's a duct tape job. It ideally it it would should all be in the same spot. And so the reality check here is that the reason SAS is great for smaller companies. They on board, they pay a little bit of money and they get this like state-of-the-art software that looks amazing that they can jump straight onto. But what happens as they scale is these per user per month subscriptions that the vast majority of these tools charge start to add up and a lot of these tools end up getting underutilized and budgets, you know, companies quickly start spending tens of thousands of dollars on these subscriptions. And so why SAS even exists in the first place, long story short, behind the scenes, tech is confusing. There's APIs, frontends, backends, servers, clients, clouds, all these technical terms. And if that doesn't make sense, it's not supposed to make sense because.3% of the world actually knows how to code. And a fraction of them are experienced enough to be able to handle all this infrastructure. So traditionally, especially when we're talking like '9s, 2000s, 2010s, even to this day, to be honest, proper software development, production grade enterprise software takes years and millions of dollars. So naturally, what happened is SAS entered the scene. Now, the same way that we go to the grocery store to buy meat, if you want to have beef hamburgers for dinner, you're buying from a grocery store, you don't have to go and kill a cow and worry about how that gets into your source bin. The grocery store handles all the messy business. You go and buy the ready-made product from the grocery store and it's ready to go. SAS did the same thing with tech. So, they take care of all the messy business. They build you a nice interface. You basically pick whatever you need off the shelves and you can use it pretty much instantly. So what happened was we had this honeymoon phase where companies typically only enterprise companies could afford to build their own software. So we had this honeymoon phase where the small business medium businesses, the real estate owners, the landscapers, the small guys could come in and they could use tools that and and compete in this market and get on board in these tools in like weeks and for a couple of thousand. But as they scale, things start to add up and couple of issues. Same way with the grocery store, there's a couple of issues with these SAS platforms. One is that there's no customization. So, you can you can pick from a couple of different types of beef or a couple of different, you know, rice brands, whatever, but you can't customize the quantities. There's a limit to the customization you can do. And the other thing is vendor lockin. So, as we're all familiar, we all remember co what happened when the grocery stores started running out of toilet paper. Uh it was absolute chaos. So we become reliant on these vendors to they handle all the messy business, we forget how to even do the messy business. And so what happens is it's all good 95% of the time, but if something happens and those vendors that we rely on start to buckle, we we don't know what to do with ourselves. And so the same thing happens with tech. But up until this day and age, those cons are well worth it. I mean, we're weighing like millions of dollars in years of development against a couple of risks, but in the grand scheme of things, that made a lot of sense until the age of AI. So, this has completely changed the game. Well, what's happened over the past couple years? So, we've had the introduction of AI coding tools and AI in general that has dropped the speed and cost of software development and it's also promised to increase productivity. But I've seen you talking about this, Liam. This is the promise. The actual reality is starting to look a little bit different. So, we've seen big consulting companies and stats come out of a lot of companies investing heavy in this AI and spending thousands of dollars, but the ROI on that investment is actually underwhelming in a lot of scenarios. And so, the answer is why? Like it, you know, we all can all go on chat GPT. We can see it can do crazy things. It's obviously very intelligent. So why are businesses struggling to actually make this AI productive in their businesses? And the reason is because is of what we call the context problem. AI is extremely intelligent and in the next year or two people are talking about super intelligence and all sorts of crazy crazy stuff. It's basically currently operating like a Harvard MBA with a blindfold on. So what's happening is a lot of businesses are bolting on what you'll see as like NAND workflows and AI automations, but it doesn't have access. The data is all over the shop. They've got meeting recordings in places, tasks in places, documents in in Google Docs, invoices in QuickBooks. All this data is all over the shop and it's not talking to each other. So, the AI brain doesn't have the actually have access to the information that it needs to generate quality output that is as good or better than a human. I still think this isn't like talked about enough like it just the the complete difference performance of your own I mean I use AI writing assistants a lot like I build my own I've been going on claw code and creating my own like a writing assistance and the the context is just the the essential ingredient it when it knows everything about me my businesses my strategy um sort of recent things I've done and if you have good data feeds to add into that and make sure that it's always up to date with with the latest information about you and your business. It's just completely game-changing. So, I think this is really there's a huge opportunity for a software or a company to come in. I don't know who would do it, whether it's like a small small guys like like us could get a get a go in there. Um, but essentially being the the all-in-one context hub that can sort of be agnostic across platforms and whether you're hooking into it's kind of like how you had the like you can have MCP servers and you could have a platform that connects all your MCPS into one and that's what you use across you know like one integration point uh rather than having to integrate into all of the different ones uh manually and I think there's a there's an opportunity for like your context brain that can shift across different uh different platforms and different providers um similar similar to what you talking right here. >> Yeah, 100%. Context is is really the diff and nobody's nobody talks about that, I think, because there's there's so much hype around like the automations and people just trying to take a screenshot of an NN automation, but don't really show the output. So, it looks cool, but the reality is is a lot different. So >> and I I think I think one of the issues as well is that context is kind of like the thing that Claude or or Chat GBT and these kind of companies when it comes to their projects uh that they are intentionally like vectorizing and chopping up that data to to retrieve it in smaller chunks right but the re real way for it to work I mean there's context engineering but in most cases it's like I here is the context I need to be it to be aware of in every situation and they just go chop it up and give you little chunks back. So, um I think it maybe they don't want to talk about it as much cuz it's going to push their their costs up massively, especially on their on their subscription plans, but yeah. >> Yeah. And well, and the other thing is like you're you don't really have access to your data. These big companies do. So, you can't really make a move unless these big companies like, okay, we're going to give ChatGpt or whatever access to your data. So, yeah, that that's kind of the issue. And the inevitable solution is what we're going to talk about now, which is an entire CRM or one unique software that's going to do two things. So there's two real problems that we solve with this tool. I think there's the problem that these business owners feel. So when you look at the sales calls on my YouTube and basically when I talk to business owners, especially nontechnical business owners that they they hear all the hype, they don't really know what it's about. The problem that they feel and they can relate to is the monthly bleed of these SAS tools. So they're spending $3,000 plus, sometimes like $10, $20,000 a month. They feel that they they it hurts them. They see the money go out every single month. They see people staff members not using these tools properly, not really using them. That's the angle that we've had the most resonation from business owners on what we solve. But I actually think there's a bigger problem here that is under the hood that most people are not aware of, which is this AI extinction event. And like I've seen some of the biggest podcasts out there. I was looking at the Steven Bartlett on the diary of the CEO. He's interviewed a bunch of people on like is AI and some of the the statements that these people are making and working every day in AI like it doesn't some people are saying that you know massive things about UBIS and and 80% of the workforce getting uh replaced and all these crazy things. Doesn't really matter what your take is, but I think everyone's on agreement that this is going to shake businesses up in a way that we've never seen before. And so in my opinion, the time frame is up for debate, but in the next 5 years or so, companies without AI unified data will not will cease to exist and not be able to compete because the competitors that have integrated AI properly are going to be operating at 10 times productivity and for a fraction of the cost. You can see this as the rails just like how we were talking before unless they have with all of these automations and I think particularly once you have these huge like AI agent workforces where or you've got multiple different specialized ones created or you have things like the chatb agent where you have these generalized computer use ones the that layer of context that can just spread across all of these different uh systems that they build is is going to be essential. >> Yeah 100%. And so that gives birth to the solution. So we've been running software company for the last four years. So, we've built a ton of internal systems previously, but the solution that we've built is, and I'll talk about some of the the issues with this a little bit later, but the solution that we've built here is it's basically a 10 to 20,000 USD offer. And what we do is we replace a large portion of your SAS stack with a custom internal tool that we build in two to four weeks that strips you of those per user per month fees, but at the same time gives you a proper system to protect yourself against this AI extinction event and be able to properly enable AI into your business. >> So just some quick stats on this. So we've been doing 40 to 60K per month on these builds in the last 3 months. So we've we've really focused we we've moved away from being a generic service agency to try and just focus on doing this one thing and doing it correctly. So that's been the main focus um of what we've done >> and and on the I don't want to like steal man the the push back you might get from from some of these business owners like okay so I'm going to give up the reliability well flaky I suppose reliability is questionable in some of these uh these bigger systems they do they do break as well but okay I'm going to put myself on the hook for a custom software now that I have to rely on you guys for as as people who can be the so it's essentially like handing the keys over to being reliant on a on an agency which is >> always the push back you're going to get. Oh, so what? So this means if I want any change I have to come back to you you've attached me and I'm reliant on you now. Um and what's this realistically if you were to add up all those maintenance fees and costs for the year um what is what would they be paying an equivalent to their their SAS thing? >> Yeah 100%. So those are two common objections. So the first one is we completely open source this. So I personally think that the SAS model is going to have problems in the next 5 or 10 years. So we we with this things this whole thing is completely open source. They can they own the code. Uh we we aim to manage the entire thing for less than a thousand USD per month. So they own the code. They could go and work with another developer if they want to. But because we know this system so well, we think that's unlikely. But this is not it's not we're not selling a SAS here. We're building them the same way that we've been building apps for companies for 5 years. And every app that we've built, we've like 98% of them will stay on with us for maintenance. I can't even remember one that hasn't. So that same approach, we're using that same approach here, but we're just building one specific kind of app that we we know thrown through. >> Mhm. >> Okay. >> So, >> cool. Um, and I'll I'll take you over the rejections as well in a sec of of of this, but essentially what happens is these are like 80% of service based businesses under the hood operate very similarly. So these basic functions we've got like CRM functions, client and company management, projects and workspaces, task boards, messaging, etc. Uh lead genen and quoting estimates, proposals, stuff like that, dashboards and reporting, social media calendars and marketing and what I think is completely essential in the next 5 years, which is AI ready infrastructure. That's what we're aiming to build into this tool and template. So a screenshot of of one of the screenshots or examples of one of the products that we've built. Now this product we're constantly a form in we're constantly improving the way we build this. AI is genuinely like even in the last year the way software development works at agencies that are actually up to date with what's going on has flipped on its head massively. Like we've changed our business processes in the last one year alone more than we have in our entire existence. So this is constantly updating. But some of the functions that you're going to see in these are like dashboards, custom dashboards. So this would replace SAS tools like PowerBI. We've got lead qualification um and yeah lead qualification. So lead genen comes through gets displayed in this board. Bunch of like AI sentiment checkers that kind of stuff. Quoting, estimating, proposal generation, invoicing, payroll, projects, some project management, more project management. So AI sentiment trackers on meetings channels so communications things that Slack Trello would typically be used for is these are some of the features that we build similar to what we talked about before and that kind of conjugates itself into this AI brain AI agent UI here where we can build these interface. Now this is just a surface level like a service level is a rag chatbot that's able to essentially extract all this data. So, we're talking every message sent in your company, every invoice sent, every proposal, every task action, everything that happens is all happening in one place. The data is all in one place. We can use it. We can access it and use it really, really quickly. We're not duct taping all these tools together, worrying about API access, all that technical stuff. It's it's dead simple to build. In this use case here, we're talking about how many hours we logged against a project, but you could you could ask it anything. >> Okay. Interesting. This is a my best shot at trying to explain what is pretty complex especially to nontechnical people on how this entire system works. So ideally you have a CRM. This contains absolutely everything in your business. Everything from leads, proposals, messages, invoices, transactions, everything. That data is synced into what we refer to as the AI brain which in technical terms is usually a vector database in along with some sort of knowledge graph technology. Then you have your AI agents. So what everyone's really familiar with is these n automations agents that do things like generate UGC social media posts, build proposals, etc. These source all their contextual information from this knowledge graph or sorry this knowledge base and then use that within your business's processes to reduce the time spent on boring admin stuff. Uh and essentially yeah reduce the time spent and increase your business's efficiency. So in as basic terms or in as basic way as we can put it this is what this entire system aims to do. >> So yeah makes sense. Yeah, really difficult to like explain this to your average small to medium business owner who does not care about technology at all. So, we've done our best shot there. >> So, so those agents are the ones that you're running sort of programmatically in the background. They're not necessarily like co-pilots or thing that are built into the uh into the software you built. Yeah, >> exactly. Yeah. So, the initial the initial product that we build is just the CRM system. We every business is different. They need different agents. So, this is what we build on top with the data that we've got here. So yeah, these these are in most cases just NAN agents that post the data back into this original system. Cool. So who's this for? We obviously there's only a very niche buyer that that is interested in this and it's usually small to medium business founders, but they tick these boxes. So typically service based businesses spending at least $3,000 per month on SAS. They've heard about AI, which is pretty much every business owner on this planet, but they don't really know what to do about it. And they just want a system, smart, simple system that works. So, how do we do it? >> Yeah, this is the source that everyone wants to know, bro. So, dig it in here. >> I could talk about this all day, but there's there's two ways that we do this. So, we use AI coding and we also use a templated based approach. So, we have a template that does in our case 60 to 80% of what most of these businesses need. So, we build all of this functionality in a template software that works, that's stable, and then when a new business owner comes in, we're using advertising to try and target the correct buyer in an industry that we know we've already got 60 to 80% of this templated approach and we we obviously tweak it to their individual business's use case. That way we can ensure that it's stable. We can build it quickly, which are the two most important things we're selling to businesses. And it's also cheaper and more efficient for us to build it. So we start with a template and then we use clawed code in conjunction with something that's called the BMAD method. Now before I like jump into more detail on what the BMAD method is, I want to shout out the guy that built this because the whole thing's open source. It's completely free. You can watch a full master class on it on YouTube um and fork the entire repo yourself. And if you're someone that's like in this vibe coding space, you're playing around in Lovable, you're playing around in VZ, you're trying to build apps, I cannot preach this system anymore, I'm not going to jump deep into the weeds. I've got full videos that I'm releasing that will jump into the weeds on exactly how this works, but essentially this is this is a framework of how to build actual stable production grade apps. We're hearing with a lot of this like AI vibe coding that it gets you 80% of the way quite well. And I've been doing a lot of playing around in Lovable and those tools, but a lot of people start to have hiccups, especially towards getting something actually production grade. This will solve a lot of those problems for you. And genuinely, no one's really even talking about it. Uh, but promise me like, go download this, try it on a project idea that you've got, spend an hour or two in here, and come back to this video and let everyone know how helpful it was, cuz I cannot preach this enough. >> I'm going to have to give it a go. >> Yeah, it's cracker. Um, and so the the key thing here is that AI coding or really coding in general is 80% planning and 20% execution. And so that that's that's what this BMA method will do is it will plan things out extremely best practice. It takes you through the proper process for how to build apps and breaks everything down really moduly. So when we scope out these projects, we use claude code along with this BMAD method to have a really stable way along with knowing technical skills as well. >> Mhm. >> But that's that's how we bolt on the extra 20 to 40% on these initial templates. And so the general AI friendly tech stack that everyone's talking about things like resend for email, we use Nex.js and superbase to build these apps. N for the workflow automations for self for hosting pine cone for your vector database and that yeah that's the general stat >> my question always is even when I'm doing building my own vibe coded apps is just like how if you've if you've like one shoted this you've done a really good plan then it executes on it like how are all the little connecting bits that are necessary cuz there's a lot of little buttons that are going to be on on a on a full dashboard and software like that like >> do they come out of the box working or is there a ton of debugging that you need to do go test every every feature. Of course, you got to test it, but like what's the the realistic failure rate on on things like that? >> Yeah. So, we before we even get to prompting anything, we build there's there's an entire playing process before we even get to to prompting these tools. In terms of fail, the way this BMAD method works, so like it's different to lovable cuz the way lovable works is you build this giant prompt. It tells it what to do. You try and like there's this is not really about oneshotting. It's a little bit slower than like those vibe coding tools that you will that you'll that the common ones out there. Um, so it's not really a oneshotting process. It actually breaks everything down into into like individual tasks and you work through each task uh methodically. But what that does is it actually helps you understand what you're doing cuz when you work with lovable looks great but you don't really know what's going on under the hood. It will it will explain everything that's happening and it is a hell of a lot more stable. So yeah, there's there's way less hallucinations. It injects the correct context into your code. It's it is slower. Uh by slower, I mean we're not oneshotting things and walking out the room in 10 minutes. Um so it's not slow by any means. It's rapid, but it's not it's we're not we're not oneshotting anything and building a full internal 10K system in 10 minutes, but we are doing it in two to four weeks with the combination of these processes. And yeah, can't hop on about this enough, but it will it will actually help you understand what you're doing cuz I don't think you can constantly sell tech with at least you or someone that you trust having an understanding of what's happening. And this will help you solve that problem. >> I suppose the the key thing is that we're about to jump into here is once you've got that base built out as the sort of the central software for them, then that gives you the platform to build the all the agents and automations on top a lot more a lot more easily. Right. >> Exactly. Exactly. And it's really just n bolting on n automations or like sometimes it's adding extra features into the software as well. But yeah, how so how do we charge for it is going to solve that answer. So it's like a three-step process to selling these. So there's the scoping. Now what happens in the scoping is we essentially the scoping is is critical. It's really important. It takes longer than the build in most scenarios. The we do two things. So we wireframe the business life cycle. Now what I mean by business life cycle is every every process in the business from client acquisition all the way through to product or service delivery. So usually that typically looks like some sort of funnel lead gen system comes through lead qualification process followed by often like an estimate a quote or proposal followed by invoice for project kickoff. Then there's the whatever ops are involved in delivering that project and then we've got the project delivery. We need to understand how that works in detail before we can really do anything. So we need to understand that how it works and we need to understand how you currently do that. From there we can do two things. We can use lovable and or v 0 or any of these tools to prototype what a new system could look like for you and we can identify areas of opportunity for and basically justify the business use case of this new solution. So there's two ways you can do that. One is you can demonstrate that you can replace a number of their SAS tools which cost X amount per month and so you can display that saving. The other way you can display savings is by reducing manual hours or manual work from their team. So for example, if their admin team spends 20 hours a week doing payroll and you can demonstrate a system that takes two, there's 18 hours times the admin's hourly rate of weekly savings that you can justify. So this scoping phase, we charge a fixed price amount for this. uh is essentially the blueprint for what you need to build, but it also extremely logically explains the business explains the business use case for the project in detail. >> And how do you how do you minimize I mean anyone who runs an agency will probably know um the amount of like proposals that never got a word back kind of thing that you you get, right? So, how are you are you putting that as a as like a paid expiration? It's like, hey, okay, for us to scope this out, it's going to be 1,500 or like 2 grand for us to do this. um this is just going to give you a full plan for it or you I doubt you're going all the way through all of that and then just go like yeah no I'm all right cuz that's >> yeah 100%. 100%. So we like I do the we we do the discovery call for free. >> Um from the discovery call we then say look we've got a we try and show them the value through a really nicely decorated funnel and and PowerPoint display on on this call. We're actually working towards giving them a clickable product like access into a demo of the tool because that's going to be super powerful. We're pretty close to getting that ready. Um, but what we'll what we'll do is yeah, we we actually so we charge 3,000 USD for we build them a prototype as well. So it's it's the scoping document plus a prototype on lovable or a tool like that. >> So that's like it's it's good because you get the financial investment. It's not a massive amount of money, but if you're dealing with small to medium businesses that have this pain point and are willing to work in this system, they will have >> Yeah. >> Yeah. >> And financially qualifying them. >> So important to to get that financial qualification before you let them go too long. >> Yeah. Exactly. It's not, you know, like we're not looking to make massive profits on that or anything, but we're not really losing money on that either. That's there then we can justify whether it's a 14 or a 28 day sprint and we do three times per week check-ins. I'm going to talk about why this particular approach is needed for business internal tools specifically. But then after we built on the tool, we work in sprints. We have a we have three pricing models that we work off post launch or post MVP. Um, and those extra sprints are like building AI agents and automations, feature upgrades, etc. And the way you justify these like the good thing about this tool is it's it's literally most of the selling process is what's your existing process? how long is it taking your staff to do it or how much are you paying for a software tool to currently do it? If we can do you this and it's and it it costs this much amount, you're going to save this much amount and we can deliver it in two weeks. >> We've got like two different two different vectors to attack on that where you've like I'll either save you the software cost and or I'll also save you the the like inefficiency that are costing you a lot of time wasted for for these different staff members. So >> yeah, it's honestly like selling it is is really not that difficult. Um it's delivery that w was definitely harder and has slowed us down up until this point. >> Are you are you just wanting to I mean the the obvious solution is just to start doing it only for one type of company which is you kind of alluded to before. Um but then then if you're doing content for your lead generation you are sort of stitched up there because you like in my case I get leads from all different angles. So, we've tried to niche down previously and then a gigantic lead comes in that we can't really say no to. And so, it's it's tricky unless you're going to be doing outbound running ads or doing um doing cold outreach and stuff. So, what's your strategy there? >> Yeah. So, we've we've got an ads funnel. You're literally speaking about my exact problem cuz that is like one of the issues that we've had is like I get all these leads, they're great, they're great projects. I'm like, I would love to do that, but then I also want to I want to build a repeatable process that's going to allow this to scale. So, but yeah. Well, so targeted advertising and a and a and a proper VSSL with a funnel, a qualification funnel to that. That's like the the other part of the puzzle to get this to work is how do we target a specific business like to the niche like landscapers, consulting companies, whatever the case is. We want to target get really good at them. Then, you know, landscapers are very similar to plumbers or whatever. Like, then you just hop to the next level. the three things to be wary of with building specifically internal systems for businesses because so we've done this a number of time before not in this offer just as a generic software agency as well and we learned a lot of lessons there which have helped us deliver this better but I think there's three things you need to be wary of jumping down this internal tool space for businesses one is businesses hate change the solution needs to be stable and simple so instead of going above and beyond trying to do all these complex things solve complex problems especially in this 14 28 is we're going for dead simple. We we want monkeys to be able to use it. And so we're trying to make where we're actually working into a a new uh UI system and framework, but we're trying to make this as simple as possible. No bells and whistles at all. So that's number one. Two, implementation needs a rip the band-aid off approach with a lot of these businesses, especially established businesses that have been operating for 20, 30 years. They've been doing the same thing year on year. If you come in and be like, \"Hey, look, we got this whole system. We're going to we're going to basically throw a good 50 to 90% of what you used to run in the bin. Come use this.\" There's a lot of push back and a lot of people get pissed off and you've got one or two strikes. Like if if there's issues with the software and it it interrupts operations just one or two times, >> they basically just going to be pissed off and just be like, \"No, we're not doing it. Throw it in the bin.\" >> So >> that's a big one. Imagine having you're not available for like maybe 24 hours or 12 hours or something might be over a weekend something breaks and like everyone is just screaming about what the [ __ ] is this new stuff we've got. So that's a big big risk to take on I guess. >> Yeah 100%. So um that also ties in I haven't got this in here but that's that is also why we stay away from certain sectors. So we stay away from finance, we stay away from healthcare. There's certain sectors where too much red tape, too much hassle. >> Yeah. >> Rather wouldn't deal with that. People always ask me, \"Oh, how do I deal with this compliance or this industry or what's the, you know, how do I deal with these risks?\" There's so many opportunities out there that there's low hanging fruit everywhere. You're going like, if you're scared about it and if you're starting out, I wouldn't recommend going for these these nalia nalia just like >> 100%. So, yeah, the rip the band-aid off is like, so the other thing is these businesses, as I said before, hate change. So often you have to have something stable, something that works, but also the reason why we check in with them three times per week and we try and do this in 14 to 28 days is two reason. One, we obviously make more money in a quicker period of time. So that's a win for us, but also if you don't get it done in that time frame, businesses, it tends to get put on the back burner. Like you're typically dealing with people that are high up at these businesses. They've got 20 other things that they're worrying about. And then this, if it if it screws up one or two times, they've got a million other things on their plate. it goes on the back burner and then it starts to drag out for months. So, we we really want to get it right. We want to get it stable. We want to get it simple and then we want to rip the band-aid off and be like, \"Hey, look, let's plan to get your entire team on board on this next week. We know there's going to be a couple of hiccups. We're going to be on deck to to worry about this, you know, 2our turnout time, whatever the case is. Um, let's let's get on board this cuz we know it's going to be uncomfortable for a week or two, but it it has to happen.\" So, that's that. And then scoping is critical as well. So like with building any software and that that's another spot where this BMAD framework is really going to help you out but you need to clearly scope out the project clearly explain what's going to be happening and that's why half the reason why we work the prototype's amazing so good news is on lovable on these tools you can basically design in large part the majority of what how this is these apps are going to work look feel in conjunction with a bunch of good documentation it's a pretty rock solid scope but yeah you need to make sure that scope is critical One thing I guess after you get over that hump of all the like the initial scoping, the the planning out using that BMAD method, building it and then pulling the band-aid off and getting it plugged in is the stickiness and kind of the lifetime value of one of those clients. I've been I've been sort of half not about this about what we're doing at Morningside, but when you do have these these big clients that can even just a smaller business client and they're going to work with you for you are their go-to AI partner now. Um you have so much context in their business, you've built the system that their business runs on. As long as you're able to deliver well and you're not going to sort of give them some crappy system sometimes or or give them reasons to break off that that relationship with you and go elsewhere, then you have their their business for basically the next 5 years if you wanted it, you know, um with all the new updates that come out and adding on new AI agents and systems on top of it. >> Yeah, 100%. And I think the thing with when you whenever you're selling a quality product that you genuinely believe in is like a lot of these business owners, they're all talking to other people in the space. Listen, if you've built a genuine quality product, I mean, what we're building here is pretty revolutionary. No one's even really doing anything close to this at the moment and getting it to work properly. But I think yeah, as you said, if you can get it to work nice and stably, these business owners will look at the the other businesses in their space, see how inefficient certain things are there and in general at if you're doing a proper if you're selling a quality product, you're doing a proper job, you know, people are willing to pay high ticket and and generally pretty happy with your service and will stay on with you. And so if if we're talking to to the beginner now, maybe the agency owner who's been selling been selling automations or agents here and there and they're looking to shift. Okay, maybe this is the offer I want I want to dial in on for maybe 2026. What would you give them as like the the quick start plan? >> You don't need to build an internal system. Like there's a lot of businesses that just want one little system like one nice B like leads board where all their sales agents can go in and view the leads and do cool things there. So it's really if you're already in the NNN like the AI automation space, all we're really doing here is like you you lovable is a perfect entry spot. I would say start with lovable cuz you can do like you can do most of this in lovable but this BMAD method and claude code is like it's level two. Lovable is level one. Level two is to go through once you're done with lovable. There's certain hiccups there. Level two is to understand this BMAD method. Start building things with clawed code and this BMAD method and that's going to unlock like the next level of complexity which is going to allow you to do this. So my tips would be yeah learn those two things. Find someone that is an expert in this nextjs super stack who can c you can do 90% of this yourself. Find someone that actually understands the tech. If you're nontechnical or you don't you know you don't code hire someone on Upwork. Find someone to just QA that tech at the end. Make sure that there's no security risks. all those kind of things. And then yeah, that that's that that would be it. Step one, learn lovable. Step two, learn Claude code and BMAD. Step three, build your own product practice. Build a templated approach to solving a particular problem for a niche. Step four, build a demo for that so that people can go through it and see the value. Step five, build a lead funnel. Step six, pump money into the leads. >> Adam, that's freaking awesome, man. Thank you so much for coming on and sharing. I've been looking forward to this uh for a few days now. So I think you guys have all got some really really good stuff to sink your teeth into there now. Uh this is definitely where where things are going. Um you've even got guys like Chimath probably up to 8090 what he's doing over there is similar but going for enterprise and they've signed 40 million in contracts for this year. I think they're going to do 40 million in revenue this year uh in their first year doing the same kind of stuff but for the enterprise which is custom software replacing all of their their clunky tech stack with something exactly like this. So, it's very interesting to see this happening at the top and at the bottom from from where you're coming from, Adam, and going to small businesses. So, this is our entry point for anyone who's looking to maybe pivot their AI automation agency into something like this or or clear offer. I think this is a really really really good horse to bet on for for the coming years. So, Adam, I really really appreciate you coming on sharing the source. You guys know how to contact him. I'll leave his uh links in the description. Um yeah, mate, it's been a pleasure and looking forward to hearing about where you go with this in the future. >> Cool. Appreciate it, mate. Yeah, all my links are down here if you want to connect with me. appreciate the opportunity as always, Liam. A lot of this is obviously inspired by the continual good work that you guys are pumping out um on this channel. So, yeah, appreciate it big time, mate. So, I hope you can see why I'm so excited for this particular opportunity. If you are running an AI business or want to start one, this is an extremely interesting place to look into, especially looking forward to 2026 as AI coding tools make it even easier for beginners to come in and make these kinds of custom softwares for businesses and that really unique advantage of centralizing everything so that the AI systems that you build for your clients have access to all of that data within one software. And I think this is really where those rails become important for them to get the edge on the competitors long term. If you're someone who wants to get the jump on this early and learn how to build these kinds of softwares, you can follow my full guide, full course, like two hours long, breaking down how as a beginner you can start to build these kind of applications using vibe coding tools like Bolt. But aside from that, guys, that's all for the video. Thank you so much for watching and I will see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Crítica ao desperdício de SAS e à apresentação de um serviço de US$15 mil que substitui todo o stack de software por um sistema de IA sob medida, mostrando como iniciantes podem criar e vender esse tipo de solução com ferramentas de baixo código.",
            "resumo": "O vídeo argumenta que o setor de IA para SaaS está prestes a sofrer transformação, pois muitas empresas gastam cerca de US$ 100 mil por ano em ferramentas de software que não se comunicam, gerando um 'lixo de SAS' e dados dispersos que tornam a IA pouco eficaz. O apresentador descreve um serviço de US$ 15 mil que substitui todo o stack SAS de uma empresa por um sistema personalizado alimentado por IA, funcionando em sprint de 2 a 4 semanas. Ele compartilha a experiência dele como freelancer e fundador de uma agência, destacando a necessidade de uma oferta única para internal systems, evitando o desperdício e o lock-in de fornecedores. O vídeo também discute como o mercado atual de automação exige conectores e integração, e como ferramentas de low-code podem ajudar iniciantes a começar a entregar esse tipo de solução.",
            "assunto_principal": "Substituição de pilhas SAS por sistemas de IA personalizados e uma oportunidade de negócio de US$15 mil.",
            "palavras_chave": [
              "Inteligência Artificial",
              "Software como Serviço",
              "Desperdício de SAS",
              "Substituição da pilha",
              "Sistemas internos",
              "Oferta de US$15 mil",
              "Desenvolvimento com baixo código",
              "Integração de dados",
              "Nicho de serviços",
              "Automação de processos"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto: o mercado de SAS é caro e desperdiça dados; muitas licenças ficam subutilizadas.\n- Problema: integração e governança de dados ruins dificultam IA eficiente.\n- Proposta: serviço de US$15 mil que substitui o stack SAS por um sistema de IA personalizado.\n- Como funciona: entregas em sprints de 2 a 4 semanas, com ferramentas de baixo código.\n- Perfil do apresentador: experiência em freelancing, agência e casos de clientes relevantes.\n- Oportunidade: foco em sistemas internos, com nicho de serviços de transformação de IA a partir de cinco anos no futuro.\n- Benefícios para iniciantes: começar com ferramentas de baixo código e vender o serviço.",
            "prompt_tokens": 1860,
            "completion_tokens": 3808,
            "model": "gpt-5-nano",
            "cost": 0.0066
          },
          "analysis_time": 66.5320770740509,
          "language": "",
          "view_count": 35954,
          "has_transcript": false
        },
        {
          "id": "kQFW3bUrOu4",
          "title": "Como automatizar qualquer negócio com IA em 3 etapas (guia para iniciantes)",
          "title_pt": "Como automatizar qualquer negócio com IA em 3 etapas (guia para iniciantes)",
          "url": "https://www.youtube.com/watch?v=kQFW3bUrOu4",
          "published": "2025-09-08T00:38:05.283236",
          "published_relative": "há 13 dias",
          "duration": "16:50",
          "date_published": "2025-09-06T23:44:12-07:00",
          "transcript_available": true,
          "transcript": "So over the past two and a half years, my agency, Morningside AI, has been on the front lines of implementing AI for some of the world's biggest brands. And I can tell you that the difference between the 5% of companies who are seeing a massive ROI on AI and the 95% who are failing right now is simple, and that's that they start with a process and not the technology. Most businesses get this backwards. They get all hyped about a new tool and they dive straight into the development and ultimately fail. And from this, companies are learning that the initial shine of AI is gone now. And this stuff takes real human skill to get right. And even OpenAI has kind of just admitted this openly by launching their own consulting team. So whether you're a business owner who wants to join this 5% of winners or an entrepreneur who wants to serve the 95% of companies who are failing and need help, then this video is for you because I'm about to open source the entire start to finish framework that we use at Morningside AI for automating any business with AI. And at the end, I'll give you a full guide so that you can go and apply this stuff yourself. So if you are new to the channel, my name is Liam Mley and for the past 2 and a half years, I've been helping businesses and individuals to use AI to get ahead. And I do this because our vision at Morningside is to ensure that the games of the AI revolution aren't just for the big guys. And that's why I share our learnings here on this channel to give businesses the tools to survive and win in this AI revolution. So, here's the deal. This is a reality check for almost every single business out there right now. But what they ultimately want is growth, which requires order. Most companies are a complete mess. Their data is scattered. Their processes are a mix of how we've always done it and a dozen different apps or tools that don't talk to each other. And now according to studies, most of their employees are secretly using a bunch of AI tools to get parts of their work done without them telling the company. And that's creating huge risks of data leaks etc. So it's organized chaos at best. And most business owners are just trying to keep the wheels from falling off. And so now when you take this chaotic system and you try to just plug in the most powerful technology on the planet right now, what do you think happens? Right? It's going to fail and it's going to fail pretty miserably. And you don't actually have to take my word for it on that. The numbers are pretty brutal. MIT has published a study recently showing that 95% of AI initiatives and businesses fail to deliver a return on investment. Let me say that again. The vast majority of businesses that try to implement AI are getting zero value from it. This is in enterprise to be fair, so it's sort of bigger businesses, but it's still an interesting point. But that's not because this technology is useless. That's because these companies are trying to copy what everyone else is doing and they're failing miserably because of it. Instead of taking the time to do the real exploratory work to figure out where AI can fit their business best, they are just looking for the headlines and looking for YouTube videos and and stealing from other people, rather than doing the ground work to find where AI best fits their organization. And often when they try to do it themselves, they are actually clueless to what it really takes to see AI adoption within teams of emotional and fearful humans. There are human barriers to adoption and actually seeing an ROI that many companies are just not aware of right now. So what the 5% who are actually seeing an ROI are doing is they're starting from square one and taking a comprehensive and holistic approach to AI opportunity identification and then development within the company in order to find what we call like layups or or quick wins with AI that can really drive immediate ROI from them. And so the reason the majority of these companies are not seeing an ROI is because they are trying to go for what the neighbor said that they were doing and and not seeing these golden nuggets laying right in front of them, which are the quick wins, the quick ROI projects that can implement AI quickly and allow them to see a return on their investment. And I can say with complete confidence from the client work we do at Morningside, there are always these quick wins lying around that companies are just not aware of and how AI can plug into those and really solve a bottleneck for them that's been troubling them for a while. Now, if you're a business owner watching this, these stats should be a massive wakeup call. It means that almost all of your competitors are trying to use AI and they're failing and they're wasting money, they're wasting time, they're getting nowhere. So, this gives you a huge advantage because if you can be one of the small percentage who gets this right by properly auditing your business and following the exact process that I'm about to lay out for you, you'll dominate your industry for years to come using these advantages. And if you're an aspiring entrepreneur, that same stat should sound to you like the biggest dinner bell you have ever heard because it means that there are millions of businesses out there who are hungry for the most powerful technology on the planet right now. And they have no idea how to use it or get an ROI from it. So this is an enormous and untapped market and your job is to figure out how to bring that power to them. And in this video, I'm going to show you the exact process to do that. Okay, so now you understand the opportunity. Now I'm going to give you the exact Morningside method playbook in order to capture it. So, this is a three-phase process that we use at Morningside to take any business from that initial state of chaos to order and then ultimately to growth. So, I'm literally open sourcing our entire method here for you guys to take and use in whatever capacity you want to. As a quick disclaimer though, we typically run this playbook for mid-market companies, businesses anywhere from 50 to 500 employees. So, if that sounds a bit above your pay grade, don't worry because the principles that I'm going to teach you are exactly the same when you're applying this whether it's a 10p person team or a massive enterprise. So, you can scale it up or down exactly as you need. It's it's all in there and the process is solid. The first thing we do when we're thinking about automating a business with AI is that before even building a single tool, we get the leadership team on the same page. So, you cannot transform business if the people at the top don't understand the game that we're playing and understand the key terms and terminology that we're going to be going through, what the opportunity is. So our goal here in this phase is to align the entire leadership team to establish a clear strategic vision for AI within the company and also to communicate both the opportunity and the urgency to all the key decision makers to make sure that they know what's at stake here. And so to do this, we'll usually run a 2-hour AI leadership workshop alongside a second workshop for employees, which usually happens a bit later, but we'll charge for this on top of our fee for a base AI audit. And here's a crucial detail from our playbook is that we always do this before we present our final recommendations on where the best AI opportunities are. This is because it frankly allows us to indoctrinate them with our frameworks, we get them to see the world the way we see it and we establish what a best-in-class AI transformation looks like. And this way when we present our final road map later, they're already bought in to the logic. They understand the key terms and it's not a surprise. It's kind of a natural conclusion of the strategy that we've already agreed on in this early phase. One key message that helps our clients to see what the end goal for this transformation is is what we call an AI first or chart where we will put up a traditional org chart and then we'll swap that out for what an AI first organization would look like. So they start to build this new vision of what the company could look like on top of what they currently understand. So I'll put that up on screen for you to see. Once leadership team is educated and aligned and genuinely excited for the change that's coming for the company, we can then move on to the next stage which is identification. The goal here is to understand their business better than they do. So we are trying to become the world's leading expert on how their company actually works including like the warts and all and all the ugly parts. So this is a multi-stage process. It's quite a lot of work. But first we start off with interviews. We'll conduct deep dive interviews with everyone from department heads down to even the frontline staff who are in the trenches every day creating value for the company. We actually write personalized interview guides for basically each person adapting our questions as we learn more and more and more about the organization. So it kind of changes as we go. And the next step is what we call process mapping. So this is where we take all of that information that came out of the interviews. All of these data points that we got and then we use that to map out the core workflows of the company visually in a tool like Figma. And let me tell you that this step alone is incredibly valuable because most companies have SOPs, sure, but they're usually gathering dust in a Google Drive somewhere and they're completely updated. So for many clients, this is actually the first time they've seen a clear and objective map of how their business actually operates on the day-to-day. And then comes the part that requires the real expertise, which is the use case identification. So our consultants take that process map and then using both their knowledge and our internal AI solutions database which is over 300 proven AI systems they start to pinpoint the bottlenecks in those process maps and they find the areas clogged up with things like manual data entry report writing and repetitive tasks. And this is really where the amateurs are separated from the experts. It's like how much experience have you got? How well do you understand AI and what it can do for businesses? And how well can you layer that on top of the process map you see in front of you. So, it's all about knowing what AI solution fits perfectly into solve each problem and kind of making sure you're leaning into the strengths of the technology. A lot of the time we see these lack of ROI projects coming out because they are trying to use AI to do things that it's not really super good at right now. And it's always best to be looking at where is AI in production in companies right now actually moving the needle and can we lean into those rather than looking for the more experimental ones which is in most cases what people are trying to do. And then finally, we have the most important step which is the opportunity grading and the validation. So my consultants will have identified dozens of different opportunities, but business is all about prioritization of resources, right? Like there's always a million opportunities of things you can do, but some opportunities are inherently more valuable than others. And some are also more difficult to build in order to realize that value. So we can plot these opportunities on what we call the opportunity matrix. And then through careful process of elimination, we can start to trim down to the right mix of what we call quick wins to get a return on their investment as soon as possible once we get into development. also looking at, hey, what are the big swings for us here that will ultimately become a major advantage for us in the market versus their competitors, but often require some prerequisite steps or just generally much more investment and development in order to see through. So, you've got the quick wins and the big swings. And so, it's a case of trimming down until you get a nice mix of both. But another key part of the process here is that we're not just doing this in a lab on our own in isolation, then present the final result. We go back into the business and we run multiple validation interviews with both employees and the leadership. And this is so so so so important because when you go back to the employees, they validate that yes, we this is really a painful problem. Can you please solve this? But the leadership validates that solving this problem aligns with the company's strategic goals. And you absolutely have to have both. Um you have to have that employee buyin or the tools won't get used. And without the leadership buyin, you're not going to get the budget. And so the deliverable from all of this work is a comprehensive 50 to 100page final report. Yes, it's a beast, but it is the master plan. It is their AI strategy roadmap. And it lays out a strategic road map for their entire AI implementation, blending those quick wins that we had before with some of the big gamechanging swings for them to hit. In the free guide that I'm going to be sharing with you guys at the end, you'll be able to get some examples of these key slides that we put in our presentations that are needed to communicate these kind of key initiatives and the overall AR road map that they're working towards. All right. So once you've delivered that 50 to 100 page report, you've turned the chaos of the company into order. The client is blown away by how well you understand the business and they've approved the road map. Now it's time to turn that order into what they really want, which is growth, which of course starts with actual development. So following that final report, we will check in with the clients. Sometimes they'll need a month or two to get their budget sorted out. Other times are like sweet, let's go. But here is the most important rule for this phase is that we always start with the quick wins. We are not going to go for the six-month multi-million dollar moonshot project first. That is a shorefire way to lose trust and momentum. So we always pick the project from the road map that is the perfect blend of that high impact and low difficulty cuz we want to get them that tangible ROI on our entire engagement including both the education, the consulting and now the development as soon as possible. And that's how you get into by working with someone who knows what they're doing. You get to that ROI where we're just as invested in making sure that this all makes sense for you getting you to be in that 5% who are really starting to see an ROI on just the first AI initiative that you actually deliver. And we see this time and time again when you actually run the numbers that a targeted and seemingly quite basic relative to all the stuff you hear about in the news. These relatively basic systems can provide hundreds of thousands of dollars in ROI and savings from staff time wasted on inefficient processes. And this is one of the key things that I really want you to all take away is that for most businesses, the biggest quick wins that can get you an ROI are in the most boring places. We're talking about like soul crushing manual data entry, endless document creation, or the constant let me just look that up for you kind of tasks. In these cases, we can build a relatively simple voice agent, a smart transcription feature, or an agent to query their internal documents and instantly save the team hundreds of hours a month. And it's these simple systems that deliver a massive impact and prove the value of what we're doing. And these kinds of quick wins can cost anywhere from 20 to $50,000 or more. But at this point, businesses are within arms length of getting their first ROI providing AI systems built and developed. But development is the hardest part and it's the most difficult to replicate this consulting side of things. You could kind of do it yourself, but at the end of the day, to get things built out and actually working in production, you need talented developers. Because having a team with enough skills and experience to be able to tackle new and custom AI problems every single time is quite rough. So, if you're an AI agency owner just starting out, your goal here is simple, to be able to find just one versatile AI developer with ideally some full stack experience as well. And the best place to find them is in communities like mine where people are already skilled up and passionate about the stuff and kind of get the kind of things that you'd likely need them to build. But when we are scoping out these projects for our clients, we give cost estimates and ranges that give enough breathing room to handle the unknowns that always pop up. And once the project's kicked off, the developers handle most of the client communication themselves. They're really good at that. And it's a lean and efficient process designed to deliver results without a ton of bureaucratic overhead, which is the worst. So, by this point, you know the business better than the owner. And a fruitful and long-lasting relationship can actually be formed. It's really awesome when you get it right. Instead of having to go through that phase over and over, you and the client just get to work with each other on getting down to business. Like you understand their business fully, you're helping them deliver, get a tangible ROI on their projects. And from there on, it's like as long as you're delivering and you're not hiking your prices up too much, then you have a long lasting relationship and partnership you can form. And at Morningside, we've literally been working with some of our clients for over a year now, coming up for two with one of them. And this is how we see the best results for businesses by following through on a road map that we laid out and staying in close contact with a team who has the air to the ground on the new things that are developing in the space and what could maybe be applied and and cutting through the noise of all of this new stuff. What is actually relevant to me? What is realistically able to be plugged into my business and actually provide an ROI. So every time a new and more powerful model like GPT5 drops, it's a business opportunity for both us and our clients because we can go back to our clients and we can offer them upgrades to make their existing systems more powerful and often cheaper as well. So this is how you can massively increase the lifetime value of every client just by providing a ridiculous amount of value over an extended period of time because you know their business so well. So this is how you build a truly scalable agency. You just focus on landing one or two of these major transformation projects a quarter. You start to stack and layer them. You of course service and deliver well and you able to build a predictable and high margin business that's deeply embedded in your client success. So while we are here to automate businesses with AI, it's also about building an irreplaceable and long-term partnership that's mutually beneficial. Okay, so that's the playbook. Now, how do you actually use it? This is going to be your action plan, and I'm going to break this down into two different parts. One, what it means for AI agency owners, and then secondly, what it means for uh your more traditional business owners. So, if you're an aspiring entrepreneur, an AI agency owner likely, then listen up because what I just showed you, becoming a full AI transformation partner or AITP like we are at Morningside, is the endgame. It's, let me be 100% clear, it took us years to get here, and you need to really build your way up to it. And here's the path. Step one is you're going to start as an AI automation agency. You're going to use no code and low code tools to deliver your first projects. You're going to get your hands dirty. You're going to learn how to deliver real value for businesses with the current tools and get comfortable working with businesses and working with your clients. Step two, you need to evolve into an AI agency and you're going to take those profits from your first few projects and you're going to be able to hire a full stack AI developer. Now, with these kinds of skills on the team, you can start to offer more custom and complex solutions. It's not just your basic automation. You can now build full platforms out of them and much more comprehensive systems. And then step three, after you've been in the trenches for a while, like we were for two years, then you can move into the AI transformation partner model and start to sell this full and strategic playbook of of AI transformation for a business from start to finish. So to help you get there, the resource that I've got in the description is going to give you everything you need to run your first AI audit, which is going to break down our questionnaires, the key slides that we use on our uh slideshows, how to calculate ROI, etc. And finally, if you are a business owner, then you have two clear options, which is option one, doing it yourself. I've made this video for you to be able to do this. Take the entire playbook that I've broken down here. Take the resource that I've got in description as well. It's going to break down how to do this on a much more granular and tactical level. So, you're going to take this entire playbook. You're going to bring it to your team. You're going to start the conversation and you're going to run an audit on one department at a time and just find one pilot project that you can use to build momentum. You can find developers and communities like mine and make a post and say, \"Hey, I'm XYZ business. I'm looking for this kind of thing. We've identified this opportunity. Can someone help us a develop it?\" And that's the best chance of finding really good talent to help you do these projects with. So long story short is that you can lead this transformation internally, but it's not going to be easy. I'm not going to sugar coat it. It's not going to be super easy. You're going to have to bump into a lot of things, make a lot of mistakes, but you can ultimately get there. Then option number two, of course, is to work with a team who can help you do this. So, for example, if you wanted to work with my team at Warningsai, we can run this playbook for you, but you have to apply to work with us. And at this point, we're quite selective with who we partner with because we're really looking for those long-term relationships of people that we really want to work with for a long time and where we can drive incredible case studies in an industry as well. But if you have a cool business and you're doing good things and you're a good person, then I'd love to have a chat and see if we can help you make your AI transition. So the opportunity at this point is pretty clear. We've got this awesome technology. People are really struggling to get value with it. But that's like I said because they're taking this back to front run the wrong way and they're not doing the ground work. They're not going through the phases of education, of identification, then ultimately development. So this video is about trying to give you the keys to do this yourself. So, I've added our complete AI audit resource uh down below based on our internal templates and what we do at Morningside AI. In there, you've got questionnaire templates, you've got examples of key slides, you've got how we calculate ROI and things like that. So, you can find that in the first link in the description. Up here, I have a video talking about how chat GBT can fundamentally change the AI automation landscape. It's very interesting stuff myself. Aside from that, it's all for the video. Thank you so much for watching and I will see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Segredo para automatizar qualquer negócio com IA não é a tecnologia, mas o processo, pessoas e governança que definem ROI, separando 5% de sucesso dos 95% de fracasso.",
            "resumo": "Nos últimos 2,5 anos, a agência Morningside AI tem liderado a implementação de IA para grandes marcas e descobriu que a diferença entre 5% das empresas que veem ROI significativo e 95% que falham está em começar pelo processo, não pela tecnologia. Dados dispersos, ferramentas que não se comunicam e equipes que usam IA de forma desordenada criam caos e riscos de vazamentos. Estudos do MIT indicam que 95% das iniciativas de IA não entregam ROI, não por falha da tecnologia, mas pela cópia de tendências sem trabalho de base e pela resistência humana à adoção. Os 5% que obtêm ROI identificam as vitórias rápidas (jogadas fáceis) e constroem retorno de curto prazo. O vídeo apresenta o método Morningside em três fases para transformar caos em ordem e crescimento, começando pela liderança antes de construir ferramentas.",
            "assunto_principal": "Transformação de negócios com IA baseada em processos, governança e adoção humana",
            "palavras_chave": [
              "Inteligência Artificial",
              "Retorno sobre o Investimento",
              "Gestão de dados",
              "Adoção de Inteligência Artificial",
              "Vitórias fáceis",
              "Vitórias rápidas",
              "Método Morningside",
              "Transformação digital",
              "Alinhamento de liderança",
              "Identificação de oportunidades"
            ],
            "resumo_em_topicos": "Resumo em tópicos (Markdown):\n- Contexto: caos organizacional com dados espalhados, processos desorganizados e ferramentas que não se comunicam.\n- Problema: 95% das iniciativas de IA não entregam ROI; causas incluem copiar modas sem base e resistência humana à adoção.\n- Diferencial dos 5%: abordagem holística para identificar oportunidades e rápidas vitórias que geram ROI.\n- Oportunidade de mercado: grande demanda entre proprietários de negócios e empreendedores para aplicar IA com ROI comprovado.\n- Solução: método Morningside em três fases para levar qualquer empresa do caos ao crescimento.\n- Fase 1: alinhamento da liderança; workshops de liderança (2 horas) e de funcionários; alinhamento de termos e visão antes de recomendar soluções.\n- Benefícios: maior clareza, adesão das equipes e roadmap mais sólido para transformação.\n- Próximos passos: guia completo disponível e framework aberto para aplicação em diferentes portes de empresa.",
            "prompt_tokens": 1797,
            "completion_tokens": 4544,
            "model": "gpt-5-nano",
            "cost": 0.0077
          },
          "analysis_time": 50.46434783935547,
          "language": "",
          "view_count": 37614,
          "has_transcript": false
        },
        {
          "id": "ENPN-KutYJc",
          "title": "Por que 95% dos sites de agências de IA NUNCA geram leads (+ modelo GRATUITO)",
          "title_pt": "Por que 95% dos sites de agências de IA nunca geram leads (+ modelo GRATUITO)",
          "url": "https://www.youtube.com/watch?v=ENPN-KutYJc",
          "published": "2025-09-07T00:38:05.283252",
          "published_relative": "há 2 semanas",
          "duration": "29:18",
          "date_published": "2025-09-04T14:05:46-07:00",
          "transcript_available": true,
          "transcript": "So despite what some people may say about websites these days, having a killer website that clearly communicates the value of your business and the customers that you serve is one of the most important things to building a scalable and profitable AI agency. And today we have the greatest expert in the world on building AI agency websites, a guy called Arthur. And he's going to be sharing all the secrets based on the over 100 AI agency websites that he's done. He has specialized in creating websites for AI agencies based on all of the learnings that he has and all the clients he's worked with. What is converting, what isn't, and he's going to be breaking down his full blueprint on exactly how you guys can take the learnings from what he's had with his clients and apply it to your own website and set one up yourself using his formula in just a few days on no code sites. Arthur is another incredible success story of people coming into AI and struggling, but then eventually finding their niche. And in this case, he's got so much source to share for all of you who are maybe a little bit unsure about is my website converting. Is it communicating in the right way? And he's using all of the data that he's got from his clients to teach you guys how to do it yourself. So, I'm so excited for you guys to check this out. Arthur, mate, it's great to have you on here and thank you for coming on to share the secret to high converting landing pages and websites for AI agencies. So, I'm super excited to hear. I remember seeing you way back in the community um back in the Discord days. So, it's awesome to see how far you've come. Um but yeah, welcome. welcome to the uh channel and looking forward to hearing what you got to say. >> Yeah, thanks for having me here. It's a big pleasure. >> If you want to jump and just tell us a bit about your background um and how you kind of ended up on the spot of being uh one of the few people who I'd say are really really expert when it comes to landing pages and funnels for AI agencies. >> Yeah. So two years ago I wanted to find how I can make money online as everyone else. So I found one of Liam's video. Before that I was trying to build my social media marketing agency. failed and decided that it's a great opportunity to build something in AI space right now. So I built I started building my agency. The biggest struggle was building a website. I spent around month building my website was talking to a guys in a community posted it and people quickly started reaching out to me about like they they were asking if I can build something like this for them. So I quickly realized that probably I will not be able to sell that many AI solutions because I'm from like second world country from Kazakhstan. I will not be able to sell to local businesses. So I decided to pivot a bit and help other agencies with getting clients with the high converting landing pages. Of course, of course they were not high converting at the beginning. So I've built more than 100 landing pages in the past two years specifically for AI agencies. I worked with Brendan from Inflate AI agency, Moni Group, one of your previous guests with Talk AI with many many others. >> So did you did you come into this with a a web design background or web development and design? >> No, I was a student. I Yeah, I studied economics in the university, but like I wasn't in the best financial situation, so I needed to find a way to make money man money online. So I quickly realized that I need to find like a hustle. it was a hassle uh by that time. So yeah, I was starting promoting myself in your discord community. Back then it was a discord but it transformed to a school community. I started LinkedIn, started building my personal brand and since that moment all of my clients they came inbound, no outreach, nothing. So what I'm trying to do is I'm trying to help other AI agencies with doing the same because it's much easier to sell to warmer clients than to pitch cold clients. So in two years I've developed my framework for AI agency for high converting AI agency landing pages. And today I'll show it to you. Would be happy if you use it and get some clients. >> Cool. Yeah. So you guys are in for a treat. he's going to reveal his ideal template and sort of layout for a high converting AI agency landing page. Um, but just so we're clear, you came in with no, you tried to start your agency to start. Um, you realize that you had trouble with the website building part of it and building a funnel and then you did the taught yourself design or you you taught yourself development. Like how did you make that jump into there? Cuz I I remember seeing that first frame template and I was like this thing looks like super legit. I think it looked way better than even like what we had at the Morningside website at that time. And then I started seeing all these agencies pop up where they had started taking that and and using it in different ways. Um just changing the logo and the name and I was like man this is a really big big opportunity and I think you may have been in touch with with Casey in between uh now and then. Um but it's been awesome to see how far that's come. So how did you how did you make that jump? Yeah, I never was like an artist, so I I don't have any background in creative stuff, but again, I just loved it. I really like the process. For example, right now, I don't get that dopamine by signing clients for something. I really, really enjoy building beautiful things and I really enjoy when people say that, okay, this brought me clients or this looks fantastic. I like I built something with my hands and I can see it in front of me. And with framer right now, you can build a really really beautiful website in days or even in hours. You don't need like a web development knowledge. You don't need to be technical. So you just jump straight to a template, change some things, click one button, and boom, your funnel is published. >> For people who are curious, uh what sort of like revenue and profits are you seeing out of this business? because obviously coming from Kazakhstan, if we're talking like the numbers that I that I I I think you're doing, it's it's a pretty significant uh income, right? >> Yeah. So, when I started, I was selling websites for $2 $300 and I was doing it for one year straight. And after that, I understood that I'm just doing the thing that any other guy can do. Like, everyone can just go into a template, change some things, and boom, you have website. So, I didn't provide that much value. So I decided to make a little bit more technical approach here. So I started building like real funnels and I started charging different money for this. Right now I built everything from scratch. We do AB testing. We collect data like we just really bring results. And in terms of revenue in the past five months we've made around 90k in profit. So this year we want to end up with $200,000 in I can't believe I'm saying this because one year ago like previous year we made 15k in profit in the entire year. So I just wanted to master one tool got like bettering it and everything changed. So yeah and my funnels by the way we are tracking the progress we collect the data. >> Awesome. >> They made more than 2 million for AI agency owners. So yeah, break it down for you today. >> And I mean that's that's essential tracking those results from your clients. So I mean I I don't want to jinx it, but I think after this when everyone kind of knows the work that you're doing, um you may be up for your biggest year yet by far. So uh let's jump into it. I'm excited to see what you got. >> First, we need to understand what we're trying to achieve with with the landing page. Usually we are selling to people from older generation like 40 years plus decision makers, people with limited time. So we need to be quick with hooking them with a good copy and good structure. So you can pause the video, check the resources here at your own pace. But summing up, what we need to do, we need to get we need to show clarity in seconds. We need to show proof that it works. We need to show that it's super easy to start. You don't need technical knowledge knowledge like you can go step by step. And our CTA should be very easy. Book a call, book a free demo, something like this. And here is my very very favorite templates like structures for high converting landing pages. Again, you can pause them and read at your own pace. >> Guys, by the way, Arthur's going to he's kind enough to give us this whole board. Um, so I'll link that as a resource below that you guys can check out. >> So, every landing page starts with social proof. So we need we need to show them like fivestar thing you know trusted by industry experts trusted by 50 plus companies. If you don't have specific metrics here just use something generic heading. It should always be results based instead of AI powered technology blah blah blah this fluff nobody cares about it. Use resultsbased language. For example double your or like voice AI agents that double your leads. something like this. The outcome is obvious. It hooks the attention and after that we are showing step by step how we are doing it. So we show the exact metrics what you can achieve by using our tool. We reveal the problem after that we want to you know put the pressure on their painoint for example manual tasks they kills your creativity and right next to it we can position like a solution to the pain point. So problem solution next to each other. After that we can like describe the solutions in uh more specific language what we build here. Voice AI agents, chatbot agents, AI workflows. You decide depending on your niche. After that we show benefits. The thing is features they don't sell. They just tell what you're doing. But benefits, this is a thing that really sells. Like it integrates with your workflow seamlessly, works 247 for you, measurable ROI, like the things that are really selling to your visitors. After that, just show them how it works step by step. Super easy to start testimonials or even better if you have case studies with exact metrics, call to action, and FAQ to, you know, detect objections up front and answer all the questions. That's super clean, straightforward. I think anyone with an agency is looking to do a website. Um there's no reason why you couldn't. I like I like how you've left in their buffer like if you don't have I know a lot of people who are starting out are trying to figure out where to place themselves, what's their offer, how are they angling themselves, what's the positioning of their agency. And so this leaves a lot of uh a lot of flexibility in terms of like how general or specific you are like voice agents at 2x or uh you can be super specific of like our AR reception system for plumbers achieves this very specific results or your money back you know like a you can move that scale along very nicely and so is this one on the right just a slightly different um setup you've got a video based landing page rather than so that's a little bit more effort for the for the beginner to get that VSSL >> absolutely but you know the thing with VSSL Well, most of people they never watch VSLs, but at least you can show your face and make the website a little bit more human. >> Yeah. And with the pricing, if you have standardized product and if you can reveal the prices, >> you will get so many bookings like so much more bookings because people they don't really understand how much all of this AI agents price. They may they may think that it might cost them five figures, but if you sell something for four figures or even cheaper, you should absolutely reveal the pricing. >> That's such a great point cuz I mean this the business is now just maybe encountering your content on LinkedIn and are yet to take their first step into into AI or or AI exploration for their company and and development and consulting. They likely have no clue about what this is going to cost. So, if you are are on the cheaper side and you are getting started, um it can be a very very effective way to hook a lot of those people in and get their get their interest. Um because they may just assume that, oh, this website looks really nice, so maybe they're out of my budget. Um so, yeah, that's that's a it's a great point. Um on I think we're probably good to just jump into some of these uh these case studies you've got. So, what's next? >> Yeah, so this is one of my recent case studies. I worked with the landing page. They're from Mexico. They had a problem. So, their LinkedIn content was performing. They have a specific industry. So they were helping financial departments with workflow automation. But the problem is they got zero bookings from their website in the past six, seven months. So they texted me, I opened their landing page and I saw this mistakes I would say on 80% of the landing pages related to AI agencies. And I'll break it down step by step for you right now. The first thing is it's black themed and if you're trying to sell in our case to financial departments, we are dealing with older generation. It's naturally much more easier to read the black text on a white paper. In our case, it's black text on the white background. So, the website wasn't really accessible for them. The good thing about their heading was that we show who's it for. So, we grab their attention, but we don't tell them the result. It's like flexible AI workflow automation. I don't understand what what that mean. >> Yeah. >> Yeah. So after that they decided to show testimonials. Testimonials are great with metrics. So it's more like case study not the testimonial but the problem is we don't understand like what we're building here. >> Yeah. >> So after that they reveal the problem. Yeah. Good thing with matrix uh great structure. So they reveal the problem and I expect personally to see a solution to my problem but instead of this I see how it works. I don't know what you're building what you are doing but you show me how to start working with you. I mean you just yeah missed the solution part and this is what costed them so much money in leads. Also, they showed metrics, but metrics are >> so they've got the they've got the problem, but they've never been specific about what exactly they've shown how they do it, what the problem is, but not like what they actually do. And I think this is this is typical a lot of agencies because they don't they're not actually 100% sure on what they do. You know, they do like they can do a lot of things. They might have done a a range of things in the past and they've yet to really refine down which I think is a is a fair enough position to be in that you haven't really decided to go all in on on a certain set of things. So it can be a tricky uh sort of transition period for people going through this. So I assume these guys are in the same position. >> Yeah. Yeah. Absolutely. So we what we did is we changed the messaging. The problem was like we're not getting leads. So we decided to fix that. This is what we did for them. So here's we have super generic social proof number one platform for finance bold statement but with no proof. So we were moving from financial departments to more departments. We right now we want to sell to HR department to ops department. So we don't have the specific number of companies that we worked with. So we have a generic social proof trusted by team lead leaders worldwide. So this is what you can do with your landing page if you're just starting out. Heading is results based right now. Automate automate back office tasks save hours every day. Super easy. Hooked my attention. I want to read what's next. Loggers of big companies. I mean just tools that we used but again builds trust problem next to its solution. Super easy to read. super easy to see how you can benefit from it. After that, who is it for? Again, like we lost a bit of attention, I think here, a bit of engagement, but after that, we are throwing like another hook. Like if you're for example from financial department and you see that this is built for you it gets your attention back and after that solutions that we built AI agents internal tools workflow automations and benefits how you can obviously benefit from our tools instead of showing them technical part we show them that we'll go live in weeks you don't have to switch your system you don't need the development team it's fast measurable analy sort of up front on the landing page. Nice. >> Yeah, exactly. After that, more social proof with metrics and again more social proof with not just testimonials but also some metrics to share some case studies. How it works? Three steps like super easy to start. Book a call with us. We do the development and after that we do the maintenance the solution and FAQs obviously to answer some questions. >> Awesome. If you just want to I mean so people know kind of what's coming up. Are you going to be able to sort of point these guys in the direction of, hey, this is how you can how you can set these up? Because if they wanted to build something similar to this, what's the best platform for them to do it on? At this point, >> honestly, you don't need any coding knowledge. You just go to framework.com, you go to marketplace, and you can find hundreds and thousands of free templates. You can even find some for AI agencies. What you need to do after that, just pick one with the simplest layout. You don't want to spend weeks or months trying to figure it out, trying to figure out the platform. Just pick the cleanest, simplest template and after that change the copy uh add some icons. You don't need to be a designer. You don't need to design this visuals. You can just go with this beautiful icons by easily find them on Google. So after doing this little manipulations uh just follow the structure that we're discussing here. Click publish button. Go buy a hosting, buy a domain, connect it again, click publish, and boom, your website is live. You don't need a coding knowledge. It's almost drag and drop. Damn. Okay. So, that's uh that's your value there, guys. That's the kernel of this video is that you can make vid make websites like this and you can go into frame like Arthur started on and pick out one of the templates and adjust it and instead of having to waste I've heard of people taking weeks and weeks and weeks and and over a month to to get their website right. It's a very like common procrastination point for people. Um so if you do want a website that looks super clean for you for your agency, you can go on and you now have the formula. I think that's really the really the value of this video that you're you're sharing, Arthur, is that they now have the formula of how to lay things out. And I think a lot of the time people, if you spend maybe two weeks on it, you better hope that it's got a good structure and it's going to convert. But a lot of the time they they don't even get that. So if you you really insist on spending a while on it, guys, at least make sure you stick to something like this and it's going to really convert for you. Um, so that's that's freaking awesome, man. if you just want to like give us a skim over the other case studies and then we can um got some interesting uh discussion points on on what this sort of means for the AI agency market as a whole. >> Yeah, absolutely. So, this one we built it for another YouTuber Brandon Joit. The problem was he scaled and he needed like a better website that will represent the quality and everything. The problem with previous one, it lacks social proof. As you can see, we don't have any testimonials, any fivestar reviews, case studies. So we built version one because Brandon wanted to sell more than just voice AI agents. So we we were trying to put here chat agents, automation agents, case studies. You know when you give a context like honestly your visitors they don't want to be lab rats. They don't want to test the product on their sales. They want to see some proofs. If you can not just show the testimonial but show the outcome how you did it as a case study that would be great. This is super powerful and this is what really worked for us. So we showed some testimonials. Here we have some beautiful graphics basically benefits again instant replies blah blah blah easy to start more testimonials uh ways to contact Brendan. In our case like when people go from YouTube they want to work with YouTubers specifically. So this is what we have as the first version but after that we saw that conversions are not the greatest and we decided to change it a bit. Right now it it's not looking that fancy but what we did is we decided to niche down again back to voice AI solutions. So it can be a thing for you guys as well. I know you saw so many videos. You can build workflow automations, n automations, voice AI, chat bots, but honestly just focus on one thing and you'll get most out of it. So this landing page right now is about inbound calls, outbound calls, and it performs like crazy. One offer, one target audience, social proof, like comparison table, and boom, you have your clients. Super easy. >> Sick. Do you think that if you put the photo real photos of the team, you'd get better conversions than the uh than the like cartoon ones or was push back on that? >> Yeah, this is what I got from them. So, I'm not like like I'm not trying to push people to take their photos. Maybe they feel they don't want to. >> You should definitely do a split test on that and see if like I mean you can just get these AI like headshot generators are so good these days. Brendan's a smart dude. I'm sure if you like, hey, look, I think we can get a few extra like like maybe a 10% increase of our current maybe like what 5% um conversion rate. Maybe we get like an extra.5 of a percent or something, you know? So, that would be that would be interesting to put really put faces to the names. But yeah, it's super super clean. So, my favorite case study that you can duplicate like today so is the case study with talk AI. What we did is we built this landing page seven months ago. design isn't great, but copy and structure did it thing. Jack, he posted on LinkedIn and his post went viral with more than 4,000 comments and this led to 102 bookings in seven days from the landing page. So, we created like a foundation with this formula. After that, he got a little success, not a little big success with the LinkedIn and boom, people landed on the landing page and they booked calls with 150k in the pipeline. So I'll break it down super quick. You can duplicate it super easy. So again results based heading some social proof peak logos metrics because we have one specific offer we can show metrics at the very top and you can just find this metrics open source. You don't need to put your experience here. So after that again problem problem and solution then uh like what we built again solutions AI customers for like customer support we build AI agents we build custom agents you can do sales on autopilot success stories after that benefits easily integrates with your current stack here you can even test your solution by pasting your phone number uh we compare it ourselves with other agency honestly your visitors will never compare you with other agencies because the market is so big and there are maybe like just 10 thousands of AI agencies. Yeah. Like but the thing is you are showing your strongest parts here like people will not compare you but again this is the place to show why you're legit, why you're master of your craft, like you're a specialist. We do this and that we do support in Slack channel. So again, we're just giving more information in super easy format. After that, three steps to start working with you. Again, testimonial, FAQ, and call to action. Super simple. >> And I mean, before I wrap things up, I do want to have an interesting interesting chat here about this opportunity that you've identified and that we have I've I've seen other people starting to get onto it, which is realizing that the AI agency thing is going to the we're going like it's picking up. We are still very very very early on the curve here. um and the demand for AI services. We're seeing all the stats come out about for 5% 95% of companies or enterprise pilots for AI is not far reaching like they're not delivering the ROI that was expected and realizing that there is this massive need for the services layer that we've been screaming about for so long now. But if they're not able to be converting there uh if you get a essentially this whole new set of businesses that pop up this AI agency services layer, there's also a services layer that can uh be built on top of that to sell to them, right? You have identified that people need land people need landing pages that convert. There's also they need maybe they need leads or they need like targeted outreach or they need ad systems set up, ad funnels that work for uh for these kinds of businesses. There's all of this stuff around it. There's like I mean uh like voice agent testing platforms. There's these different kinds of software opportunities and also service opportunities that pop up on top of the the AI agency space which uh it's really exciting to see. I mean your case and other ones popping up that kind of validates that there's a lot of people really seeing success with this that you can have not only a services layer but a services layer on top of the services layer. Um and so so have you seen anything else kind of popping up like this around you? You you've obviously worked with a lot of uh agencies. um what are you kind of seeing from your clients the most in terms of uh other other parts of their funnel that are working or kind of the maybe the other service providers that they're they're accessing as well to to get results. >> Yeah, honestly there are just a few problems that I saw and how I see them right now. So for example when I started with the websites web design is oversaturated niche like there are millions of web designers for $50 for $100 and right now many people think that everyone is building a agents we have this AI noise here yes we have and this is what you need to do you need to pick one niche one offer and become best in it that's it you you will get most results if you sell one AI solution and you will become best in your industry So you don't have to sell chat bots and voice AI and workflows. You can sell just one of these things. It's not specifically voice AI. It can be chat bots. It can be workflow automations. But just become the best guy in your industry. And this is how you can get most of your like AI agency. >> Yeah, I totally agree. Um there's these these industries while I say voice AI was just really fledgling and a small thing uh maybe a year a year year and a half ago. um it's only like just starting to take off now. And each of these different categories of whether it's like uh uh like workflow based agents that are going to be used internally or that built into automations, that's its whole that's a whole own uh category that you can become really really good at. Then there's the these voice agents that are popping up and there's all these different fields that you can just specialize in. And if you have the the landing page and website set up to be able to convert that kind of traffic. And then I guess like you've seen with some of your clients here, the ability to talk talk in a targeted way about the results that you're getting or the all the improvements that you've noticed in the space and be able to talk to a specific people about what you're doing um is really the key. So I think there's a whole lot more we could talk about content and how to how to drive traffic to these landing pages and convert them. But uh I think that might be a a conversation for another day, Arthur. Uh but it's been awesome to have you on here, mate. I'm so happy that you've been uh that you found success here and I think after this you're only going to get a whole lot more. So um and entirely well deserved. You spotted this opportunity and I really really hope you get a lot of people coming to you because you definitely deserve it and these things are obviously getting the job done for your clients. So yeah, >> thanks Liam. Thanks for providing this platform for us. And the last thing I wanted to did is when I started like I was super confused. I was struggling with finding the direction and if I I want to support like a new founders and what you can do is you can text me on LinkedIn send me your websites or even you can even book a call with me I will invest my time I'll break down your landing page what you should do step by step it's free just want to get back to give back to the community so guys if you need some help with your funnel it's completely free just text me would be happy to help you >> with that attitude you're going to go fast seriously So, uh, this might be the first we first we see you, mate. But, um, yeah, Arthur, seriously, appreciate it, mate. And I'm sure we'll be talking to you very soon. And if you guys want to grab this this Figma, that's going to be linked down below as well. Cheers. So, that is all for this interview with Arthur, man. I'm so happy to have brought him on the channel to give him a platform. As you can see, dude clearly deserves it and I'm so happy to give him a platform here. So, if you guys please check his stuff out in the description. He's got his links down there if you want to work with him. He's also got that figment down below as well. So, all the source he's given away. So, please go and show him some love and go connect with the guy on LinkedIn. go shoot him a message as he said, but generally just take some inspiration from the story of a guy who's busted his ass. He's come into the AI agency space. He had struggles. He's identified a problem that many many agency owners face. And I think the smart people watching will see that there's many other problems that the AI agency services space which is just exploding right now. There's so many of these problems that need to be solved. So whether you're going to attack the AI agency thing head on or you're maybe going to look for a different entry point like Arthur did, there's so much value to be created. There's so much money to be made in the space. So I'm looking forward to seeing you guys on the next one. And if you want to learn more about me and my businesses or work with us, you can find that information in the description below. But if you want to check out another awesome podcast for some 19year-olds from Turkey who have made $300,000 with the AI agency, then you can check this out up here. But aside from that, guys, that's all for the video. Thanks so much for watching and I will see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Arthur, especialista em sites para agências de IA, compartilha um plano de páginas de destino de alta taxa de conversão, sua trajetória profissional, uso de ferramentas sem código e estratégias para gerar leads.",
            "resumo": "Neste vídeo, Arthur, referência em sites para agências de IA, revela seu plano de páginas de destino de alta conversão. Ele conta como criou mais de 100 páginas para agências de IA, evoluindo de sites básicos para funis com teste A/B, usando Framer para construir rapidamente sem precisar de codificação. Relata sua trajetória desde uma origem humilde no Cazaquistão, a importância de mensagens e estruturas adequadas para decisores com 40 anos ou mais, com pouco tempo, e como inbound e conteúdo ajudaram a atrair clientes sem prospecção fria. Além disso, descreve a evolução de precificação, passando de sites de 200–300 dólares para soluções técnicas com resultados mensuráveis. Os números de resultados, como cerca de 90 mil dólares de lucro nos últimos 5 meses e meta de 200 mil dólares neste ano, reforçam a eficácia. O vídeo promete apresentar o modelo ideal para páginas de agências de IA, com foco em dados, testes e mensuração.",
            "assunto_principal": "Páginas de destino de alta conversão para agências de IA e estratégias de geração de leads",
            "palavras_chave": [
              "página de destino",
              "agências de inteligência artificial",
              "alta taxa de conversão",
              "Framer",
              "sem código",
              "funil",
              "teste A/B",
              "dados",
              "geração de leads",
              "modelo gratuito",
              "marketing de atração"
            ],
            "resumo_em_topicos": "- Contexto: muitas páginas de agências de IA falham em gerar leads; o vídeo propõe um modelo de alta conversão.\n- Quem é Arthur: especialista em sites para IA, já criou mais de 100 landing pages, trabalha com dados e testes A/B.\n- Jornada pessoal: origem no Cazaquistão, sem formação criativa, início com promoção em comunidade e inbound via LinkedIn.\n- Ferramentas e método: uso de Framer para construir modelos sem código rapidamente; foco em estrutura e copy que convertem.\n- Evolução profissional: de sites de 200–300 dólares para funis completos com resultados mensuráveis, incluindo testes A/B e dados de desempenho.\n- Resultados: lucro de aproximadamente 90 mil nos últimos 5 meses; meta de 200 mil neste ano; clientes como Inflate AI, Moni Group, Talk AI.\n- Público-alvo e estratégia: decisores com mais de 40 anos, com pouco tempo; necessidade de ganchos rápidos e mensagens diretas.\n- Promessa do vídeo: apresentar o modelo/roteiro ideal para landing pages de agências de IA que convertem, com foco em dados, testes e mensuração de resultados.",
            "prompt_tokens": 1870,
            "completion_tokens": 3114,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 66.75592708587646,
          "language": "",
          "view_count": 18890,
          "has_transcript": false
        },
        {
          "id": "2CdNLDttOSg",
          "title": "Como dois jovens de 19 anos ganharam US$ 320 mil em 6 meses vendendo auditorias de IA (análise co...",
          "title_pt": "Texto: Como dois jovens de 19 anos ganharam US$ 320 mil em 6 meses vendendo auditorias de IA (análise co...",
          "url": "https://www.youtube.com/watch?v=2CdNLDttOSg",
          "published": "2025-09-07T00:38:05.283272",
          "published_relative": "há 2 semanas",
          "duration": "33:47",
          "date_published": "2025-09-02T17:45:58-07:00",
          "transcript_available": true,
          "transcript": "The majority of the people sitting on the sidelines in AI these days have some kind of reason about why they can't succeed and why they're not qualified, why they aren't one of the people who can succeed with us. And today I'm so excited to be sharing an incredible case study of success at an incredibly young age of just 19 years old. Mert and Ali are the founders of Monk AI and they're two 19year-olds from Turkey and they have gone on to do over $300,000 in revenue with the AI agency. And so in this video they are sharing all of the source about how they've been able to use social media in particular LinkedIn to generate leads and the very specific strategies of how they've positioned themselves despite being so young and succeeding on the platform. They're giving away all the source on how often they post what they're posting and links to their page as well if you want to take a look. And also they're sharing the secret source on how they've been able to see success despite being completely non-technical and how they figured out the one key unlock that allowed them to go from 12 months of struggling to scaling to over $300,000 in revenue. So, super excited to share this with you all. These guys have been absolutely crushing it. I'm so excited to give them a platform to talk about what they're doing because I think all of you from all different backgrounds and aged and stages can learn something from the success stories that these two have been able to pull off. So, we have the uh the Monk AI team on here to share their journey today. Got a lot of cool stuff they're going to talk about. So, I'll let you guys jump in and give a little intro. >> Hey guys, I'm Mart, originally from Istanul, Turkey, and I'm the co-founder of Moni Group. >> Hey guys, this is Ali. I'm originally from Istanul, Turkey as well and I live in the US. I'm also the co-founder of Mon Group alongside with my 10 years of best friend Matt. >> Sweet. And just give us a rundown on uh what Moni is, what you guys sell and and sort of the numbers that you guys are seeing recently and what you're going to be sharing with everyone most importantly. >> Yeah, of course. So, we have been building Moni Groups since October 2023. Throughout our AI agency journey, we have successfully completed over 50 AI projects working with clients from all around the world with across 10 more than 10 industries. We are currently working with even billion dollar enterprises to build their AI strategies and implement custom AI solutions for them. Over the past six months, we have generated over 300K with our trip AAA as two 19 year olds. and we did all this while still being 19 and having a lot of fun. >> That's some of the craziest craziest results I've had for people of of your age. So, that's it's a massive result for you guys and I know how long you guys have been uh grinding away on this. Um, so particularly today, I' I wanted to bring you guys on just because I think you've got a really interesting story. So, you guys were obviously in the accelerator quite a while back. So, it's it's been sick to see you guys progress over the last particularly the last like six or 12 months. So, I just wanted to get you guys on here because obviously you guys are super young, absolutely crushing it. And I really am really, really excited for the trajectory that you're on. Um, particularly I want to share, get sort of pull out of your brains the uh strategies for getting clients that has worked for you cuz I know you guys are tested quite a lot and now you're really crushing it. Um, and also the offers because I know you've been playing around with your offer. You guys are working as a operating as a general agency which is uh notoriously difficult to scale. Like I'll be the first to tell you that. um Ali's smiling because he knows what I'm talking about. Um but there's a lot of issues and difficulties that come from that. But there's also massive benefits which is what we're really going to get into this that gives you sort of much broader scope and the ability to do larger more transformation based projects. So I'm super excited. I know you guys have got something to share with us. So if you just want to whip that up and um you guys can start running us through. So today we are very excited to show you the exact systems and strategies especially focusing on AI audits and LinkedIn that made us scale from zero to 50,000 per month. We see that the single biggest thing business owners are looking for right now is a clear answer to where and how to get started with AI. And as of 2025 a lot of people have a lot of ideas about AI but they don't really know where and how to start. And that's also really hard to figure out unless you have someone like our agency who could jump in, explore your ideas, explore your business workflows, and give you the right guidance in terms of AI. >> Yeah. Yeah, and that brings up an interesting interesting discussion point which we'll probably get into a bit more later, but around the benefits of of going general versus versus stay going niched and that's obviously everyone wants to get the super scalable agency that's productized service and all this stuff, but um I think you guys can be a good uh a good testament to why it's worth going through the through the difficult things. Just just so we're on the same page, what was the the background of you guys coming in? And obviously just coming straight out of high school is is one of you sort of more on the technical side and what's the structure of the team so people kind of know what the sort of the initial ingredients that started Mari were to get you to this point. >> Once we were out of basically high school, uh Mart is also 10 years of my friend. So we always had this intention to start the business to be honest with you. The first path we took wasn't a really efficient path. It was about SMMA, but then we just realized this massive opportunity in the AI space. Fun fact, neither Martin nor I are technical guys. So, how we handle is he he's a great guy in terms of content. And actually, I'm more interested into uh sales and operations. So, when Matt strategies start working and when someone needs to handle those clients or prospects, basically, I take care of them and lead the operation team. And that's how it worked. In the first days, we were just like, you know, uh outsourcing the dead work, but then we created an uh an in an in-house team uh as well. And from the early days, we were a general agency uh to be honest with you because we didn't know which niche to focus on. And then uh we decided to niche down slowly, but then there were opportunities that we couldn't reject and and we stay. this exact same for us. >> Yeah. It's like you everyone's got a plan until they get punched in the face and then like the business equivalent of that is like everyone's niching down until like a big deal comes in that's like too hard to say, right? So, >> and then BA team gives you an offer. >> Yeah, basically that was that was what it was for us. Um but yeah, if you want to you want to jump in M onto um what we've got to break down here um and explaining what what's worked for you guys in your journey. Yeah, today as we mentioned at the beginning we will be focusing on AI audits and LinkedIn as these are the two most important things that enabled us to hit consistent 50k months. So we would like to give you a brief breakdown of how and why these two completely changed the trajectory of our agency Monk AI. So we launched our AI agency back in October 2023. As I said in the first 12 months of our journey, we fully followed what was what we saw on YouTube and what was trending which is building and selling no code and low code solutions like chat bots and so on. For client acquisition, we tried all sorts of outbound strategies like cold calling and cold emailing. However, at the end of the 12 months, what we ended up having was a journey marked by huge ups and downs, inconsistent income, and little to no progress. So, we absolutely knew that we had to change some stuff. And that's when we came up with the idea of AI audits. To define an AI audit in our terms, it is an assessment process where we uncover the highest impact and highest return on investment opportunities for AI integration and provide a strategic road map on what to build and how to actually build it. And after testing out our AI audit offer with a couple of leads, we came to the realization that this is actually what businesses are looking for rather than some no code or low code solutions. And that meant that our conversion rates went much higher compared to when we were uh pitching these solutions right off the bat. That's a super valuable point to to make there that like you still technically can be delivering the same thing, right? Like you may get to the end of the the the audit and realize like, okay, well, this is what we need to build for. It might be majority low code or no code or like a mix of no code versus custom development, but just the way that it it's framed is different. And it starts with a conversation and exploration rather than like buy my chatbot which is is what works with with early adopters but as we've seen like as you start to tap that early adopters and they're looking more for for the guided and managed experience. But I do want to point out there on because you guys coming into this is nontechnical. Uh do you find that your experience in getting hands-on with like this is what I keep telling people to like you still have to put you can't put the cart before the horse like you guys wouldn't have been able to do AI audits without first having had that experience of being hands-on with those first few clients you had. Right. So, what what do you think the importance of that was for your journeys? And and do you think it's possible to just dive straight into those those audits um without having a bit of hands-on experience first? Cuz I I'm definitely in the camp of like you need you need to how can you consult a audit without really having uh being hands- on with it at some point. >> Great question. So, I want to jump in here. So definitely we have a time from between 8 to 12 months as Matt said like little to no gains in terms of financials but as you stated the knowhow that we actually acquired throughout that process including the accelerator and your early videos as well uh was it it was insane. So when we were actually starting the orders, we already like when we see the problem, when we see the current market, we already knew like what what type of solutions would work. So at the same time though, I'm just thinking if we started with the AI or the strategy from day one, I think it would still be better because I was always like a kind of people in in in school as well. But when there was an exam, I didn't enjoy like going through all the lesson materials. Instead, I would just solve questions and whenever there is something that I don't understand, I would get back to the materials. So the audit approach, I started doing the same. In the first audit, I was just getting into the audit. I had the knowledge because I was trying to acquire that knowledge based upon the strategy of audit. But after that, I wouldn't wait to be perfect. I would just immediately jump into an audit call with a client. I would do some free ones because I'm not that experienced maybe. And after doing them, whenever I learn a concept that I didn't hear, then I would go to those lessons materials and just basically learn it with progress. >> Yeah, that's a it's a it's a great way of doing it. And I always I always recommend for people who are scared of getting on those first calls, whether it's it's it's audits or whether it's just like discovery calls, you don't you're not expected to know everything on the call. You're not expected to be able to roll out just like a like off the tip of your tongue, give them an AI strategy like road map just on the on the freaking call. Like it's a discovery call. It's a it's an initial uh initial call. And sure, as you get a little bit more experience, you can like all of us could probably hop on a call with a client now and riff and be like, \"Okay, tell me about it. Okay, bam, bam, bam, bam. Here's what we'd recommend.\" But that's a that's a later stage skill set initially. If you can just say, \"Look, this is for data collection. I'm going to ask a lot of questions. Then I'm going to go away and I'm going to get it back to you separately.\" you buy yourself a day, a couple of days to piece this together and then like you said, go and find those extra resources and and find the the answers for that for that road map. So I think that's a great way of doing it. >> So yeah, now it's if if it's okay before we get into the LinkedIn strategy, I would like to first talk about the very high overview of the offer itself and why we switched to this. There are five main reasons we did this. So I want to go through them one by one. But before this, I still remember that day Matt proposed. I'm gonna be honest. Matt proposed, let's do an AI audit. And I said it was the worst idea I've ever heard in in my life. We were doing discovery calls. I was in a sales call and suddenly he said, \"Hey, don't on board them into a discover.\" I said, \"What do you mean? Tell him that we need to get 1k before getting into a discovery call.\" I was like, \"Matt, this is not no one is going to pay 1K for an hour long of a call, an hour long of an strategy call.\" Like, are you crazy? And the whole team did the same thing. And then anyways, I just I was angry and I just said it and then the guy said, \"Okay, yeah, let's do it.\" >> Yeah. >> And that's funny. It's the exact same thing that we remember when I started talking about the expiration milestone. That's the same that's the equivalent of what happened with us at Morningside. like I'm I'm not taking another freaking discovery call with some dude who's like got a like majority of tire kickers you're going to pay me for more of my time basically. Um, so it's interesting to hear you guys came to the same conclusion and I think like you guys tell me if this is the same case for you, but we got to that point because we had so many leads that you can kind of yolo it like you like for like if this guy says no, who cares? We've got more and so you can kind of just yolo it and say okay, but it's going to cost you two grand for us to do this little thing to to kick it off and then someone says yes and you realize like that's like opening up. So is that did that align with M your LinkedIn sort of popping off? It is actually the first thing I will be mentioning in this table and I would say it is also the most important factor of us switching from free discovery calls to you know paid exploration milestones of AI audits. >> So there are basically five reasons why I proposed this great idea not m so first of all as you said you waste your most valuable asset which is your time doing free discovery calls. Everyone did it. I did it as well up to 1 to three hours with prospects who are not even willing to work with you for an AI project. So in terms of the qualification system, AI audit is a great approach. Secondly, you first need to convince the business owners, especially in today's world and especially when you look at our experience with clients at least the traditional and skeptical ones always want to learn about the impact of AI before getting into any kind of solution. So if you start talking about chat agent, voice agent, automation, AI powered platform building, it doesn't make any sense. they first need to learn about a general AI concept and their impact in into their business probably. And as you're doing this with AI audits, uh it is so much easier to get a yes in the in the first meeting from a decision maker because of the second second point and also a 1 to 5k AI audit. I'm talking for beginners, right? comp uh 1 to 5k AI audit compared to a 5 to 10k AI project AI chat agent build automation whatever is a lot easier to get a yes from the client and when you get that first yes yes don't get me wrong of course our goal is to not just sell a 1k 5k maximum uh let's say audit that's not the goal our goal is definitely to convert them into a product dev client or into a long-term client but when you get that first yes yes you're starting to building a financial relationship ship as well. So they pay you, they get the service. Now after the audit, if you propose them a 10K plus 20K plus AI project, now you built that relationship and now you have a financial relationship as well. And now you walk them through a service to >> they trust you. They've seen seen the proof of work. And what we find at Morningside is that we know their business better than than they do in most cases. like the depth that we go into particularly cuz we we do our audits for for bigger bigger clients like 200 300 person companies now and the like that's a lot of people to know what the hell's you know like for for a leadership team to know what the hell's going on at every division there's a that's a a very tricky thing to do and so actually us going in there and doing the full audit to breaking down their processes and then being able to communicate that to them if if these AI experts know so much more about my business than I do and they're telling me that I need these it just comes from such a such better place of uh of authority because you've taken the time to learn that you've you've shown that you can execute well. Um so yeah I I completely agree. >> Yeah exactly and lastly the skipping the fourth part because we already talked about it you you need to because of these reasons you need to productize actually your knowhow on AI. So basically now your main offers are actually discovery calls. So you can't that you can't do that for free. You listening to a business their problems and operations is actually your product. So instead of giving the secret source for free in the discovery calls, if you position it in this way with AI audits, you're going to see how much easier it is to get a yes. As I said for an eight, nine months we did the complete you know structure that Mart outlined and the day we switched AI audits one month later we were interviewed in your channel. So I can I can I can summarize it like that >> and I mean the cash flow from it was is huge. I mean for us in the early days at Morningside uh those like 2 3 4 5k expiration milestones where we wouldn't we would do the discovery call but we wouldn't hop on to like any other calls. It's like okay yeah by the end of this we're clear we're pretty sure we can do this. The next step from here with all of our clients is a discovery as an expiration milestones is going to be 2k 3k 4k. Now we're selling them for like up to $10,000 but just for an expiration. And it's like if you want more of my time then then stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start stop start paying for it. I'm not going to sit here and keep consulting you on as I do it. And that even though those don't those might not always convert into paid projects, and they do with more and more frequency as you go on, but early stages as an agency, you need that cash flow to be able to support a developer. Like if you got a guy burning a $7,000 hole in your pocket, that stuff is what the lifeblood of your agency until you get a few of those converting because it can take a few months for them to actually convert into bigger dev projects. >> Correct. Totally correct. Yeah. I mean for us even like when you start doing AI audits you also start building a team because you have the cash flow and then you have to pay the salaries. So it's again really nice in terms of even though if they're not converting into a product dev client which I'm going to talk about here our conversion rates are around 83% from audits to product dev. But yeah, even though that's not the case, you still need to be able to pay the salaries or like be able to hire a basically in the first days a CTO. >> Just as a side note, I think when we started out doing AI audits, we were in total four or five. Now we are a team of uh 13. >> Wow, boys, that's impressive. Okay, so now I would like to just like high level if that's okay and then I'll pass it to M to shortly talk about the LinkedIn strategy here. I would like to show you what is like what happens after you conduct an AI audit and what is like the overall process and how it's different. So here basically you're adding one more layer which is the introductory call which is the actual sales call actually. So you don't do a discovery call before proposal. So just as an example let's say that we have a potential prospect Jane. If Jane gets connected with monks somehow inbound or if we get connected with her uh the most important thing with audits is that this is not like the regular way of doing things. So warm-up is so important before the prospect joins to the call explaining that this call would be basically showing him uh let's say you don't have to tell the offer specifically but at least she needs to know that this is not a call that she's going to get in share all the problems and get a proposal for their work. So and that's why we name it introductory call instead of discovery call because for us to discover you you need to pay us. That's the whole product of o of of the company. So here in this introductory call a lot of people ask about the sales. So very short I can say that uh when you just outline audit is not just another expense they're making because they can say you know easily why am I paying for this discovery call there are a lot of people doing this for free and I can get into their work. The way we handled was we said because we want you to prevent expensive missteps and expensive guesswork. So we're first planning and then you can invest into a product. >> Mhm. >> Yeah. And if they're not willing to put up a a th000 bucks or something to like get a good foundation and they're not the kind of client you want. It's really good having that financial filter. You guys like anyone else with an agency will know there's a lot of tie kickers. the majority of people coming are tie kickers that they're not really willing to spend or they want you to give some like free template so they can do it themselves. So like financially qualifying them um initially to make sure that they actually have the money um and then also that they are are serious about this and if they don't blink an eye at 1,000 or 2,000 bucks then you know that there someone that you can work with. >> Correct. Exactly. And when you position yourself as like, hey, this is not just another expense, this is actually a big saving for your future because before investing into something, before doing some guesswork, we need to make sure we have the strategy. When you say this, you're creating two very impactful things. One is fear, which just creates fear. They're like, \"Oh, if I don't do AI planning and invest into a product, I might lose money.\" But then you slap him with that that 95% failure rate stat that's going around. It's like the reason the reason these guys are failing at 95%. If you want to be in a five, we do it properly. This is why like so well. >> That's the third slide of our pitch. Like >> 80% alias now like 95. Like yeah, it's real. >> Exactly. >> You're saying Alli, what's that? What's the second point? And I was just saying and secondly, you're positioning yourself next to the client. So it makes them more comfortable and they're in psychologically they're more like comfortable saying yes because you're saying hey we want to protect you so you don't invest into an expensive solution. >> And in terms of perception this is this just positions you next to the client. And then the next steps are basically discover call which I don't want to get into great specifics to keep a tie overview and just pass it to Matt to explain the LinkedIn strategy of this first sales part. But then the important things are in the discovery call one sentence I can say make sure here you are aligning the success metrics. So what looks success for you also looks success for the client. You're telling that from day one. So you have you will maintain satisfied clients which could be the most important thing. And then with the audit again as I said currently we have 83% conversion rates and as I said if you conduct this process if you start conducting this process you will also see that your conversions to product they will increase a lot because basically from the beginning if the people are paying you 1K 3K okay these are qualified people and definitely you are >> not wasting time. >> Yeah. Yeah. Love it. And I know you guys have got a whole lot of extra source on uh on audits that you can share. So I think uh if you guys watching want to want to hear more from these guys on on exactly how two 19-year-olds are running these and particularly I think your guys angle is is for for small agencies like small teams to be able to run these audits. Um if you guys want to hear that we can bring these guys back on and um have a chat. So let me know down in the comments if you want to get the uh monk AI AI audit source in in a different interview. >> Now I want to pass it to Matt to just like let him explain. Okay, I was executing this audit process, but like how he made his LinkedIn a machine in terms of uh getting all of these clients inbound. >> Thanks, Ali. So, basically, I grew my LinkedIn profile from zero to a,000 followers in approximately 6 months, but then I grew it from a,000 to 3,000 in under a month and from 3,000 to 5,000 in under a week. So now LinkedIn has become our number one client acquisition channel and we book approximately 10 to 20 qual qualified meetings per week. >> That banner is clean, man. >> Nice. >> That banner is pretty clean, man. It's your design guy. >> This is actually like, you know, a lot of people are after M did this. A lot of people are copying this exact structure. >> What with the cartoon guy in the middle? Two colors. >> Yeah. >> The AI even the copy. You're one AI audit away from growing your business. >> Oh, trust after this uh after this goes out, you're going to see a lot more of that. >> Yeah. >> Oh, you're safe. >> Yeah. Basically, throughout this process, I have learned what works and what doesn't on LinkedIn. So, I can so confidently say that if used effectively and strategically, LinkedIn could be all you need in terms of generating incon generating consistent inbound leads. And basically our core philosophy here is a quote from no raikant that I know you know as well which is productize yourself and that's our approach to LinkedIn and our online presence in general. So we believe whatever social media platform you choose you need to escape cont competition and you do this by finding your own niche or in other words by your differentiation points. So we achieved this by embracing who we really are as 19year-old AI founders and giving actionable insightful value on AI audits and importance of AI audits for businesses on our choosing chosen platform which is LinkedIn and our audience can achieve this by targeting a really specific ICP especially if they have a network of people in that industry or they have been working in the professional sector. and they have a great industry knowledge on that or having a unique AI offer which in our case was AI audits. >> Well, so you're combining um like the 19year-old which I think is really interesting people to to note that you you're actually putting that front and center what people would think is a is a I'm cracking up at those AirPods, man. I need Wait, I need an explanation on the AirPods. Is it like more comfortable for your ears that way? Uh so the explanation for it is that I just switched to AirPods 2. I think these are two and thing is falling out every second. So I need them as like >> okay so I'm sure some people are wondering but yeah the 19-year-old thing is a lot of people would be worried about oh I'm too young for this. I mean if if you can put that front and center I think it just shows that if you can pos like communicate your yourself and what you're doing at your company well like look at that. that's you in the lab, you know, like they don't this this kid's actually out there doing it. And at this point, people want the pract practitioners. They don't need you don't need to have some crazy degree. This has been the message the whole time, right? Um if you're actually deep in it, they know this stuff's moving so fast. Um that if you're actually out there doing it and can communicate that well, um then then there's obviously no issue considering how much interest you guys are getting. >> As a fun fact, the two most vital posts that I got was both in the hook. I was I wrote you know I challenged a CEO at a big company while being 19 year old and that's actually like key brand pillars that we have that's building the brand that we want and here I listed some you know key brand pillars of monkai group which is you know speed and execution as an advantage and when you really emphasize these and have a pattern in your posts then that's what creates that authenticity and that's how you escape competition even though let's say you don't have a really specific target audience or a unique AI offer. >> I love it. Crushed it, man. >> And this post of M specifically where he combines how we do audits with speed and execution and also telling that how we replace the 45year-old CEO with n with uh you know 19-year-old kids. Basically, his post got like around 75k impressions, 2K likes, like three 320 comments, and more importantly, like 50 qualified meetings booked uh from from a single post. >> And and for all the the guys watching this, what they really want to know, all the source is how many times a week you posting, how are you coming up with ideas, like what's your writing process? So, can you just share a little bit of source on that? I think that's going to be really helpful for people. >> Absolutely. So about the process you would also know this. I actually took like a month to basically create the branding of Monk AI group because at the early stages what we were doing is basically copying and pasting every other AI agency you know posting maybe demos uh information about no code low code solutions and >> the loom the loom video with the the the make scenario that's so over done on LinkedIn now >> you know that got us zero leads maybe one you know meeting booked And reflecting on that I told Ali that I need to take some time off to create create a branding because I have seen that Alex or Mosi if you see that you know white board or the yellow color you know that it's Alex or Moi you know he's a gym bro and we had to use our age and how you know young we are passionate we are as an advantage because that's the way we could you know escape the competition. So I would say the most important part which also takes the most amount of time is creating that branding and then al of course you know knowing the problems that your ICP has and the solutions and outcomes you can achieve for them. Just you know basing all your content ideas on these two things you can you know create hundreds of thousands of ideas. So basically have your brand positioning. Know you know know how you want to position yourself who you want to target and what you want to sell and that should bring you ideas. And if that doesn't bring you ideas maybe work a bit more on AI on the intersection of AI and getting more calls. >> You guys are so far ahead your age reach like seriously thinking that like starting with the branding like that's even something that I still struggle with and like that you've been able to get clear on that from from day one. And I mean you are leading that LinkedIn through storytelling uh which is is so much more powerful than spamming out uh automation things because a lot of the time if you're just doing those automation kind of posts you're likely going to get a lot of agency owners who kind of understand that and they're looking to like steal your templates and sell them to other people. So um it's very interesting that uh you've been able to position yourself so well um even at such a young age and using that as as as the thing in the front of it. So um unless you guys got some extra last minute source I think we can wrap it there. That's been an absolute banger. And um if you guys want to see see the M guys back on, I'm sure they have some really exciting stuff to share from their agency in a few months. Um but breaking down more of their consulting process that they do. Um I'd be I'd be interested to hear what you guys are running. >> In terms of the amount of time I spend uh on LinkedIn per day, it's probably going to be at least two hours. And the reason for that is very simple. So we book calls from LinkedIn. LinkedIn became our number one client acquisition channel. we double down on that. So probably a similar scenario with you with YouTube and if something is working I believe you just need to do more of it and at this again to our spend which includes you know content ideation writing that content DMing people connecting with people engaging with people which I believe 50% of LinkedIn is your profile and the valuable content you create but 50% of is actually connecting with people and outreach DMs. >> Yeah, >> exactly. You know, doing consistent outreach via DMs and posting. I basically post every single day if you know the business meetings aren't back to back uh in 24 hours or we are at a location or something. >> Yeah, sick. Okay, that is uh some incredible source for for the aspiring AI agency. Guys, I really appreciate you coming on here telling your story. >> Thank you for having us. It's all right, mate. It's my absolute pleasure to have you guys on here and um seriously so proud of how far you guys have come and just proving that you can do it at any age and uh you guys carry yourself really really well like beyond your years. So, this won't be the last year here at the Monkey Eye Boys. So, I'd look forward to having you guys back on again um in the near future. But if you guys want to get in touch with the the Monkey Eye team, you can connect with them. Links will be in the description. You can reach out to them if you need agency help as well. But yeah, appreciate it, boys. So, I hope you guys are feeling inspired after hearing that. Two 19year-olds from Turkey, over $300,000 in revenue in the past 6 months. Incredible results. So, I'm so happy to be able to give them a platform to get some more eyeballs on them because they're absolutely, as you can tell, they're also kind of thought leaders. They're leading the space as well. They are in innovating with the AI audits and the consulting as well as we are at Morningside, too. Of course, if you want to reach out to the boys or connect with them in any way, their links will be in the description. Also, if you want to work with me and any of my companies, all my information is down below, including links to my second channel where you get to see the behind the scenes of me building Morningside over here. If you want to check out another awesome podcast like this of a nontechnical person making $300,000 a month, you can check my interview with Nate up over here. But aside from that, guys, that is all for the video. Thank you so much for watching and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Caso de sucesso de Mert e Ali, com 19 anos, fundadores da Monk AI, que geraram mais de US$ 300 mil em seis meses vendendo auditorias de IA e usando o LinkedIn para gerar leads, apesar de não serem técnicos.",
            "resumo": "Este vídeo apresenta o caso de sucesso de Mert e Ali, dois jovens turcos de 19 anos que criaram a Monk AI e alcançaram mais de US$ 300 mil em receita em seis meses, atuando como agência de IA. Eles explicam como usaram o LinkedIn para gerar leads e fechar projetos, incluindo a oferta de auditorias de IA como serviço central. O papo aborda quem são, como dividiram as funções (Mert foca em conteúdo, Ali em vendas e operações) e como, apesar de não serem técnicos, conseguiram escalar com uma equipe interna. Começaram em 2023 buscando soluções no-code/low-code e diversas estratégias de outbound, mas perceberam que atuar como agência geral era desafiador. Ao nichar progressivamente e concentrar-se em auditorias de IA, além de transformar clientes com soluções personalizadas, alcançaram meses estáveis de US$ 50 mil, mostrando que pessoas jovens podem aprender com estratégias de prospecção e posicionamento.",
            "assunto_principal": "Caso de sucesso de jovens empreendedores que venderam auditorias de IA e escalaram uma agência usando LinkedIn",
            "palavras_chave": [
              "Monk Inteligência Artificial",
              "Mert",
              "Ali",
              "auditorias de Inteligência Artificial",
              "LinkedIn",
              "prospecção",
              "agência de Inteligência Artificial",
              "não técnico",
              "nichar",
              "transformação de negócios"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Apresentação de Mert e Ali, 19 anos, fundadores da Monk AI, e seus resultados expressivos.\n- Foco estratégico: auditorias de IA e LinkedIn como vetores de geração de leads.\n- Estrutura da equipe: Mart cuida de conteúdo, Ali de vendas e operações; construção de time interno ao longo do caminho.\n- Jornada inicial: tentativas com soluções no-code/low-code e outbound (cold calls, cold emails) sem sucesso sustentável.\n- Desafio de nicho vs agência geral: equilíbrio entre manter uma operação ampla e aproveitar oportunidades maiores.\n- Transformação de serviço: transição para auditorias de IA com foco em entregas de transformação para clientes globais.\n- Resultados: faturamento acima de US$ 300 mil em seis meses e meses consistentes de ~US$ 50 mil.\n- Lições para o público: pessoas de diferentes origens podem aprender com esse modelo de posicionamento, prospecção e construção de oferta com foco em IA.",
            "prompt_tokens": 1874,
            "completion_tokens": 3051,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 59.32206320762634,
          "language": "",
          "view_count": 22881,
          "has_transcript": false
        },
        {
          "id": "T6iDmSIpitc",
          "title": "Como largar seu emprego em uma empresa de IA com apenas uma pessoa (e ganhar MAIS dinheiro)",
          "title_pt": "Como largar seu emprego em uma empresa de IA com apenas uma pessoa (e ganhar mais dinheiro)",
          "url": "https://www.youtube.com/watch?v=T6iDmSIpitc",
          "published": "2025-09-07T00:38:05.283290",
          "published_relative": "há 2 semanas",
          "duration": "13:21",
          "date_published": "2025-08-31T02:23:15-07:00",
          "transcript_available": true,
          "transcript": "The CEO of OpenAI predicts the first oneperson billiondoll company is on the horizon thanks to AI. And if one person can do a billion, then you sure as hell can build a business that makes you $10,000 a month. And in this video, I'll show you how. If you're new to the channel, my name is Lee Mley and I went from zero AI experience to generating over $7 million over the past 2 and a half years by starting every kind of AI business imaginable. I've started an AI agency. I've started an AI software. I've done AI consulting. You name it, I've done it. And after seeing what works for me in my journey and for the hundreds of thousands of members in my AI business community, I've engineered the ultimate oneperson AI business model for beginners to start. I had a strict criteria on this. It had to be one, simple to start with almost no cost or experience needed. Secondly, it had to be powerful using AI as your digital team so that one person could do the work of 100. And three, it had to be profitable enough to actually replace your salary. So in this video, I'm going to be giving you that complete blueprint. I'm going to be showing you what to sell, who to sell it to, and the AI tools that will do the work for you. So, let's get started. If you clicked on this video, chances are that you've been curious about starting a business of some form for a long time, and you're hoping that AI is the thing that finally makes it possible, that maybe it's easier now, and maybe there's less risk. And you're absolutely right. AI isn't just some fad or trend. It's a tectonic shift in the way work is done. It's the single greatest wealth creation event for individuals of our lifetime. But most people are at best using AI as some kind of Google replacement and are not utilizing it fully for what it can really do. In in 30 years time, people will look back at this exact moment as the great unlocking, the moment that the chains of the old world, the the 9to-5 corporate system, they finally began to break. And the reason it's all happening now is because of a concept that I call the solo entrepreneurs trifecta. It's essentially a revolution that's 50 years in the making. And AI is this final explosive piece to the puzzle. So let me explain. So back in the 70s, computers were seen as big brother, a tool for centralized control. Sounds kind of familiar, right? But then a bunch of hippies out in California flipped that script. They saw the computer not as an oppressive tool for centralized control, but rather one for individual freedom. And from this, the personal computer was born. And that was the first piece in this trifecta. Then in the '90s, we got the internet. It started connecting those personal computers, giving all these individuals access to the world's information and creating the first wave of online businesses. the individual was getting more powerful. That was the second piece. And now we have the final piece of that puzzle, artificial intelligence. To understand why this is such an empowering thing for the individual like you and I trying to build businesses and create the life of our dreams and have freedom, you need to know the real secret of the wealthy, which is leverage. It's a pretty simple idea, but it is extremely powerful. It's essentially getting more output for the same amount of input. It's a difference between pushing a boulder with your bare hands versus using a lever to move it more easily. The famous investor and philosopher Nal Raakant says that the wealthy use three levers. Labor which is people, capital which is money, and code and content which is essentially systems at scale. For years, these were locked away from you and I. And that's why all the money has been sort of going to the same people for so long. And AI is the key that unlocks all of it. You don't need to hire a team anymore. AI is your digital labor. You don't need to be a coder. AI helps you build your own apps and you don't need to be a professional writer. AI is your partner in creating incredible content that connects with millions. You are no longer one person. With the right AI tools, you can be a team of 100. And so the solo entrepreneurs trifecta is complete. This is the single greatest empowerment of the individual in history. And like I said, the CEO of Open AI, Sam Alman, predicts that the first one person billion dollar company is coming soon thanks to AI. That's because he understands this trifecta and how powerful it is when used right. People look back at this time and realize that was the moment that the power shifted into our hands. And this video is your guide to taking that power and running with it. So, how do we take this incredible power, this solo entrepreneurs trifecta, and actually use it to build your oneperson AI business? How do we build your escape plan from the life that you don't want into the one that you do? Well, every great escape needs a map. And a map has three parts. First, we need a destination, a clear financial goal that means that you can quit your job. Secondly, we need a vehicle, a proven service that you can sell to get there. And thirdly, we need a route, a secret to find your first clients. So, let's break down the first part of our plan. First up is the destination. This isn't just a number. It's your freedom. And our target is going to be $10,000 a month. That's a number at for most people means you can quit your job, you can pay all your bills, and you can finally have control over your time. And it's the number that gets you out of the trap, basically. Now, I know that might sound like a scary or a huge number when you're starting from zero. But let's break it down. This is the most important part. To make $10,000 a month, you don't need hundreds of customers. You just need four clients paying you $2,500 a month. That's it. your entire goal over the next few months isn't to build a massive business. It's just to find four people that you can help. And so I've reframed like this because that feels a lot more achievable, right? And the next logical questions are, what on earth can I sell to people for $2,500? Where do I find these four people? And that's what the next two parts of this map are for. So let's talk about the next step, which is your vehicle. Okay, so now we have our destination, $10,000 a month. Now we need a vehicle to get us there. And look, I've run all the different AI business models over the past 2 and a half years. I started off doing freelance AI consulting, and then I started an AI automation agency. Then I started an AI education business. Then I started an AI SAS. And recently I built an AI consulting company as well. So I can tell you firsthand what is beginner friendly and what isn't. There's a lot of people online that would tell you to start some like micro SAS or something. But that's honestly one of the hardest ways to make money, especially if you're a beginner. You're going to need hundreds and hundreds of users just to get by and get to that 10K. Other people will tell you that you should just go and start selling some kind of online course. But that requires a ton of trust and usually an audience that can take months or years to build. So, the fastest and most direct path to that $10,000 a month is selling a simple and proven AI automation system to a business that you can build using no code tools. This is what's called an AI automation agency. But even with an agency, there are two main ways of doing it. There's the general agency like my own Morning Side AI where we can build almost anything our clients want. But if I'm honest, that's quite a tough game to play alone. It requires a team of expert developers who are are so skilled that they can do whatever is put on their plate basically. But for a oneperson business, you want to play a different game, a smarter game. You want to become a niched AI automation agency. You sell one system to one type of business. This is the key. You take the entire universe of AI and you shrink it down to this one tiny manageable area that you can become an expert in fast. Now, I know what you're thinking, Liam, that sounds great, but I can't build AI systems. I'm not a coder and I'm not technical. I hear you, but listen to me. That is seriously the old way of thinking. Now, I have taught hundreds of thousands of people in my community and on this channel how to build and sell AI automations using simple no code tools. I have seen people from every background, every age, every race, and every country learn these skills and sell them successfully to businesses. I know without a doubt that anyone can do this. And to make it even easier for you, I have done all the hard work for you here. I've analyzed all the data from my community and from my own agency, and I've narrowed it down to the four most in- demand AI systems that beginners can build and sell right now. Almost every local business on the planet needs one or more of these. What's called a speedtole system, which makes sure that they never miss any new customers when they get in touch with them. A WhatsApp or SMS AI booking system that allows customers to get in touch with businesses and book appointments around the clock. Thirdly, there is huge demand for social media AI DM bots that can handle questions incoming on things like Instagram and Facebook. And finally, what's called an AI receptionist that can answer the phone on behalf of a business, handling support questions and real-time booking. explaining exactly how each of these systems works right now is just going to drag this video out way too long. So, I'm going to be giving you my AI solarpreneurs blueprint, which you can get in the first link in the description. And inside that guide, there's going to be a full step-by-step tutorial on how to build each one of these systems using simple no code software. Your only job is to go through each of those tutorials, follow along, build them out, and then see which one clicks with you, which one you're most interested in or see the most potential in. That's it. That is the vehicle that you're going to sell. And in that free guide, I'll also include a full list of the AI tools that you'll need at every step of your journey as an AI solarpreneur to handle everything from creating beautiful proposals to give to your clients to writing engaging content and more. Okay, so you have your destination and you have built your vehicle. Now, how do you find those first four clients you need to get to $10,000? There are a few different ways that you could do this. You could run paid ads, but they're going to burn cash. And our first rule of this business was low cost. you could start to create content and that's how I've built my brand and got the leads for my businesses but that's a long game and we need system that gets you results now. So we're going to use the most highly leveraged tool that a beginner has remember getting more output for the same input and that's cold outreach specifically cold email. So cold email is leverage at its finest. You're going to write one email campaign and it's going to talk to hundreds of businesses a day for you on autopilot. It's like having a sales team of 20 people working around the clock for you at a fraction of the cost. And now AI makes it even easier. The email tools that we're going to use have AI features that help you write your campaigns and even respond to emails for you to make sure that you don't leave them sitting unresponded for too long. It's essentially like creating your own automated salesforce. So, next question is, who are we going to be emailing? And this is the most important part of the strategy. The easiest way to make money is to sell to people who know less than you. We're not going to be going after the techsavvy e-commerce brands or digital agencies. They're much more advanced with the AI adoption and they're much more familiar with it and therefore they're much harder to help as a beginner. We're going to be going after the most AI clueless businesses you can find. So, think of local businesses like HVAC companies, roofers, plumbers, home cleaners, contractors. They are years behind when it comes to AI adoption and understanding, which means the simple systems that you just learned how to build in the previous section are going to seem like magic to them. And most of these businesses need all four of the systems that I've picked out to you. This creates a massive knowledge gap between where they are and where your knowledge with AI is. And they'll be happy to pay you to fill that. So, here's how it works. You'll get a list of leads for each type of business using a tool like Apollo.io. Then you'll send a simple email campaign for each of your four offers to each of those business types you've selected. After running the campaigns for a while, you'll see which niche is responding best to which offer. Maybe the plumbers love the AI receptionist and roofers love the speed to lead system. Whichever one gets the most positive replies, that's your winner. And you go allin on that combination. And I know this might seem scary and confusing like running cold email campaigns. So, I've got my expert cold outreach coaches from my AAA accelerator program to put together a straightforward guide for you based on what is actually working for my students right now with cold email with email examples and everything that you need to get started. It's all going to be in that AI solarreneurs blueprint that's included with this video in the first link in the description. So, just take a second now look at what we've done. We've taken the chaos of starting a business and narrowed it down to two simple jobs. Your only mission is to learn firstly how to build one of these AI systems from the step-by-step tutorials I've included in the free guide. And secondly, how to run this one type of cold outreach in order to find your clients. That's it. You don't need to learn everything at once. You just need to master the simple and repeatable process. Now, the blueprint that I've given you is your path to getting on your feet. But I want to be honest here at the start, it's a real grind. It of course it's going to be. Starting a business isn't easy. This is just easier than basically any other way of starting a business. Right now, the real opportunity with a one person AI business like this isn't just in getting clients. It's in what you do after you have them. Once your cold email client system is running, you'll be delivering the same thing over and over to the same type of client. And this is where your job starts to change. You need to stop being the worker and you need to start being the architect of your business. And your new mission is to identify your own bottlenecks and to use AI to destroy them. If you're spending way too much time preparing proposals for clients, you need to build an AI automation for that. If you're spending hours setting up the templates for each new client, then create a system for that. If you're wasting your mornings on reporting and keeping clients up to date and doing audits for them, then build an AI agent to do that for you. Your job at this point is to gradually automate yourself out of the business. And this is truly how you create leverage. You're going to be using those no code tools, your form of code, to build your own digital labor, like Naval talked about. This is why learning AI automation is the most powerful skill that you can have in the AI era. Over the past 2 and a half years, I've taught millions of people how to do that here on this channel. So, I'll include all of my best free guides on how to learn AI automation in the AI solarpreneurs blueprint that you'll get in the description below. So, what I'm trying to say here is that this video and the guide that comes with it is just getting you to the starting line. But this process of analyzing what you're doing and using AI and automation to do that for you, this is what gets you to the dream, a business making 10 to $20,000 per month on autopilot where you're only working for a few hours per day from anywhere in the world. And I can promise you that it is not going to be easy, but it will undoubtedly be worth it. So, that's the plan. You have the map, the vehicle, and the route to your $10,000 a month AI automation agency. The best time to start, this was yesterday, and the next best time to start is right now. This isn't a fantasy. There's hundreds of thousands of people with no technical experience or background and no business experience either that are learning AI automation and building their own AI businesses as we speak. Getting into AI business right now is the opportunity of a lifetime to ride this wave. But it's not going to wait for you. You have to take the jump right now. You don't have any more excuses now. I've put everything you need in that AI solarpreneurs blueprint down below. It's going to be in the first link in the description. And of course, it is completely free. It has the tutorials, the templates, and the entire plan that we just walked through, including access to all of my free courses on learning AI automation. And subscribe to the channel if you haven't already to be in the loop on how to use AI to build your dream life. And leave a like on the video while you're down there. And if you want to learn more about me, my businesses, and what I do, you can find a link to my second channel in the description. We have behind the scenes content documenting what we're building. And if you want to go even deeper on the technical side and learning AI automation right now, I have my full 4hour free course on how to build AI agents. That's going to be right here. But aside from that guys, thank you so much for watching and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Guia para empreender sozinho com IA, alcançando US$10.000/mês vendendo uma solução de automação sem código para um nicho específico, utilizando a tríade de alavancagem (pessoas, dinheiro e sistemas).",
            "resumo": "Resumo do vídeo: O apresentador diz que a IA é uma mudança tectônica que empodera o empreendedor solo. Apresenta a tríade do empreendedorismo: mão de obra (pessoas), capital (dinheiro) e código/conteúdo (sistemas), com IA atuando como mão de obra digital e parceiro de conteúdo. O plano é chegar a US$ 10.000 por mês vendendo uma solução de automação de IA sem código para um nicho específico, com quatro clientes a US$ 2.500 por mês. O caminho recomendado é uma agência de automação de IA sem código, voltada para nichos, que oferece uma única solução para uma categoria de negócio, em vez de um serviço generalista. O roteiro tem três partes: destino (metas para deixar o emprego), veículo (serviço comprovado) e rota (como encontrar os primeiros clientes). Modelos como micro-SaaS ou cursos são considerados menos acessíveis para iniciantes.",
            "assunto_principal": "Empreendedorismo solo com IA e agência de automação no-code",
            "palavras_chave": [
              "inteligência artificial",
              "empreendedorismo solo",
              "agência de automação",
              "sem código",
              "automação de inteligência artificial",
              "de nicho",
              "tríade do empreendedor solo",
              "liberdade financeira",
              "US$10.000/mês",
              "clientes B2B",
              "substituição de salário",
              "escala com inteligência artificial",
              "plano"
            ],
            "resumo_em_topicos": "- Contexto: Inteligência Artificial como motor de liberdade para o empreendedor individual; a tríade do empreendedor solo.\n- Objetivo financeiro: alcançar US$ 10.000/mês com quatro clientes de US$ 2.500.\n- Veículo: agência de automação de IA sem código, de nicho, com uma única solução para um tipo de negócio.\n- Por que esse caminho: evita micro-SaaS e cursos; IA como mão de obra digital e conteúdo escalável.\n- Estrutura do plano: destino, veículo e rota; passos para encontrar os primeiros clientes.\n- Observação: menciona a promessa de grandes ganhos com IA e a ideia de escalabilidade para atuação solo.",
            "prompt_tokens": 1895,
            "completion_tokens": 4448,
            "model": "gpt-5-nano",
            "cost": 0.0076
          },
          "analysis_time": 74.70117902755737,
          "language": "",
          "view_count": 110839,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@SaraFinance",
      "name": "@SaraFinance",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@eusoukelvincleto",
      "name": "@eusoukelvincleto",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "f4PveaUJLd8",
          "title": "O que eu estudaria em vez de automação em 2026",
          "title_pt": "Texto: O que eu estudaria em vez de automação em 2026",
          "url": "https://www.youtube.com/watch?v=f4PveaUJLd8",
          "published": "2025-09-20T00:46:38.542575",
          "published_relative": "há 1 dia",
          "duration": "10:23",
          "date_published": "2025-09-18T20:05:56-07:00",
          "transcript_available": true,
          "transcript": "Nesse vídeo aqui, eu vou te falar o por que você não deveria focar em aprender automações, ou melhor, em aprender automações, não, em ser um automatizador em 2026. Talvez eu te fale algumas verdades duras, mas é importante que você ouça isso com atenção, entenda e tome suas próprias decisões com relação aos fatos que eu vou trazer aqui para você. Ah, vamos lá. Primeira coisa que eu já quero pontuar, eu tenho total propriedade para falar isso que eu vou falar para vocês. Eu sou da área de tecnologia desde que eu me conheço por gente. Comecei a desenvolver aos meus 16 anos, montei uma empresa de tecnologia, uma das principais insurtechs do Brasil. Eu vendi essa empresa, eu tive uma carreira também como desenvolvedor, programador, fui evoluindo, virei arquiteto de software. Eh, eu adoro programar. Até hoje eu só deixei de programar porque eu decidi focar realmente naquilo que dá dinheiro, que é negócio, tá? Então eu tenho bastante propriedade para falar isso para vocês. Hoje eu tenho uma empresa de tecnologia que é a Acelera 360, que é uma escola onde eu ajudo pessoas a empreender com inteligência artificial, com tecnologia. Então assim, eu tenho muita propriedade para falar nisso. Eu vou trazer alguns fatos relevantes aqui para você, para que você entenda o meu ponto de vista. Primeiro ponto, a evolução da inteligência artificial. A I tá evoluindo numa velocidade tão grande, mas tão grande, que eu diria que nos próximos 6 meses essas grandes empresas que inclusive desenvolveram ferramentas de automação, vão desenvolver um modelo onde é possível criar qualquer tipo de automação através de linguagem natural, como se você através do prompt. Então, pessoas que se especializarem em escrever bons prompts vão conseguir criar qualquer tipo de automação. Recadinho rápido para você que tá assistindo meu vídeo. No dia 4/10 eu vou te mostrar no meu workshop que vai acontecer online como você pode empreender com inteligência artificial. Então, mesmo que você não seja técnico, mesmo que você não entenda nada de programação, mesmo que você não saiba nem mexer no N8N, no make, em agente, não importa. Eu quero que você esteja lá comigo no dia 4/10, porque eu vou te mostrar uma infraestrutura de crescimento com inteligência artificial. Você vai clicar no link que tá aqui na descrição desse vídeo e vai garantir a sua vaga, porque são 200 vagas e eu já vendi mais de 170. Então não perca, tá terminando já, hein? Te vejo lá. Entendam uma coisa, a barreira da tecnologia, a barreira tecnológica de programar, de codificar, de desenvolver, ela está diminuindo a cada dia que passa. Do mesmo jeito que os programadores estão sendo ameaçados, os automatizadores que atuam ali mais num meio que num low code, baixo código para você que não conhece, estarão cada vez ainda mais ameaçados que o próprio programador. Então se pro programador vai ficar difícil, imagina para você que mexe no N8N, no Make, no organizando bloquinhos no CTRA e por aí vai. Então, só isso já deixa para você um grande sinal de alerta, tá, Kelvin? Quer dizer que eu não preciso aprender sobre automação? Não, não foi isso que eu disse. Eu disse que você não deve focar 100% em ser um automatizador, em ser um construtor de fluxo. O mercado tá ficando saturado. Existe uma baixa barreira de entrada para pessoas que querem se tornar automatizadores, pessoas que querem construir automações. Então, por esse motivo, cara, tá virando um Mar Vermelho. E quem tá falando isso para você é um cara que consegue vender, por exemplo, uma automação a R$ 40, R$ 50.000, entendeu? Tá, Kelvin, mas se você consegue vender tudo isso, por que que eu não deveria focar em automação? Porque o B2B, o empresário que me paga R$ 40, R$ 50.000 por uma automação, ele não está comprando automação. A automação ela é o meio, mas o que eu vendo é o fim. Então, por isso eu quero que você entenda que você deve desenvolver outras habilidades, focar em desenvolver outras habilidades que sim vão fazer você ter mais sucesso em 2026 do que você ser um excepcional, um exímio automatizador. Assim como hoje não faz mais sentido você ser um programador muito um especialista em tudo, não faz sentido você ser um automatizador muito Você pode desenvolver outras habilidades que vai fazer você ganhar muito mais dinheiro do que necessariamente a automação. E é sobre isso que nós vamos falar aqui nesse vídeo. No final das contas, a gente vai falar sobre como você vai fazer mais dinheiro, tá? Passando aqui de novo para perguntar se você já comprou, já garantiu essa vaga do meu workshop. Não. Clica aqui, ó. Tá no link na descrição desse vídeo. Bora, vamos empreender com >> primeiro passo. É muito fácil as pessoas saberem criar fluxos de automação, mas saber o que automatizar e o que priorizar primeiro para ser automatizado, isso é difícil. E para que você saiba o que é automatizar e o que que pode ser automatizado, o ideal é você entender mais de negócio, entender como uma empresa funciona, empreender, por exemplo, de não não de forma profunda, mas de forma detalhada sobre como funciona um processo de vendas, como funciona, por exemplo, um processo de entrega eh de nichos específicos, como funciona um processo de pós-vendas, um processo financeiro, como que funciona um processo de captação de lead, um processo de marketing. Se você tiver uma visão de dessas áreas, de um determinado nicho, você vai ser uma pessoa extremamente requisitada no mercado. Se você então entender do negócio e também entender da automação, da programação, da lógica, da lógica de programação, da lógica de desenvolvimento de software e da lógica de negócio, você se torna uma pessoa altamente requisitada. E isso sim vai fazer você ganhar muito dinheiro. Porque, por exemplo, o cara que vou vou dar um um pequeno exemplo aqui. Eu peguei um cliente, o cliente ele é um expert, esse cliente ele vende um produto digital e a gente fez um trabalho nele de recuperação de carrinho. Que que é recuperação de carrinho? Entrava para ele 1000 leads por mês. Dos 1000 leads, ele fazia 5% de vendas daqueles leads. 95% ele não vendia. Então o que que nós construímos? Sim, com automação, com chatbot, com um monte de coisinha, com ferramenta, com CRM, por aí vai. Nós construímos para ele uma máquina de recuperação de carrinhos. O que que é uma máquina de recuperação de carrinhos? É um CRM fazendo a gestão dos possíveis leads. É um fluxo de importação dos leads de um de algum determinado lugar para dentro dessa ferramenta, desse CRM. é um processo onde a gente começa a nutrir estes leads em um determinado momento do tempo com uma determinada narrativa, com uma determinada oferta e aí no final é o pit, a entrada em contato via ligação ou a oferta. É a oferta, chamar ele e falar: \"E aí quer comprar?\" E depois a conversão. Nessa brincadeira, nessa brincadeira de 1000 leads, a gente conseguiu trazer para ele mais 5% de conversão. Sabe o que significa isso? A gente dobrou o faturamento dele. E aí você pode pensar assim: \"Nossa, Kelvin, mas cara, como assim? Ele vendia só 5%.\" É, é assim que funciona. As pessoas elas ganham dinheiro, mas elas também deixam muito dinheiro na mesa. Elas perdem, elas elas não estão preocupadas em pegar esses dinheiros mais difíceis, né? Elas estão preocupadas em pegar os dinheiros mais fáceis, né? Todo mundo foca ali geralmente nas frutas baixas. Então, às vezes, até mesmo às vezes não, a maioria das da das empresas tem processos que são extremamente ineficientes. E esses processos eles se tornam cada vez mais ineficientes, até mesmo por conta das pessoas que estão lá e por conta do processo operacional que as próprias empresas implementam. Então, é muito difícil você encontrar uma empresa que para fazer uma revisão completa em seus processos. Então, a ineficiência é uma ineficiência que tá lá desde antes até daquele profissional ter entrado, ter sido contratado, tudo mais e ninguém trata, às vezes ninguém nem sabe o motivo. Então, por isso que eu digo em vários meus vídeos que é muito importante pr, no caso, as pessoas que querem empreender, entender muito bem o nicho de atuação, escolher um nicho de atuação, porque a partir do momento que você entende o nicho de atuação, você foca em o nicho, você começa a entender as dores que aquele nicho tem, que as empresas daquele nicho t e aí você meio que fala a língua daquelas empresas e você consegue captar mais clientes. Mas voltando ao ponto aqui das automações, cara, faz muito mais sentido vocês gastarem energia estudando, vai coloca ali 20% do tempo de vocês estudando a parte técnica e 80% estudando a parte de negócio do que vocês focarem em 100% da energia de vocês aprendendo a parte técnica. Tô passando aqui de novo para perguntar se você já garantiu a sua vaga do workshop grow que vai acontecer no dia 4/10. Não clica no link aqui na descrição desse vídeo, vai ser online, não perca. É mais barato que uma pizza, Estudando N8N, estudando make, estudando ser o melhor automatizador do mundo, ser o melhor construtor de agentes via N8N do mundo, construir os melhores chatbots e sabe, não faz sentido. Faz muito mais sentido você focar energia em 20% na parte técnica e 80% na parte de negócio, porque a parte de negócio é a parte que vai fazer você fechar bons contratos. A parte de negócio é realmente a parte que vai fazer você ganhar dinheiro, que você vai sair do zero. Então esse é meu conselho para vocês. É um vídeo rápido, é uma opinião minha que eu decidi trazer aqui para vocês para poder ajudar vocês, porque o ano de 2025 já acabou, né? Valeu, rapaziada. Tchau.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apesar da relevância da automação, em 2026 não se deve focar apenas em ser automatizador; é essencial combinar negócios, IA e automação com outras habilidades para obter resultados maiores em um mercado saturado.",
            "resumo": "Neste vídeo, Kelvin Cleto afirma que, apesar da relevância da automação, não se deve focar 100% em ser automatizador em 2026. Ele traz experiência em tecnologia e empreendedorismo com IA, dizendo que a IA evolui rápido e grandes empresas poderão criar automações via linguagem natural, tornando quem escreve bons prompts essencial. A barreira tecnológica cai e o mercado de automatizadores low-code fica saturado, o que ele chama de Mar Vermelho; logo, não basta depender só da automação. O B2B vende resultados, não automação em si, então convém desenvolver outras habilidades que gerem valor maior. O vídeo mostra como combinar conhecimento de negócios com automação para melhorar processos, citando um exemplo de recuperação de carrinhos que dobrou faturamento. Entende-se a importância de entender vendas, entrega, pós-venda, financeiro e marketing. Há convite para workshop online no dia 4/10, com vagas limitadas.",
            "assunto_principal": "Não depender exclusivamente da automação em 2026; desenvolver habilidades complementares e compreender processos de negócios para maximizar ganhos.",
            "palavras_chave": [
              "automação",
              "IA",
              "instruções de prompt",
              "low-code",
              "negócios",
              "B2B",
              "recuperação de carrinho",
              "eficiência de processos",
              "Mar Vermelho",
              "competências complementares",
              "empreendedorismo com IA"
            ],
            "resumo_em_topicos": "- Contexto e posicionamento do apresentador\n- Evolução da IA e implicações para automação\n- Saturação do mercado de automatizadores e o conceito de Mar Vermelho\n- Por que não basta automatizar: foco em resultados para B2B\n- Habilidades recomendadas: entender negócio, lógica de automação, combinar com outras áreas\n- Exemplo prático: recuperação de carrinho que dobrou faturamento\n- Recomendações para entender processos: vendas, entrega, pós-venda, financeiro, marketing\n- Convite para workshop online no dia 4/10 com vagas limitadas",
            "prompt_tokens": 1975,
            "completion_tokens": 4037,
            "model": "gpt-5-nano",
            "cost": 0.007
          },
          "analysis_time": 43.62551784515381,
          "language": "",
          "view_count": 3426,
          "has_transcript": false
        },
        {
          "id": "V7UyaYpKyUg",
          "title": "Como construir e vender infraestruturas de IA (guia completo)",
          "title_pt": "Como construir e vender infraestruturas de IA (guia completo)",
          "url": "https://www.youtube.com/watch?v=V7UyaYpKyUg",
          "published": "2025-09-18T00:46:38.542627",
          "published_relative": "há 3 dias",
          "duration": "44:26",
          "date_published": "2025-09-16T17:49:32-07:00",
          "transcript_available": true,
          "transcript": "Nesse vídeo aqui eu vou te ensinar a como construir, embalar e vender uma infraestrutura de inteligência artificial, uma infraestrutura de crescimento com IA. Não é um vídeo técnico, a gente não vai falar sobre N8N, make, creiem, nada dessas porcarias, não tem nada a ver com técnico. Para você que gosta de coisa técnica, pode ir embora. Agora você quer ganhar dinheiro com IA, esse vídeo é para você. Para você que não me conhece, muito prazer. Meu nome é Kelvin. Eu sou um programador empreendedor serial. Montei a General Cleans em 2015, uma das principais insurtecs do Brasil. Vendi 50.1% dela pro grupo IS, uma empresa de capital aberto 2022 e o restante eu vendi agora em 2025. Logo na minha saída, no meu exit, já montei a acelera 360, que hoje é uma edtec. Basicamente eu ajudo pessoas como você a empreender com inteligência artificial. Eu dou um modelo de negócio, toda a estrutura e auxilio até que você possa emitir as suas primeiras notas fiscais com IA no mercado em até 90 dias. Se você quiser saber mais da Acelera 360, você vai clicar no link aqui na descrição desse vídeo. Aviso, se você não é um cara técnico, não tem problema, esse vídeo é para você. Se você é técnico, não tem problema, esse vídeo também é para você. Porque eu acho que tanto você que não é técnico, quanto você que é técnico, quer ganhar dinheiro e quer surfar essa big dessa oportunidade que a gente tem quando a gente tá falando de inteligência. artificial vertical e principalmente sobre infraestruturas de crescimento com o IA. O mercado tá propício, os caras estão rasgando dinheiro, velho. Agora é a hora da gente, ó, pegar o máximo possível. Não rasga não, gasta comigo, porque eu dou ROI. Beleza? Então, vamos lá. Vamos começar. Vamos começar entendendo qual que é o ciclo de um negócio. Qualquer negócio sempre começa pela oferta. Então vamos ofertar aquele produto. No caso, por exemplo, da de uma corretora, ela precisa oferecer para o mundo que ela tem vende seguro, que ela faz vendas de seguro. Por exemplo, no caso de uma lanchonete, ela fala pro mundo que ela vende lanches, que ela faz comida e por aí vai. Então, todo negócio precisa ter uma oferta. E depois da oferta, as pessoas precisam ouvir aquela oferta. ou eu tenho lanche. Geralmente a gente faz isso com marketing. Marketing no caso, boca a boca. Opa, tô ten o melhor lanche do Brasil. Eu tenho a corretora que venda de vende seguro mais rápido do Brasil. Acelera é a melhor de do Brasil. E eu realmente ajudo as pessoas a empreender, a tirar suas ideias do papel. Eu tenho a melhor desenvolvimento de software do Brasil e por aí vai. Então, marketing. E o marketing pode ser boca a boca, pode ser pagando, usando tráfego pago, usando mídia paga. Então vou colocar mídia paga em geral, né, nesse caso, ou cara prospecção, que é você falando o mundo, panfletagem, que seja, são formas de das pessoas saberem que você existe. E a partir do momento que elas sabem que você existe, você vende, você executa a venda e depois que você vende, então aqui você coloca o dinheiro no bolso. Depois que uma empresa vende, ela tem que entregar o produto. Então, produtos que t o onboarding, então existem serviços principalmente que tem o onboard, que é o cliente, ele entra para dentro, então é uma venda longa, uma entrega longa, na verdade você vai entrar aqui na escola, vai acontecer isso, isso e isso, o meu processo de trabalho vai ser assim com você, tem toda a explicação, os boasvindas, seja bem-vindo à nossa escola, seja bem-vinda à nossa empresa, seja bem-vinda a esse produto, saca? Isso é um onboard. Às vezes a gente acha que onboard é só para empresa de serviço, né? Não, eu vou explicar para vocês. Eu comprei um carro esses tempos, aí eu fui pegar o carro, cara, teve todo um processo de entrega daquele carro, umbarding da empresa. Cara, a empresa é assim, assim, assada, você pode contar com a gente com isso, com isso, com isso, com isso, com isso. A gente vai entregar o seu carro assim, assim, assim, assado. Isso é um boarding. Aí depois teve o delivery, uma [ __ ] de uma entrega, fumaça, foguinho, eh, eh, eh, laço em cima e o [ __ ] delivery, entrega, entrega do produto ou do serviço. Então, olha que legal, a entrega, o onboarding, ele pode existir para qualquer negócio. Delivery, mesma coisa. Isso aqui escala valor para [ __ ] tá? E depois da entrega, feedback e otimização. Empresa pediu feedback para aquele cliente, para aquela que consumiu aquele produto ou aquele serviço e entender o que que ele acertou, o que que ele errou. Aqui a gente entra, por exemplo, com a pesquisa de NPS para saber, aí você gostou, não gostou, como que foi o nosso atendimento? dito aqui de um a cinco, nos avalie o que que foi bom, o que que foi ruim. Por quê? Porque a partir desse feedback você consegue otimizar a sua oferta. Foi bom por quê? Foi ruim por quê? Melhora a oferta, melhora marketing, melhora as vendas. E aí qualquer empresa desse jeito, qualquer empresa desse jeito. E aí para cada área de uma empresa, você pode criar um sistema, uma plataforma, uma solução. E aqui você pode perguntar aqui, ó, por que que umas estão verdes e outras estão vermelhas? Porque as que estão verdes é quando você são áreas, segmentos, né, que você cria uma solução e aquela solução pode te dar muito dinheiro e quando tá em vermelho é bucha, não compensa. Então vou dar um exemplo para vocês. Comentei no começo do vídeo sobre a General Clans. General Cleans, uma das principais insurtec do Brasil. Deixa eu abrir aqui. Gcle combr. Então o que que a GCINS faz? Cleans, general cleans, ela leva a tecnologia pro mercado de seguros, um ecossistema digital de seguros que atende a parte de sinistro. E o que, que que é o sinistro? O sinistro é quando dá o BO, você vende comprou um seguro, seu seguro de sua casa, aí você foi lá e bateu, ou melhor, sua casa pegou fogo, você acionou a seguradora. Isso é um sinistro. Olha onde eu posicionei o meu sistema para regulação de sinistro. Regulação de sinistro. Você acha que a seguradora tá preocupada em regular o sinistro? Tá nada. Seguradora tá preocupada em vender. Toda empresa ela injeta mais dinheiro sempre aonde? Oferta, marketing e vendas, entendeu? E feedback também, porque feedback gera mais venda. E aonde que ela injeta menos dinheiro? No delivery, na entrega do produto. Aonde que eu posicionei a General Cleans? No delivery. Na entrega. é o momento que você asiona o seguro, ali é o momento da dor de cabeça. Então, as empresas elas não têm costume de olhar pro delivery, então elas colocam menos dinheiro aqui. Então, se você quer criar uma solução, o que eu indico, crie sempre soluções focadas em oferta, marketing vendas. Por isso que eu ensino vocês a criar uma infraestrutura de crescimento com IA. E agora eu vou explicar para vocês o que é uma infra de crescimento com IA. Vamos lá. Uma infraestrutura de crescimento com IA é uma infraestrutura, são sistemas, por isso que o nome é infraestrutura, porque não é uma coisa só. Então é inteligência artificial mais ferramenta mais processo. Todos eles alinhados em trazer resultados. resultado resultado ou resultados extraordinários para os clientes que consomem esse produto. Simples assim. Isso aqui é uma infraestrutura de crescimento com IA. E por que que ela é de crescimento? porque ela é voltada pro gr, pro crescimento do negócio. Então, quando eu tô falando de infrestrutura de crescimento, eu tô falando numa infra que usa IA, mais ferramenta, mais processo para fazer as empresas venderem mais, entendeu? É uma solução que ela atende este quadrante aqui. Kelvin, poderia atender o delivery, poderia atender o onboard, poderia, vale a pena? Não, para este momento que nós estamos vivendo com inteligência artificial e para que você tenha sucesso empreendendo com infraestruturas de crescimento em faz sentido vocês focarem energia em ferramentas que gera dinheiro pro seu cliente. Porque qual que é o jeito mais rápido de você ganhar dinheiro? fazendo o seu cliente ganhar dinheiro. E aqui então, como eu já adiantei logo no início, eu vou focar no nicho de corretoras de seguros que vendem, por exemplo, seguro automóvel de de carro, seguro de carro. Então, esse aqui é meu nicho escolhido. Então, como seria uma infraestrutura de crescimento com IA? A gente vai chegar lá no final do vídeo, mas já no começo você tem, já entende que é uma infraestrutura, é uma ferramenta, é um conjunto de ferramentas, inteligências artificiais, processos que são especificamente travados para geração de oferta, marketing e vendas para corretoras de seguro. Resumindo, com a minha solução, as corretoras vendem mais, elas ganham mais dinheiro, entendeu? Então, olha, olha que loucura aqui já logo no começo você já entende o valor de uma ferramenta dessa. Então, corretora, corretora um não tem a infraestrutura de A, corretora dois tem a infraestrutura de A. Corretora um faz 100.000 por mês. 15 milhão por ano, 1.200 por ano. KK ano. Corretora dois com o mesmo cenário tradicional fazendo 100.000 por mês. Mas aí ela implementa a infraestrutura de crescimento. Que que ela que que acontece? Resultados extraordinários. Então a gente tem que dobrar o resultado dela aqui, por exemplo. Ela vai começar a fazer 200.000 por mês, ela vai pular para 2.hões400 por ano com quase o mesmo time, praticamente com o mesmo time, porém com uma infraestrutura que permita um negócio tradicional escalar. Entenderam? Balizei vocês? Creio que sim. Então, vamos começar. Tá gravando? tá gravando. Então, a partir do agora que vocês entenderam um pouco sobre esse conceito que ele é muito importante, já que a gente tá falando de business, por que que eu comecei por aqui? Você quer empreender. Não faz sentido você jogar energia aqui. Demora muito tempo, [ __ ] Isso aqui, isso aqui, cara, focar aqui, ó, focar nessa área, sabe? É você remar o seu barquinho contra a maré. Não, vamos, vamos a favor da maré e a e vendas, entendeu? Legal, Kelvin, eu entendi. Você falou para mim que vai falar do nicho de mercado seguros, beleza? Corretoras, mas eu quero já entender como que eu escolho meu nicho. Calma, gafanhoto. Aí a gente vai passar por tudo isso. Eu vou trazer o nicho de exemplo, mas porque eu já escolhi, né, para acelerar esse vídeo, mas eu vou explicar para você. Etapa um, como você escolhe o nicho. Etapa dois, você vai entender os gaps do setor que você escolheu. Para você chegar na etapa três, você vai construir uma tese, vai envelopar e vender. Então, esse vídeo é um guia completo. Nós vamos passar por tudo para que você realmente consiga fazer isso. Então, vamos lá. Como que a gente escolhe um nicho? Tem bilhões de nichos, mas eu vou explicar um critério muito simples aqui. São cinco filtros de nicho ideal. Olha o que eu coloquei aqui logo no começo. Se não passar por algum desses critérios, não perca seu tempo, nem gaste energia tentando e atender um nicho que não passa por algum desses critérios aqui, porque você vai gastar muita energia e vai não vai ganhar dinheiro no final das contas. Então o nicho ele precisa ter uma dor urgente e visível. Então, é um problema que tá doendo agora, é um problema que o dono já sente no bolso ou no tempo dele. É muito importante você entender isso. O seu nicho tem que ter uma dor urgente, tem que ser um mercado que tá ativo, um mercado que tá crescendo, entendeu? Já tentaram e aí o o cliente já tentou resolver isso? Tem ferramenta, ele já tentou contratar ferramenta, agência ou funcionário para isso? Então assim, é um mercado que já tá tentando gastar dinheiro para resolver esse problema, porque se sim, é ótimo. É sinal que o mercado tá sofrendo realmente com aquela dor. Ele vai investir dinheiro. O seu cliente daquele nicho tem poder de compra real para pagar pela solução? orçamento. Olha só, curioso. Eu vou dar um exemplo para vocês. Ontem eu tava conversando com o aluno da Acelera e ele é um tatuador e aí ele falou assim para mim, falou: \"Cara, eu quero sair do do do mercado de tatuagem\". Aí eu falei: \"Pô, você tem prêmio na nesse mundo, cara, por que que você não investe nesse mercado?\" Aí ele me falou assim, falou: \"Kelvve, o pessoal que é tatuador, ele tatua por hobby porque gosta e ele tem um uma vida muito freestyle, muito solta. Então assim, o cara que ganha para viver, ele ganha de dia para comer de noite ou para tomar uma cerveja ou para ir no final de semana, ele não investe. Então, montar uma infraestrutura para eh lojas de tatuagem, eu não sei se é loja que fala, não vale a pena, porque o dono da loja tá pouco se [ __ ] para isso, entendeu? Então assim, se o seu nicho não tem poder de compra real, se é um cara que não tá ali pronto para colocar R$ 20, 30, R$ 40.000 numa ferramenta que vai resolver o problema dele e pagar mais R$ 2, R$ 3.000 por mês, não gasta energia com isso, entendeu? Eh, timing e prestas de oferta, tem espaço para entrar agora com algo muito diferente, você pode ser disruptivo aqui é o melhor cenário. Por quê? Por conta da IA. Mercado inteiro, você tá no tá no time da inteligência artificial. Alguns mercados você vai sofrer muito, por exemplo, colocar IA numa seguradora, não na corretora. Mercados seguros, mas apontando pra seguradora. Cara, seguradora é muito complexo, banco muito complexa, os caras são quadrados, são chatos, tem um time de T gigantesco lá dentro que não aceita você, experiência própria. Minha empresa era totalmente disruptiva, a a General Clans, o quanto eu sofri para entrar em seguradoras, foi um sofrimento, anos trabalhando para entrar, entendeu? Então assim, cara, esses mercado quadradão tradicional, deixa esses caras se [ __ ] foca em quem quer crescer de verdade. Empresa que tem muito grande, empresa muito grande, cara, os cara deixa eles quebrar a cabeça lá, entendeu? Eles gostam de gastar dinheiro com SAP, com totos. Não foca, não foca no grandão, foca no pequeno para médio. Dá para você ganhar muito dinheiro, crescer muito fazendo isso, tá? E validação rápida. Você tem que validar mercado rápido, testar o nicho em 7 dias, soltar a oferta, subiu o anúncio, clicou, viu realmente que aquela é uma dor realmente necessária. Então, por exemplo, montei aqui a tese rápida do mercado seguro, certo? Corretoras, monta a campanha, subo a campanha, corretora clicou, validou, opa, houve interesse. Realmente, realmente, corretoras quer investir em inteligência artificial. Tô com uma oferta super forte, a minha promessa é maravilhosa, entendeu? É assim que funciona, é assim que você valida. Não sai desenvolvendo, criando, criando um monstro antes. Não, não faça isso. Isso aí é para louco. Isso aí é para deve. Desenvolvedor que gosta de fazer isso. Desenvolvedor gosta de desenvolver tudo para ter tudo pronto para depois lançar. Aí quando lança ninguém quer, entenderam? Esse é o maior erro que você pode cometer como empresário, entendeu? Então vamos pegar aqui, ó. Nicho corretoras de seguros de automóvel. automóvel, ó, subnichado, corretoras de seguro para automóvel. Para você que não conhece o mercado de seguros, tem corretora de seguro para automóvel, para casa, para eh para máquinas e equipamentos, para trator, para caminhão, para para tudo, para tudo, para vida, para cargos de trabalho, cara, tem seguro para tudo no Brasil, para bike, tem seguro até para garrafa d'água. Então assim, cada ramo desse aqui você é um nicho. Então eu posso, por exemplo, ser o cara especializado em seguro de automóvel, enquanto tem um outro cara que ele é especializado em outros ramos, ramos elementares e por aí vai. Isso é, isso é legal falar porque é o seguinte, a General Clans, olha, olha que interessante, tá aqui no site, ó, ã, ecossistema digital de seguros. Pá, customização de solução. Tá, tá, tá. Deixa eu ver onde que tá aqui. Documentos, informações, aplicativo, fluxo de trabalho na nuvem. Ah, tiraram, mas ela era para ramos elementares. Então assim, eu atuava para não atuava para automóvel. Por quê? Porque automóvel é muito concorrido. Atuava para outros ramos que não tinha ninguém olhando, entendeu? Então é muito importante você nichar, vai facilitar muito o teu processo. Mesma coisa aqui, ó. Vamos fazer corretora de seguros para automóvel, tipos negócios locais, podendo de escalar online. Mercado Brasil, a nível Brasil, subnicho, corretoras focadas em veículos de alto valor, ó, subnichendo aqui, ó, ou frotas empresariais. Cara, tesão isso aqui, hein? Isso aqui é tesão. E aqui alto valor, eu tô falando de não é muito alto valor, não, tá? Carros acima de 100.000 hoje em dia é padrão. Hoje em dia aí um HB20 tá sem pau. Qual que é o tamanho desse mercado? Primeira coisa, tem gente para vender? Tem, [ __ ] Olha aqui, ó. Primeira coisa, pesquisinha. Vamos ver o tamanho do mercado. De acordo com a SUSEP, órgão regulador, você tem mais de 62.000 empresas corretoras de seguro registrado, fora mais 80.000 corretores no particular. Vamos vender particular? Não, vamos vender para quem tem empresa, para as corretoras em si. Então, esquece esse número de baixo. Vamos olhar o número de cima. 62.000. Kelvin, poderia vender para de baixo? Poderia. Não vale a pena muito não. Eles não vão pagar o ticket que a gente quer. É um mercado que cresce. [ __ ] eu não vou não vou entrar num mercado que tá em recessão, né? Faz sentido? A mesma coisa que eu entrar no mercado, por exemplo, de paleta mexicana. Faz sentido? [ __ ] claro que não. Quebrado. Então, vamos lá. Crescimento setor anual do setor. Deixa eu entender. Google. Setor de seguros cresce mais de 12% 2024. Setor de seguros cresce mais de 10% 2025. setor que tá crescendo, setor que tem perspectiva, só no primeiro trimestre já cresceu 6%. Putz, lindo. Baita indicador importante. Setor que cresce, setor que tá sendo movimentado. Qual que é o ticket médio desse mercado? Quanto que custa um seguro? Cara, meu seguro aqui tá bem baixinho, hein? Porque, por exemplo, seguro de alto padrão é mais de 8000. Aqui já começa, vai, coloca de 8500, vou até subir aqui, de 8500 a 15 pau, por exemplo, seguro. Carro de alto padrão de frota. Então, hum, tesão, lindo, hein? Mas não vou entrar nesses, não vou entrar nas especificidades para deixar mais simples para você. Por que que eu quero entender o ticket médio? Porque, lembra que eu falei para vocês que a gente vai focar em vendas, máquina de vendas? Cara, quando a gente tá focando em máquina de vendas, a gente tem que entender quanto que o cliente ganha. Por quê? Porque a nossa precificação de plataforma, e aí que entra um dos principais segredos, quando a gente tá falando de infraestrutura de crescimento com IA, a precificação, ela não é por hora trabalhada, por usuário, por fluxo, não. Você precifica sobre o valor agregado, o valor que você gera. Pô, se você gera mais 15% em vendas pro cara, mais 10% em vendas, mais x% a mais, você tem que precificar isso de um jeito diferente. Você pode precificar isso num valor tabelado seu. Você define o valor, por exemplo, ah, cobrar 40.000 mais de implantação, de instalação, mais 3% sobre o ganho operacional, 2%, já é um [ __ ] dinheiro, entendeu? Já mensalidades aqui já vai para 10.000, 12.000. Esse é o segredo. E o cliente paga feliz. Por que que o cliente paga feliz? Porque você está gerando retorno para ele. Corretor, ele tem um probleminha. Corretor, ele geralmente não quer vender um, ele não quer geralmente que cobrem sobre o percentual da comissão que ele ganha ou sobre o quanto você gera para ele. Mas aí você pode cobrar um fixo de R$ 4.000 por mês. Se a sua ferramenta der retorno, ele vai pagar feliz a vida. E para você, eu tenho certeza que já vai ser um [ __ ] de um golaço fazer isso. Deixa eu travar aqui. Por isso focando na venda, tá? Por isso focando na venda. Ã, vamos pegar aqui então comissão. Pegar comissão média, 20% de comissão. Se a gente tiver falando de um produto de 8 a 15.000, vamos pegar de média um um seguro de um carro médio ali que tá custando 9.000 1000 de comissão ponto do cara vai ganhar aqui 10000 nessa comissão desse desse seguro aqui, tá? 1800. Então o corretor por venda ele puxa mais R$800. Olha que legal. Olha que legal aqui. Entenderam? Então o fator médio de uma faturamento médio de uma corretorazinha dessa daqui, isso aqui é uma corretora pequena, 300 a 1.500 por ano da carteira, segura por carteira. Então, o cara que compra segura, é só se perguntar, você já trocou de corretora? A minha corretora eu tenho há uns 8 anos. Eu não troco, nem ligo para ela, nem sei quem é. Sei quando ela me manda mensagem, ó, tem que renovar, quando ela lembra. É um problema. O corretor esquece da gente. Corretora esquece. Isso é um problema, porque você vê como que para mim é indiferente a minha corretora. Tá aqui o por que a nossa infraestrutura de crescimento vai resolver o problema das corretoras, porque a gente vai tratar isso também. Então assim, entendi o mercado, cara, mercado maravilhoso, Kelvo, como que eu acho um nicho? Porque, por exemplo, você, K, conhece o nicho das corretoras. Eu não conheço. Tô conhecendo agora porque você tá me falando. Vou te explicar. Você vai aprender a fazer uma análise de gap do setor. Eu vou entrar aqui no passo dois, porque eu entendi, eu já conheço o mercado, escolhi ele e agora eu vou entender qual que é o gap das corretoras. Mas você pode subir essa essa etapa pro um. Então, por exemplo, vou pegar um nicho aleatório aqui. Clínicas, essas de implante capilar. Implante capilar. Você, será que a sua pergunta aqui é, será que implante capilar é bom? É bom, é um nicho bom? Você vai fazer essa análise que eu fiz e você já puxa na sequência para analisar o gap. Será que tem gap aqui para eu resolver? Porque eu vi que o mercado é grande, mas será que tem gap para eu resolver no setor? E aí você vai fazer a análise. E como que você analisa esse gap? Simples, Google, problemas das empresas de implante de cabelo no Brasil, no meu caso, problemas de corretoras de seguro. Ager é um multicálculo, né? Corretor. Multicálculo, para você que não conhece, é, tem um monte de seguradora. Seguradora, ela é como se fosse um fabricante. Ela faz o seguro e a corretora é quem vende, entendeu? Então, a seguradora, por exemplo, é como se fosse a Dell, fabricante de notebook, só que ela fabrica seguro. E a corretora como se fosse o Walmart, vende os notebook da Dell, entendeu? Aí aqui, ó, problemas com corretor de seguro. Você vai pegar a Ager, que vai fazer cálculo de seguro, Texculo, cinco erros que corretoras de seguro que impedem. vai estudar isso aqui, Fenacor, estuda, entra no Susp, Scor, vai, vai lendo, estudando, pesquisando, porque a partir daqui você vai começar a entender quais são as dores comuns. Outra dica, pesquisa de mercado com expert. Pega os principais corretores de seguro que gravam vídeo para YouTube para Deixa eu ver se tá gravando ainda. Tá gravando. Pega vídeo para YouTube, lê as descrições, vai estudando, pesquisa de mercado. Tem uma metodologia para fazer isso aqui também. eh entrevistas com corretores e eh corretoras e pesquisa, faz pesquisa de mercado, estuda isso daqui. E aí o que que você vai perceber? A dor. E aí você vai construir uma tese. O que que é uma tese? Vou explicar para vocês aqui. Logicamente eu trouxe a a minha experiência, né? Mercado hoje de seguro é um modelo rouba monte. Então o que que é rouba monte? Eu tenho a minha, tenho 10, 10, eu sou uma corretora e eu tenho 10 clientes. A outra corretora vem e rouba os meus clientes. Em vez de pegar novos clientes, eles vem e atacar os meus. Então ele vai roubando um monte. É assim que funciona esse mercado. Prospecção lenta, cara. Corretor é uma porcaria. Eles só é tudo por indicação. Eles vão atrás de loja de venda de carro para ir pegar cliente. Eles não sabem fazer prospecção ativa, entendeu? Vocês não sabem usar internet para isso. São quadrado, velho. Se você é corretor, tá me assistindo, você sabe disso. Base histórica de vedas mal aproveitada. Eu não conheço uma corretora que aproveita uma base histórica. Que que é base histórica? O cara vendeu na história da corretora. O cara se orgulha. Tenho 20 anos de corretora de seguro. Tem uma, já vendeu o seguro para mais de 10.000 pessoas. Aí a base ativa dele é 50. Ele não consegue reaproveitar isso aqui. Ele não consegue trabalhar essa base. Problemaço. Olha quanto de dinheiro. Imagina assim, ó. Chegou, chegou o cliente para você aí, ó. Bateu na sua porta, tá? Tá simular, ó. Oi, eu sou uma corretora. Legal. Seja bem-vindo. Eu vi que você vende infraestrutura de quero entender mais. Legal. Aí a primeira pergunta que eu faço é: quanto que você fatura? Fatura 300.000 por mês. Quantos clientes você tem na sua base ativa? 50. Você já vendeu para quantos? 3.000. Se eu preciso dar resultado rápido para esse cara, onde que eu vou mexer? Olha para mim, entendeu? Eu não tô falando de solução aqui. Eu não tô falando de de de programação, de técnico, eu tô falando de solução. Se o cara tá te contratando para você resolver o problema para ele, você vai vender para ele um CRM, uma automação de A, um chatbot, ou você vai vender o seguinte: eu vou retrabalhar. Eu tenho uma ferramenta que vai retrabalhar a sua base e vai fazer a sua base aumentar de 50 para 100. Entendeu? Isso é uma infraestrutura de crescimento com IA. É você usar inteligência artificial para reaproveitar, por exemplo, retrabalhar uma base de 10.000 pessoas. Entenderam? Por quê? Imagina o seguinte, deixa eu abrir aqui para vocês, ó. Presta bem atenção nisso aqui antes da gente construir tese. Se é uma corretora que tem dois vendedores, você concorda que eles não têm capacidade humana para trabalhar numa base de 10.000 pessoas? Ou que seja uma corretora maior? Tem lá 15 corretores. 15 corretores. Ó, vou fazer uma conta aqui, ó. 10.000. 10.000 1000 dividido eh por 15 corretores são 66 leads por corretor e eu vou dividir uma média de ele consegue entrar em contato com 15 leads por dia. São 10 são 66 dias, ou melhor, 10 leads por dia. São 66 dias cada corretor atuando. Então, colocar aqui 22 dias úteis no mês, 3 meses para 15 corretores trabalhar uma base de 10.000 pessoas. Eu com IA mais processo mais ferramenta, faço isso aqui em 10 dias bem trabalhados, sem afogar, sem afogar sistema, sem fazer nada, de boa, assim, assim, fluindo. Kelvin, eu consigo fazer em um. Parabéns para você. Eu não faço um, eu faço 10, 10 dias, entendeu? Desses 10.000, se essa minha máquina em 10 dias recuperar 1% 01, perdão, 01. Eu recuperei 100 novas vendas. 100 novas vendas. Sem novas vendas, a um ticket de 100. Opa. Vezes 100 mais 180.000 no bolso do meu cliente corretor. Que que eu tô fazendo aqui? Meu cliente ganhar dinheiro. Conseguiram entender? Isso aqui só é com uma estratégia, com uma ferramenta de uma infraestrutura de a. E vocês lembram que eu falei aqui de uma infraestrutura de crescimento? Cadê? Não é só isso. Uma infraestrutura de crescimento é inteligência, mas processo, mas um monte de outras coisas para trazer esse resultado. Kelvin, isso dá muito trabalho. Realmente no outro vídeo que eu fiz, eu mostrei sobre o varejo. Mesma coisa, mesmo processo que eu tô fazendo aqui agora. muito parecido, na verdade. E aí o Víor, por exemplo, comentou o seguinte: \"Na moral, se tivesse dando dinheiro mesmo, o Kelvin estaria vendendo eh isso e não curso. É que, Vittor, só para te responder, tá? Acelera não é o curso, Acelera é uma empresa também, é uma editec, é uma outra empresa. Eu tenho soluções de plataformas de IA também. E um dos meus processos dentro da minha editeceração para empreendedores. Então, Víor, inclusive, se você quiser tirar sua ideia do papel, se você quiser aprender, deixar de ser programador e quiser empreender, acelera para você. Você vai clicar no link aqui na descrição desse vídeo. Então, eu faço isso, tá? Inclusive, eu faço tanto isso, ó, que eu trouxe até alguns prints aqui da minha ferramenta da Grow AI. Então, que é ferramenta, fluxo, ó aqui, fluxo de N8N, gente. Ó, o fluxo de N8N também tenho. Eu tenho agente N8N, eu tenho agente usando Google ADK, eu tenho a gente usando Langchain, tem todo um conjunto de ferramentas focadas em trazer resultado para meus clientes. E eu vou apresentar isso no dia 4/10. No dia 4/10 eu vou fazer um workshop que vai acontecer online. Vai ser um workshop online. Então você pode participar, gente. Custa R$ 67. possível você não ter dinheiro para participar do meu workshop, né? Então eu vou fazer um workshop online, onde eu vou mostrar para você como que você pode escalar com inteligência artificial os seus serviços e gerar aí resultados acima de R$ 100.000 por mês, tá? Então o que que a gente vai passar lá nesse workshop? O que que você vai aprender? como identificar gaps de alto valor no mercado, igual eu tô mostrando aqui nesse vídeo para vocês, só que com par e passo, ferramentas para te suportar e te ajudar, para você analisar qualquer nicho, como você constrói sistemas que vendem sozinho. Então, como você transforma esses gaps em sistemas que saem, que fazem a venda, que a venda acontece de forma autônoma praticamente, e como se tornar insubstituível no teu mercado. Então isso aqui é para quem é técnico, é. É para quem é não técnico? É, também. É para quem quer empreender. É você que tem agência, gestor de tráfego, desenvolvedor, consultor, quer entrar no mundo da inteligência artificial, vem comigo para esse workshop aqui da Grow AI, porque eu vou mostrar como você pode fazer e principalmente eu vou apresentar a minha, você vai ver a minha máquina de growth rodando e você pode simplesmente replicar isso. Então assim, Víor, dá para ganhar muita grana com isso. Só que aí ele comentou o seguinte ainda, ó. Essa estrutura é linda. Claro que é. E realmente é o futuro do mercado. Lógico, todo mundo sabe disso. Quem não sabe ainda tá sabendo agora. Mas deixar isso rodando ainda mais em uma média, em uma média empresa vai muito, mas muito trabalho. No mínimo um ano para aplicar. Não vai. Eu mostro para você. Eu te provo que em 30 dias você consegue fazer isso, você consegue botar para rodar e você consegue ganhar dinheiro com esse negócio. Tanto que na Acelera nós fazemos isso. Então assim, Víor, você tá completamente equivocado. Inclusive, olha o cálculo que ele fez aqui. Falou: \"1000 ligações de 15 minutos na sai no mínimo $.500. Ó, primeiro que a gente não fica 15 minutos no telefone. Vamos entrar aqui na 11 Labs. Vamos entrar aqui em price 11 Labs. Para você que não conhece, é uma forma de você colocar uma IA para fazer ligação pro telefone, tá? Então vamos pegar aqui, ó, o preço do minuto. Cadê? P p pá. Vamos pegar minutos adicionais. Vmore. Aqui, ó, 20 minutos. Aqui, ó, minutos adicionais, ó, no creator, 015 cent. Então, 1000 minutos de ligação. Vamos pegar essa base aqui, ó. Vamos aplicar, ó. 10.000. Vou fazer 10.000 ligações. 10.000 ligações. Eu vou considerar que todo mundo me atendeu e que a IA ficou conversando com cada um 2 minutos. 2 minutos, cara. Uma I, conversar 2 minutos com a pessoa é muita coisa. Porque qual que é o segredo? Liga, ó, tô te mandando uma mensagem no WhatsApp agora. Olha aí no seu WhatsApp que eu vou te mandar a cotação. OK. OK. Beleza. Acabou. Desligou. 2 minutos. 20.000 minutos a 15 centavos a ligação. 15 cent 3.000. 3.000 a R$ 6 colocando imposto e tudo mais. R$ 18.000 de custo. Não é nada. Isso aqui não é nada. Vou te mostrar como isso aqui não é nada. Considerando que 10.000 pessoas atenderam e ficou 2 minutos ligando, deu R$ 18.000, né? Então vamos considerar que se 10.000 pessoas atenderam o telefone, a gente teve uma conversão superior a 1%. Uma média é de 5% de recuperação. Vamos considerar que a gente teve 5% de recuperação. Aqui a gente converteu 500. E aí aqui a gente vai trazer esse custo de 500 a um ticket de R800. R$ 900.000. Aí vamos colocar aqui, ó, que teve 18.000 de ligação. Daí teve também, vamos colocar de infraestrutura de servidor, mais 20.000 de infraestrutura de servidor aqui. Custo, né? Custo tem que ter custo. Se a gente quer ganhar dinheiro, tem que ter custo. Vamos colocar aqui mais 10.000 de mensagens no WhatsApp, disparas de mensagem no WhatsApp. Vamos colocar aqui mais, sei o custo da infraestrutura, mas R$ 8.000 R$ 1000 por mês que o cara pagou para fazer isso. Vamos somar tudo. Vamos somar aqui também, ó. Mais 50.000. Custou 50.000 para implantar esse sistema, tá? Vamos somar tudo, ó. 50.000 + 8.000 + 10.000 + 20.000 + 18.000 R$ 106.000. O cara investiu 106. Aí aqui tem que considerar outros cursos, por exemplo, pode ter custo de de vamos pegar aqui de cotador, mas vocês perceberam que tá bem elevado esses números, né? Investiu 106 para voltar 900. O cálculo é básico. O grande X da questão é que você quando tá fazendo uma infraestrutura de a, você tem que considerar isso aqui no teu cálculo. Você tem que ter noção do teu custo, porque o grande segredo é você dar ROI. Que que é ROY? Retorno sobre investimento. A questão não é o cara gastar, não é você falar pro empresário gastar 100.000. A questão é você falar 100.000, mas vai volotar 900. Ô fulano, seguinte, você colocar R$ 100.000 R$ 1.000 aqui e volta 900 do outro lado. [ __ ] que pariu. Um para é isso. Um para se eu colocar 10.000 volta 90. Entendeu? A conta é simples. A conta é muito simples. Então Vittor vale a pena. Agora se você quiser ficar no mundo de Nárnia ganhando R$ 1.000, R$ 2.000, R$ 3.000 ou não é mesmo? Tem um programador ganhando um salário aí de R$ 15, R$ 20.000, tá tudo bem também. Isso aí é uma opção sua por escolha, tá? Ou você faz igual os alunos da Acelera, bota fé nisso que eu tô falando e faz igual o Lucas Castro aqui, entendeu? Que ele tomou a decisão, entrou na acelera e talvez foi a melhor decisão dos últimos anos. Ele pode ser que 30% dela é técnica, 70% é construir prática e ele tá empreendendo, gerando negócio. Ou você faz aqui, por exemplo, igual o Alan que nos quanto tempo aqui que o Alan ficou, ó. Eh, sou Dev já há 7 anos. Acho que ele entrou, entrou na escola em pouco tempo usando as técnicas do Kelvin. Cinco clientes, duas parcerias, faturou os primeiros R$ 60.000. Pô, o Alan tá ganhando grana. Quem quiser conhecer mais ele, ó, Zel Hub, só entrar aqui. Ou o Vittor da Opus, da Opus Hub. Mesma coisa também. O Vittor e o Lucas estão ganhando grana lá. Quem que Quem que mandou mensagem aqui? Fez 16.500 em vendas. Outro outro aqui, ó. Eh, tipo, meu primeiro, na verdade, 12.000. Nunca tinha feito, não tinha ganhado isso em um job. Ó, tem tem garota do job que tá ganhando mais isso aqui. Entenderam? Vocês têm sempre esses dois caminhos, o caminho de ficar criticando ou o caminho de fazer acontecer. Vamos voltar pro vídeo aqui, gente. Vamos voltar aqui. Legal. Então, no na minha necessidade aqui, ó, vamos lá. dores que eu eh detectei no mercado. Mercado com modelo de rouba monte, prospecção lenta, base de cliente histórica mal aproveitado, sem cotações automáticas em lote. Problemas sérios na renovação, perdendo carteira. Problema de seguro geralmente é na renovação, cara. Esse cara perde muita, muita, muita carteira. E qual que é a proposta? O que que é a growth AI do mercado de seguros? Simples. Deixa eu segurar aqui para ficar mais fácil. Então vamos lá. Paraa prospecção lenta, qual que é a solução? Método antigo, ligação free, indicação rede social orgânica, sem processo definido, consequência, pipeline fraco. Então, qual que é a nossa solução? E adiven laps, fazer follow-up automático, leads, reativação de leads inativo, chatbot com IA, treinamento para realizar triagem interessados em encaminhar para cotação automática. Então, olha aqui. Aqui começou a se consolidar o conceito de infraestrutura de crescimento, CRM no centro, um processo, um funil de vendas. Então, funil de vendas aqui do digital, trazendo conceitos do digital. Vamos colocar aqui campanhas de tráfego pago. Campanhas de tráfego pago. Só que aqui tem que ter página, né? Então, vamos colocar aqui, ó, LP. LP de vendas. Que corretora que você que vem que tem LP de vendas? Não tem. Tem sites institucional tudo feio. Aí aqui a gente coloca o quê? Funil no CRM conectado aqui. Aí coloca aqui, ó, IA de atendimento. Tanto chatbot. Chatbot também para venda. Le entrou já chamar na hora. Chatbot de venda. Cotação via WhatsApp. Pronto. Ó, isso aqui é o quê? Infraestrutura de crescimento isso aqui o cara paga. O cara não tá comprando chatbot, o cara não tá comprando CRM, o cara não tá comprando em de atendimento, o cara não tá comprando agência de marketing com tráfego pago, o cara não tá comprando eh gestor de tráfego, ele está comprando uma infraestrutura de crescimento com IA que vai trazer retorno. Ele vai comprar o crescimento do negócio dele. A corretora vai comprar o crescimento do negócio dele, vai comprar uma máquina que o cara coloca lá, eh, que tá faturando 100.000 e começa a faturar 200.000. É isso que ele vai fazer. A corretora fica feliz, a seguradora fica feliz, o relacionamento dos dois aumenta. Maravilhoso, maravilhoso, maravilhoso. Beautiful. Aí você vem cobrindo o quê? Oferta. Oferta para venda de seguro. Marketing. Marketing para venda de seguro. Venda. O mecanismo de venda para venda de seguro. Esquece o onboard. Esquece o delivery. Isso aqui é BO. Feedback. E o onboard é até legal, cara. Você pode criar jornada de onboard para segura aqui também, porque eu me sinto, por exemplo, abandonada pela minha corretora. Então, começou a entender a tese, eh, cotação demorada e manual, cara, como que a gente resolve isso? E a con API para os cotadores e múltiplas seguradoras. Então, tipo assim, pega lá a PI da Tex, a PI da AG, a Ager, pega a PI de não sei do que lá, monta um MCP para isso, conecta isso numa IA para que ela faça cotação automática, chamando as APIs, automação que envia PDF. Ah, não tem não. O cotador não faz isso. Não conseguir API e faz a [ __ ] de um de um robô. Faz um robô a de automação que faça a cotação automática. Ou melhor calcula a média das cotações e envie um valor. Olha, segurado, de acordo com o que eu analisei, seu seguro vai ficar de tanto a tanto. Faz sentido para você conversar? Faz. Aí joga na mão de uma pessoa e a pessoa faz lá de forma manual. Ferramentas para você fazer isso. Usa o CRM. CRM na base, hein? Multicálculo, GPT, API, N8N, WhatsApp, Evolution API ou API oficial. Tem 300 casos para fazer isso aqui. Nossa, baixa o retorno de cliente por falta CRM, falta fluxo de reativo, falta lembrete de renovação, ch altíssimo, LTV baixo, eles não têm nada, não tem previsibilidade de receita. corretor é assim, cara, isso é [ __ ] É muita, muita oportunidade, gente. Workflow de ativação automática baseado na data da última renovação envio de proposta automática nos 30 dias anterior e antes do vencimento, depois vem cobrando 15 dias, 14 dias, 13 dias, 12 dias, ou melhor, já vem trabalhando isso muito antes, dando dicas para ele melhorar, lembrando dele. Cara, dá para fazer muita coisa aqui, cara. Muita coisa. Resumo. Deixa eu falar para vocês. Construir a tese, tá aqui. Agora é só fazer o quê? Envelopar isso daqui, criar uma oferta, uma promessa e botar para vender. Simples assim. E aí, Kev? Vendeu, como que entrega? Entra para acelerar aqui lá, eu te mostro. Fechou, rapaziada? É isso. Essa é uma oportunidade de ouro. Essa oportunidade da do nosso momento atual de infraestrutura com inteligência artificial. A, o momento da IA permite isso, o momento do mercado permite isso. Se você for esperto, você aproveita. Isso não é só para quem é técnico, isso é para quem quer ganhar dinheiro com empreendendo com inteligência artificial. Então, se você quer empreender com IA, se você quer trazer IA pro teu negócio, se você quer fazer o seu negócio crescer, quero você comigo no dia 4/10 no meu workshop, onde a gente vai falar sobre a Growth AI, beleza? Se você gostou do meu vídeo, já clica no joinha, já clica em me seguir aqui, já se inscreve no canal e vai lá no Instagram também e @euocvincleto e bora. Um abraço, tchau vocês, até mais. M.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Como construir, embalar e vender infraestruturas de IA de crescimento com foco em ROI, entregando valor rápido aos clientes sem se prender a detalhes técnicos.",
            "resumo": "Neste vídeo, Kelvin ensina a construir, embalar e vender infraestruturas de IA de crescimento, com foco em gerar receita para clientes sem conteúdo técnico. Ele descreve o ciclo de um negócio: oferta, marketing (boca a boca, mídia paga), venda, implantação e entrega, e feedback/otimização. Prioriza soluções que gerem dinheiro rapidamente, posicionando-as para áreas com maior retorno (verde) e evitando altos custos de entrega. Usa a General Cleans como exemplo, mostrando como direcionar tecnologia para regulação de sinistros, uma dor crítica para seguradoras e um caminho de ROI. A abordagem envolve um conjunto de sistemas, ferramentas e processos integrados — a infraestrutura de crescimento com IA — voltada a aumentar o crescimento dos clientes. Também menciona a Acelera 360 e a promessa de faturar com IA em até 90 dias.",
            "assunto_principal": "Construção e venda de infraestruturas de IA de crescimento para geração de receita, com foco em oferta, marketing, vendas, entrega e feedback.",
            "palavras_chave": [
              "infraestrutura de IA",
              "crescimento empresarial",
              "oferta",
              "marketing",
              "vendas",
              "entrega",
              "integração",
              "retroalimentação",
              "retorno sobre investimento",
              "segurtech",
              "limpezas gerais",
              "Acelera 360",
              "IA sem tecnicismo",
              "marketing de crescimento"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Proposta central: construir e vender infraestruturas de IA para crescimento\n- Ciclo de negócio: oferta, marketing (boca a boca, mídia paga), venda, entrega (onboarding e delivery) e feedback\n- Foco estratégico: soluções que gerem dinheiro para o cliente, com ROI rápido\n- Exemplo prático: General Cleans e regulação de sinistros em insurtechs\n- Componentes da infra: sistemas, ferramentas e processos integrados\n- Abordagem de ROI: priorizar áreas com maior retorno (verde) e otimizar o delivery\n- Chamada para ação: menção da Acelera 360 para iniciar faturamento com IA em até 90 dias",
            "prompt_tokens": 2030,
            "completion_tokens": 3480,
            "model": "gpt-5-nano",
            "cost": 0.0062
          },
          "analysis_time": 53.620814085006714,
          "language": "",
          "view_count": 3084,
          "has_transcript": false
        },
        {
          "id": "Ze2O5pfmdRo",
          "title": "Parei minha consultoria de R$600.000/mês para vender ISSO (vou te explicar)",
          "title_pt": "Parei minha consultoria de R$600.000/mês para vender ISSO (vou te explicar)",
          "url": "https://www.youtube.com/watch?v=Ze2O5pfmdRo",
          "published": "2025-09-15T00:46:38.542649",
          "published_relative": "há 6 dias",
          "duration": "14:47",
          "date_published": "2025-09-13T19:58:03-07:00",
          "transcript_available": true,
          "transcript": "Eu abandonei a minha empresa que fatura de R$ 400 a R$ 600.000 todos os meses para focar 100% em inteligência artificial. Eu vou mostrar aqui agora a conta bancária do meu negócio para você acreditar em mim e eu vou te explicar o motivo de eu ter feito isso para que você também entenda isso, absorva o máximo que você conseguir e também faça esse movimento, porque a gente tem uma janela de 18 meses para aproveitar o máximo possível e ganhar dinheiro para [ __ ] Ganhar dinheiro não, porque quem ganha dinheiro é criança ou mendigo, a gente fazer dinheiro com o IA, tá bom? Quarto vídeo. Sábado, 13 de setembro, às 19:4. Eu tô aqui com o aplicativo do meu banco aberto da empresa, né, o Itaú, onde a gente tem conta. E eu vou mostrar aqui para vocês um pouco, ó. Então, 21 de agosto, 56.000, 25.000, 3.000. Aqui são contratos que a gente tem de recorrência, 18.000, 80.000, 23.000, 112.000, 16.000, 5.000, 8.000. Ah, e por aí vai. É um monte, ó. Então assim, que que eu quero que vocês vejam com isso? O mesmo se repete em agosto, o mesmo se repete em julho. Você pode ver que são contratos que eu tenho de forma recorrente para a consultoria. O que que faz alguém largar isso daqui e focar 100% IA? Agora que você viu que é verdade, eu quero que você preste muito bem atenção no que eu vou te explicar aqui, porque do mesmo jeito que eu tô colocando a minha pele em risco aqui, ó, e mostrando para você a verdade, eu quero que você também aproveite esta oportunidade, que é a oportunidade de você empreender com inteligência artificial, montando um negócio de tecnologia voltado para IA ou colocando IA dentro do teu negócio mais rápido possível para que você ganhe realmente escala. Kelvin, mas eu não sou técnico. Esse vídeo é para mim é porque daqui para frente não tem mais essa. A barreira de desenvolvimento de software está cada vez menor. Ela a barreira de você criar um código está cada vez menor. Então assim, não se preocupe que você não saiba programar, não se preocupe que você não é um cara técnico. Se preocupe em começar a aprender os conceitos e fundamentos, porque isso é muito importante. principalmente se preocupe em desenvolver esta visão de futuro, porque isto é o que realmente vai fazer diferença no teu negócio. Então vamos lá. Deixa eu me apresentar para vocês que estão caído de para-quedas aqui no meu vídeo para vocês me conhecerem. Meu nome é Kelvin, eu sou um programador, ex-programador, porque eu faz tempo que eu não programo e empreendedor serial. Comecei em 2000 2015, eu montei a minha primeira empresa, General Clans. Eu tinha 22 anos. A General Clans, depois de 8 anos, eu vendi 50.1% dela pro grupo IS. Isso foi em 2022. Notícia aqui para vocês. Eh, em 2025, esse ano, no começo do ano, eu fiz o meu exit total e eu saí da General Clans. Só que antes da minha saída eu já montei a KCG. Que que é a KCG? Que foi essa empresa que vocês acabaram de ver aqui, essa dinheirão todo. Ela fatura aí de R$ 400 a R$ 600.000 por mês. A gente tem lá as principais linhas de negócio são um SAS e a gente também tem desenvolvimento de software. A gente desenvolve software para algumas empresas. Kelvin é uma fábrica de software, não. A gente meio que aloca os recursos, né? Então, tipo um modelo chamado squadas a service. E a Casj é um bom negócio, é uma empresa que tem capacidade, hoje a gente tá com aproximadamente 24 colaboradores, tem um time extremamente bom. Agora tem uma CEO, mas não tinha, tinha uma CEO. E eu estava à frente desta companhia desde janeiro de 2025. E aí eu montei em março de 2025 Acelera. Que que é Acelera? Só para você entender, Acelera é uma empresa que nasceu, onde eu comecei a ensinar programadores a empreender. Esse canal, inclusive, foi criado por conta disso, porque eu falei: \"Cara, eu quero ensinar pessoas assim como eu que foram desenvolvedoras de são desenvolvedores de software, querem sair da CLT a empreender.\" Isso foi em março de 2025. E aí, pensando em ajudar os os desenvolvedores a empreender mais rápido, eu instruí eles a criar uma consultoria estratégica em IA. Por quê? Porque o mundo tá buscando por inteligência artificial, as empresas estão buscando por IA. Então a gente tá num momento de hype, de bolha. Então era unir o útil ao habilidade do desenvolvedor de criar software com a necessidade atual de mercado da inteligência artificial e automações e por aí vai. E aí, gente, chegou junho, chegou junho, aconteceu uma virada de chave absurda na minha cabeça, porque a gente pegou um cliente e entregou esse cliente. A gente automatizou, a gente, a gente na verdade mapeou o processo dele e a gente automatizou o processo dele e colocou IA. Era uma clínica, a gente implementou o Figle, colocamos um CRM, colocamos um processo de vendas extremamente bem desenhado. Cara, a gente transforma a clínica praticamente numa empresa do digital, cara, como se o cara tivesse vendendo curso, literalmente. Criamos vários funis de conversão. Ficou um negócio assim absurdo. Absurdo. Meu pasme. Esse cara teve um ganho absurdo de venda, começou a vender mais, aumentou. Ele teve um ganho absurdo de faturamento, cara. aumentou drasticamente o faturamento dele aumentou em 30%. A hora que eu olhei aquilo, eu falei: \"Cara, todas as clínicas têm esse mesmo problema\". E aí eu parei para desenhar uma tese. Nos próximos 18 meses, as empresas que não implementarem inteligência artificial estarão tão obsoletas comparadas às empresas que implementarem que elas simplesmente vão deixar de existir. Vai ser a maior extinção em massa de empresas no Brasil e no mundo. Essa é a minha tese. E qual que é a missão da minha empresa? Da Acelera 360. Salvar mais de 10.000 1000 empresas da extinção, como implementando infraestruturas de crescimento com IA, implementando IA real, IA que dá ROI, que dá retorno financeiro, não projetos de chatbote, pedaços falidos, de sisteminha, porque não é isso que dá o retorno. O retorno não dá em você pegar um chatbot e colocar num atendimento. O retorno não dá em você pegar, por exemplo, o Lovable e desenvolver uma solução qualquer. Não. o ROY, que é o você ter uma uma implementação com IA, que dê retorno pro empresário, que aumente o faturamento, que aumente a margem, que ele diminui as despesas, ele só vai acontecer quando você implementa e há mais processo dentro daquele negócio mais o trabalho em cima das pessoas lá dentro. Isso a gente consegue fazer como? Com uma infraestrutura diá. E aí, a partir desta tese que eu construí, eu falei: \"Cara, eu preciso me dedicar 1000% neste negócio.\" Eu comecei a transformar a Acelera, não só mais para ser a escola que ajudava o programador a empreender, mas para ser a empresa onde eu ajudo pessoas a empreenderem com inteligência artificial e tecnologia. Então, se você quer empreender com o IAI tecnologia, se você quer ter um produto, se você quer aproveitar esta oportunidade também, vem para acelera. Inclusive, no dia 4/10 eu vou dar um workshop onde eu vou mostrar a minha infraestrutura de crescimento com IA. Eu vou mostrar quais são os nichos com grandes oportunidades. Eu vou explicar e apresentar para vocês como vocês podem estruturar a infraestrutura de vocês e como vocês literalmente podem ganhar dinheiro escalando o serviço de vocês em sistemas e fazerem aí R$ 100.000 por mês com inteligência artificial. Se você tiver interessado, o link tá aqui na descrição desse vídeo. Você vai clicar no link e vai cair para dentro aí do nosso workshop. O workshop se chama Growth AI. vai acontecer online no dia 4/10, é sábado, das 13 horas às 17, onde eu vou ficar com vocês e vou abrir tudo, explicar sobre furios de venda, sobre oferta, sobre nicho, sobre oportunidade, como implementar, como estruture cases de sucesso, nichos específicos para que você possa também fazer isso. Cara, vai ser incrível. Não perca, não perca. Clique aqui no link e cai para dentro. Entenda o que eu estou fazendo para você também aproveitar. Para você também aproveitar que eu detectei? Eu detectei assim, cara, o mercado é extremamente o mercado tradicional. A gente tem lá uma são mais ou menos 22 milhões CNPJ, né? CNPJ para [ __ ] mas tem uma fatia ali específica que é, não é o micro empreendedor, é o cara que fatura de 2 a 5 milhões e ele quer crescer. E tem tem alguns outros também, mas os principais são esses, tá? é o cara que tá faturando ali já acima de R$ 150.000 por mês. Ele tem uma uma ele quer crescer, ele tá preso na operação, ele não consegue crescer porque ele não tem tecnologia o suficiente e ele tá colocando chatbot, ele tá desperdiçando dinheiro com agentes isolados, ele tá desperdiçando dinheiro com tráfego pago, só que ele não tá conseguindo tracionar, ele não tá conseguindo. Então esse cara, qual que é a minha proposta? Pegar uma infraestrutura, não tem nada. Pegar uma infraestrutura de A e colocar nele assim, ó. Tá aqui, pronto, CRM, pronto, RP para você, pronto, processo desenhado, funil de venda desenhado, oferta pro seu produto desenhado, promessa desenhado, sua landing page tá aqui, tudo pronto para ele. A gente só coloca clequ. E aí essa infraestrutura de A, eu tenho dois modelos de venda. Eu posso simplesmente vender ela, fala: \"Toma aqui, empresário, toma, instala aí. E eu vendo o código ou o pacote, ele paga uma vez só\". Ou eu posso vender também uma implantação e uma recorrência e cobrar uma recorrência. Vocês viram que eu abandonei uma uma consultoria de software. Vocês acham que eu quero entrar em outra consultoria de software? Não. Por quê? Porque para mim eu quero um jogo muito maior, de muito mais escala e muito mais rápido. Beleza? Então vamos voltar pra acelera school, né? paraa escola, para aquele primeiro produto. A minha proposta é: eu ajudo você a empreender. Qual que é a minha missão? Fazer você emitir a sua primeira nota fiscal com tecnologia. Eu estou criando uma infraestrutura que ela é genérica e eu estou dando ela para os meus alunos para que ensinando os meus alunos a ir para mercado atacar nichos específicos. Eu estou mapeando os nichos. Eu já mapei mais de 22 nichos. Esses nichos eu entendo qual que é a principal oferta para ser feita para ele, quais são as dores. Eu já meio que facilito todo o processo pro meu aluno e e dou pro meu aluno um modelo de negócio pronto para ele simplesmente vender. Bem que a gente acaba virando sócio naquele negócio, entendeu? Então, com Acelera, eu comecei a trazer donos de agência, programadores, a galera de tecnologia que quer empreender. Eh, comecei a trazer a galera de tráfego pago. Kelvin, mas por que que você acha que esse modelo ele é tão potente, né? O que que você tá vendo? Gente, eu não sei se você que tá me assistindo, se você é técnico ou não. Eu eu sou um cara técnico. Eu fui arquiteto de software. Eu sei desenvolver para [ __ ] ainda. Eu tô enferrujado. Eu falo que eu sei desenvolver, mas eu tô bem enferrujado. Bem enferrujado. Mas assim, eu tenho uma base de arquitetura de software, de desenvolvimento de software muito grande, muito grande. Quando eu pego para ver uma tecnologia, eu olho, eu já consigo me ver lá na frente. E o que que eu vejo? Eu vejo, eu vejo toda a empresa não precisando mais contratar agências de marketing, porque o processo de marketing, o processo de atração, de captação do lead vai acontecer 100% com inteligência artificial. O processo de vendas, ele vai acontecer, se não com IA, com uma tecnologia que a gente tá desenvolvendo, mas 60% com IA, porque ele vai ser automatizado. Inclusive os closers vão ter acompanhamentos com IA. Eu vejo sistemas operacionais surgindo com o IA Nativa. Eu vejo, eu vejo, gente, eu vejo, ah, [ __ ] aí eu posso até sonhar um pouco e falar para vocês que eu vejo o final dos tempos com inteligência artificial de tão bizarro que que vai ser nos próximos anos, entendeu? Eh, mas isso é um papo para outro vídeo. Então assim, aproveite a janela de oportunidade. Um chamado para você que tá enxergando este movimento de a vem comigo, vamos junto. Seja você que quer empreender com tecnologia, que quer montar um software, vem pegar aqui, ó. Eu tô mapeando a infraestrutura de ar, eu tô mapeando tudo isso. Tem um modelo de negócio pronto para você e validado e validado com com meus alunos já ganhando dinheiro. Clica, vem no workshop comigo, clica no link aqui, ó. Compra workshop, vem para dentro. Kelvin, eu quero entrar na Acelera, cara. Entra no site da Acelera e se inscreve acelera 360.com.br. Vem, saca? Vamos junto. Eu tô indo também. Skin the game, entendeu? Isso aqui é um, quem tá falando aqui para vocês é um empreendedor. Eu ainda não bati. Sabe o que que eu quero? Eu quero bater 1 milhão, 2 milhões por mês em vendas. É isso. Eu quero um negócio que seja escalável. É esse patamar, entendeu? Eu ainda não montei nenhum negócio, por exemplo, que faça 1 milhão de vendas por mês. É, esse é meu limite, esse é meu nível. Agora, se você tá abaixo disso, [ __ ] eu posso te ajudar tranquilamente a você tirar sua ideia do papel, a você escalar o teu negócio, aplicar Iá de forma real, de forma clara, de forma que funcione, de forma que te traga a Roy, porque aqui tem um cara que é de tecnologia e também é de negócio para est do teu lado, entendeu? Então esse vídeo é sobre isso. Esse vídeo é para te dar essa visão do meu movimento e te chamar para vir. Bora, bora, vamos, vamos para cima, cara. Vai dar certo, não tem como dar errado. A oportunidade é agora, o momento é agora. Assim, isso é isso, isso é igual Bitcoin lá no começo, igual internet. Imagina, a gente tá começando a internet em 2000, cara, com a com a cabeça já sabendo o que que aquilo é possível fazer. Meu Deus, meu Deus. É muita oportunidade. Bom, eu não sei se você vai ou não. Eu já tô indo, fechou? Se você quiser, meu convite tá aqui nesse vídeo para você. já me segue neste canal, já dá um joinha, dá um like, já comenta, já me segue no Instagram também, fechou? Um abraço para vocês e até a próxima. Yeah.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Kelvin abandona uma consultoria de alto faturamento para dedicar 100% à IA, apresenta evidências financeiras, defende que 18 meses são decisivos para lucrar com IA e convida para o workshop Growth AI.",
            "resumo": "Neste vídeo, Kelvin revela ter deixado uma empresa que faturava entre R$ 400 mil e R$ 600 mil/mês para dedicar 100% à Inteligência Artificial. Ele mostra extratos bancários como prova de contratos recorrentes e explica que a decisão foi motivada pela percepção de que IA transformará negócios nos próximos 18 meses. O relato percorre sua trajetória: ex-programador, fundador da General Clans (venda parcial em 2022, saída total em 2025), criação da KCG e, em 2025, da Acelera, para ensinar programadores a empreender e, agora, montar consultorias estratégicas em IA. Um caso de clínica, que automatizou processos com IA e aumentou o faturamento, ilustra a tese de que empresas sem IA irão desaparecer. O vídeo encerra com o convite para o workshop Growth AI, em 4/10, com foco em infraestrutura de crescimento com IA e ROI.",
            "assunto_principal": "Transformação de negócios com IA e construção de consultorias estratégicas em IA",
            "palavras_chave": [
              "inteligência artificial",
              "inteligência artificial",
              "consultoria de inteligência artificial",
              "infraestrutura de crescimento com inteligência artificial",
              "retorno sobre investimento",
              "caso clínico",
              "oficina Growth AI",
              "empreendedorismo em tecnologia",
              "transformação digital",
              "automatização de processos",
              "estratégia de negócios"
            ],
            "resumo_em_topicos": "- Quem é Kelvin e qual foi sua trajetória (General Clans, KCG, Acelera)\n- Motivo da mudança: deixar a consultoria lucrativa para focar 100% em IA\n- Evidências apresentadas: extratos bancários e contratos recorrentes\n- Tese central: empresas que não implementarem IA ficarão obsoletas nos próximos 18 meses\n- Missão da Acelera: ajudar milhares de empresas a crescer com IA e ROI real\n- Case ilustrativo: clínica que, ao automatizar processos com IA, aumentou faturamento\n- Growth AI: workshop (data 4/10) para ensinar infraestrutura de crescimento com IA e nichos lucrativos\n- Convite para participação: link na descrição e próximos passos para empreender com IA",
            "prompt_tokens": 2080,
            "completion_tokens": 3243,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 47.69812488555908,
          "language": "",
          "view_count": 1592,
          "has_transcript": false
        },
        {
          "id": "X7TYWqQfukA",
          "title": "Você não vai enriquecer com IA (sem entender o JOGO)",
          "title_pt": "Você não vai enriquecer com IA (sem entender o jogo)",
          "url": "https://www.youtube.com/watch?v=X7TYWqQfukA",
          "published": "2025-09-12T00:46:38.542675",
          "published_relative": "há 9 dias",
          "duration": "23:11",
          "date_published": "2025-09-11T15:30:05-07:00",
          "transcript_available": true,
          "transcript": "Você não tá construindo um botequinho de esquina, um mercadinho de esquina para trabalhar desse jeito. Se você quiser ficar rico com inteligência artificial, se você quiser ganhar muito dinheiro, você tem que tirar essa mentalidade de pobre. É, você tá querendo lançar um foguete para fora da terra, porque mexer com IA, IA vertical, infraestrutura de I, se você não é aqueles caras de automaçãozinha, porque eu acho que não é mais, você tá no meu vídeo aqui, você não é o cara da automaçãozinha do N8N. Você já tá pensando em infraestruturas de inteligência artificial e a vertical e entregar resultado pro teu cliente. Então isso aí é um foguete. E você quer lançar o foguete para fora da terra, você tem que gastar combustível. você tem que investir. Então assim, não tem como você pensar em crescer economizando. Esse vídeo aqui é sobre isso. Nesse vídeo eu vou te ensinar a sair de um cliente para 10. Primeiro do zero pro. Do zero cliente pro cliente e do um cliente para 10 clientes. E como você cresce isso, como você expande? Isso aqui não é sobre N8N, isso aqui não é sobre Long Chain, Crew AI, Google ADK, não é sobre ferramenta, nem framework, nem código, é sobre modelo de negócio. Então tudo que eu vou explicar nesse vídeo aqui é como você realmente faz dinheiro, mas sem pensar nessa parte técnica. A parte técnica você resolve. Eu garanto pr você que se você fechar um cliente, dois clientes, três clientes, você vai resolver a parte técnica, porque você vai ter dinheiro para contratar um desenvolvedor. Não vou ficar falando pr vocês, apresentando como, ah, como criar um agente no chat EPT, integrar isso no NTN, colocar isso num flow eyes da vida. Não, não, isso aí é ferramenta, isso aí é a parte braçal do rolê. Aqui a gente vai pensar sobre como você tira sua ideia do papel, como você emite a sua primeira nota fiscal, como você vai pros seus 10.000 de faturamento, depois 50.000 1000, depois 100.000 por mês, depois 200, 300, 400, 500, como você levanta investimento, por aí vai. É sobre isso, business. Entenderam? Pegaram? Agora se você quiser ficar fazendo eh automaçãozinha, contratinho de 1000, 2.000, ah, quero só fazer 5.000 por mês, já sai do meu vídeo. Esse vídeo não é para você. Beleza? Bora começar. Ah, deixa eu me apresentar para você que não me conhece. Meu nome é Kelvin. Eu sou um programador, ex-programador empreendedor. Eu fundei a General Cleans em 2015, uma das principais insurtecs do Brasil. Fiz a venda de 50.1% dessa minha insurtec em 2022 pro grupo IS. Fiz o resto da vendi o resto agora em 2025 e montei agora acelera 360. Então se você quer empreender com inteligência artificial, acelera para você. Aí você acessa o link que tá aqui na descrição desse vídeo. Mas bora começar. Vamos lá, então. Deixa eu compartilhar minha tela com vocês. Então, nesse vídeo aqui, cara, parece besteira, mas não é. Essa questão de mentalidade pobre é o que faz a maioria dos empresários andar de lado. Mentalidade de quebrado, de falido, de  Se você tiver essa mentalidade, ah, tô começando pequeno, eu quero fechar um cliente por mês, aí eu fecho aquele cliente, aí eu quero entregar aquele cliente, se fodeu, já perdeu o jogo. Não é assim que você cria um negócio grande. E eu vou te explicar. Vamos lá, então, Kelvin, me explica aí. E quero entender já como transformar um cliente para 10. Calma, primeiro você tem que entender o problema. Então vamos pegar aqui, ó. Imagina aqui. Isso aqui acontece muito com freelancer, muita agência, consultorias, maioria dos empresários, isso aqui é o jogo do empresário que anda de lado ou o cara que quer empreender e quer andar de lado. Por quê? Porque ele faz o que? ele faz do o que ele aprendeu na vida pessoal dele na no profissional, na empresa. Então vamos lá. O cara vai lá fala assim: \"Pô, vou montar uma consultoria de A, uma agência de A, uma infraestrutura de A, alguma coisa do tipo.\" E aí ele começa a prospectar os primeiros clientes. Vai atrás de um, de um cliente, pá, pá, pá, vai no LinkedIn, e-mail, liga, telefone, Instagram, pá, pá, pá, conseguiu o primeiro cliente. Contrato de R$ 10.000. Que que ele faz? Deixa eu entregar esse cliente primeiro agora. Depois que eu entregar, eu pego o próximo. E depois que ele ele pega o cliente, gasta o dinheiro para pagar, para se pagar, entrega e aí depois ele vai pro próximo. Aí hora que ele for próximo, ele já não tem mais dinheiro, ele não consegue ter rotatividade, ele não tem previsibilidade, ele não tem reinvestimento, ele não trabalha alavancado, não vai pra frente. Então assim, essa aqui é a mentalidade de pobre, ó. Se você tá aqui nesse vídeo e é o cara que, ah, eu só quero fazer 20.000 por mês, já sai. Esse vídeo não é para você. Esse vídeo não é para quem pensa pequeno. Aqui é para quem tá lançando foguete, velho. Aqui é para quem quer criar negócio de fazer 100.000, 200.000, 300.000 por mês, entendeu? O cara quer bater por ano ali, ó. Primeiro a meta começar a empreender, na primeira nota fiscal, depois 50.000 de faturamento, depois 100.000 1000 por de faturamento por mês, depois 200, 300, 400, 500, 1 milhão e aí o céu é o limite. Então se você tem essa mentalidade, não é assim. O jogo não é esse. Esse aqui é o jogo errado. Esse aqui é o jogo errado. E eu vou mostrar alguns cases de aluno para vocês entenderem. Então vamos lá. Se você quer realmente fazer dinheiro com Iá, você tem que entender que você vai ter que deletar, dar um delete nessa mentalidade escassez, nessa mentalidade de pobre que favelado, vai te deixar travado. E não quer dizer que é pobre de dinheiro, é pobre de mentalidade mesmo. Aqui, ó, a cabeça tá travada. E você vai ter que começar o jogo certo. Você vai ter que trabalhar com alavancagem, reinvestimento e ter previsibilidade em vendas. Kelvin, que que é a alavancagem? A alavancagem é o seguinte, imagina assim, ó. Eu tenho minha casa aqui. Tenho minha casa e eu quero fazer um negócio. Eu não tenho dinheiro para fazer. Eu vou fazer um investimento que eu não tenho dinheiro. Eu pego emprestado esse dinheiro com o banco. Eu vou deixar minha casa de garantia. Aí eu vou pegar aquele dinheiro porque eu vou aplicar aqui, vamos supor, 1 milhão. Eu vou fazer 1 milhão vira 10. Eu vou pagar o banco, vai me sobrar nove, oito. O juro. Isso é alavancagem, entendeu? Alavancagem empresarial. Eu vou, olha aqui, vou dar um exemplo de alavancagem aqui que eu ensino meus alunos. Eu quero trabalhar com I, mas em vez do meu aluno eu falar para ele fazer, eu falo para ele fazer, não, eu falo para ele vender, vai vender, vai prospectar e vai conseguir o primeiro cliente. Porque a hora que ele consegue esse primeiro cliente, vamos supor, fechou lá 10.000, Viu? Ele contrata um cara que vai fazer por cinco, pega os outros cinco que sobrou e reinveste em tráfego pago, em canais de aquisição alavancado. Você troca dinheiro por cliente, por acesso, por visualização, por qualquer coisa que vai te trazer mais cliente e ele vai trazer dois, que vai trazer três, vai trazer quatro. Então, o caminho que todo mundo segue é esse aqui, ó. Eu quero trabalhar com deixa eu fazer primeiro. Eu tenho que primeiro fazer para depois eu ter o meu CNPJ perfeito para depois eu fazer não sei o que lá. Aí passou 2 anos, não conseguiu nem sair da CLT ainda, não conseguiu nem fazer a agência dele crescer. Tá fazendo a agência faturar 20, 30.000 por mês. Esquece. Trabalhar alavancada é diferente. Isso. Isso. Existe alavancagem patrimonial, alavancagem financeira, alavancagem empresarial. Os grandes jogam esse jogo aqui. Isso aqui é jogo de gente grande e a gente quer ser grande. Então a gente tem que pensar como grande e ver como eles fazem dinheiro e fazer igual. Reinvestimento. Sem reinvestir dinheiro, sem você investir e sem reinvestir não volta. É igual entrar no acelera, vai entrar, vai comprar tempo, vai acelerar no tempo, vai comprar networking, porque vai acelerar com uma rede de mais de 150 pessoas que também tá empreendendo, já tá fazendo muito dinheiro, vai comprar o que mais? A minha expertise de ter acesso ao Kelvin, de ter acesso à minha visão e principalmente é o seu advisor te ajudar. Então é isso aqui é investir, entendeu? é colocar dinheiro de tráfego pago, não é gastar, é investir em trazer mais clientes, é comprar, entrar num grupo, numa comunidade, num evento, é investir para voltar. Esse é o pensamento do crescimento. E ter previsibilidade em vendas, tem que entender qual que é o funil de aquisição. Então, tem que estudar de vendas, tem que ir atrás, tem que tentar prospectar, tem que tentar vender para ter fluxo de vendas, fluxo de cliente e principalmente atender um mercado que tem a demanda, porque todo mês tem que vender, entendeu? Todo mês tem é construção de carteira. Tá bom, Kelvin. Então, beleza. Já entendi o jogo errado. Mostra o jogo certo. Eu vou trazer o case de um aluno meu que entrou agora. Cara, ele é bem legal porque eu não vou falar o nicho dele porque eu não quero que vocês copiem esse cara aqui. O nicho dele é muito bom, muito bom, muito, muito bom, muito bom, incrível. E ele, olha, olha como que ele começou pequeno. Ele tá tentando sair da CLT. Ele quer fazer de 15 a 20.000 por mês, ó, e sair da CLT esse ano. Vai fazer. É, é, ele é deve, né? já fechou o primeiro cliente dele. 6K de implantação mais 1700 de recorrência. O que que significa isso aqui? Isso aqui significa o seguinte, ó. Ele já tem a infraestrutura de crescimento dele. Por mais que seja pequena, ele já tem a infraestrutura de crescimento dele com a Kelvin, o que que é? Tô perdido, Kelvin. O que que é uma infraestrutura de crescimento com a? Vou explicar de forma rápida aqui para você, mas se você não sabe, você vai clicar, ó, na lateral aqui do YouTube tem meus vídeos, meu canal. Entra lá e entenda, assista lá como eu vou ficar rico em A em 2025. você vai entender o que que é uma infraestrutura de crescimento. É um conceito. É um conceito. Em vez de vender chatbot, em vez de vender ferramenta, em vez de vender esse monte de coisa, em vez de vender agente, isso aqui, isso aqui é ferramenta, isso aqui não resolve o problema. Eu falo para vender uma infraestrutura de crescimento com IA. O que que é uma infraestrutura de crescimento com IA? São inteligências artificiais, chatbot, agente, automações e um monte de coisa. Mais sistemas tão de mercado, por exemplo, CRM para fazer a parte do do do processo de vendas, um RP de mercado. Então, se é um RP para clínica, por exemplo, um figle da vida integrado, eh, sistema de gestão, por exemplo, um click, um Notion. Então, o processo desenhado dentro desses sistemas, as IA integradas com esses sistemas, então tem que ter processos, processos mapeados para ajudar o cliente, no caso, a pessoa que está comprando o seu sistema, a sua infraestrutura, a ter resultados extraordinários. Resultados extraordinários. Que que é resultado para empresário? Aumento de faturamento, aumento de margem, mais margem, mais dinheiro sobrando no bolso dele, certo? Consecutivamente, escala escalabilidade, tornar um negócio que é tradicional escalável, que ele cresça em faturamento e não cresça no volume de pessoas de forma proporcional. Se você fizer o seu cliente do seu nicho ter isso aqui, você consegue, em vez de cobrar uma um chatbotzinho, R$ 200, em uma automaçãozinha, vamos supor R$ 3.000, em vez de você cobrar esses tickets, você cobra 20.000, 30.000, 40.000, 50.000 e por aí vai, entenderam? Porque você trabalha em cima do resultado e não da ferramenta. É isso que eu vou ensinar no dia 4 do Tex no meu workshop, como transformar seu serviço em sistemas de A que geram R$ 100.000 por mês. Vou mostrar a minha. A minha se chama Growth AI System, que é uma estrutura de crescimento voltada para para vendas, né? Uma máquina de vendas completa desde o da aquisição até a venda, até o processo de venda. E você vai poder entender como você pode fazer a sua, entendendo como você achar seu nicho, como você criar a oferta, como que você vai atrás do cliente, como você prospecta. Eu vou mostrar tudo para que você realmente consiga fazer. Então vamos lá, vamos pegar aqui, vamos voltar no meu aluno. Agora que você entendeu o que que é IA, ele tem um nicho específico, um nicho muito bom. Esse nicho tem muita demanda e é um nicho grande. Que que é um nicho grande? Tem mais de 80.000 empresas. Mais de 80.000 empresas. nesse nicho dele. Então aqui é o t, o tamanho do mercado. São mais de 80.000 empresas que ele pode vender essa plataforma dele, essa solução. E ele foi lá e conseguiu o primeiro cliente, cara. Conseguiu o primeiro cliente 6.000 de implantação mais ã 1700 por mês vai totalizar ali no ano 26.400 por cliente. É isso aqui que é esse valor que ele consegue gerar por cliente. E qual que é o pensamento correto? pensamento correto é o seguinte, vamos entender qual que é a previsibilidade de vendas. Então, para conseguir este cliente, ele fez 19 prospecções. Então, a cada 19 eh clientes, possíveis clientes, que daquele nicho, daquele perfil específico dele, ele tem um fechamento e então significa que ele tem uma taxa de conversão de 5%. Qual que é o pensamento aqui, cara? Se eu quero faturar 1 milhão, eu não, eu tenho que ir atrás de 40 clientes. Por quê? Porque a cada cliente eu fecho a 26.000. 26.4 4 x 40 dá 1 milhão de faturamento. E para ele fazer 40 fechamentos a essa taxa de conversão de 5%, ele tem que fazer 760 prospecções. Conseguiu entender a lei de raciocínio nesse mercado dele de 760 prospecções, olha o tamanho do mercado que insignificante para ele ser 40. Então assim, ele tem um mercado vasto para ele trabalhar, vasto. Então ele consegue ter previsibilidade nas vendas porque ele tem já os dados e teve o primeiro cliente, teve a máquina de vendas. Qual que é o grande da questão? Esse primeiro cliente, ele conseguiu prospectando, ele conseguiu ligando, trocando o tempo dele, trocando o tempo dele para fechar o primeiro cliente. Agora que fechou, o que que a gente vai fazer? A gente vai primeiro entender quais são os canais de alavancagem que ele tem, como que a gente acelera, como ele trabalha alavancado. Ele vai entregar este cliente e vai usar esse dinheiro de implantação, vai reinvestir 50% dele num canal de alavancagem, um canal que ele troca dinheiro por visualização, por venda. Conseguiram entender? Por quê? Porque a gente tá com a meta de fazer 40 fechamentos e 760 prospecções. Gente, isso daqui, isso aqui faz parte do planejamento estratégico da imprensa. Então, ele não tá olhando, ele poderia olhar para esse putz, eu quero fazer só esses 26.500 por mês. Na verdade, ele tá, ele tava olhando em fazer de 15 a 20.000 por mês porque ele quer sair da CLT. maravilhoso. Esse é o step one, é o passo um. A gente vai ajudar ele a fazer isso. Meu foco é ajudar ele a já foi, né, para emitir a primeira nota fiscal. Já emitindo. Agora vamos pro segundo faco. Sai, fazer ele sair da CLT. E depois, qual que é o terceiro? Fazer ele bater 1 milhão. 1 milhão ano. São R$ 83.000 por mês. Não é muita coisa não. R$ 83.000 por mês não é muita coisa. Legal. Então como que a gente vai fazer isso? 40 fechamentos, 760 prospecções para que ele bata 1 milhão por cliente no ano. Show. Quais são os canais de alavancagem que ele tem? meta, canal que ele coloca dinheiro, coloca R$ 100 desse lado e ele entrega tantas visualizações. Google Ads, grupos de mentoria, grupos de network, onde já tem aquele determinado nicho dele lá dentro. Vamos criar toda uma estratégia. Por exemplo, aqui, aqui é high expensive, aqui é alto investimento, alta despesa. Então, cara, aqui ele gasta mais, aqui em cima ele gasta mais ou menos dinheiro, né? E aí continua tendo um canal aqui que é um canal de prospecção. É, continua sendo um canal ativo, prospecção, outbalde total, que ele gasta menos dinheiro, porém aqui é mais. tempo mais energia que para ele não faz sentido. Kelvin, mas daí, cara, é fácil, é só se calcular aqui. Mas e aí? Como que ele entrega? Contratando. Pensar em escala. Ah, mas merda, contratar, meu Deus do céu, cara. Eu nunca contratei ninguém na vida. É o que eu te falei no começo desse vídeo. Você quer montar um boteco de esquina ou você quer montar um negócio gigante, algo robusto? Tem que contratar. Ah, mas eu queria fazer 1 milhão fazendo one person business. Negócio de sai do vídeo, sai do vídeo, sai do vídeo. Não, não é assim que funciona, entendeu? Com infraestrutura de crescimento e a você consegue fazer 1 milhão com quatro pessoas no time, tranquilo, cinco pessoas no time, mas com uma única pessoa é difícil. É difícil, não é fácil não, hein? São para poucos, para poucos que vai ter que escalar fazendo mais na linha de mentoria, na linha de curso para conseguir fazer isso. Tem que ter time de vendas, time de suporte, tem que ter um monte de coisa aqui envolvida no meio. Então tem toda uma projeção. Então assim, olha, olha olha, olha o o cenário aqui em cima, que é os pensamento, mentalidade que quebrado, que é o cara que anda de lado. Esse cara aqui é essas empresas que você conhece, ó. Se você tá nessa mentalidade fazendo 20, 30, 40.000 por mês a 2, 3 anos de empresa, 5 anos de empresa, cara, entra, vem, vem, vem, vem para acelera, vem pro workshop, ó, vem pro workshop que você vai entender mais o que que você tem que fazer. Você não só tem que ir para IA, empreender com IA, mas você também tem que mudar sua mentalidade. Você não pode continuar do jeito que tá, não pode. Assiste mais meus vídeos para você ir entendendo e oxigenando. Muda essa mentalidade. E tem que jogar mentalidade de cara que joga o o jogo real. Um jogo grande, entendeu? Ó, o o Bruno, Bruno Berge. Bruno Berg, cara, ele deixou um depoimento maravilhoso, não vai dar tempo de eu explicar tudo aqui o caso dele, mas ele fechou três clientes e atingiu o faturamento de 41.000 em um mês e meio. 41.000 tá com ticket muito maior. Show, Kelvin. Entendi. Preciso de um passo a passo. Vamos replicar. É só você seguir isso aqui, ó. Etapa número um. Que que você tem que fazer? Escolha um mercado. Primeiro passo, você vai escolher o teu nicho lá. Daí, etapa número dois, você tem que certificar que você realmente tá resolvendo um problema deles, desse mercado, desse nicho, dessa, desse seu cliente. Você vai ter que tapa três, você vai ter que certificar seu cliente está ganhando dinheiro com você. Então assim, que é lucrativo contratar sua infraestrutura é lucrativo de pagar. Faz sentido, você gera dinheiro, você tá resolvendo uma dor real. Etapa quatro, tornei tenha previsibilidade nas vendas. Então, para que você faça isso, estruture a sua máquina de aquisição de cliente. E aqui nesse momento você vai fazer o seguinte, ó. Para que você tenha essa previsibilidade, você vai fazer esse reinvestimento. Então, se no caso do meu aluno aqui, ó, se um cliente dele gera 6K, 6.000, ele vai manter 6.000 dentro do caixa e vai pegar 3.000 e vai reinvestir, porque ele vai fazer um cliente com esses 3.000 que ele tá reinvestindo, a ideia é que ele atraia dois clientes novos e com o dinheiro desses dois, uma parte reinvestida, ele atraia mais quatro e aí ele vai crescendo de forma alavancada e ganhando corpo e ganhando estrutura, entendeu? E aí ele só consegue fazer isso daqui, ó, de um para dois, de dois para quatro, para seis, para 8, para 10. Se você, ele e você, né, só vai conseguir fazer isso se você estruturar a sua máquina de aquisição de clientes e escolher um canal de distribuição que você que possibilite você adquirir clientes de forma alavancada. Conseguiram entender, cara? Não dá. Prospecção ativa funciona, funciona, mas é um canal. O outro canal tem que ser onde? Você tem que, pô, trazer dois, três, 5, 10 dentro da dentro daquele canal. Esse é o segredo, entendeu? E aí, cara, aí é criar a máquina e colocar dinheiro aí. Aí, tipo, entrou dinheiro aqui, ó, ele reinveste, ele vai ser, entrou dinheiro aqui, vamos supor, metade desse dinheiro vai ser utilizado para fazer um reinvestimento que vai trazer mais clientes. E aí você tem uma máquina de dinheiro, você consegue crescer, você contrata a gente no processo, você faz tudo no processo, você faz tudo no processo. Isso aqui é sobre negócio. Então, vamos lá. quer crescer, tire essa mentalidade de escassez. Foque em trabalhar alavancado, foque em investir e reinvestir o dinheiro que entra nos seus primeiros contratos para dentro do teu negócio para que você cresça mais rápido. Tenha previsibilidade na sua máquina de venda. Estruture a sua máquina de vendas para que você adquira mais cliente. Comece a ter visão sobre os seus números. Eu faço tantos de prospecção para tantos me responderem, para fechar tantos. Entendeu? Não existe meia venda. Se você não vendeu ainda, continua tentando até você fechar, porque a partir do momento que você vai fechar, você vai conseguir ter todos os números. Quantos eu chamei, quantos me responderam, quantos eu marquei a reunião e quantos eu fechei um contrato. E a partir disso, você vai conseguir estruturar sua máquina, você vai conseguir ter essa visão que eu acabei de te dar aqui e você vai saber os números necessários para que você bata 1 milhão, 2 milhões, 3 milhões. E aí o resto é constância. dia após dia trabalhando, olhando pro negócio, é refinando, ajustando e parafusinho aqui, ali e pau no gato. Se você quiser aprender a fazer R$ 100.000 por mês com infraestrutura de ar, inteligência artificial vertical, clica no link aqui na descrição desse vídeo e cai para dentro do meu workshop que vai ser no dia 4/10. Não se esqueça de se inscrever no meu canal, de dar o joinha, de comentar, de emendar sinal de fumaça, de ir lá no Instagram e falar comigo e blá blá blá. Falou, rapaziada.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Adotar a mentalidade de crescimento, usando alavancagem, reinvestimento e um modelo de negócio baseado em IA para sair do zero e alcançar mais de 10 clientes, não apenas depender de ferramentas.",
            "resumo": "Kelvin afirma que enriquecer com IA não depende de ferramentas, mas de um modelo de negócio escalável. Ele critica a mentalidade de pobre que impede crescimento e defende sair do modo freelancer: começar com um cliente, entregar, e então escalar para muitos. O caminho, segundo ele, é usar alavancagem, reinvestimento e previsibilidade de vendas. Primeiro você vende, emite a nota fiscal e usa a receita para contratar alguém e investir em aquisição de clientes (ex.: tráfego pago), gerando novos contratos e repetindo o ciclo. O objetivo é chegar a faturamentos cada vez maiores (de milhares a dezenas de milhares por mês) com recorrência e expansão. O vídeo enfatiza que o foco não é em N8N, Google AI ou outras ferramentas, mas em pensar grande, investir e repetir o processo até alcançar uma escala de 100 mil a 1 milhão por ano.",
            "assunto_principal": "Mentalidade de crescimento e estratégia de escalabilidade para negócios baseados em IA: alavancagem, reinvestimento e expansão da base de clientes.",
            "palavras_chave": [
              "Inteligência Artificial",
              "Inteligência Artificial",
              "mentalidade de pobre",
              "alavancagem",
              "reinvestimento",
              "escala",
              "modelo de negócio",
              "prospecção de clientes",
              "faturamento",
              "nota fiscal",
              "CNPJ",
              "prospecção",
              "investimento em tráfego",
              "empreendedorismo",
              "infraestrutura de Inteligência Artificial"
            ],
            "resumo_em_topicos": "- Objetivo do vídeo: transformar mentalidade e estratégia de negócios com IA.\n- Mentalidade: abandonar a mentalidade de pobre e buscar escala.\n- Do zero a 10+ clientes: sair do modo freelancer; foco no modelo de negócios.\n- Conceitos-chave: alavancagem, reinvestimento, previsibilidade de vendas.\n- Como fazer: vender primeiro, emitir a primeira nota fiscal, usar a receita para contratar e investir em aquisição de clientes.\n- Caminho de crescimento: 50 mil, 100 mil/mês, 200 mil a 500 mil/mês e além (faturamento anual).\n- Erros comuns: ficar preso a burocracias (CNPJ) ou depender de ferramentas sem escalabilidade.\n- Diferenciação: não se trata de ferramentas específicas, mas de estratégia de negócios.\n- Chamada para ação: acelera 360; link na descrição.",
            "prompt_tokens": 2145,
            "completion_tokens": 4315,
            "model": "gpt-5-nano",
            "cost": 0.0075
          },
          "analysis_time": 63.801356077194214,
          "language": "",
          "view_count": 1420,
          "has_transcript": false
        },
        {
          "id": "XeBBlmAaRhg",
          "title": "Esses Sistemas de IA Estão Criando uma Nova Classe de Milionários Silenciosos (sem Você Saber)",
          "title_pt": "Esses sistemas de IA estão criando uma nova classe de milionários silenciosos (sem você saber)",
          "url": "https://www.youtube.com/watch?v=XeBBlmAaRhg",
          "published": "2025-09-09T00:46:38.542692",
          "published_relative": "há 12 dias",
          "duration": "14:04",
          "date_published": "2025-09-08T17:00:39-07:00",
          "transcript_available": true,
          "transcript": "Nesse vídeo aqui eu quero te mostrar uma coisa muito assustadora, mas ao mesmo tempo excitante que tá acontecendo no mercado agora. E talvez você nem esteja percebendo. A inteligência artificial, ela não tá só mudando o mercado, mas ela tá criando uma nova classe de milionários. É, chega a ser, chega a ser um absurdo. E eu vou mostrar isso aqui para vocês, tá? Cara, na semana passada eu tava conversando com um seguidor meu, o Alex. Talvez ele venha até aqui comentar nesse vídeo, tá? Esse aqui é o Alex. Eu não tenho a foto desse cachorro aqui, né, para preservar ele, mas ele tem 17 anos de idade, é um seguidor, não é meu aluno da Acelera, cara. Ele tem zero experiência, ele nunca montou uma empresa na vida real. O pai e a mãe dele não são empresários e inclusive ele é de um local meio que humilde em Minas, tá? Moral da história, ele faturou R$ 50.000 R em um mês. É isso mesmo. Aí aqui agora, antes de eu falar para você o como ele faturou isso, eu quero te indagar aqui sobre dois caminhos. Qual caminho você acha que ele conseguiu fazer esse faturamento, né? Então tem temos dois caminhos. O primeiro caminho para ele ter feito esse faturamento, ele desenvolveu alguns agentes inúteis, ou melhor, ele pegou alguns fluxos e automações de N8N e saiu oferecendo automação para os empresários e para as empresas. ou ele criou alguns chatbots no WhatsApp e tudo mais, ou melhor, ele criou um microSAS no Lovable. Ele usou o Love para criar um microSAS e saiu vendendo na internet. Focou em vender para quem quisesse comprar, independente de quem que era o cliente e tudo mais e qualquer coisa. Ele falou: \"Meus, meu ICP é o mundo inteiro, todo mundo pode comprar de mim porque todo mundo quer ir a ele apontou para isso. Você acha que ele foi para esse caminho aqui ou ele foi pro caminho dois? Qual que é o caminho dois? Ele identificou uma dor real e forte em um único nicho. Ele viu que poderia resolver essa dor com IA e montou uma infraestrutura de crescimento que vendeu. Que que vocês acham? É lógico, já tá aqui, ó. Duas vendas de 25.000 cada. É lógico que é o dois, tá? Esse caminho um aqui é o caminho que a galera tá seguindo. Primeiro, quem tá seguindo esse caminho? empresas que estão tentando colocar os times de tecnologia para criar a gente, sair automatizando e fazendo acontecer. Vai fracassar. 95 das empresas, % das empresas falham em acelerar receita com inteligência artificial. Revele estudo do MIT. Desenvolvedor não sabe como tem que acelerar a receita. Você tem que ter um tipo de profissional específico que ou é o desenvolvedor que tem a mente empreendedora, aquele cara que quer empreender, ou é a pessoa da operação ou diretor que tem a mente visionária, que tá indo atrás da inteligência artificial e tá vendo o que dá para fazer, pedindo pra equipe de TI fazer. Se isso não acontecer, vai acontecer isso daqui. E se você tá seguindo este caminho aqui, ó, um, deixa eu te falar, você vai fracassar, tá? Não siga esse caminho um, mas fica nesse vídeo porque eu vou te mostrar o que o Alex fez e eu vou te mostrar o caminho correto, tá bom? Então o Alex, basicamente ele seguiu o caminho dois, ele identificou uma dor absurda e ele criou uma infraestrutura de crescimento que resolve um problema de fim a fim. E a infraestrutura dele é muito simples, cara. uma infraestrutura que integra agentes de IA mais CRM mais um workflow, que é um processo específico mais inteligência de oferta. Que que é inteligência de oferta? É o modo como ele vende essa oferta para experts. Olha que olha esse filtro aqui, ó. Olha o nicho dele. Experts, que já tem mentoria lançada e já tem mais de 50 alunos. Esse aqui é o nicho dele. O ticket dele é R$ 25.000. E o que que ele resolve com essa infraestrutura de IA dele? Ele diminui o ch de novos clientes. Então que aquele cara, que que é ch? É o cancelamento. O cara contrata, paga lá, vamos supor, R$ 20.000, mas ele cancela nos primeiros 7 dias ou nos primeiros 30 dias. essa infraestrutura de a diminuir esse churn. Chern é despesa total, aumenta as vendas, mas recuperação de carrinho e melhora o processo de onboarding e suporte com inteligência artificial. Então ele ele juntou esses três caras aqui e ele deu um preço, R$ 25.000 de implantação, mais R00 por mês de sustentação. Esse moleque tem 17 anos de idade. 17 anos de idade, Alex. Ó, Parabéns. E é isso que você tem que fazer. É isso que você tem que entender. Essa aqui é a verdadeira virada de jogo. É isso aqui que você tem que entender. Não é sobre fazer IA, não é sobre saber IA, não é sobre dominar crew AI, Lchain, a Google ADK. Não é sobre você entender sobre N8N, teros todos os fluxos de automação e tudo mais. Não se trata disso. É sobre você saber aplicar. onde você aplicar isso, como posicionar e transformar em algo indispensável. Esse é o segredo, entendeu? Então o que eu quero dizer para você aqui nesse vídeo é não foque no dinheiro rápido, não foque no que a galera, por exemplo, dessas ã ã que estão ensinando você a programar ou a desenvolver esses agentes de estão falando: \"Ah, vende automação, ganha dinheiro com nisso, você vai conseguir fazer 1000, 2000, R$ 3.000\". não foca nisso, entendeu? Esse é o jogo errado. A barreira de entrada é extremamente baixa, a saturação é altíssima. Que que é saturação? Vai tá lotado de gente rapidinho. E os grandes players como Open AI, Microsoft, Google vão comoditizar essas funções de marketing, vendas e suporte o mais rápido possível. E aqui eu trouxe até algumas notícias para você ver. A Open AI quer disputar currículos com LinkedIn, por exemplo. Meta quer automatizar totalmente a publicidade de A até 2026. Google vai mudar para sempre a vida de agências, marcas e veículos de notícia com o Google IO. Então assim, é o que tem de acontecer. A meta tá colocando, por exemplo, formulário no WhatsApp, já o negócio vai ficar louco. Se você focar nisso, cara, seu ciclo de vida vai ser muito curto no empreendedorismo. Você vai se frustrar e você não vai conseguir fazer dinheiro. Kelvin, mas então aonde eu tenho que focar, meu Deus do céu, onde tá em oportunidade realmento, de inteligência artificial. Inclusive, no dia 4 de outubro, eu vou apresentar para vocês a minha infraestrutura. Olha o tamanho já do meu do meu é do meu do meu blueprint, hein? isso aqui tá um absurdo. Ó, a minha infraestrutura de A, eu vou apresentar ela para vocês aqui. Ela tá aqui, ó, no dia 4. Então, lá no meu workshop, chama, a minha se chama Growth AI. Eu vou explicar para vocês como que funciona desde a camada de atração. Agentes, por exemplo, de cópia de landing page, agentes para criação de landing page, agente para criação de tráfego pago de campanha de acompanhamento. CP, o que eu entrego pro meu cliente, COP pronta para nichos específicos, camada de aquisição, meus agentes de produto de venda direta, nuvem de agentes no caso, né? Nuvem de agentes para agendamento de call. Então, no dia 4 de outubro eu estarei fazendo um workshop ao vivo. Ao vivo, hein? O preço do ingresso é R$ 67.  que pariu. E lá eu vou te mostrar como você pode aproveitar essa oportunidade de inteligência artificial para que você crie o seu negócio e fature aí pelo menos R$ 100.000 por mês com IA. Você vai clicar no link aqui na descrição desse vídeo, vai comprar o ingresso e vai cair para dentro desse workshop, hein? Então lá eu vou, deixa eu mostrar aqui para vocês, ó, rapidamente, ó, só, só o cheirinho. A gente vai passar sobre como você escolher o seu nicho. A gente vai falar sobre análise de mercado, identificação de gap, proposta única de valor. Então, como você cria sua máquina de valor? A gente vai falar sobre posicionamento estratégico, a gente vai falar sobre ofertas vencedoras, a gente vai falar sobre preços e margens, a gente vai falar como você desenha sua infraestrutura de A. Eu vou te mostrar a minha infraestrutura de A. Você vai ver ela rodando, funcionando. Você vai ter clareza em como você tem que estruturar a sua infraestrutura de ar. E eu perdi a minha apresentação aqui. É isso. E você vai sair desse workshop. São mais ou menos umas 6 horas que eu vou ficar com você te ensinando tudo sobre o que eu estou fazendo, como eu tô ganhando dinheiro, como os meus alunos estão ganhando dinheiro. No final você vai ter capacidade de construir a sua própria infraestrutura de ar, ter este pensamento, ver o futuro e seguir esse caminho aqui, ó. Chega de seguir esse caminho, tá todo mundo te falando, gente, tá sendo bombardeado de propaganda, falando, cara, fique rico, faça 10.000 1000 por mês. Quem que você conhece dos seus grupos que você participa de mentoria, de comunidade no code, que faz 10, 20, 30.000 por mês, tá tendo sucesso, que já faturou 100.000 por mês com isso, não tem, entendeu? Então, algum problema tem aí nessa promessa, né? Então, vamos lá. Então, assim, ó, foque na em criar uma infraestrutura de crescimento, assim como o Alex fez, ele criou uma infraestrutura de crescimento voltada para expert com lixada, entendeu? E é por isso que você vai conseguir cobrar, quando você foca na infraestrutura de crescimento, você vai conseguir cobrar ali de 50, de 20 a R$ 50.000, por exemplo, mais um upfront por um projeto único, um único projeto. Não tô nem falando da recorrência. O Alex, por exemplo, cara, olha que loucura o preço dele aqui, ó. Cadê? 25 pau mais 15.00 + 15.000 aqui no ano. R$ 15.000, não, R$ 18.000 R$ 1000 no ano que ele pegou a mais de um único cliente. Então o ticket dele por cliente aqui foi R$ 43.000. Um único cliente, único cliente em um único mês ele pegou dois, entendeu? Fazendo prospecção ativa no Instagram. Que que é prospecção ativa no Instagram? Chama os experts Instagram e oferece. Você também consegue. Ele tem 17 anos. Você tem quantos? Entendeu? Então beleza. Aí aqui qual que é o conceito? Ó, quando você faz isso, você constrói a solução sob medida. Então você, deixa eu só explicar aqui um um passo antes. Pensa assim, ó, Kelvin, mas cara, isso não dá para virar uma plataforma? Deixa eu até colocar aqui, ó. Dá, mas a vida é feita de estágios. Qual que é o primeiro passo? estrutura sua infraestrutura de ar para um nicho específico, com uma dor específico e resolve o problema deles, entendeu? Resolve. Quer ver? Ó, tem até um um passinho aqui que eu não coloquei aqui nesse vídeo. Deixa eu pegar aqui no meu material. Então, ó, se você vai escolher um nicho específico, você vai identificar um gap naquele nicho, Kelvin, não consigo achar um gap. Tem um método para isso. Por isso que, inclusive, você tem que vir no nosso workshop no dia 4 que eu vou mostrar. E aí você vai começar, por exemplo, a trair esses caras, vai criar o seu primeiro funil, um funil de VSL, vai fazer prospecção ativa ou funil do YouTube, igual o meu que seja, tem n funiis para eu te apresentar e você vai fechar os seus primeiros clientes e vai fazer a implantação dessa infraestrutura de ar. O primeiro vai dar mais trabalho, o segundo vai ser mais rápido, o terceiro vai ser plugin play, o quarto então plugin play, quinto plugin play. Depois que você se capitalizou com isso, você vai pro próximo estágio envelopar tudo isso dentro de uma plataforma, montar um ecossistema em volta. Então, sim, dá para fazer, dá para criar um ecossistema, mas não é no D zero. No Dzer é você juntar todas as peças e resolver um problema fim a fim, entendeu? Então você constrói a solução sobre medida, instala uma vez e libera o valor contínuo sem depender de de retentores de mensalidade. Você não precisa ficar se preocupando com o turn aqui. Então, por exemplo, uma clínica odontológica que ela paga ali, você vai vender para ela por R.500 por algo que tecnicamente ela pagaria R$ 200 por mês de mensalidade, R$ 300 por mês. Por que que ela paga mais? Porque ela tem a percepção de valor é outra. Então, a a percepção de valor não está na automação, mas no sistema completo de crescimento. Por que que ela paga? Porque você vai fazer essa clínica faturar mais. Você vai trazer três pilares para ela aqui, ó. Principais, ó. aumento de aumento de faturamento mais margem e possibilidade de escala. Essa aqui é a língua do empresário. São os três pilares. É a tríade do empresário, escala, faturamento e margem. Pronto, a infra de A você consegue trazer essa visão, entendeu? Então assim, deixa eu deixar aqui um ponto para vocês, ó. Timing tudo. Quem entra cedo, mesmo sem ser perfeito, ganha muito. Quem espera para entrar tarde, mesmo sendo excelente, ganha pouco. Quem chega primeiro, bebe água limpa. Entendeu? Faça como Alex. Começa a ganhar os seus primeiros R$ 50.000. Para de ficar tentando escalar e ganhar 2, 3, R$ 4.000 com IA. Se Ah, tem um outro ponto. Quero ver, quero ver você no dia 4 comigo no meu workshop. Belezinha? Se você gostou desse vídeo, já dá um joinha, já dá um like, já se inscreve no meu canal, já comenta aqui também e me segue lá no Instagram também, fechou? Um abraço. Fica com Deus. Eu espero que vocês tenham entendido o recado e tenham gostado desse vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo defende que a IA está criando uma nova classe de milionários silenciosos, enfatizando a importância de aplicar IA de forma estratégica em nichos específicos com uma infraestrutura integrada, em vez de buscar dinheiro rápido com automação genérica.",
            "resumo": "Este vídeo explica que a inteligência artificial está criando uma nova classe de milionários silenciosos ao exigir menos talento técnico e mais estratégia de aplicação. O apresentador compara dois caminhos de monetização: (1) vender automação genérica (fluxos, N8N, chatbots, microSaaS) para o mundo inteiro; (2) identificar uma dor real em um nicho e construir uma infraestrutura de crescimento que integra IA, CRM e fluxos de trabalho para entregar uma solução de ponta a ponta. Usa o exemplo de Alex, um jovem de 17 anos, que faturou cerca de 50 mil em um mês com duas vendas de 25 mil para especialistas com mentoria já estabelecida, cobrando implantação de 25 mil reais mais uma mensalidade de sustentação. O vídeo alerta sobre saturação de mercado e o avanço de grandes empresas, e anuncia o workshop Growth AI em 4 de outubro, prometendo ensinar a escolher nicho, propor valor e estruturar a infraestrutura de IA para faturar alto.",
            "assunto_principal": "Aplicação estratégica de IA para nichos específicos com infraestrutura integrada, destacando diferenciação entre caminhos de monetização e enfatizando a criação de valor sustentável em vez de dinheiro rápido.",
            "palavras_chave": [
              "Inteligência Artificial",
              "milionários silenciosos",
              "infraestrutura de Inteligência Artificial",
              "Gestão de Relacionamento com o Cliente",
              "fluxo de trabalho",
              "nichos",
              "especialistas",
              "oferta vencedora",
              "rotatividade de clientes",
              "OpenAI",
              "Google",
              "Meta",
              "Crescimento com IA",
              "oficina",
              "faixa de preço",
              "proposta de valor"
            ],
            "resumo_em_topicos": "- Tese central: IA está criando milionários silenciosos quando aplicada com estratégia e infraestrutura, não apenas com automação genérica.\n- Dois caminhos de monetização: (1) automação/genérica para o mundo todo; (2) solução end-to-end para um nicho específico com IA integrada.\n- Exemplo do Alex: jovem de 17 anos, faturou cerca de 50 mil em um mês com duas vendas de 25 mil para experts com mentoria já estabelecida.\n- Nicho-alvo: experts com mentoria e mais de 50 alunos, com ticket alto (25 mil).\n- Infraestrutura proposta: IA + CRM + workflow + inteligência de oferta para reduzir churn, aumentar vendas e melhorar onboarding.\n- Modelo de precificação: implantação de 25 mil reais + mensalidade de sustentação (valor não especificado no vídeo).\n- Advertência ao mercado: saturação crescente e gigantes como OpenAI, Google e Meta com planos de commoditizar funções-chave.\n- Anúncio de evento: workshop Growth AI no dia 4 de outubro, com ingresso de 67 reais, visando ensinar nicho, mercado, valor, e estrutura de IA.\n- Mensagem final: foco na aplicação prática, posicionamento e oferta para transformar IA em negócio lucrativo, não em aprendizado isolado.",
            "prompt_tokens": 2070,
            "completion_tokens": 3204,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 51.271312952041626,
          "language": "",
          "view_count": 2333,
          "has_transcript": false
        },
        {
          "id": "d4qVbWil1R8",
          "title": "A Verdade sobre Vender Automações de IA (Erro de R$ 1.2Mi/ano)",
          "title_pt": "A Verdade sobre Vender Automações de IA (Erro de R$ 1,2 milhão/ano)",
          "url": "https://www.youtube.com/watch?v=d4qVbWil1R8",
          "published": "2025-09-07T00:46:38.542710",
          "published_relative": "há 2 semanas",
          "duration": "24:08",
          "date_published": "2025-09-05T05:01:16-07:00",
          "transcript_available": true,
          "transcript": "Como ganhar dinheiro com inteligência artificial? Assim como você, eu também sou bombardeado por um monte de anúncio. É o dia inteiro, cara. Anúncio de N8N, 2000 fluxos por tantos reais. Automatize a sua empresa, make, crie agentes, agentes é o futuro. Faça isso, faça aquilo, implemente chatbote e tudo mais. Chega a ser absurdo, sabe? Eh, mas se você parar para pensar, vamos lá, friamente, se a gente sentar aqui agora, falar, cara, provavelmente você já comprou algum curso de inteligência artificial, você já comprou, já entrou em comunidades de automação, de no code, por aí vai. Pergunta quantas pessoas dessa comunidade que realmente estão tendo sucesso. Sucesso de verdade, já faturaram, ó, não precisa ser tanto sucesso, já faturaram mais de 1 milhão no ano, sabe? tão fazendo ali faturamentos, vai de acima de 300, 400.000 por mês. Quantas delas que estão fazendo automações com or, com make, com agentes, realmente estão fazendo isso? Eu zero. Eu entrei em algumas e vejo assim, falo: \"Cara, ninguém aqui tá ganhando dinheiro\". Tá todo mundo ali focado realmente em, caraca, olha como que é legal automatizar essa planilha, olha como é legal fazer isso, fazer aquilo. E talvez até você se pergunte falando: \"Cara, será que não dá para ganhar dinheiro com a inteligência artificial? Será que é um hype? Não dá para fazer, não dá para criar algo sustentável aqui que mude a minha vida desse jeito que a galera tá ensinando?\" Não, isso aí é sonho. Agora, dá sim para ganhar muita grana. Esse aqui é o Bruno Bergo, ó, aluno, um dos meus alunos, um dos primeiros que entrou na na Acelera. 40 pau em dois meses. Ele faturou 40.000. Isso aqui foi um contrato com infraestrutura de inteligência artificial. Então ele vendeu para um, ó, quer ver, ó? Tá até aqui, ó. Fábrica de confecção e uma rede de quatro supermercados, tá? Ele fechou, ele fechou. Esse contrato aqui foi da fábrica. [ __ ] olha que legal, 40 pau. Então, dá para ganhar dinheiro com inteligência artificial? Dá. Mas mesmo assim, mesmo eu te mostrando isso, você pode pensar, cara, será que não é um hype? Porque até para quem é super experiente, para quem já é da área da tecnologia, assim como eu, tá difícil de você distinguir o que que é hype ou não. E eu me fiz várias perguntas quando nesse ano, esse ano aqui, por você que deixa eu até me apresentar um pouquinho antes, para você que não me conhece, tá me assistindo pela primeira vez, meu nome é Kelvin, eu sou um ex-programador empreendedor. Eu programo já tem, [ __ ] tem mais de 16 anos. Montei a minha primeira startup lá, ó, dos 20 anos de idade tava querendo empreender. Montei o RP Brasil. 2023 eu montei o Copia e Cola, tudo né? Então tudo quebrado. Mas eu montei a minha primeira eh startup de sucesso em 2015. O nome dela era General Cleans. Ela se tornou uma das principais insurtexs do Brasil. Em 2022 eu fiz a venda de 50.1% da General Clên pro Grupo IS. que eu tinha 30 anos de idade e agora em 2025 eu falei, fiz o meu exit total, saí da empresa e falei: \"Cara, preciso começar alguma coisa nova e alguma coisa nova que tem a ver com o digital e tem a ver com inteligência artificial\". E aí eu montei a acelera 360. Quando eu montei aera 360, ela nasceu em março desse ano. O meu foco foi começar a ensinar programadores a empreender. E aí, quando eu comecei a ensinar programadores a empreender, eu falei: \"Cara, o melhor caminho é empreender com o IA.\" E aí a gente começou a trabalhar com consultorias estratégicas inteligência artificial. Mas eu não queria que esses meus que esses meus alunos começassem a fazer voo de galinha, cara. Vender, tipo, implementar N8N. Isso aí não, isso aí não é sustentável. Isso aí entra nesse ciclo que eu falei aqui para vocês, ó. Quantos, quanto dessas galera, dessa galera aqui realmente ganha dinheiro, faz grana com isso? Não faz. Então assim, não fazia sentido. E aí eu coloquei algumas perguntas, né? Vamos responder elas juntas, inclusive aqui. Como que a gente pode ganhar dinheiro com o IA? Eh, como que a gente consegue também criar algum sólido? Então, é ganhar dinheiro e criar algo sólido. E como no processo a gente não quebra, porque tá mudando muito rápido. Então, como que a gente não fica obsoleto nesse processo de criar um negócio com inteligência artificial? E aí perguntando aquilo, eu falei: \"Cara, quem realmente tá ganhando hoje dinheiro com IA, né? Quem que são as pessoas que tm mais chance de fazer dinheiro com IA? Quem quer ficar rico rápido. Então a galera que quer ganhar dinheiro de em 6 meses, se meses fazer 1 milhão, 2 milhões, 3 milhões, 10 milhões, que é meio aquele sonho do do marketing digital de lançamento e tudo mais, ou pessoas experientes com no e um determinado nicho. Então vamos entender qual que é a real oportunidade da IA. Deixa eu dar um zoom aqui, ó. A maioria das pessoas elas estão pensando que é automação com N8N, com make, integração com chatbot, pá pá pá. Elas acham que é implementar IA, chatbot de IA, usar o 11 Labs, usar o Tulho, chat base e evolution API para integrar isso no WhatsApp. Isso, isso, isso não é a real oportunidade com inteligência artificial. Isso aí é commodity. Isso aí você acha pessoas, deixa eu me posicionar de uma forma melhor aqui, porque eu tô com a caneta. Eu quero, deixa eu encaixar isso aí. Você acha hoje pessoas que, cadê? Aqui, aqui assim. [ __ ] isso aí, cara, você vê ali, o mercado tá lotado disso. É, compre X000 fluxos de N8N por R$ 100. Entre na minha comunidade, faça 10.000 por mês, vendendo meus fluxos de automação e não sei o que lá. Crie chatbots inteligentes e pá pá, rag, tudo por R9,90. Você acha que isso vai te deixar ric? Não, isso aí comode. Tá todo mundo fazendo isso aí, entendeu? Então é só você olhar para todos os grupos de comunidade, então, grupos e comunidade sobre isso. Entra lá dentro, olha assim, se pergunta quem é que realmente tá fazendo 1 milhão, quem é que fez, quem é que já montou um negócio que bateu 9 milhões por ano com inteligência artificial ou mais de 9 milhões? Quem é que tá montando uma startup que seja sólida com relação a isso? E aí olha também pros fabricantes de inteligência artificial, né? Olha para Open AI, para Eleven Labs, para essa galera que cria a a a IA Prompt, o valor deles está no equity, tá no volume, então tá na alta venda. Tanto que o preço deles é centavos, por mês, 15 por mês, centavos por token, porque eles vendem no volume, então eles vendem na escala. E isso é commodity. pensar nisso me fez pensar o seguinte: se o nosso objetivo aqui é ganhar dinheiro com inteligência artificial e ferramentas não valem nada, então o valor tá onde? O valor tá nas pessoas, nas pessoas que têm ali os melhores insightes, as melhores ideias de aplicação com inteligência artificial, que tem pessoas que t o melhor conhecimento sobre como as ferramentas, como N8N, como Make, como chatbot, como chatbase, como Open como a Cloud, como todas essa cacetada de ferramenta pode trazer ali o máximo de valor para uma pessoa certa, para um mercado certo, para um nicho específico, para resolver uma dor específica. Logo, então, quem que ganha mais, quem que vai ganhar mais dinheiro nesse mundo da inteligência artificial? Quem já é especialista em algo, não só especialista em algo, mas também é visionário. É visionário e já está entrando no mundo da inteligência artificial. E quem que vai ganhar pouco dinheiro? Quem que for novato nessa área, quem tiver pelo hype, quem tiver focando em ganhar dinheiro rápido, isso não existe. Ganhar dinheiro rápido não existe, tá? Não funciona, não é sustentável, não se paga, tá bom? E sempre tem os desconfiados. Então, vou até trouxe alguns casos aqui para eu responder, né? Pensou, penso muito assim, é a nova onda que os vendedores de curso estão surfando agora. Se eu se eu não conhecesse o que eu conheço, talvez eu pensaria igual a ele. Por quê? Porque eu tô sendo inundado de anúncios e as pessoas tentando vender. Fique rico, faça 10.000 por mês, 15.000 por mês automatizando. P p p pa p p pá. Isso. Isso. Assim, você consegue ganhar dinheiro com isso, mas você não consegue criar algo sólido e nem escalável. Você fica refém do negócio todo, né? E não faz muito sentido. O pessoal, ele aqui até comentou, verdade, todo mundo vendendo consultoria. Basicamente a nova forma de pirâmide. Quem chegar primeiro se dá bem, o resto vai se ferrar. Entendo uma coisa, eh, quando eu falo, quando, eh, eu falo de infraestrutura de a aqui para vocês no YouTube, talvez vocês pensem que é só esse o caminho, mas são dois, são dois e passos, né, two steps. Então, primeiro passo, deixa eu dar um zoom aqui maior para eu conseguir riscar, ó. Primeiro passo é você escolher um nicho. Você escolhe um nicho, você estuda esse nicho, você absorve todas as dores desse nicho, você vira especialista desse nicho ou traz um especialista desse nicho, entendeu? Aí você tem um tem todo um método para você fazer isso daqui e aí você envelopa isso aqui dentro de uma infra, uma infra de crescimento usando IA para resolver as dores desse nicho aqui. Ganha dinheiro com isso, fecha clientes, entende? Vai aprimorando e vai melhorando. Vai pegando clientes aqui. E aí você vê o passo dois. Qual que é o passo dois? transforma tudo isso numa solução robusta. Aí aqui você pensa em criar um SAS. Aí aqui você pensa em criar a o seu próprio ecossistema, entendeu? Eh, não dá para você ficar milionário em um mês, nem dois meses, nem 3 meses. Isso é uma construção. No caso da General Cleans, por exemplo, me levou quase 10 anos para que eu saísse desde a fundação da empresa até a venda total. Vendi agora em 2025. Vendi 7 anos para fazer a venda dos primeiros 50.1%, 7 anos para eu conseguir fazer o meu primeiro milhão. Hum. Isso se tornou muito mais rápido com a acelera, por exemplo, eu fiz isso em 7 meses, muito mais rápido, muito mais rápido, você vai aprendendo, entendeu? Então é o mesmo aqui com a infraestrutura de ar, escolhe um nicho, estuda o nicho, vira especialista ou traga um especialista e aí você cria a infra de crescimento e depois transforma isso numa solução. As pessoas acham que em 10 minutos elas acabam julgando toda uma estrutura. É uma besteira. E outro aqui, falou, falou, falou e não entregou nada. Mais um vendedor de sonhos, mas nesse vídeo eu vou entregar e vocês vão ver isso rodando, tá? Para quem não acredita, fica mandando aquelas mensagens, não funciona, é isso, aquilo, aquilo, outro. E tem os que acreditam, tem os que botam a fé e entram, por exemplo, esses daqui são meus alunos, entraram no começo da Acelera quando eu tava ensinando eles a fazer e a testar os nichos com inteligência artificial. Olha isso aqui, ó. Ah, dica docana matador, fechei dois contratinhos esse mês, 30.000. Hein? 30.000 entrando. Nunca imaginei que ia conseguir isso tão rápido. É nós. Vamos embora. Olha esse outro aqui. Deixa eu ver se eu apaguei o número aqui, gente. Ó, minha primeira venda desse mês. 20k. Solução proposta foi integração Figo. Olha isso aqui. Isso aqui tá no ramo médico, tá? Figo é um ERP médico. Ele colocou o chatwot, o go high level, o IA. Então aqui ele criou a solução dele, ó. ali ele criou a infra de A dele e aí depois que essa infra de A tá OK para aquela para aqueles primeiros clientes, ele só sai replicando, entendeu? Aí é 20, 30, 40 e por aí vai. Olha esse outro aqui, pessoal. Agora um relato. Agora, essa semana eu fiz 16.500. Pô, isso é um absurdo. Olha isso. Isso aqui não tem dinheiro que pague, ó. Conseguindo trazer muito mais qualidade de vida para o meu filhinho e para a minha família. Pessoal, é sobre isso. Empreender, é sobre isso. E com a infraestrutura de ars conseguem fazer isso. Esse aqui, ó, é uma entrevista que eu fiz com o Alan e com o Motinha. Olha lá na conta deles, ó. Os moleques estão voando, hein? Esses moleques aqui fecharam contrato esses dias de 16.000 €. Ah, o Mota e o Alan já tem carreira internacional, foram arquiteto de software, então, tipo assim, eles têm, primeiro que falam muito bem, então não tem uma barreira de língua e entendem muito bem do processo e aí viraram experts agora e tão tão voando, tão do [ __ ] Então assim, não é sorte, tá? Isso é tudo tudo é uma estratégia. Tudo tem estratégia. Então, o que eu já falo para vocês é o seguinte, ó. Não vendam ferramentas, não vendam, não foquem e criar um negócio com IA, vendendo commodity, vendendo pecinha, porque isso aí vai fazer vocês serem uns falidos, uns fodidos, frustrado, é o jogo errado, entendeu? Trouxe até uma mensagem aqui, irmão, já pensou em gravar algumas aulas dessas automações no YouTube? É muito diferente do que a maioria ensina. É, eh, não faz sentido eu ensinar vocês a fazer automação, porque não é nisso que tá o dinheiro. O dinheiro tá em você estruturar todo esse conhecimento de um nicho dentro de uma infraestrutura de inteligência artificial. Kelvin, o que que é uma infra? Acabei de chegar nesse vídeo aqui, eu não sei nem do que você tá falando. Então, deixa eu te falar, ó. Você que é novo, já clica em me seguir aqui, já dá um joinha, já comenta e depois maratona meu canal, principalmente pega os últimos vídeos, não vem da gente, né? Não venda ferramenta, venda agentes de ar, não lembro qual que é o termo. Outro é como que eu infraestrutura de varejo. Inclusive vou até mostrar aqui para vocês, para vocês entenderem, para você entender um pouco mais sobre isso que eu tô falando, sobre essa proposta, tá? Mas resumindo, que que é uma infraestrutura? Infraestrutura inteligência artificial é o seguinte, ó. É IA. E aqui a gente tá falando, ó, aqui sim entra lá o chatbot, chatbot. Aqui entra a criação de agentes. Aqui entra um monte de coisa. Aqui processo. Então o desenho de um processo de vendas, playbooks de vendas, por exemplo, treinamento, mas pessoas as pessoas daquela empresa que estão comprando, que elas serão potencializadas porque precisa no final das contas sempre ter pessoas. As pessoas elas têm que ser multiplicadas, tipo assim, uma pessoa tem que valer por 10 com a infraestrutura de a tudo isso aqui focado em trazer crescimento. Crescimento para quem? Para quem comprou, pro B2B. Que que é crescimento pro B2B? Dinheiro, aumento de faturamento ou de margem, entendeu? Tangível, nada de historinha. quando você cria sua infraestrutura, e por isso que é importante você entender, se você é um especialista, cara, é incrível, porque você conhece as dores e isso aqui você consegue fazer, você consegue entender quais são as dores e pensar nas ias e nos processos e nas pessoas usando e o foco no crescimento e o crescimento vindo. Cara, que incrível. Ó, se você, eu postei esse vídeo aqui, cara. Nossa, meu aluno fechou, safado. Nós montamos essa estrutura de A aqui. Ele fechou 79K. 79K. Dava para fechar mais, mas ele negociou bem aqui. Mais 3K de mensalidade, mais 2,5% sobre vendas novas. Ele isso aqui para ele vai dar uns 9k mês, gente. 9K mês é 100k, é sem pau ano, só de um cliente. Aí isso aqui que ele fez para um, ele replica para todos os outros do varejo. Assiste lá, ó. Esse vídeo vale muito a pena. O futuro do varejo com IA vertical em 2025. Muito, muito bom. Mas deixa eu terminar esse vídeo aqui, tá? O pessoal até pergunta às vezes, né, Kelvin, mas cara, porque eu fiz esse vídeo e aqui a gente tá falando de a processo, atendimento, CRM, CRM configurado, aí vídeo sobre como vender para um nicho específico. Aí alguns falam assim: \"Tá, cara, mas a minha dúvida principal é o quão escalável é esse serviço de alta complexidade com IA vertical. Hoje você padroniza o processo ou é totalmente personalizado?\" E aí que entra o principal segredo. Você tem também steps, fases. Na fase um, ele é mais personalizado, por são os principais clientes. É aqui que você vai entender a dor. Aí você vem e produtiza isso na fase dois. Aí na fase três, você cria o quê? Um ecossistema. em cima disso. Então você consegue ganhar nesse passo aqui, ó, você consegue escalar. Então você consegue ter, por exemplo, uma uma infra totalmente escalável. E isso a gente já tem hoje, por exemplo, para clínicas odontológicas. Eu tenho alunos específicos que fazem para clínicas odontológicas, clínicas médicas, hospitalares, ah, tem um monte que agências de marketing, tem de tudo, cada um com seu nicho ou subnicho, entendeu? E esse é o grande X da questão. O Vittor me falou algo interessante aqui também, ó. Ele falou assim, ó. Na moral, se tivesse dando dinheiro, o Kelvin estaria somente vendendo isso e não o curso. Ah, mas quem disse que eu não vendo essa estratégia? Ele falou aqui porque eu falo, geralmente fala que eu aplico, né? E aplico mesmo. Essa estrutura é linda, realmente é o futuro do mercado, mas para deixar isto redondo, ainda mais em uma média empresa, vai muito, mas muito trabalho, no mínimo um ano, pá, pá, pá, é fora os custos e tudo mais. Então, tudo meio ilusório, mas genial ser aplicado. Legal, Víor. Ó, ô fazendo esse vídeo, porque eu vou mostrar isso na prática, rodando para você. Inclusive, Víor, eu quero que você esteja lá, tá? Ã, no dia 30 desse mês, eu vou fazer um workshop e convido todos vocês a participar. O valor é simbólico, acho que vai tá R$ 30, R$ 40. Eu quero que vocês cliquem aqui e garantam o ingresso, porque aqui no dia 30, o link tá aqui na descrição desse vídeo, eu vou mostrar toda essa infraestrutura de inteligência artificial, eu chamo de growth AI, rodando. Então aqui tem uma promessa, né? como transformar seus serviços em sistemas de IA que realmente geram R$ 100 R$ 100.000 todos os meses. Então, o link do meu workshop, esse é o meu primeiro workshop, onde eu vou demonstrar a infraestrutura de inteligência artificial rodando de fim a fim. Vocês vão poder utilizar. Eu vou mostrar, gente. Manda, liga para esse número. Vocês vão ligar, vocês vão ver aí a rodando com casos reais. Rodando. Olha que loucura, hein? No dia 30. Não perca. Qual que é a ideia? Vocês podem pegar isso e aplicar. É igual, é idêntico, saca? E beleza, esse aqui é o primeiro ponto de então tudo meio ilusório. Não, não é ilusório, porque eu vou apresentar para vocês todos os custos também nesse workshop para vocês entenderem como que funciona, como que a conta fecha, tá? H, aí ele comentou aqui o seguinte: se você tivesse dinheiro, eh, se estivesse dando dinheiro mesmo, você não estaria vendendo o curso. Tenta uma coisa, Víor, eh, o negócio ele precisa ser grande. Então, a infra de A, ela tem que ter nichos, ela tem que ser nichada. E é por isso que eu criei o movimento da Acelera 360, porque os meus alunos viraram meus parceiros de negócio. Eles são praticamente meu sócio. Então você que quer, o meu foco é que eu quero que você venha, você que é um especialista, venha pr pra acelera, venha utilizar a infraestrutura de a, porque você conhece um nicho, você conhece uma dor específica e aí a gente pode explorar este mercado em conjunto. E é isso que faz com que a gente possa escalar, criar algo grande. Não dá para dominar, criar algo grande sozinho. Não dá para criar algo grande sozinho, Vittor. O negócio ele precisa ser feito para ser robusto. Saca a história do gigante com pé de barro não faz sentido. Tem que criar algo sólido. E algo sólido você cria com um grupo de pessoas, com duas ou mais pessoas, todas focadas no mesmo objetivo. Então, quando a gente fala, quando eu falo que a IA ela tem que ser nichada, é porque eh imagina assim, ó. Você talvez deve conhecer, você que tá assistindo esse vídeo, não sei se você é de tecnologia ou não, mas imagina assim, ó, você conhece dores específicas do seu nicho, então é mais fácil você pegar essa infra pronta e adaptar ela pro teu nicho e vender a infra de crescimento de pro teu nicho e a gente ganhar junto do que eu tentar vender pro teu nicho. Entendeu? Essa que é a lógica, é dividir para conquistar. Fechou? Espero que eu tenha te respondido bem, Vittor. Você tenha entendido tudo. Então, galera, eu deixo esse convite aqui para vocês. E para quem que é esse workshop? Quem que deve tá lá? Se você tá assistindo e você tem uma agência ou é um consultor, um gestor de tráfego, um consultor empresarial, migrou, tá querendo migrar pra inteligência artificial porque já não tá conseguindo mais crescer no teu mercado, no teu ramo, porque ou já é um mar vermelho, ou o hype já passou, ou você tá sofrendo por alguma obsolescência competitiva, esse workshop é para você, vai te dar uma visão incrível sobre a infraestrutura de inteligência artificial. Você vai poder ver isso na prática. Você que é freelancer, já tá vendendo aí os seus, as suas primeiras IAS, já tá fazendo acontecer, ou é uma urgência de IA, ou é um programador que tá querendo empreender, sabe que a IA tem potencial, mas ainda não sabe como o workshop para você. Então você também pode já ter validado ou tá tendo, você que validou, tá tendo dificuldade de cobrar bem, tá não tá conseguindo, sabe, engatar o preço coerente. Talvez você até escute meus preços aí, os que os meus alunos estão fazendo e falam assim: \"Você é louco, não é mentira isso, não tem como workshop para você, hein? Se você tá lutando também com a falta de leads, esse workshop é para você, porque o próprio conceito do funil que eu vou explicar lá, você pode aplicar e ter resultado. Se você é um expert, expert mesmo do mundo aí do digital, tá querendo, tá, tem o seu, tá, tem a sua própria mentoria, porque se você tem a sua própria mentoria, você já, você já sabe que o seu mercado tem uma dor, quer embalar isso numa infra de A, cara, o workshop é para você. Se você tem muita experiência num mercado, esse workshop é para você. Se você quer empacotar o teu conhecimento numa infraestrutura de a cara, esse workshop é para você, tá? Então, médicos, advogados, consultores, contador, dentista, etc. Fica aqui o meu convite. Se você quer ver o Maiá rodando na prática, a coisa toda acontecendo de forma real e testar, sabe? Olhar e falar: \"Cara, realmente o mundo vai mudar, esse workshop para você\". Você vai clicar no link que tá aqui na descrição desse vídeo, vai cair para dentro. Fechou? Chegou a hora de revelar para você realmente o que que é uma infraestrutura de inteligência artificial de verdade. Se você gostou desse vídeo, se você entendeu, eu quero que você curta, eu quero que você já me siga, que você compartilhe, já vai lá no meu Instagram, já me segue por lá e um abraço e até a próxima. Te vejo dia 30, hein? Você vai ficar abismado com que eu vou mostrar lá. Um abraço. Tchau. Tchau.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Desmistifica o hype de vender automações de IA e defende que lucros sustentáveis vêm de aplicações estratégicas em nichos, não de fluxos prontos.",
            "resumo": "Neste vídeo, Kelvin discute o verdadeiro caminho para lucrar com inteligência artificial, rejeitando o hype de vender automações de IA. Ele observa que somos bombardeados por anúncios de N8N, Make, chatbots e cursos que prometem faturar alto, mas poucos realmente ganham dinheiro de forma estável. Mesmo assim, não é impossível ganhar muito; ele cita Bruno Bergo, aluno da Acelera 360, que faturou 40 mil em dois meses com um contrato de infraestrutura de IA para uma fábrica e uma rede de supermercados. Kelvin, ex-programador e empreendedor, enfatiza que fluxos prontos e fluxos de automação são commodity e insustentáveis a longo prazo. A real oportunidade está em pessoas com insights profundos que sabem aplicar IA a nichos específicos, criando soluções valiosas para problemas reais. Grandes fabricantes de IA ganham pelo equity e pela escala, não por vender pacotes isolados. Portanto, o sucesso vem de especialização, visão e aplicação estratégica, não de ganhos rápidos.",
            "assunto_principal": "Hype de IA versus lucro sustentável; importância de nichos e especialização",
            "palavras_chave": [
              "Inteligência Artificial",
              "automações",
              "N8N",
              "Make",
              "assistentes de chat",
              "expectativa exagerada",
              "lucro sustentável",
              "nichos",
              "especialização",
              "participação acionária",
              "OpenAI",
              "Eleven Labs",
              "consultorias estratégicas",
              "Acelera 360",
              "inovação"
            ],
            "resumo_em_topicos": "- Contexto: inundação de anúncios de IA e promessas rápidas\n- Pergunta: quem realmente ganha dinheiro com IA?\n- Exemplo: Bruno Bergo faturou 40 mil em 2 meses com contrato de infraestrutura de IA\n- Crítica: vender fluxos de automação é commodity e pouco sustentável\n- Proposta: valor vem de especialistas visionários aplicando IA a nichos\n- Observação: equity e escala são diferenciais para grandes players de IA\n- Conclusão: ganhos rápidos não existem; sucesso depende de expertise e aplicação estratégica",
            "prompt_tokens": 2125,
            "completion_tokens": 3206,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 58.537516832351685,
          "language": "",
          "view_count": 1856,
          "has_transcript": false
        },
        {
          "id": "dmLxOFJeYNY",
          "title": "O Futuro do Varejo com IA Vertical em 2025 (Quem Entrar Agora Vai Liderar)",
          "title_pt": "O futuro do varejo com IA vertical em 2025 (quem entrar agora vai liderar)",
          "url": "https://www.youtube.com/watch?v=dmLxOFJeYNY",
          "published": "2025-09-07T00:46:38.542732",
          "published_relative": "há 2 semanas",
          "duration": "44:52",
          "date_published": "2025-09-02T09:01:08-07:00",
          "transcript_available": true,
          "transcript": "Aqui tem todo o desenho do que a gente vai passar aqui nessa aula, tá? Duas coisas mudaram o jogo completamente nos últimos 12 meses. A primeira, você já sabe que são os modelos de inteligência artificial que vem evoluindo drasticamente. A segunda é que chegamos no momento que a gente tá conseguindo escalar serviço com infraestrutura de inteligência artificial. Eu quero que você presta muita atenção nesse vídeo aqui, porque o meu aluno, um dos alunos lá da Acelera, fechou um contrato de R$ 80.000 R$ 1000 de implantação para uma infraestrutura de inteligência artificial voltada para varejo e mensalidades de mais de R$ 4.000. Você quer saber o mais insano? que nós desenhamos esse modelo juntos em aula e ele pegou, aplicou e vendeu. Então assim, nesse vídeo eu vou te mostrar como que ele fez isso, qual que é o contrato, como que você estrutura também a sua IA de Grove voltada pro varejo e o funil de vendas que você tem que vender. É simples assim, ó. Não é sobre nada técnico, não vou explicar sobre Crew AI, Long Chain, N8N, Python, nada disso. Aqui a gente vai falar sobre como você ganha dinheiro com IA. Eu vou explicar todo o modelo, todo o funil, toda a estrutura, toda a explicação de contrato bem detalhada, bem detalhado. Esse vídeo aqui vai dar provavelmente mais que 40 minutos. E se você acompanhar tudo que eu vou falar aqui, se você aplicar o que eu vou falar aqui, você também vai fechar contratos assim, porque o mercado tá precisando disso. Belezinha, vamos começar. Antes de começar, deixa eu me apresentar, muito prazer. Meu nome é Kelvin. Eu sou um programador empreendedor serial. Fundei a General Clans em 2015, a minha primeira startup, uma das principais insuretexs do Brasil. Vim a vender ela em 2022, 50.1% 1% pro grupo IS e vendi o restante agora em 2025. Também fundei a KCG, que é uma consultoria de software e aí um Inspect. E agora eu tô num projeto que é Acelera 360. Se você quiser conhecer mais sobre Acelera 360, o link tá aqui na descrição desse vídeo. Bora meter pressão. Bora lá então. Vamos. Aqui tem todo o desenho do que a gente vai passar aqui nessa aula, tá? uma infraestrutura de growth com inteligência artificial voltada pro varejo. Kelvin, o que que é o varejo? Varejo são essas empresas que vendem produtos ou serviços para o consumidor final diretamente pro CPF, supermercado, loja física, eh eh óticas, eh especialistas de algum determinado produto que vem direto pro CPF, outlet, por aí vai, lojinha. Beleza? E aqui, ó, esse é o contrato que foi assinado, uma implantação de infraestrutura de IA. O valor foi negociado ali de 98 para 78.900, 30% de entrada mais seis vezes no boleto, nesse caso aqui, uma mensalidade fixa de R$ 3.875 fixo por mês, mais um variável de 2,5% de comissão para vendas novas mais recuperação. O que que quer dizer isso daqui? Que essa mensalidade ela varia ali de 3800 e ela tem um um plus de performance que é o quê? Essa infraestrutura de a ela é voltada para crescimento da empresa, para fazer a empresa ganhar mais dinheiro. E eu vou mostrar isso para vocês, para vocês entenderem como foi estruturada essa promessa. E nesse dinheiro novo que vai entrar, que o aquele proprietário não tá contando ainda, o nosso cliente não tá contando, a gente vai ganhar 2,5% de comissão. Kelv, poderia ser mais? Poderia, mas como as margens desse cliente são muito apertadas, a gente optou por deixar em 2,5 de comissão, tá? Se você fechar um contrato desse por mês, no final de 2026, vocês terão faturado praticamente R 1 milhão deais. Entenderam? Entenderam? Mas poderia ser 5%, poderia ser 7%, depende do negócio. Eh, esse preço aqui, ele foi todo calculado com base na energia necessária para desenvolver e aplicar essa infraestrutura mais o que é a energia necessária para manter. Até porque se você não sabe o que que é uma infraestrutura de a, deixa eu te explicar, não é só a IA, é a inteligência artificial, mas processo de vendas, mais ferramentas como CRMs voltadas em dar, em trazer resultado para aquele CNPJ, para aquela empresa que tá contratando. Deixa eu te contar uma coisa, o jeito mais rápido para você ficar rico, para você ganhar dinheiro, é fazer outras pessoas ganharem dinheiro no processo. Então, todo o conceito de infraestrutura de inteligência artificial que eu que eu apresento aqui para vocês, é todo, inclusive não só IA, mas todo modelo de negócio é sempre em criar algo sólido, criar algo que faça o nosso cliente ter retorno, porque a partir do momento que o cliente tem retorno, você vai ter facilidade em vender, você vai ter cases de sucesso e consecutivamente você vai conseguir crescer, você vai conseguir criar uma empresa sólida e grande. Aqui não se trata de criar negócios rápidos, tá? E vamos lá. Aí eu coloquei aqui, ó, customização, mas desenvolvimento, que é fora o que tá desenhado no escopo. Se tiver alguma alteração futura, aí é cobrado por hora, R$ 220 a hora, tá? E quem que é esse cliente desse contrato aqui? Então, o qual que é o cenário? É um cliente que ele fatura ali 380.000 por mês de faturamento. É isso aqui que ele fatura de média, só que ele já teve picos de 700.000 por mês de faturamento com o mesmo time. Então assim, olha o poder de escala que ele tem. As margens líquidas que esse cliente tem hoje, a margem líquida dele é de 14%. Tá tá baixo. Tem tem empresas nesse mercado aqui no mesmo segmento que ele, que tem uns 20%, então tem muito espaço para crescer aqui. Não tá muito baixo, mas tá baixo. Dá para aumentar em muito. Ele tem o e-commerce, só que só 18% dessas vendas vão realmente pro digital com venda direta. O restante ele tem rede social, cai ali 82% dessas vendas via fluxo de WhatsApp. Então a pessoa ela ainda interage com uma pessoa para vender. Significa que 300, dos R$ 380.000, R 311.000 é gerado via WhatsApp. O resto que vai pelo e-commerce. Olha que taxa baixa. Então claramente aqui a o e-commerce não fez diferença nenhuma na vida dele, né? Tá? Ã, então vamos lá. Desses 380.000 que ele gera de dinheiro, sobra 53.000 por mês no caixa da empresa. É uma empresa que tá saudável, entendeu? Deixa eu fazer essa conta certa aqui para ver se tá batendo mesmo. Pera aí, vamos abrir a calculadora aqui. 380.14 R$ 53.200 todos os meses que sobram. Hum. É uma empresa que tá saudável, tá gerando caixa, gera dividendo e tudo mais. Qual que é a minha estratégia de venda, né, que eu auxiliei esse meu aluno aqui, no caso, para implementar nesse cliente, ter que dar ROI. Que que é da ROY? Dar retorno sobre investimento. Então assim, essa esse cliente vai pagar 78.900, no caso antes era 98.000, mas ele tem que ter retorno, ele tem que ter, ele tem que pagar e ele tem que receber. Então, para ele receber aquele dinheiro que ele investiu, a gente tem que aumentar, por exemplo, ou o faturamento dele ou aumentar a margem dele por conta dele tá implementando em A, ou os dois. Então, esse mecanismo de infraestrutura de A que a gente tá fazendo aqui tem que dar dinheiro. Então, qual que é a nossa estratégia de ROI que foi desenhada? A gente vai aumentar em 10% as vendas. Então, depois de implementado essa esse mecanismo de IA aqui e a gente vai passar detalhadamente por ele, vocês vão entender cada etapa, mas antes de entender a etapa, eu quero que vocês entendam a estratégia de precificação. Então vamos lá. Ele vai, depois dele implementar, eh, vamos aumentar em 10% as vendas novas. Então, assim, ó, ele vende 380.000, ele vai passar a vender mais 38.000 1000 por mês. Então vai ser 380 + 38. Ele vai para 418.000 de média de faturamento por mês. E vamos aumentar a margem em mais dois pontos percentuais. Então a margem líquida vai sair de 14% e vai pro e vai pular para 16%. O que vai gerar em vez de hoje ele gera 53.000 1000 por mês de média caindo no sobrando no caixa líquido, tudo pago, tudo pago e ele vai pular para 66. Então é mais R$ 13.000 no bolso deste cliente. Então aqui, se você pegar esse valor assim, eu não sei se você achou alto, se você achou esse valor aqui de implantação alta, falando assim, Kelvin, cara, como fechar um contrato desse? Entenda uma coisa, este preço ele foi calculado e no modelo de apresentação pro cliente nós vamos mostrar o que vai ser feito, que é o que eu vou ensinar vocês a fazer, mas nem se atrelem tanto ao que vai ser feito, e sim ao resultado que vai ser gerado, porque o dinheiro tá nisso. Isso aqui é a língua do empresário. Ele quer, ele não quer saber quanto ele vai gastar, ele quer saber o seguinte, ó. Quanto que ele dá de entrada, cabe no bolso dele as parcelas. E principalmente é quanto que isso aqui vai voltar pro meu bolso. Então a gente tá mostrando para ele, cara, no mínimo mais R$ 13.000, porque assim, tem um gargalo al gigantesco no atendimento, rede social, 82% do seu dinheiro é gerado por aqui. O seu atendente não tá conseguindo dar vazão à quantidade de leads, a um atendimento rápido, não tá tendo conversão, não tá tendo nutrição, sua base de atendimento, ela é pequena. Então assim, esse valor aqui está subdimensionado, a gente consegue aumentar muito mais do que esses 10% aqui, do que esses 2%. E se você pegar esses 78.900 e dividir por 13, você vai chegar ali em torno de seis. Significa que são 6 meses para ele se pagar. O payback calculado é de se a 8 meses, porque nos cálculos a gente acha que a gente vai conseguir aumentar esses números aqui para mais de 15% e isso aqui para mais ou menos uns 3% de margem, pulando para 17% e não 16%. Tá bom? Então vamos lá. Primeira lição que eu dou para vocês, conversa, conversa a língua do empresário. O empresário quer saber do resultado no bolso dele. Mostra para ele que você tem qualidade técnica e também tem a qualidade de negócio de falar assim: \"Cara, eu quero ser teu parceiro nesse negócio e fazer você ganhar mais dinheiro, por isso que eu vou implementar\". Pode ver que até o meu parcelamento tá atrelado, tá atrelado ao meu payback, ao meu tempo de ROY. Por quê? porque eu quero que ele pague o meu o o valor da mensalidade utilizando o próprio dinheiro que a gente vai gerar mais para ele. Conseguiu entender? Eu estou diminuindo aqui praticamente todo o risco. O único ponto que talvez ele fique desconfortável é esse variável de 2,5%. Mas aí como que eu negocio isso? Eu posso aumentar muito o valor da minha mensalidade, negociar, começar negociando ali em R$ 6.000 e aí a gente vem descontando esse valor e coloca o skin the game aqui, ó. Cara, eu vou entrar com você, eu vou abaixar o meu preço, minha mensalidade, o meu fixo mensal, mas eu quero 2,5% em cima das novas vendas e também do recuperado. Conseguiram entender? Show de bola. Tá, Kelvin, e como que é essa infra de growth com AI? Eu vou te mostrar, ela foi determinada, ela foi e destrinchada aqui, ó, em três etapas principais, tá? Então, qual que é a primeira etapa? Primeiro que esse cliente aqui é um cliente que nós analisamos a a dor de mercado, falou: \"Cara, varejo tem dor\". Foi foi feito um processo de codec, prospecção ativa, então entrar em contato com as pessoas. E aí a hora que a gente identificou o cliente, esse meu, no caso, meu aluno, identificou o cliente, ele trouxe, a gente estruturou essa infraestrutura para que ela fosse vendida, tá? E como que ela foi estruturada? Primeira coisa, eh, é feito um diagnóstico inicial para entender qual que é o cenário daquele cliente. Então, no caso, pra gente ter aqueles números ali, entender como precificar, como calcular e como cobrar. Agora, entendeu aquele cenário? O que que a gente vai entregar? Vamos lá. Qual que é a etapa um? Qual que é o cenário do varejo atual no Brasil? Então, cara, varejo é um um mercado, um nicho de que tá nos últimos anos ali, tá vindo com crescimento acelerado, só que 2025 ele tá tendo uma a previsão para 2025 é retrair eh nesse ano, né, e pro ano que vem é ainda ficar um pouquinho menor, ele vai desacelerar, retrair não, desacelerar. Então, por exemplo, crescimento de 0,56 no ano que vem e o modelo de consumo, ele tá mudando. Então, assim, é um mercado que tá sendo alterado, tá tá tá mudando constantemente, principalmente por conta das redes sociais. Só que qual que é o X da questão? Todo mundo vendeu pra galera do varejo que para eles irem pro mundo digital era só colocar criar um e-commerce. E aí eles aumentaram custos com ferramenta, mas não teve retorno nenhum. Então eles têm uma dor muito grande com e-commerce e com tráfego pago. Por quê? Porque joga-se muito dinheiro em tráfego pago para jogar para dentro do e-commerce e as conversões são baixas, literalmente baixas. Os caras sofrem muito, muito, muito com e-commerce. Fora isso, tem uma falta gigantesca de inteligência de dados dos clientes e de vendas. Qual que é o perfil do meu cliente? Qual que é o ICP do meu cliente? Que produto que ele compra, quando que ele compra, qual que é a sazonalidade? Ninguém analisa isso. Não tô falando dos grandes, tá? Tô falando desse tipo de cliente aqui, ó. Esse tipo de cliente aqui, faturamento de 4 milhões e meio ano, 5 milhões no máximo, ele é pequeno ainda, entendeu? Então não é gigantesco. Então eles têm essa dor. Uma baixa personalização no atendimento. Atendimento é ridículo, só você tentar comprar que você vai ver. Deixa eu ver se tá gravando certinho aqui. Deixa eu abrir um parênteses aqui para você. Entenda uma coisa, ó. Aqui a gente tá falando de você criar um business que seja robusto, que você tenha preço competitivo, ou melhor competitivo não, um preço diferenciado para que você entregue valor pro teu cliente, para que você cobre um valor correto, até para você ter margem no teu negócio, para você poder crescer, para que você, para que esse seu negócio te sustente, faça você realmente não ser um empreendedor frustrado, igual tantos outros por aí. Então, se você quiser aprender a criar um negócio de verdade, você vai entrar na Acelera 360. Acelera 360 é para você. Você vai clicar no link aqui na descrição desse vídeo, porque lá eu te ajudo a fazer isso. Inclusive, eu tô montando a minha para fornecer isso aqui pros meus alunos, tá? Para eles poderem revender no mercado, porque isso aqui é o futuro. O mercado está mudando, o modelo AI first tá vindo para quebrar tudo. As empresas têm que se adequar, quem não se adequar vai morrer. Então essa é a hora de você aproveitar e botar para quebrar. Aproveita para entrar agora no mercado enquanto isso aqui não tá explodido, porque a hora que explodir vai ser tarde demais para você. Não perca. Isso aqui é literalmente uma revolução. Bora voltar. Estoques mal otimizados, mal gerenciados, só que assim, não vamos mexer em estoque, dá trabalho. Nosso foco dessa IAD growth é venda, não é estoque, não é pós-venda, não é a entrega, entendeu? Então assim, ela é uma IA, essa essa estrutura aqui, IA não, essa infraestrutura que é a IA mais o processo, elas estão sendo desenhadas para aumentar as vendas. É isso que ela resolve, tá? Dependências de promoções genéricas para vendas. Outra coisa, o pessoal depende muito de promoção genérica. Ah, qualquer coisa tá entrando com 10% de desconto, 15% de desconto, o estoque fica atolado lá, fica velho e, cara, tem que desovar, então toma ele desconto. Não tem estratégia nenhuma, né? E uma uma equipe operacional muito sobrecarregada, com tarefas repetitivas e principalmente um time de vendas no varejo é péssimo. Pessoal de teleendimento péssimo, não sabem vender. Então, o objetivo dessa infraestrutura é o quê? aumentar o ticket média, a frequência de compra, reduzir perdas e estoques encalhados. Só que, ó, esse ponto aqui foi despriorizado. Esse ponto aqui foi despriorizado. Vou colocar em vermelho. Gerar campanhas automatizadas e personalizadas com base comportamento. Automatizar atendimento e conversão e gerar dashboards de decisão com base de dados reais em tempo real sendo analisada. Então, um cara tem inteligência de dados, tá? Então, esse aqui é a primeira etapa. Depois do diagnóstico, como que entrou? etapa dois. Aí aqui a gente vem e estrutura o a infraestrutura. Então vamos lá. Primeira coisa, qual que é o nome dessa solução? Essa aqui, por exemplo, Retail Scaler AI. Nossa, esse nome ficou gigante. Qual que é o pilar um? Pilar um ea para aumento, eh, para atendimento de vendas. Esse aqui é o principal pilar, galera. Eu vou entrar aqui, ó, principalmente ness nesse vídeo, eu não vou entrar na parte técnica, mas eu vou falar para vocês as ferramentas que vocês podem utilizar. Isso aqui já vai dar um adianto gigantesco. Por exemplo, nessa estrutura aqui, a gente decidiu utilizar o CRM, o GHL, não sei se vocês já ouviram falar, chama-se Go High Level. Muito bom. Por conta das otimizações que a gente conseguia criar dentro desse desse CRM. a gente pegou um modelo lá de $98, se eu não me engano. Eh, ele é um CRM que ele tem um modelo mais white label, só que a gente nem pegou por causa do white label, a gente pegou por conta da estrutura de planner que tem dentro dele. No final das contas, a gente ia acabar economizando, eh, usando o GHL, tá? Nesse caso. Então, vamos lá. Pilar, poderia ser outro CRM, poderia, poderia ser qualquer outro. O GHL foi estruturalmente pensado para isso e também esse meu aluno já tem a licença do GH. Então, serve perfeitamente. Qual que é o pilar um? Iá para atendimento. Por que que i para atendimento? 82% das vendas segue fluxo via WhatsApp. Então, como que é saiar para atendimento? Então o foco é em aqui, ó, objetivo: capturar mais vendas e eliminar perdas de oportunidade no ponto de contato com o cliente. Mecanismo: Iar de voz para WhatsApp e telefone. Pessoa não tá respondendo, liga com uma I de voz, literalmente assim, ó. Ligou usando, por exemplo, Sync Flow mais o Twil, nesse caso aqui. Integração. Atendeu, atualiza o CRM. CRM nesse caso é a base de verdade, é o coração desse processo de venda. CRM aqui é o GHL chatbot com personalizada plugada no WhatsApp e também no Instagram. No Instagram a gente usou, vai usar o Mini Chat nesse caso aqui. E aqui usa o Assistable mais um um um GPT customizado. E esse chatbot vai est no site, no WhatsApp e no Instagram. Reativação automática de leads antigos usando o CRMs workflows, que é o workflow do CRM, mais o GPT 4 para 4 aqui nesse caso e sempre atualizando o CRM. Qual que é o foco aqui? Reativação de automática de leads antigos. É, cara, temos uma base gigantesca de lead, cara. Vamos disparar para todo mundo a jornada inteira. Aí aqui tem uma outra ferramenta que a gente colocou aqui que não tá, que é o brevo, o brevo para fazer disparo aqui de de e-mail usando e-mail transacional, que é para o e-mail não cair na na na blacklist, na Espanha, por aí vai. Ou usando aqui também a mail, que também é muito boa para isso, para fazer as campanhas. Mas qual que é a ideia? Reativar esses leads e nutrir. É fazer o processo de nutrição e ficar mantendo esses caras aqui também. Nesse caso aqui ele não entrou, mas ele poderia ter entrado, tá? Que é a nutrição via grupo de WhatsApp. Então é uma estratégia aqui no Brasil funciona muito e para esse tamanho de varejo também funciona muito, que é manter um grupo do WhatsApp ali com novidades. Poderia ter colocado um grupo aqui, tá? Então, basicamente nessa etapa um, IA para atendimento e venda seria esse essa etapa aqui. Junto com isso, você tem que entender o seguinte, ó, que aqui não entra só a IA, entra a o mecanismo, né, as ferramentas, mas um ponto muito importante de detalhar para vocês é o fluxo. Todo o processo de funil de vendas aqui, ele tá desenhado já para atender, tá? Isso aqui é composição da infraestrutura. Então, entrou essa IA, olha que loucura, entrou a IA aqui, ó, entrou o processo e entrou a ferramenta, ferramenta de mercado, no caso aqui é o GHL, o Go High Level, esses três aqui pra gente trazer o resultado absurdo, aquele resultado inteiro aqui, ó, porque provavelmente a gente vai puxar a grande parte só dessa área de atendimento, só desse módulo aqui. Qual que é o outro ponto? Pilar dois e a para campanhas e ofertas inteligentes. Por exemplo, esses caras aqui, eles gastam ali em média R$ 3.000 por mês de agência de marketing, fora o tráfego pago, que praticamente já é a mensalidade aquilo que o meu aluno vai cobrar. Então, qual que é a ideia, cara? Vamos cortar a agência de marketing nesse caso, e a gente vai ensinar essa própria pessoa, essa uma pessoa de dentro da empresa a cuidar da agência de marketing, então ou a cuidar do marketing no caso, né? Então a gente vai estruturar aqui uma geração automática de ofertas semanais com IA. A gente vai deixar as IAs prontas, a gente vai usar para isso o prompt GPT, mais uma tabela, uma planilha no Google Sheets, né, no no Excel do Google mais o CRM. Eh, a gente vai utilizar aqui o N8 Make para fazer este processo. Então, olha que legal, com essa planilha aqui a gente já vai meter uma geração de de ads, imagens e propagandas e criativos, por exemplo, usando aqui o AD Creative ou Creativey ou por exemplo, para quem não conhece, ó, deixa eu até mostrar aqui, deixa eu ver o AD Creative. Você consegue com essa ferramenta gerar posts automáticos, ó. mostrar que a gente já tem isso aqui tudo integrado com fluxos, né? Então você coloca o seu logo, o tamanho que você quer gerar, o texto e a imagem, ele monta já as imagens aqui de criativos para você. E é extrema, é uma qualidade assim absurda e ela monta muito rápido. Então isso já traz muito retorno. Pessoal de marketing cobra uma fortuna para isso, não precisa, entendeu? Se tiver algum caso ou outro, aciona alguém diretamente para gerar ali uma imagem, cobra R$ 50, R$ 40. Qual que é o grande foco? Olha que doideira. Nesse caso, o próprio cliente, ele vai internalizar com esse pilar o time de marketing dele. Então, ele vai economizar ali, ó, 3K e ele vai ter a proeficiência, um saving aqui de 3K. E ele vai ter a proeficiência de poder fazer isso ele mesmo. Olha que bacana, cara. Ó, falar para você, hein? Se as agências de marketing não se reinventarem, isso aqui é o cenário comum. O próprio empresário absorvendo a parte de marketing dele. Marketing é core business, então tem que ser absorvido, sim. Tem que ter de forma interna, tá? Ã, que mais? Segmentação com base em histórico de compra. Então, a gente vai segmentar todos os clientes ali usando Big Query com base histórico de compra e atualizar o CRM. Para quê? Para sempre ajustar as campanhas por período. Entendeu a estratégia? Você acha que as empresas de marketing faz isso? Não, não faz. Envio automático por e-mail e WhatsApp usando enertu Brev ou High Code também aqui. Integração via API. Quer fazer o quê? As jornadas disparadas. Fulano, você comprou tal roupa há tanto tempo, estamos com uma promoção aqui especificamente sobre isso, a gente sabe que você gosta, tem interesse, cara. O que a gente vai puxar de venda aqui nessa nesse bloco não tá escrito. Deixa eu ver se tá gravando a tela certa, tá? Entendeu? Então aqui, ó, entrega final, sistema de campanhas semanais com promos prontos, sistema de envio inteligente baseado em comportamento, painel de performance por campanha. Então vai conseguir acompanhar toda a campanha. Kelvin, mas e subir o tráfego pago no MetaS? No Google Ads? Cara, essa a parte mais simples, né, gente? Você criar lá as campanhas e segmentar o seu público. Se você tiver a estratégia correta e entender, é a coisa mais simples, grava vídeo e ensina o cliente a usar e faz ali um acompanhamento semanal. Ah, mas não sei fazer. Contrata um gestor de tráfego, pede para ele treinar o teu cliente para isso que vai sair mais barato, absorve no preço, entendeu? Porque você faz uma vez só, depois que você aprendeu já era. Ou aprende você mesmo também, que pra gente não tem segredo. Estamos criando iar, velho. Você acha que o segredo é subir campanha? Cada vez mais Google Ads, Meta tá ficando mais inteligente para ele mesmo entender qual que é o melhor público para fazer a segmentação necessária. Não tem segredo isso aqui. Isso aqui não tem segredo não. Pessoal de marketing aqui me desculpe. Pilar três e a para estoque inteligente. Essa aqui vamos deixar de fora. Por quê? porque foi mapeada, mas foi completamente por conta da complexidade e necessidade de integração com o sistema com o ERP da empresa nesse caso. E assim, o estoque ele depende muito de pessoas atualizando. Se não atualizar ele não funciona. Então aqui a foi o melhor dos mundos que a gente fez o mapeamento. Por exemplo, previsão de demandas com IA, alertas automatizados para produtos parados, recomendação de reposição com base histórico. Cara, isso aqui é mais PowerBI e puxar dados do RP do sistema, da saída, né, da saída do do estoque do que qualquer outra coisa. E o pilar quatro, esse pilar é extremamente importante, que é o seguinte, é uma IA para decisões estratégicas, mas não só a IA, e sim a construção de um dashboard. Então, dashboard estratégico com IA usando Look, Power BI, integrações de dados via Zapper, via PI, ter esses dados na mão e principalmente ensinar, que é mais o sales ops, né? Então, ensinar aquele cliente a ver os dados dele, enxergar aqueles números na operação para ele acompanhar linha a linha. geração de insightes com IA com linguagem eh natural colocar um GPT dentro do do PowerBi ou do big data ou do do da do do DW deles, entendeu? GPT planilha mais banco de dados e automação e relatórios semanais automatizados. Aqui a gente usa click e o Notion mais o e-mail para disparar tudo isso e aí integração via automação, né? Então é trazer, ó, por exemplo, uma visão real, vendas, estoques e lucro, a geração automática de decisões e recomendados sobre toda semana e reportes automatizados pro dono, pro gerente, é trazer vida, número pra operação, porque se você constrói isso, o que que você consegue dar pro seu cliente? Você consegue dar uma visão de que você tá dando retorno, para você que tá me assistindo, isso aqui é muito importante, entendeu? Deixa eu te falar uma outra coisa. Se você quer entender a como construir infraestrutura de, se você quer cair pro mundo da inteligência artificial desse jeito, criando modelos de negócios que sejam escaláveis, que dê dinheiro para você, que você consiga criar uma empresa de verdade, Acelera para você. Você vai clicar no link que tá aqui na descrição desse vídeo, porque lá na Acelera eu te ensino a empreender desse jeito, criar algo sólido, algo robusto. Não tô falando de você criar chatbotzinha tô indo, não. Tô falando de você criar algo realmente robusto para o mercado que tá em extrema transformação, hein. P, se você é empresário, o recado para você agora que tem empresa, que tem negócio, tá na hora de você implementar inteligência artificial de verdade no teu negócio, implementar uma infraestrutura de A que vai fazer você crescer e que vai fazer você performar, porque o modelo de IA não é só hype. Você não tá entendendo que se você não implementar isso, o teu concorrente vai implementar e ele vai te destruir. Você vai sofrer um negócio chamado obsolescência competitiva, que é o quê? Quando você se torna irrelevante, teu processo é tão lento, tão manual, que você tá literalmente irrelevante perante a sua concorrência. Se você não quer que isso aconteça com a sua empresa, com o teu negócio, você vai clicar no link aqui na descrição desse vídeo e vai cair dentro da Acelera 360. Lá na Acelera 360, os meus alunos vão te ajudar porque eles sabem fazer infraestruturas de inteligência artificial que te dão retorno, que fazem você realmente ter retorno com IA aplicada de forma real no teu negócio. Fechou? É isso. Bora continuar essa aula aqui. Então, vamos lá. Qual que é a etapa três, galera? Ó, passamos aqui então pelos três, pelos quatro principais pilares, que é atendimento, campanhas de ofertas, mais a parte do estoque que foi desporizada e a ali pra decisão estratégica. Qual que é a etapa quatro? você estruturar completamente o funil para o varejo. Então, olha que doido, esse cliente ele não comprou sua ferramenta, ele comprou o processo, pronto, um processo que funciona, que vai dar retorno para ele. É isso que eu falo para vocês. Vocês entendem como não é só fazer um fluxo de N8N, que não é só fazer um make com automação no make, que não é só isso, que tem muito mais por de trás. Para que você possa ter confiança de dar esse retorno aqui, cara, você tem que fazer, você tem que entregar junto um processo, você tem que entregar junto um treinamento, você tem que fazer o acompanhamento do teu cliente para que para que ele ganhe dinheiro. A hora que ele ganhar dinheiro, você vai ganhar também. E aí é lindo, maravilhoso, né? Aí todas as partes ganham. Então vamos lá. Topo de funil. Topo de funil é atração e captação. O que que a gente, que que a gente entra? Quais são as estratégias? Oferta isca, 10% off na primeira compra. Olha aqui. Isso aqui a gente dá tudo pros nossos alunos, tá? A gente já, isso aqui já tá tudo pronto. Isso aqui já é documento, documento atrás de documento mastigadinho, ó. Funil de venda para clínica. Vamos, tem um monte de coisa aqui. Então, vamos lá. Ah, anúncios concreativos gerados por IA. Mesma coisa. Usa as ferramentas de IA, igual, por exemplo, essa daqui, ó. Inclusive, se você tá assistindo esse vídeo, já pesquise essa decreative aqui, que é muito boa. Só que a gente tem uma um mecanismo para que gere as ofertas, porque o anúncio ele precisa de uma oferta, ele precisa de um texto lá, é aquilo lá que vende. E a gente já tem isso aqui pronto. Qode na loja para capturar quem passa. Então, outro estratégia lá dentro da loja no QRC, bateu no QR code, joga para dentro do CRM. Olha aqui a parte física se inteirando com a parte digital, entendeu? Aí já joga direto no funil, já cai no WhatsApp, já cai nas jornadas e por aí vai. E a que responde dúvida direto no anúncio. Então o cara clica ali, já tira dúvida, já cai no WhatsApp totalmente direto aqui usando metal s flow, saca? Aí depois etapa dois, meio de funil, conversão e acompanhamento. E aqui a gente primeiro atrai, legal. Agora a gente tem que converter. O cara entrou, ele tem que sair, né? E ele só sai com a venda. Então qual que é a estratégia? E ad voz ou chatbot para fazer oferta, tirar dúvidas. Caiu no funil. Don tá respondendo. Telefone tocou. Fala Kelvin. Já comprou aquela blusinha? Não comprou ainda? Pô cara, vou te mandar um link aí agora para você ver um vídeo que nós fizemos daquela blusinha. Tá bom? Olha que legal. Isso é diferente. Isso é você mudar o modelo de consumo de informação. Você liga e você manda o WhatsApp. Pode mandar áudio no WhatsApp também e o vídeo. Olha que louco. Entendeu? Venda cruzada com base histórico. ninguém tem isso. Ninguém tem isso. Que loja que vocês conhecem que tem isso? Que varejo que tem isso hoje? Só grandes ecommerces. E olha lá, sequência de urgência, último dia, é última hora, é última unidade. Tudo isso pronto é trazer os modelos que funcionam no mundo digital para um varejo. Cara, por isso que eu tô falando para vocês, agências de marketing vão desaparecer, tá? estruturou o meio de funil, aí cai pro fundo de funil. Retenção e recompra. Que que é retenção e recompra? Estratégias, as ferramentas e a descrição aqui, ó. Envio semanal de campanhas personalizadas com IA. Reativação automática após 30, 60 e 90 dias sem compra. Olha que loucura. Tô falando de de eu reativar um cara de 30 dias após, 60 dias após, 90 dias após a última chamada, entendeu? Tudo conectado dentro do CRM. Isso é qualidade. Isso aqui traz Roy. Isso aqui vende. Kelvin. Vai ficar muito caro o custo por mês. Não vai. Isso aqui vai dar uns 100 150 de de Open AI. Uns $ de vai tudo aqui deve dar uns 400, 500. Tudo tudo tudo tudo contando com servidor, token, chama API, tweler e por aí vai. No máximo, no máximo, no máximo, no máximo. E outra que dê mais é porque o volume é maior. Então é só colocar isso aí no custo, no CAC, e vai fechar a conta. No final das contas, a conta fecha, tá? Programa de fidelidade com IA integrado com NAL, Clickup, Cadernetinho. Pô, você comprou hoje, compra semana que vem, desconto de aniversário. tem cara infinidades de estratégias. Qual que é a etapa três? Estrutura completa de funil pro varejo. Pronto. Isso aqui é uma infra de ar. Agora, se você, cara, você só, você só tem que aplicar o que eu desenhei aqui, só isso. Você não tem que fazer mais nada e entrar na acelera, né? Entra em contato com as lojas de varejo, coloca eles para dentro, faz o diagnóstico e oferece isso aqui do jeito que eu fiz aqui. Tá pronto, tá validado. Gente, você entende que tá validado, sabe o que é validado? É contrato fechado. Isso aqui já tá sendo feito por um aluno meu. É só você fazer também. Não tem segredo, entendeu? Kelvin, não consigo fazer. Então, acelera, cai aqui para dentro que nós te ajuda. Legal, Kelv, agora que que é esse passo a passo aí. Aí, aqui a gente vai entrar, por exemplo, no detalhamento do funil, ó. Vou mostrar aqui para vocês agora. Essa aula aqui vai ficar grande, mas é porque é um conteúdo que eu prometi que eu ia fazer de forma detalhado para vocês. Então, eu vou mostrar toda a trajetória dentro do funil dessa máquina rodando para que vocês entendam isso, tá? De novo, ó, clica no link aqui na descrição desse vídeo e cai para dentro da Acelera. Vem conhecer a Acelera 360. Você vai ver como que funciona o rolê. Então vamos lá. Topo de funil, atração e captação. Foco, transformar desconhecidos em leades qualificados. Como que isso aqui acontece? Primeiro passo, etapa, criação de criativos e anúncios com IA. Então, qual que é o objetivo? Gerar cliques e capturar dados com auto CTR, tá? Então, como que ele faz isso? A gente vai mapear, coletar ali os 20 melhores criativos de varejo no segmento, moda, perfumaria e por aí vai. Calvin, como assim? Deixa eu mostrar para vocês, ó. Você, como vendedor de infraestrutura de ar, você vai vender um modelo de negócio que funciona. Então, você tem que fazer isso aqui pro seu cliente. Entra nos funil concorrentes dele e mapea tudo, ó. Ou vem na acelera que a gente tem tudo mapeado, tá vendo? Não vou não vou dar zoom no detalhe, mas que que nós fizemos aqui? Entramos nos funis, fomos seguindo, pegando as cópias, entendendo como que fazia todo o processo para clínicas, porque a gente tem uma outra IA específica para clínica, entendeu? Mapeia tudo. Próximo passo, criar um prompt para GPT para gerar variações com base nos melhores desempenhos. Então, tudo isso aqui você gera texto e aí você vai treinar um GPT com esse texto que foi gerado para que ele crie variações com as especificidades do seu cliente, no caso desse cliente aqui, que vai fazer a geração desses conteúdos ali com base no melhor desempenho. Então, olha que legal, o conteúdo que ela gerar, a gente vai entrar aqui na ferramenta e vai pedir para ela montar pra gente as imagens, os vídeos e por aí vai. Então, ó, usar o AD Creative para gerar automaticamente variações visuais com headlines e CTA diferente e aí testar no MetaS com a segmentação de geolocalização raio de 3 km da loja. É, é só executar isso daqui, ó. Vocês entenderam o passo a passo? Para cada item desse, ó, isso aqui é material, isso aqui é agente. Isso aqui é manual. Isso aqui é manual com tutorial ensinando a fazer. Entenderam? Já tem a parte da criativos com anúncio, com IA e já tem o funil porque o cara vai clicar, vai cair no CRM porque o CRM já vai vir configurado. Etapa dois, landing page ou link da oferta. Ó, rodou o criativo. Clicou no criativo, cria uma landing page simples no CRM com headline clara, mas benefício direto. Ganhe 15% off na primeira compra. Integra com WhatsApp via botão. Tem interesse, chama no WhatsApp, joga pro WhatsApp. Após a captura, redireciona para o WhatsApp com automação ativa de IA de atendimento. Aí aqui entra, aqui é o chatbot, ó. Ó o shortbot aqui. Vocês estão vendo o que que é um um processo AI first? Tão entendendo o que que é um processo AI first? É isso aqui. Olha aqui o desenho, gente. Tô passando para vocês o ouro aqui, hein. Passo três, QR codes estratégicos. Então, gera o QRcode com.Ou direcionando a mesma pra mesma landing page. Coloca esse daí na onde? Nas lojas, ó. Coloqua em locais estratégicos da loja, da vitrine, sacola e por aí vai. Por quê? Porque a pessoa tá lá na loja física, puf, ler o QR code, ela cai dentro do teu processo, dentro do teu processo digital. Mensagem clara: scane e ganhe algo exclusivo para ela ler e clicar. Olha a estratégia, gente. Tá pronto. Tô dando para você o ouro. Meio do funil, conversão. Vamos lá. O cara caiu para dentro do CRM. Passo um, automatização com IA. Texto e voz. Ó, aqui, ó. Criar árvore de diálogo com GPT para receber o lead, apresentar oferta, tirar dúvidas, direcionar as ações à ação final, loja física ou link de pagamento. Aí aqui é no vend agentes, não é um agente só. Se você fizer em um agente só, ele vai se perder, ele não vai conseguir entregar uma boa qualidade. Para aparecer um agente que realmente não seja parecido com o robô, tem que ser nuvem de agente. Microagentes, todos coordenados por um agente principal. Se você não entendeu, acesse meu último vídeo aí que você vai entender um pouco mais. Depois, escolhe o canal ideal, WhatsApp, Instagram ou site. Três, usar o Sfow para voz no assistable, para chatbot. Isso aqui é para fazer ligação, ó. Bem legal, ó. Que tá escrito errado. Nesse caso, a gente tá usando o 11 labs diretamente, mas o assistible. Assistable.aiaii AI ele é como se fosse um elevs, só que ele já é integrado, por exemplo, no CRM que a gente tá usando, que é o GHL. Então, facilita muito. Só que nesse caso aqui, a gente preferiu usar o o Eleven Labs mesmo. Você pode usar também a mesma coisa. Integrar com CRM para registrar a conversão. Então, tudo isso aqui tá sendo atualizado no CRM. Passo 2.1, 2.12 cross selling com IA. O que que é o cross selling, gente? aumentar o ticket médio. Então, faz venda casada. Se você, o cara comprou X, recomenda a Y, tenta vender a mais, adicional. Aí a tem que tá preparado para isso. Nesse mesmo agente aqui, ó, que ele já manda o link, ele tem a opção também de um agente que faz o crosselling. Você não quer adicionar mais esse item por tanto ou compra mais isso, faça mais aquilo, entendeu? Se você já, se ele comprou X, recomenda Y com base de dado histórico. Então, base de produtos e cliente demonstrou interesse, roda script de GPT com se comprou X, recomende Y. Passo dois, montar automação com essas ofertas via WhatsApp, e-mail. cara, isso aqui é ai top. Personalize a COP com o nome produto mais a urgência. De novo, o agente faz isso. Passo três, sequência de conversão automática. Criar trainer, três mensagens automática. Uma hora após o interesse, seu desconto está quase acabando. 12 horas após, última chance, você ainda tem 15% off. 24 horas depois, oferta encerrada, mas temos algo novo. Isso aqui é isso aqui, isso aqui é ouro. Ouro. Vamos lá. Eh, sequência de conversão. Ah, tá. Uso o CRM mais fluxo com timers para fazer aquilo ali. Medir conversão em cada etapa. Tem que tá na ponta da língua ali. Qual que é o processo de conversão? Número BI. Meio do funil aqui. Tá. Agora fundo de funil e último pra gente encerrar. Campanhas semanais com IA. Criar quatro promps GPT. Campanha com base em produto de destaque campanha com base em estação. Verão ou inverno. Campanha com base em comportamento. Você comprou o X há 30 dias. Campanha de urgência. Alimentar a base semanal com no CRM com essas campanhas. Nossa, já cansei de falar. Vamos lá. Automatizar envio via WhatsApp e SMS e-mail. Top. Monitorar CTR e vendas. Top. Depois reativação de clientes inativos. Criar automação que dispara após 30 dias sem compra. pró 60 dias sem clique. Entenda uma coisa, não tem lead perdido, não existe no varejo não existe lead perdido. O cara clicou uma vez, você enche o saco dele pro resto da vida, entendeu? Cria um lead scoring lá, alguma coisa do tipo, até para você não gastar dinheiro à toa, né? Mas entenda uma coisa, se o cara tá consumindo teu conteúdo, não importa se ele não compra o agora, às vezes o ciclo de compra é de um mês, dois meses, enche o saco dele do mesmo jeito. Às vezes ela é sazonal, você vai ter que entender o comportamento de compra. enviar campanhas personalizadas com novos produtos ou benefícios. Você sumiu. Cadê você? Iak gera mensagens baseada no perfil do cliente. Nossa, isso aqui é Isso aqui é Isso aqui é Imagina só você ter uma hag com todos os clientes, com tudo que foi consumido, todo o detalhe. E aí você chama a da Iá lá para fazer a cópia. Eu vou falar pro cliente tal. Ele vai lá e lindo, lindo, lindo, lindo, lindo, lindo. Vamos lá. Programa de fidelidade gamificado. Criar sistema simples de ponto por compra. R$ 1 um ponto. E há que envia alertas de saldo. Você tem 460 pontos. Troque X. Olha aqui, que louco, uma um programa de fidelidade digitalizado, automatização de envio de rank, desafio e bônus por tempo limitado. Então assim, ó, aqui tá o desenho passo a passo de um funil e aqui tá toda a infraestrutura de para growth focada no varejo. Aqui tá desenhado para você como você escala esse preço. Agora você já entendeu que está de graça para tudo isso que entrega, não é verdade? Então, só que entenda uma coisa, pega o primeiro cliente, depois você replica e aí os outros é contrl C, conttrol V, margens absurdas, tempo infinitamente menor de implantação e por aí vai. Então assim, ó, aqui isso aqui que eu apresentei para vocês é tudo que vocês precisam para começar o seu negócio de inteligência artificial. Se você fechar um contrato desse por mês, no final de 2026, vocês terão faturado praticamente R 1 milhão deais. Entenderam? Entenderam? Que emprego na face da terra daria isso para você? Nenhum. Quais oportunidades isso pode te abrir no meio do caminho? Várias. N Kelvin, como eu prospecto meus primeiros clientes, prospecção ativa, ligação, telefone, code, code cal e vai embora, cai para dentro, roda tráfego. Kelvin, sou empresário, o que que eu faço? Implanto inteligência artificial de forma real para dar ROI pro teu negócio. Se você não sabe como fazer, você vai clicar no link aqui na descrição desse vídeo, vai cair dentro da acelera, que lá a gente vai te ajudar. Kelvin, quero empreender. Que que eu faço? Entra na acelera lá, eu te ajudo também, rapaziada. Foi isso, senhoritas. Foi isso. Espero que vocês tenham gostado. Eh, apliquem o que eu expliquei aqui, porque isso aqui é ouro. Isso aqui é ouro. Fechou?",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Explora como IA vertical no varejo e infraestrutura de IA geram ROI real, com um exemplo de implantação, um modelo de precificação e um funil de vendas.",
            "resumo": "Este vídeo mostra como a IA vertical aplicada ao varejo, combinada com uma infraestrutura de IA para crescimento, pode gerar retorno sobre investimento real. O apresentador descreve duas mudanças importantes dos últimos 12 meses: evolução dos modelos de IA e a possibilidade de escalar a infraestrutura. Apresenta o caso de um aluno que fechou um contrato de implantação por 78.900 reais (valor anterior 98 mil), com 30% de entrada, seis parcelas, mensalidade fixa de 3.875 reais e comissão de 2,5% sobre vendas novas. O objetivo é aumentar o faturamento em 10% e melhorar a margem líquida de 14% para 16%, elevando o lucro líquido de 53,2 mil para cerca de 66 mil reais/mês. O vídeo detalha o cliente-alvo, a precificação, a estrutura do contrato, a configuração de retorno sobre investimento (ROI) e o funil de vendas, sem foco técnico em ferramentas específicas.",
            "assunto_principal": "IA aplicada ao varejo com infraestrutura de IA para crescimento, visando ROI por meio do aumento do faturamento e das margens de lucro.",
            "palavras_chave": [
              "Inteligência artificial vertical",
              "varejo",
              "infraestrutura de inteligência artificial",
              "retorno sobre investimento",
              "contrato de implantação",
              "comissão de vendas",
              "crescimento",
              "gestão de relacionamento com o cliente",
              "funil de vendas",
              "precificação",
              "caso de sucesso"
            ],
            "resumo_em_topicos": "- Contexto: mudanças decisivas nos últimos 12 meses (IA e escalabilidade de infraestrutura).\n- Caso de sucesso: contrato de implantação por 78.900 reais, 30% de entrada, 6 parcelas, mensalidade fixa de 3.875, comissão de 2,5%.\n- Cliente-alvo e cenário: faturamento de 380 mil/mês, 82% via WhatsApp, 18% e-commerce, margem líquida ~14%.\n- Proposta de ROI: aumentar vendas em 10% (~38 mil/mês) e margem em 2 p.p. (+2%), elevando lucro líquido de ~53,2 mil para ~66 mil.\n- Oferta de valor: infraestrutura de IA para varejo, com foco em vendas, CRM e processos, não em técnica.\n- Funil de vendas e precificação: estrutura contratual, condições de pagamento e estratégia para fechar contratos semelhantes.",
            "prompt_tokens": 2116,
            "completion_tokens": 3383,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 62.849120140075684,
          "language": "",
          "view_count": 4955,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@krishnaik06",
      "name": "@krishnaik06",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "MMS04bku3FE",
          "title": "4-Construindo RAG com Typesense - Pesquisa rápida e de código aberto",
          "title_pt": "4 - Construindo RAG com Typesense - Pesquisa rápida e de código aberto",
          "url": "https://www.youtube.com/watch?v=MMS04bku3FE",
          "published": "2025-09-20T03:53:06.327056",
          "published_relative": "há 21 horas",
          "duration": "23:07",
          "date_published": "2025-09-19T20:41:39-07:00",
          "transcript_available": true,
          "transcript": "Hello guys. So we are going to continue a discussion with respect to rag. Already in our previous video if you remember we have completed the entire pipeline from data injection to chunking to embedding and finally converting the text to vectors and storing into a vector store which was stored locally. Now in this particular video I want to show you an example wherein after we convert the text into vectors we store this into a vector DB that is hosted in a cloud. Okay. So for this we are going to use this amazing platform which is called as Typesense and thank you Typesense for sponsoring this video. Now for all those people who do not know about Typesense. It is lightning fast open-source search and here it is designed for use cases such as website mobile search. It provides amazing features like instance search uh natural language support semantic and vector search capabilities. Right? So if you just go ahead and search for something right let's say that there are so many different kind of records over here how fast it is able to probably make that particular search and display you the result right so that is the most amazing thing now you may be thinking why typesense is really really fast when compared to other vector databases that are available so this is actually built in C++ and it is written in an in-memory architecture and because of this it is incredibly fast and memory efficient. Now in this particular video I am going to show you that how we can go ahead and work with typesense cloud. How we can create a collection over there directly from our code. How we can actually perform the data injection performing the embedding storing the entire vector inside this particular uh database uh as in a vector DB and then how we can query it and get the result. So all this specifically thing will be showed in this particular video as in we are just trying to develop a rag application. you can consider where our vector database is basically coming from Typesense cloud right so let me go ahead and upload this so first of all I will show case my previous code that I have actually written now I'll close this and here what I will do I will quickly first of all go to my requirement txt and we will go ahead and import one more library which is called as typesense okay so this typesense needs to be installed so I will go to my command prompt and I will write uv type sense. Okay. So once the installation happens uh so here you'll be able to see that uh the installation will take place and here you can see that typesense 1.1 is basically installed. So once we do this the next thing that I will do I will go ahead and write typesense dot ipyv. Okay. Now inside this ipv I will go ahead and select my kernel and then we will start writing the code over here. And the code this will be with respect to creating a rag application. Rag application using type sense. Okay. Using type sense. Perfect. Now once this is done first of all you need to go ahead and sign up into this particular account. So once you go ahead and sign up with any email id right the first thing that you will see is that it'll tell you to probably go ahead and make a new cluster and initially this new cluster can be created for this default configuration completely for free and you can also go ahead and create some of the collection inside this particular clusters okay so here what I will do I will just go ahead and click on launch okay so once I go ahead and click on launch here you'll be able to see that your cluster is being provisioned and after this we will also go ahead and create our own API keys. Okay. So let this happen. It will probably take around 4 to 5 minutes. So till then what I will do I will go back to my IPB file and from here I will start writing my code. Okay. Now step by step I will show you that how I will be creating the entire data injection pipeline along with that embeddings and then how I will go ahead and store inside this particular vector database collection that is available inside our typesense. Okay. So step by step I will go ahead and show it. So first thing that you have to do is that we will go ahead and import types since we have already uh you know we have already import uh installed this. So I think it will tell me that hey uh it is giving me an error. No worries. So I'll just say import typesense. And now you can see that I'm able to work with this in a very easy way and it is imported correctly. That basically means the library has been installed correctly. Okay. Now the first thing is that when I need to create the typesense collection right so inside this particular platform after this cluster is being initialized you know so we also need to go ahead and create a collection the collection will be the place where we will be storing the entire vector store right so for that in order to create the collection or in order to access this particular DB you know what we need to do is that we need to go ahead and create a typense client okay so now what we will do we will quickly go over here and I will go ahead and write client is equal to okay I'll create a variable I'll use the same type since dotclient here you can see that I'm using this dotclient function and inside this doclient function right inside this client function we have to go ahead and provide some information okay now what all information we need to go ahead and provide so let me paste it over here so that you'll be able to understand so here you can see that I'm providing some nodes information over here. So for the first inside my nodes there is something called as host there is something called as port there is something called as protocol. Okay along with this we also provide API key and we also provide connection timeout. Okay now by default you may be thinking kish where did this host come from? Where did this port come from? Where did this protocol come from or where did this API come from? Right? So we will be discussing about this but understand why we are specifically creating this client so that we will be able to communicate with our types cloud platform right now the question rises Chris how do we decide what host we really need to use okay let's say that you want to just go ahead and use local so what I will do I will say local over here that basically means I'm working it local so I'm just writing local over here you can go ahead and provide any port that you want which is available in your local let's say uh 88080 and Then if you are not if you're just using local you can also use HTTP right so this is basically the local configuration and here you also don't require any API key okay so let's say that if I go ahead and write XY Z this is more than sufficient like API key is not there right so since in local you don't require an API key but if I'm specifically using the cloud platform we make this specific changes so let me see that whether this is got initialized or not still it is taking some amount of time for initialization but it it is going to take for the first time for somewhere around 4 to 6 minutes. Okay. But later on we will go ahead and update this changes. So till now what I will do I will just go ahead and write like this and I will just keep the default values. This is there right and this entire information the host information we will be getting from the cluster right the cluster that we are creating port number whenever we are connecting to the typesense cloud you can see that by default we need to use 443 and the protocol will be https and this API key we directly get from the types cloud. Okay. So once the cluster is basically created, we will be able to get that specific information. So right now I will just go ahead and execute this by putting some default values and this is how my client looks like. Okay. So this is my typesense client and I will be using this particular client to create collections to do anything that I really want. Okay. So all these things will be there. Now let me go over here and let me see that whether this cluster is initialized or not. Okay. So now here you can see that the cluster is initialized. Now the first thing is that you will be able to see some node information right. So this node information you can directly copy it from here. So I will copy it over here. Okay. And I will paste it over here. Okay. Node information is basically over here uh with respect to the host. Okay. And that usually goes with the host. Right? Port will be like that. Protocol will be like that. Now we need to think of how we will be able to get the API key. So now again I will go over here and if you click on this API keys here you can see you can just go ahead and click on create API key and this key is basically called as admin key right whenever you have an admin key that basically means you will be able to use it for any purpose like read write delete any kind of operation so I'll copy this API key I'll go back to my code over here and then I will paste it over here right so this is how we basically go ahead and create the client okay now very simple way I have all the information over here itself with respect to this my API key uh my host uh my connection timeout each and everything right now the next thing is that we will go ahead and create our collection now for creating a collections we will look for first of all we need to provide a schema okay now how does a schema looks like right let's say that if I have some kind of data now in that particular data I may have fields like name I may have fields like type, authors, it can be different different information, right? It can be having some more information like publication year, ratings, average rating, it can have anything, right? So here you'll be able to see that I have one example where I have in this particular format. Let's say that I have a JSON format which is basically coming from the API. Now inside this the schema looks like it has title, it has authors, it has publication year, it has ID, it has average rating, right? It has some kind of image information. So all this and it also has the rating counts. So let's say in my JSON I have all the specific values and I really want to convert this into a rag application and also stores this information in our types cloud. Okay. So for doing that what I will do I will go ahead and create my schema. So here I will go ahead and write my book schema. My book schema will look something like this. See so this is how my book schema will look like. So the name is book and here I have used some kind of fields. Inside my fields, it may have name, title, type. Okay, it may have name, author's, type, string, facet, true. It may have this is the key. The name can be publication year. Type is int 32. Facet is true. Then again I have name, rating counts. You can see rating counts is also one of the feature that is available inside this JSON. Right? It can be considered as a new column altogether. Right? So all this is how we are setting up the schema. The reason of setting up this particular schema is that we are going to go ahead and create our own collection by using the schema and then we will go ahead and insert some information out there. Okay. Like uh after creating the schema whatever things are available over here we'll try to insert it inside our types cloud. Okay. Now we will go ahead and write print and let's go ahead and create client.colction.createbook schema. So once I go ahead and write, we can go ahead and see that it has got created. Okay. And we have used the same client. This is the typesense client. Now let's see whether it has got updated over here or not. So I'll go to my collection. I will see that my books is been created. Right? But still I will not be able to see any kind of data. But here clearly you can see that in a very easy way. What did I do out of this particular code? In this particular code, you'll be able to see that I created my client. I created my book schema and then we used client.colction.create or book schema whenin I created the entire collection. Now once this is done, what we will do is that we will try to read this JSONal file books.json file and then we will try to uh import all this particular information inside our collection. Okay. So for doing that we will go ahead and write this particular code with books.json JSON dot read that basically means we are opening this particular file in the read mode by using a encoding UTF8 characters and then we are reading this particular file and then we are saying that hey select this particular collection that is book document.imp import of data. So with the help of this particular function automatically the import will happen. So if I go ahead and execute this based on some amount of time the entire information will directly go over here. So if I just go ahead and see the collection now and here you can see the document count is 9979 right in a such a easy way you are able to see that with the help of Typescence cloud we are able to you know just go ahead and upload all the records and all the records is basically shown over here right you have titles you have publication year rating count average rating all the informations over here uh is easily uploaded and you can probably go ahead and do the search since Typesense supports puts faster search you'll be able to probably do semantic search you'll be able to do any kind of vector search right now it's time that we go ahead and see the search right so the best part about the search is that when I go to this particular book right I can query by title I can probably query by any kind of parameters right so I can query by title I can do apply face it and filter by you know author's publication date and all now in the coding side how do I probably go ahead and apply this search parameters okay so here what I will do I will go ahead and create this I'll create some search parameters. Okay, inside the search parameter first parameter is nothing but Q and I have just seen this. Okay, so here you can see inside this this is my query parameter, right? Q query by and all this all these criterias we'll try to put it over there in our code. Okay, so Q is nothing but let's say I want to search for Harry Potter. Okay, so let's say I'm searching for Harry Potter in the book. Okay, there are some information related to Harry Potter. And let's say there is my another parameter which is something called as query by title authors. Title comm, authors. I can also do that query by title or authors. And finally I will also go ahead and sort sort by rating count in the description order in the decreasing order. Okay. So now this actually becomes my search parameters. Okay. Now by using the search parameter now I can again go ahead and call my client docolction.books books dod documents do.arch based on this search parameter. So if I just use client collection dod documents dots search and if I just give a query directly over here it'll be based on that. If I add some more additional parameters it will be based on this particular information that is query by and sort by. Okay. And once I probably do the search you should be able to see that I'm getting 17 documents and these are all my information that is probably coming from the vector DB. The most amazing part is that see how fast this is. Yes, how amazing and how fast this is. Right now you may be thinking Kish can we also add filter by you know can we do some kind of filtering criteria or yes definitely. So now here you can see that if I go ahead and write code and here you can see filter by publication year less than 9898. Right? So once I do this here you'll be able to see all the information which is less than 1998 like the publication year is less than 1998 you'll be able to see all those information over here. Now just just imagine this is what is the context right at the end of the day if you remember here what is the main name we are hitting the vector DB we are getting the context now we can just give this context to our LLM and probably generate any kind of output that we want. Yes. So that is the reason why we are doing this specific thing where is uh we are using some specific search parameters called Harry Potter I mean getting this entire information out there right now you can go ahead and write any kind of queries based on your uh requirement you know uh let's say that I also want to apply face it right so we had also a feature called a face it right so let's let's say my query is experiment I'm giving the tit query by title face it by authors right and average rating is equal to uh in disc decreasing order. So here you can see highlighted author names are there value all the information Mahatma Gandhi value Mahatma Gandhi highlighted James Peterson right so here you will be able to see that much more in an amazing way the result is basically been displayed now this is all the basic stuffs that we have learned already okay now the main thing is that kish can we also do this with the help of langchen so the best part is that langchen and typense plus typense Yes, press GRO lm and we can definitely go ahead and create a rag application. Now let's try one more with the help of lang chain you know I will just go ahead and quickly create an entire simple rag. Okay and what I will do I I'll go ahead and create a new collection on the go. Okay so this is my first libraries that I'm going to use. I'm going to use document loaders text loader uh vector storage type sense langchen text splitter character text splitter langchen embedding hugging face embeddings we'll go ahead and use langchen gro chat gro. So let's let's go ahead and use this. Okay. So these are libraries we'll be specifically using. Along with this, we will also go ahead and set up our gro API with this API key. And I hope everybody knows how to get the gro API key. I'll go ahead and use this. Now there is one file over here test.txt. So let's say that this is my file and this is like an essay on artificial intelligence. What we'll do? We'll try to store this entire information with the help of langen directly into our types cloud. Okay. So first of all what we'll do we will convert we will read this data by using text loader. Then we do loader.load. We get the documents. We apply character text splitter. Let's say that chunk overlap we'll go ahead and apply 100 text.plit documents. And finally we go ahead and apply the embeddings. So embedding also we are initializing it over here. If you're getting this deprecated warning you can use langin_hugging face. So all these things I've already discussed in my entire rack playlist. Okay. So here what we are doing here we are doing data injection here we are doing pre-processing here we are splitting the documents and with the help of this embeddings we will go ahead and apply the embeddings and the best part is that here uh you can see that I have also imported lang community.vector Vector stores import time sense right so typesense is available in the form of a vector store also you can also do it in local you can also go ahead and do it in cloud okay it is up to you so however you want to probably go ahead and do it you can go ahead and do it okay now what I will do till then I will go ahead and write doc search now I'll show you how we can use typesense along with langchen so for here what I am going to do is that I'll write typesense dot from documents here I given the documents We are embeddings and then we have this type client parameters and here we are going to specify that entire information which we had right so if I go up that all information we'll try to put it up so this is my host so let's say that this is my entire client I will copy and paste it over here okay code okay so we'll try to replace this this is my host my host will be pasted over here then 443 https and then this is my key and here you can see my collection name is lang chain that is what I have actually considered right now once I execute this the best part will be that you'll be able to see the collection getting created okay so now this has got executed I think the collection has got created so if I just go ahead and click on the collections and refresh it here you can see lang chain so they eight specific documents that is available over here and here you can see autonomy accountability who's responsible uh who's responsible when an AI system makes mistakes so let's ask this question also okay and here you can see national security and defense AI is increasing uh transportation AI so all the chunking specifically everything is basically over here right now I'll go back over here quickly and I will do a normal similarity search so this is my query what is artificial intelligence? I'll use the same doc search and there is a function called as dots similarity search of query. Okay. And I can just go ahead and print found sorry found docs of page content. So if I go ahead and write this you should be able to see that I'm able to get the response right. Similarly you can go ahead and search for more things. You can also even convert this into a retriever also. See I will go ahead and convert into a retriever right. So for doing that I will write retriever doc search as retriever and you can use the same retriever to invoke the queries right. So here you can use this. So here you can see that I'm getting a artifier transforming has emerged as one of the transformative centuries and all right. So this is how easy it is and the best part is that you are able to see everything is over here in the cloud right I've created two collections books I've created books as a collection you can see all the books over here it has 9,000 plus records and probably done each and everything over here so this is one beautiful example where I try to showcase that how you can go ahead and use all these things and uh you know probably go ahead and uh you know see that how records have been getting appended uh how you are able to add how you are able to create collections you can also do this in local as I told you the local setting is very simple I'll just go ahead and set this to local I'll give the port number of the local and make this HTTP API key is not required at all okay but that is what we have actually able to do with the help of type sense you should definitely go ahead and use it it is very very fast the open source alternative it is written away easier to use alternative for elastics search here from scrappy startups to household name so many different clients are basically using it has all this particular functionalities like search as your type autocomplete geio search semantic search recommendation built-in rag and then here you can also go ahead and compare how it is different from the other search that is available out there and since this is open source search definitely go ahead and use it right so uh I hope you like this particular video this was it from my side uh go ahead and implement more examples and let me know that whether you have understood it or not. Right? So yeah, this was it for my side. I'll see you in the next video. Thank you.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Este vídeo mostra como construir uma aplicação RAG usando Typesense Cloud para armazenar vetores de embeddings, criar uma coleção e realizar consultas rápidas de busca semântica.",
            "resumo": "Neste vídeo, o apresentador continua a discutir o fluxo RAG, mostrando como, após converter o texto em vetores, armazená-los em um banco de dados vetorial hospedado na nuvem com o Typesense. Ele apresenta o Typesense como uma solução de busca de código aberto extremamente rápida, projetada para buscas em sites e aplicativos móveis, com recursos de busca por linguagem natural, semântica e vetores. Explica por que o Typesense é mais veloz (em memória, C++), e demonstra como criar uma conta no Typesense Cloud, provisionar um cluster e gerar as chaves de API. Em seguida, ele mostra o código para criar um cliente Typesense, conectando-se ao cluster (local ou na nuvem) e preparando a coleção onde os vetores serão armazenados. O vídeo também aborda o fluxo completo: injeção de dados, embeddings e armazenamento, preparando o caminho para consultas de QA com RAG.",
            "assunto_principal": "Construção de uma aplicação RAG utilizando Typesense Cloud para armazenamento de vetores (embeddings) e busca rápida e semântica.",
            "palavras_chave": [
              "Geração aumentada por recuperação",
              "Typesense",
              "vetores",
              "vetores de embedding",
              "Typesense Cloud",
              "coleção",
              "consulta semântica",
              "busca vetorial",
              "ingestão de dados",
              "fluxo de dados"
            ],
            "resumo_em_topicos": "- Contexto: continuidade do fluxo RAG, movendo o armazenamento de vetores locais para um banco de vetores na nuvem com Typesense.\n- Sobre o Typesense: plataforma de busca rápida, de código aberto, construída em C++, com suporte à busca em linguagem natural, semântica e vetores.\n- Nuvem e configuração: criação de conta no Typesense Cloud, provisionamento de cluster e geração de chaves de API.\n- Implementação: demonstração de código para criar o cliente Typesense, configurando host, porta, protocolo e chave de API, diferenciando o ambiente local e nuvem.\n- Pipeline de dados: explicação da injeção de dados, geração de embeddings e armazenamento dos vetores na coleção do Typesense.\n- Próximos passos: preparação para consultas de QA com RAG e demonstração prática de busca no banco de vetores.",
            "prompt_tokens": 1788,
            "completion_tokens": 1885,
            "model": "gpt-5-nano",
            "cost": 0.0037
          },
          "analysis_time": 66.55319404602051,
          "language": "",
          "view_count": 3378,
          "has_transcript": false
        },
        {
          "id": "GdohqcPB33U",
          "title": "Abordagem moderna para aprender IA para qualquer função",
          "title_pt": "Abordagem moderna para aprender IA para qualquer função",
          "url": "https://www.youtube.com/watch?v=GdohqcPB33U",
          "published": "2025-09-17T00:53:06.327130",
          "published_relative": "há 4 dias",
          "duration": "12:22",
          "date_published": "2025-09-16T08:06:56-07:00",
          "transcript_available": true,
          "transcript": "Hello all, my name is Krishna and uh welcome to my YouTube channel. So guys um before I start this particular video, I really want to give a brief background about myself for those who don't know. I've started I I got into this IT industry from 2011. I'm working from 2011. I started working specifically in the data analytics industry from 2013. I have worked as data analyst. I've worked as product managers. I've worked as data scientists. I've worked as uh senior lead data scientist. I've worked as principal architect in various projects in amazing companies. Then I started my startup and this is probably my second startup which I'm currently going on. And from past uh 7 to 8 years I've always seen that as AI is evolving I try to find out ways path so that I help others probably to get into the AI field because I feel AI is necessary in any kind of work that you actually do. Yes there will be some people who will always say that AI is not important but right now from past seven to eight years what I have actually said all the things are actually happening. If you are seeing my YouTube channel, I make sure that I put a lot of up-to-date content with respect to the current evolvement that is going specifically in the field of AI. You know, let it be technical guidance, you know, roadmap guidance along with free videos, Udemy videos, you know, we also run live classes. So, we are making sure that we are providing each and every content so that people will be able to learn it, right? And the main part about this is that people are able to make amazing career transition and from past 7 to 8 years we are also making that guidance path. We are making the path how you can actually make into a transition into AI. I'm also able to do that and how we are able to say that because we have seen lot of amazing career transition. You can just check my LinkedIn and all. And still since AI is evolving we started with machine learning now deep learning is there now generative AI is there. Now agentic AI is coming. Now AI agents are coming right we also need to catch up with this but still there are people who are specifically working in different different industry sectors you know there may be freshers there may be professionals there may be leaders there may be coders there may be people who are working in as a nonex let's say in marketing sales HR there may be people who are working in tech with different different roles right these all people say that now if we want to learn AI what should be the specific path what should be that modern approach how should we go ahead so by this diagram you will be able to understand each and everything I will provide you the right guidance how you should probably go ahead this will definitely clear all your doubts even in my previous batch the live boot camp which we were started it in this Sunday that batch was specifically for generative AI for leaders and professionals okay and many people Chris I'm 17 years of experience tell me how should I probably learn you know, so let me just go ahead and explain you with respect to this particular diagram. And please make sure that you watch this video till the end. We'll keep a like target of thousands and try to share with all your friends. We'll also keep a target of comments around 500. Okay, please try to do that. Okay, now let's start with freshers because freshers are someone who are either in college or have just passed out or is just about to get passed out. for them you know if you see over here we have given start here okay then choose your path so whenever we talk about freshers right I have divided this entire path to learn AI into three things one is traditional route modern route and this is advanced route okay let's say you as a fresher know machine learning and deep learning then you can definitely go to the modern route but let's say you are a fresher who has never learned anything about AI then your path since you are in college you have sufficient amount of time will be this traditional route okay so if you still if all these professionals leaders coders non- tech people you know and remember when we talk about traditional route I'm considering that hey a IML is definitely there okay a ML is definitely there so whenever we talk about freshers since they have sufficient amount of time Please definitely go ahead with traditional route. I'm not saying that hey if if you have never learned AI it is always best to start from scratch. So here you have data science first you have a programming language like Python then you master DSML that is machine learning CV NLP then you go ahead and add on top of that generative AI skills and finally you go ahead and add agentic AI skills and at the end of this you start creating your own AI agents okay own AI agents or any kind of projects. So this process is very good for freshers who are still in college or who are about to pass out. If you give a dedication of around 8 months, when I say 8 months dedication, at least two to three hours every day, I think you should be able to cover this traditional route in an amazing way. Okay. So, this is one specific approach. Now, let's go to the next one. Let's say I will go ahead and change the role. Let's say there are roles like professionals, leaders and coders. Now, before taking the next path, right? Now what this professional let's say that there is a professional who has 10 years of experience or who has 5 years of experience. So now there are two types of professionals also right. So before going to this 10 years experience I'll also say that hey let's say that there is a professional who is having 10 plus years of experience. Leadership obviously minimum 15 plus years of experience will definitely be there. Right now these people what is the main important thing if they really want to know about AI? Why do they want to know about AI? The reason is very simple because we obviously know that this professionals and leaders are usually in that higher position, right? So they don't have to do the coding from scratch. They want to understand how AI works and how they can actually derive a specific use case so that tomorrow if they are working in a team, they should be able to guide others. So here if I specifically consider professionals and leaders they can follow either of these two part modern route and advanced route right so let's say in the modern route first of all since generative AI agentic AI is the talk of the town they should definitely start with this they need to understand the concepts of generative AI first master generative AI then add agentic AI skill set now when I say Okay, this is fine. You're saying that okay for professional and leaders since they are having high experience they start with generative AI they add the skill set of they master generative AI and add the skill set of agentic but what if they don't have any coding knowledge see after you master the conceptual knowledge the next thing is that you can definitely use two paths let's say you're not interested in uh and this is where your things will come up right if you are a professional when I say professional I'm considering that you are from a coding background right if you are from from a coding background you may know Python you may know specific programming language so for you to learn any new things will be very much easy so here let's say if you are a professional and if you're coming from the coding background here you use some coding frameworks to implement everything let's say python lang chain and all right now you may be asking krish what about leaders so for leaders you can actually use no code platform now there are also something called as no code platform wherein you will be able to implement all the concepts that we learn in generative AI agent AI everything like rag generative AI lm applications you can also go ahead and connect LLM with multiple tools all with the no code tool platforms so here you can specifically use no code tool platform I cannot say a leader hey go ahead and learn coding first then only you'll be able to implement this when it comes to implementation whether you are a professional specifically in the coding background you can go ahead and learn with coding frameworks like how you do in python you can use frameworks like langchain and all but If you are a leader then there is no other way. But I'm not saying that you cannot implement things. You can use a no coding tool platform. Some of the no coding tool platforms examples are like nin you can actually use lang flow. You can actually use other other frameworks and in this you have integrations of different different tools altogether. Right? Through this you will be able to automate all the workflows and once you are good at both of them then try to get the DS fundamentals. You know that is the path you can basically take. Yes. And this also gets applied to non- tech people. This also gets applied to tech with other domain other different roles, right? They they also get basically you can easily apply this specific thing for them also. Why? Because non- tech they are let's say that someone is working in HR domain in finance domain right they're working as a product manager. You don't have to do coding. If you understand the concepts of AI and then you start implementing things with the help of no code tool platform that is more than sufficient right so if you have that particular path now after explaining this I know you your path should be very very easy since why we are telling you to either go with modern route or advanced route it is very simple because these things are evolving quickly. So whatever things are evolving you try to learn that fast and then parallelly learn DS fundamentals DS basically and data science fundamentals. So that is what right master data science machine learning in the later stages once you feel that you have covered all these things right why this will be necessary because these are the fundamental concepts that we just prioritizing that at the last but in the case of a fresher you need to switch jobs you need to go for the interviews at any kind of interviews they will first of all focus on the basics okay now the thing is that what is the advanced route Krish is talking about learn everything parallelly generative AI data science Usually I don't suggest it but people who definitely are professionals who are coders you know can actually follow this particular part. When I say coders they may be in different different background like Java, JavaScript and all there also they can learn all these things and follow this advanced route where you're learning all three parallel and becoming a comprehensive AI expert. Now I hope your answer your queries whatever it comes right what is the modern approach to learn a IML just ask yourself hey see this diagram ask yourself how much experience you are right whether I know coding whether I don't know coding if I know coding what should be the path if I don't know coding what should be the path since no code tool platforms are also going on and main thing is that these professionals and leaders initially will think of a problem statement and develop an MVP product right usually in 2015 what used to happen if I have a startup idea I need to think of a team right how much team I am I want a front end back end person some database guys all these things and then I was able to implement it but now because of AI that is not necessary right you can actually create a MVP just by using VIP coding right you can do this but your fundamental concept should be very very strong I have done that in past One month I have implemented four different ideas and I have asked for feedbacks from various people. Many of them liked it. Some of them said this point that point right and we are able to do this. So this should be your necessary path with respect to implementing or going like how you should probably follow a modern approach to learn AI. I hope you like this particular video. As I said guys at the end of the day it's you take that decision by yourself. I will also provide a GitHub link which will provide all the free videos like with respect to this specific path. I have created the entire GitHub. Uh you can refer videos each and everything and that will be provided in the description of this particular video. So yes, this was it from my side. I'll see you in the next video. Thank you. IC.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Abordagem prática para aprender IA adaptada a diferentes funções, com caminhos tradicionais, modernos e avançados, incluindo IA Generativa e IA Agentica, com opções de código e no-code.",
            "resumo": "Neste vídeo, Krishnaik06 compartilha como aprender IA de forma prática para qualquer função. Ele apresenta sua trajetória na indústria de dados e seu objetivo de ajudar mais pessoas a entrar no campo, acompanhando a evolução da IA: aprendizado de máquina, aprendizado profundo, IA generativa e IA baseada em agentes. O conteúdo é estruturado em três caminhos de aprendizado: tradicional, moderno e avançado, com adaptações para iniciantes, profissionais, líderes e codificadores. Para iniciantes, o caminho tradicional envolve Python, ciência de dados, aprendizado de máquina, visão computacional e PLN, seguido por IA generativa, IA baseada em agentes e a criação de seus próprios agentes de IA, em cerca de 8 meses com 2–3 horas diárias. Para profissionais e líderes, o foco é compreender como a IA funciona e como aplicar casos de uso, começando pela IA generativa e IA baseada em agentes. Dependendo da origem (codificação ou sem código), utiliza-se código (Python, LangChain) ou plataformas sem código para construir aplicações.",
            "assunto_principal": "Abordagens modernas para aprender IA para diferentes perfis profissionais, com caminhos tradicionais, modernos e avançados, adaptados para recém-formados, profissionais e líderes, com opções de código e sem código.",
            "palavras_chave": [
              "inteligência artificial",
              "aprendizado de inteligência artificial",
              "caminhos de aprendizado",
              "tradicional",
              "moderno",
              "avançado",
              "inteligência artificial generativa",
              "inteligência artificial agencial",
              "recém-formado",
              "profissionais",
              "líderes",
              "programadores",
              "Python",
              "LangChain",
              "sem código",
              "casos de uso",
              "carreira em inteligência artificial",
              "curso intensivo",
              "linguagem de programação",
              "visão computacional",
              "processamento de linguagem natural",
              "aprendizado de máquina",
              "ciência de dados"
            ],
            "resumo_em_topicos": "## Resumo por Tópicos\n- Introdução: apresentador e objetivo de orientar o aprendizado de IA\n- Contexto: evolução da IA e necessidade de guiar diferentes perfis\n- Estruturas de caminhos: tradicional, moderno e avançado\n- Para iniciantes: caminho tradicional com etapas (Python, Ciência de Dados/Aprendizado de Máquina, Visão Computacional/Processamento de Linguagem Natural, IA Generativa, IA Agentica) e dedicação de ~8 meses\n- Para profissionais e líderes: foco em entender IA e aplicar casos de uso; começam com IA Generativa e IA Agentica\n- Abordagem prática: se você tem background em programação, use código (Python, LangChain); se não, plataformas no-code para líderes\n- Observação final: bootcamp ao vivo e incentivo ao engajamento",
            "prompt_tokens": 1770,
            "completion_tokens": 4409,
            "model": "gpt-5-nano",
            "cost": 0.0075
          },
          "analysis_time": 79.36127781867981,
          "language": "",
          "view_count": 25291,
          "has_transcript": false
        },
        {
          "id": "0lL94h1z72A",
          "title": "Começando com o Claude Code com o VS Code",
          "title_pt": "Começando com o Claude Code usando o VS Code",
          "url": "https://www.youtube.com/watch?v=0lL94h1z72A",
          "published": "2025-09-09T00:53:06.327147",
          "published_relative": "há 12 dias",
          "duration": "16:02",
          "date_published": "2025-09-08T07:54:04-07:00",
          "transcript_available": true,
          "transcript": "Hello all, my name is Krishna and welcome to my YouTube channel. So guys, today in this specific video, we are going to discuss about this amazing tool that is cloud code. And if you do not know about this, it's basically your code's new collaborator. Uh why developer specifically uses this is to improve productivity. And uh uh I'll also make a detailed comparison between this and GitHub copilot because many people definitely have a lot of questions related to that. But in this particular video, we'll do a deep dive how you can actually get started with respect to cloud code. Okay. So here you can see your code's new collaborator unleash cloud raw power directly in your terminal. So from the terminal uh just by providing some instructions you'll be able you'll be able to use AI along with the LLM models to specifically do the coding based on the plan that you have developed. Okay. Turns our long's workflow into a single command. your tools, your workflow, your code base evolving at a thought speed. Many many companies specifically uses this. I have I have asked many people who are working in various multi MNC companies and they are using it. Okay. And here you can see deep coding at terminal velocity. It also provides you different different LLM like cloudy opus 4.1. It also provides you cloudy sonnet models. U the same model our researchers and engineers use right in your terminal. Right. It has deep codebase awareness and ability to edit files and run commands directly into your environment. So I'll show you each and everything how you can get started. So here you can quickly see that I have a VS code over here. Uh I usually use cloudy along with that I also use GitHub copilot. You know I'll make a detailed dedicated video for GitHub copilot. It should be like a oneshot tutorial. Now uh quickly what I will do inside this VS code. First of all, uh let me quickly go to my command prompt and quickly I will just go ahead and write UV in it so that I initialize it with the help of UV package. Then I will go ahead and create my environment UV env. So here you can see my virtual environment is created. I will go ahead and activate this. Okay. Yes, these all commands that I have actually done it. If I also say cloudy code uh sorry cloud code then it will also be able to do it. Okay. Now quickly what I'm actually going to do I will go to my extensions. So here you will be able to see extensions and I will go ahead and install cloudy code. Okay. So once I go ahead and just search for it, you'll be able to see that I have this. Okay, cloudy code and you can see that I've already installed it. Now as soon as you install this, you'll be able to see that there is a icon on the right hand side right over here. So you just go ahead and click on this and your cloudy code chat terminal will get started. Now you can see that by default you are able to see something like this. The reason uh you can see all this particular chat over here it's very simple because I've already done the login. Okay. So you can either use cloud code over here from here to the chat terminal from here to or what you can do you can just terminate this and you can also go ahead and open your command prompt. Okay. So let's go ahead and open the command prompt. I will go to my working location specifically in this particular directory. The directory is nothing but cloudy demo. It is basically there in my E drive. So I'll say cd cloudy demo and from here I will just go ahead and write cloudy. Okay. So sorry cloud. So once I write this you'll be able to see that it'll go ahead and login right. It'll tell me to login and um you can just go ahead and login uh from the browser itself. Okay. But here right now you can see that I've already logged in. So it is not asking me to do that. Now if you go over here and see what are the pricing options with respect to cloud. Here you'll be able to see that it has a pro version. It has max 5x and it has max 20x. So in my companies uh I've told all my employees uh basically it is uh given by the company itself my company itself wherein we have told that everybody can consider this $100 per person build monthly right because the coding productivity is very very high. Uh for people who are specifically using chat GP they can also use this pro version where you have $17 or $20 if build monthly. You can try out this and it is perfect for short coding sprints in smaller code bases, right? And here it provides you cloudy. So sonet for usually in companies since I have a very large code base, my uh employees, my people who are specifically working along with me, they use this. I also use this. Okay, $100. And again, uh for people who are running a business, they should definitely go with this or that. Okay, it is up to you because the performance is very very good, right? For the people who definitely want to try it out, you can go with this. Okay. Now I'll go ahead and open my command prompt. So let me quickly open my command prompt. So here you can see that uh my pro command prompt is basically there. Here you have different different options. Okay. So uh what you can also do is that you can go ahead and just write down all the instruction over here. Okay. Whatever instructions you want to specifically go ahead and write. Let's say that I will write some instruction. I'll say that hey uh what is there in the codebase since I'm I'm in the same uh folder. So here you'll be able to see that I can ask any instruction it'll be able to give me that specific information. See I'll explore the codebase to see what there is and it is probably going and hitting all the commands that is required. It is reading all these things and it'll probably say me that hey it's probably nothing. We have not even started the development. Okay. So let's go ahead and see this. Okay. So now I think it'll be able to probably summarize the entire thing. So the codebase contains main.py file this this this. Okay. Now let's say that I will go ahead and say that hey please create a simple flask cap uh for a basic for an advanced calculator. Okay. So now I'm just going and giving this specific instruction as soon as I probably go ahead and do this. You'll be able to see that it will start doing the planning. Okay. So did you know that you can drag and drop image files in a terminal? So see it it started probably doing this. I'll create a flask app for advanced calculator. Let me start by planning this task. So the first important thing is that whenever you're using this kind of uh code terminal specifically like cloud code or GitHub copilot, first of all you need to go ahead and set up the plan. So it'll it'll go ahead and create a plan. So here you can see that what are the dependency it will require for ask and all right. So I will just go ahead and say do you want to make this edit to pi project.2ml. I will say one yes that basically means this particular step will basically happen. So it will keep on asking me with respect to the flow that I've just given in a single line command. Right? And this is very much handy for an experienced developer because an experienced developer will make sure that uh you know they have to do a lot of repetitive task again and again simple applications simple modules that we do again and again the logic that we specifically build usually it's timeconuming it is always good that if I have some kind of options and I directly see it so here you can see that um do you want to make this edit to the main py file. So here I will go ahead and say plus one. I'll press one and automatically you'll be able to see that this will get executed. Now here this file that you'll be able to see you will be seeing that it will get created over here. Okay. So here you can see bash command make directory templates create template directory for file html file. Right. So I will just go ahead and press one. Automatically you can see that template folders is also getting created. Right? So everything is happening from this particular command prompt. Okay. Yes. It takes time. it basically now it is act it is adding the CSS styling and JavaScript functionality okay and automatically after some time you'll be able to see that that file will also get created over here but first of all it'll ask me for the specific permission and then you can see next step is nothing but implement advanced calculator function again based on the plan this is going to take some amount of time uh so here you can see that the entire code the JavaScript code everything I even I did not give the programming language whichever is the efficient one it is trying to create it okay so Here I can just go ahead and write one and then you'll be able to see that now inside my templates my calculator.html HTML is created right so if you go ahead and see this you'll be able to see this okay and this particular file is created along with the entire code yeah great right now here you can see that it is saying that install the flask dependencies I'll just go ahead and say press one because it is telling me to just press one okay error file file setup r directory cannot be installed in editable now it will automatically even do the see you're seeing that it is doing pip install call flask. Okay, I don't have to properly do it because we are using command prompt, right? So here what I will do, I will say, hey, uv add flask. I'll do the installation because I'm not even using pip. I'm using uv. Okay. Now here you can see that uh I have installed flask. Please continue the app. Now I'm just giving the instruction. Now here you can see that I've already given the instruction. I've installed the uh flask app. So I'm not waiting for everything to happen over here. Then it is saying me that hey uh let's go ahead and run this python main. py. So it'll run in the background and automatically you will be able to see this. So here you can see that uh trace back some error is probably coming up but it is also going to fix up the error. Okay, it is also going to fix up the error and here only you'll be able to do each and everything in short. Okay. So quickly let's see what error the issue is conflicting with this particular containment try installing flask in your virtual environment source this this this pip install flask I've already done that so I don't need to probably do it okay now what I will do I will quickly go ahead and execute python main py from this right so here you'll be able to see that main py is over here and automatically this is basically getting executed now this is my application see within 5 minutes within 5 minutes I'm able to do this right I'll put my first number 12 second number 34 I'll calculate it automatically I should be able to get the answer result 46 right power operation 2 to the power of 8 89 just go ahead and calculate it you'll be able to see the answer 2 the^ of 8 calculate right I should be able to see uh angles let's say 30° sin 45 log I don't know 10,000 square root factorial 45 I'm able to get the answer. So how fast I was able to do this right now let me show you some more amazing features over here. I'll go back to my terminal. So here also I can go ahead and start my terminal. Now see if I just go ahead and ask this over here also I should be able to see it but I think you'll not be able to see my face. So I will go ahead and open. Now uh what I'll do is that hey uh let's do one thing. First of all I'll create a source folder. Okay. Now inside the source folder I will just tell this right create a rag application. Okay, inside the src folder or I'll say hey create the rack pipeline pipeline inside the src folder start with data injection where it can read or where it can probably read the data I'm just giving a plan okay data from the data folder or where it can read the PDFs from data folder. Then uh perform chunking and then store store it in the vector store. Vector store. Vector store. And before that apply apply hugging face sentence transformer transformer uh embedding. Okay. Uh whatever spelling is there I'll just go and press enter. Now here you can see that automatically it will start probably doing that specific work and automatically inside the source folder my entire application will get created right and I don't have to probably do anything I will just say 111 yes you need to be an experienced developer to just see that some kind of errors make up right so here it is saying that make directory source rack data so let's go ahead and make this so my rag data is over basically created over here I'll go over here now here it is saying Okay fine init_init.py py because this will be considered as a package. This is my rack folder, right? Okay, I will go ahead and write like this inside my rack folder also initiate.py py file is there automatically this all things will basically keep on happening right and I'm just enjoying so this is what now the main thing is that you need to have knowledge you need to have knowledge that is more than sufficient if you if you are a good coder in this industry you really need to be a very good coder okay you need to be a very good coder if you are a very good coder your productivity is basically on peak because now whatever code this AI specifically writes using different different LM models I'm able to understand So I will be able to see that what kind of errors is basically happening. What kind of changes is actually happening right? Now see automatically this data injection code is basically written. I will just show you how this file looks like. Right? And now if I go ahead over here inside my rag. See this is what is my data transition. This is how it looks like. Right? And I can definitely see from this there is a init method. There is extract text from PDF. All the code is specifically written by the AI. Right? All I have to do is that go ahead and test it out. Right? So that is the reason why I say that if you really want to improve your productivity, this is the thing that you really need to do. Be a very good coder. Do enough type of codings for freshers. Definitely don't waste your time in college. Be a good coder. If you're a good coder, that is more sufficient to go ahead with and do anything in this world. with just a small team you'll be able to do this because at the end of the day it's all about AI because these all AI are specifically trained with huge amount of data right so now it is implementing embedding modules hanging sentence transformer automatically you'll be able to see that entire code will get created see chunking py is also done right here you have the code all you have to do is that just execute and see whether everything is working out fine or not right so yeah uh again you can go ahead and test it out uh I'm also going to make a detailed video on GitHub copilot But once you do this, you just keep on giving the instruction and automatically this will be taken care of. Uh it'll also you can also tell that hey go ahead and run this test this if some error is giving it will show you the error and it'll again backtrack and it'll also show you the solution. That is the beautiful thing about cloud code right. So uh one video I'm going to specifically make a complete end to-end project with the help of cloud code and I'll show you how you can actually work as a research architect and probably just go ahead and go ahead with the development. So nowadays people who just have amazing experience can do a lot of things that is the best thing. So for this same thing what we actually teach if you go ahead in our live classes there is a course that is coming from generative AI for leaders and in this we are going to teach you all the specific things right this is our main focus uh about this particular course the description the link will be given in the description of this particular video itself right so I hope you like this particular video this was it from my side I'll see you in the next video thank you take",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o Cloud Code como um assistente de IA para codificação integrado ao VS Code e ao terminal, explorando instalação, login, planos, modelos de linguagem e um fluxo prático para planejar e gerar código, incluindo a criação de uma API Flask.",
            "resumo": "Neste vídeo, Krishnaik06 apresenta o Cloud Code como o novo colaborador de código alimentado por IA que se integra ao terminal e ao VS Code para aumentar a produtividade. Ele descreve por que desenvolvedores usam essa ferramenta, compara rapidamente com o GitHub Copilot, e faz um guia prático de início: instalar a extensão, fazer login, escolher um plano (pro, 5x, 20x) e entender os modelos (Cloudy Opus, Cloudy Sonet). Em seguida, ele demonstra um fluxo de trabalho típico: criar e ativar um ambiente virtual, abrir o prompt de comando, pedir ao Cloud Code para explorar o código, planejar uma tarefa e aplicar alterações automaticamente, como criar uma aplicação Flask simples e a estrutura de diretórios/templates. O vídeo enfatiza a importância do planejamento antes de pedir código, mostra a edição de arquivos diretamente no ambiente e destaca a utilidade para equipes com grandes bases de código.",
            "assunto_principal": "Assistente de código alimentado por IA (Cloud Code) integrado ao VS Code/terminal, com foco em produtividade, planejamento, configuração e comparação com GitHub Copilot.",
            "palavras_chave": [
              "Código na nuvem",
              "Inteligência Artificial",
              "Visual Studio Code",
              "terminal",
              "produtividade",
              "planejamento",
              "modelos de linguagem de grande porte",
              "Cloudy Opus",
              "Cloudy Sonet",
              "GitHub Copilot",
              "Flask",
              "aplicação web",
              "fluxo de código",
              "extensão",
              "início de sessão",
              "planos"
            ],
            "resumo_em_topicos": "- O que é o Cloud Code e por que usar\n- Integração com VS Code e terminal\n- Instalação, login e configuração\n- Planos e modelos (Opus, Sonet) e preços\n- Fluxo de trabalho com planejamento de tarefas e prompts\n- Demonstração prática: criar uma API Flask simples e estruturar diretórios/templates\n- Comparação rápida com GitHub Copilot\n- Dicas para equipes com grandes bases de código\n- Observação sobre uso do terminal e edição de arquivos no ambiente",
            "prompt_tokens": 1867,
            "completion_tokens": 3867,
            "model": "gpt-5-nano",
            "cost": 0.0067
          },
          "analysis_time": 50.57210612297058,
          "language": "",
          "view_count": 19374,
          "has_transcript": false
        },
        {
          "id": "adPi3a8fq4c",
          "title": "3-Build RAG Pipeline From Scratch-Building Advanced Retreival Query Pipline-Part 2",
          "title_pt": "3-Construir Pipeline RAG do Zero - Construindo um Pipeline de Recuperação Avançada por Consulta - Parte 2",
          "url": "https://www.youtube.com/watch?v=adPi3a8fq4c",
          "published": "2025-09-09T00:53:06.327161",
          "published_relative": "há 12 dias",
          "duration": "16:40",
          "date_published": "2025-09-08T02:52:21-07:00",
          "transcript_available": true,
          "transcript": "Hello guys. So we are going to continue the discussion with respect to rag. Uh till now we have already discussed about the entire data injection pipeline and with the help of user query you know we are also able to retrieve the context. uh we have completely implemented this first pipeline that is called as data injection pipeline where we did the data injection. We did the chunking uh then we converted the text into vectors and after that you know uh we were able to probably store everything inside a vector DB and we also persisted in the local directory so that we can always read whenever we definitely want okay based on a specific query. Now we are going to go towards the second pipeline that is the query retrieval pipeline wherein we are also going to use LLM with it. Okay. So here we are going to specifically use LLM models and this LLM models will actually help us to generate a summarized output okay in the rag. So the entire pipeline will look something like this. And uh when we talk about this query retrieval pipeline, we are specifically talking about something called as augmented generation. Okay. See in retrieval uh rack basically means retrieval augmented generation. And this augmented generation how does it specifically work? Okay. So let's consider that this vector DB is already ready. And you know that how did I create this particular vector DB? By following this particular pipeline, right? Now once we follow this pipeline the data is stored inside the vector DB. Now whenever a user gives a new query okay it has a new query related to the documents that are already ingested inside the vector DB then what we do we take up this query we apply the same embedding and in this particular embedding what we do we convert the query to vectors right and then from this particular embedding we hit the vector DB we get the context and then whatever context we get along with the prompt engineering like basically with a simple prompt we give that instruction to the LLM right so prompt is just like an instruction to the LLM like how the LLM should basically work now once we are doing this right this this step is basically called as augmentation okay this step is basically called as augmentation wherein we are giving we are taking the context and along with that we are also combining it with a specific prompt And finally you'll be able to see that we'll generate the output from the LLM. And this step is nothing but generation right this is the retrieval step. So here I have my retrieval step wherein we are giving a query we're converting that into vectors and we hitting the vector DB. So you really need to understand the entire concepts with respect to rag. Okay. So let's go ahead and implement this entire retrieval uh query retrieval pipeline along with the LLMs. Okay. Now here we are also going to go ahead and set up the LLM. So guys, now let's go ahead and implement this uh with the help of practical implementation. So here we are going to integrate vector DB context pipeline with LLM output. U as suggested we are going to implement the augmented and generation. Now first first of all what we are going to do is that I'm going to use the my Gro API key. Okay. So I have updated the gro API key over here in the env file and uh you know here we are going to probably go ahead and create a simple rag pipeline okay uh with the gro lm okay so first of all what we are going to do is that uh again uh if you remember in our requirement txt we will go ahead and import this two libraries that is called as langin- gro and then you have pythonv Okay. And then after this uh we will go ahead and uh you know quickly initialize from langchain grock import chat gro. Okay. Along with this I'm also going to go ahead and import os. Then from env I'm going to use load_.env so that we import or we load the entire environment variables. Then the next thing is that we will go ahead and initialize the gro lm and set your environment a gro api key inside this. Okay. And in order to do this again here you'll be able to see that I'm using gro api key o.get env something like this. Okay. If you just go ahead and call this sometime uh my suggestion would be that directly don't call from get envit directly test it by pasting the environment keys directly over here. Okay. So here I will go ahead and paste it. Otherwise you go ahead and replace it. Just for testing purpose I'm actually doing this. Now we'll go ahead and initialize our LLM model chat gro. And here I will use my gro API key is equal to API sorry Grock API key. Okay. And then model name is gamma 2 temperature I will select it as 0.1 and maximum number of tokens it will generate is 1024. Okay. So this is my LLM. We have initialized the gromm. Now the second thing is that we will quickly go ahead and create a simple rag function and this is going to integrate everything from retrieve context plus generate response and if you remember guys here is my retriever before class like the previous u session we have already seen that how this rag retriever was actually created we created a class for that okay so here uh we are going to probably take two different parameters Inside this we'll first of all define a function called as rag simple and then here we are going to go ahead and give our query. Then we are going to go ahead and give our retriever llm top k is equal to three. Okay. And then uh over here uh quickly let's go ahead and first of all retrieve the context. Yeah. So we going to retrieve the context. So here I'm going to write results is equal to retriever dot retrieve query. So here you have this query and top k is equal to k. Okay. And then uh we are just going to get the context or I'll go ahead and define my context inside this context. I will say that hey whatever information I'm getting from my results right just go ahead and combine everything and put it inside this right. So here I'm saying that hey for doc in results whatever content I'm getting I'm going to join it with a uh double new line over here. If results are this empty we are just going to keep it as empty. So this is my context over here right then uh I can still go ahead and write one more condition saying that hey if not context okay we are just going to go ahead and return saying that no relevant context form. Okay to the answer question and then we are going to generate the answer using gro lm okay and now I'm just going to go ahead and define my prompt obviously I required a prompt if you remember here I can again use a prompt template also I can directly use a prompt over here so here with respect to the prompt I will give a query saying that hey this is what you really need to do, you need to go ahead and answer this specific question and you should probably get a response for that. Right? So here what I will do, I will quickly go ahead and paste it. Use the following context. So here you can see use the following context to answer the question uh uh question concisely. Okay. And here what we can basically do is that we can just go ahead and um do one thing on over here quickly. I'll say just put tab. Okay. So use the following context to answer the question uh precisely or concisely. So here I have given the context here I've given the query. Okay. Now the next thing after this is that we will go ahead and create a response. So response is equal to this time we are going to use llm dot invoke. Okay. And here uh let's go ahead and put something like prompt dot format. And here we are going to write context is equal to context and here you have query is equal to query whatever query I have. Okay. And then we go ahead and return the response dot content. So once we do this uh then we can specifically call this particular function. Okay. So now what we are going to do is that I will just go ahead and write answer is equal to rag simple and let's say I go ahead and ask a question what is attention mechanism okay and here I need to give my rag retriever along with the llm and then we can go ahead and print the answer okay so here you can see attention mechanism is a function that maps a query in this right And we are able to get the answer over here. This is really good. See a very simple pipeline where I have initialized my LLM model. I've defined a function and then this function what it is doing first of all it is hitting the rag retriever retrieve function. It is getting the context. It is combining the context and along with the prompt we are hitting the llm. So if you remember we are we are just following this entire process and generating a proper output right if that particular output is available inside the uh vector DB right now guys uh what we are going to do is that we are going to enhance the rack pipeline the simple rack pipeline that we have created over here okay we'll enhance in such a way that it will have more amazing features in it okay so now we're going to go ahead and create an amazing enhanced track pipeline and this is the code so now you can see over Here we have a function called as rag advanced. I'm giving a query retriever llm top key elements like how many we want minimum scores return context is equal to false. So here you can see that um beforeh we were simply like we were just combining the context we are putting the information in the prompt and we were probably generating the response. In this what we will do is that here we are going to generate this entire pipeline with some more additional features like what all additional features we'll be requiring. See here we are directly getting the answers right but we do not have much information about the source about the context over here right so here what we are doing we will return answers sources confidence score optionally fully context full context okay so first of all again the code will be similar where we are retrieving the context so this becomes my context when we are retrieving it from retriever retrieve and then uh I have written if not results if results are empty we are saying that no relevant context found and here we are giving sources is blank, confidence is 0.0 and context is blank. This context is basically coming from the vector DB. Let's say that if we are getting some kind of results over here, we are combining all those results and we are preparing the context over here and then we are adding sources. See this sources which is the list here we are adding metadata information source file right and along with that you can see metadata page number from which page number you are able to get then what is the similarity score and here what I will do is that I'll just try to go ahead and you know display at least 300 um length of the content right so up to 300 characters we'll try to display and then we are going through each and every docs that is available inside this results then we are going to calculate the confidence uh we are actually getting that information in this doc similarity score here is my prompt in this prompt we are giving context query each and everything and we are invoking it and the output will be in this format so let's now go ahead and execute this rag advanced function here I've given all the information like I've asked what is the attention mechanism what is rag retrie like rag retrievy I'm given over here llm written context is equal to true minimum score all these things is given right so now I'll go ahead and execute this now as soon as I ask what is attention mechanism here you'll be able to see that I'm getting this particular information right and it is also giving me the source information which number page number what is the score and what is the preview information along with that here is my final information that you can see right where we are displaying the first 300 characters let's say that I go ahead and change my question okay I I ask something else I'll say hey uh attention mechanism was one of the thing But if I go ahead and see my data, my PDFs. Okay, I will go ahead and ask something else. Okay, let's see what I can ask. So I'll go to embeddings.pdf. I'll say okay. And then let me search something else, right? I will say hard negative. I'll ask this question hard negative mining techniques. Okay, so I will go to my question over here. hard negative mining techniques. Okay. And I'll go ahead and search this thing from my vector retriever. So here you can see that I'm able to get this entire information. and the test destroy several hard NC conan embeddings NV retriever all these information and again you can see that embedding PDF page 4 I'm able to see all the information along with the context right so this is uh really amazing and here we have just created an enstrack pipeline why we say this as an N rack pipeline because here we are providing information related to answers we are providing information related to confidence score and each and everything now let me just show you one more amazing way and this is also an advanced rack pipeline but this time I will tell you to probably go through this particular code and tell me so here what we are doing we're doing streaming citation history and summarization so all these things we have included over here and uh you can just go and search for this and you can see the answer okay final answer roment context found because that question may not be there okay I will just or let me just change this minimum score to 0.1 I think we should be able to get something still nothing uh let Let me change the question. Let's say hard negative mining techniques. And here we are just going to go ahead and display this particular output. Okay. So now you just go ahead and explore this. Okay. I'll keep this for you at least see some kind of coding. Okay. So here we are not able to get anything as such. Uh let's see. Advanced rack query hard query top quering summarize equal to true. Uh no relevant this one. Let's see that I go ahead and ask what is what is attention is all you need. Okay, I'll go ahead and execute it. So here you can see that I'm able to see all these particular answers over here. Right. Yeah, for some of the queries this will not it is not giving there may be some problem with respect to the context size but it's okay. You can try out with different different things. If it if something is not coming then we'll try to optimize that also as we go ahead we'll try to see this. So here we have seen three amazing rack pipelines. One was a simple rack pipeline here was an enhanced rack pipeline and here uh in the last one we have made sure to put streaming citation and history and summarization with all this kind of information over here. You just go ahead and check it out all the information and just see the code. I think you should be able to understand it. So overall uh if you see I hope you were able to understand this particular video and uh yeah this was about rack pipeline. Now in the upcoming videos what we will do is that we will try to create some modular coding because see here the entire everything is basically created in one IP file. Now what I will do is that as we go ahead I will start implementing all these things inside a source folder like how a model structure of coding can be applied inside this entire rack pipeline. Right? So yes this was it from my side. I'll see you in the next video. Thank you. Take care.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta a segunda parte de um tutorial sobre Geração com Recuperação Aumentada (RAG), explicando o fluxo de recuperação de contexto com embeddings e um LLM para gerar respostas, incluindo a integração entre o banco de vetores, o enriquecimento do prompt e a geração final.",
            "resumo": "Este vídeo continua a explicação do RAG (Retrieval-Augmented Generation) iniciada na parte anterior, detalhando a pipeline de consulta e recuperação que utiliza embeddings para consultar um banco de vetores já populado, obtém o contexto relevante e, em seguida, usa um LLM para gerar a resposta com base nesse contexto. O apresentador descreve as etapas: configurar o ambiente e o Grok com a chave de API, escolher o modelo gamma 2, definir temperatura 0,1 e máximo de 1024 tokens; criar uma função rag_simple que recupera o contexto com top_k, concatena o conteúdo relevante, trata cenários sem contexto e monta um prompt que instrui o LLM a responder usando o contexto. O fluxo é de augmentação (contexto + prompt) seguido de geração (resposta do LLM). Também é mencionada a integração com pipelines já existentes e a ênfase em uma implementação prática de ponta a ponta.",
            "assunto_principal": "RAG (Retrieval-Augmented Generation) e a implementação do pipeline de recuperação de consultas com embeddings, banco de vetores, engenharia de prompts e geração de respostas via LLM (Grok).",
            "palavras_chave": [
              "Geração aumentada por recuperação",
              "Geração aumentada por recuperação",
              "pipeline de recuperação",
              "representação vetorial",
              "banco de dados vetorial",
              "engenharia de prompts",
              "Modelos de Linguagem de Grande Escala",
              "Grok",
              "top_k",
              "aumento",
              "geração",
              "integração com LangChain",
              "implementação prática"
            ],
            "resumo_em_topicos": "- Visão geral do RAG e objetivo deste vídeo\n- Revisão do pipeline de injeção de dados da parte 1 (chunking, vetorização, banco de dados vetorial, persistência)\n- Detalhes da pipeline de recuperação de consultas (vetorização da consulta, recuperação de contexto, augmentação)\n- Conceitos de augmentação e geração dentro do fluxo RAG\n- Arquitetura prática: Grok LLM, configuração de API, parâmetros gamma 2, temperatura 0,1 e tokens 1024\n- Implementação da função rag_simple: recuperação de contexto, construção do contexto, prompt e invocação do LLM\n- Observações sobre integração com LangChain e uso de pipelines existentes\n- Notas sobre limitações e próximos passos",
            "prompt_tokens": 1831,
            "completion_tokens": 3123,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 79.95237827301025,
          "language": "",
          "view_count": 11691,
          "has_transcript": false
        },
        {
          "id": "aJfebE5_nHk",
          "title": "IA Generativa para Iniciantes - Anúncio do Bootcamp para Profissionais e Líderes",
          "title_pt": "IA Generativa para Iniciantes - Anúncio do Bootcamp para Profissionais e Líderes",
          "url": "https://www.youtube.com/watch?v=aJfebE5_nHk",
          "published": "2025-09-08T00:53:06.327174",
          "published_relative": "há 13 dias",
          "duration": "11:00",
          "date_published": "2025-09-07T02:53:36-07:00",
          "transcript_available": true,
          "transcript": "Hello everyone, my name is Krishna and welcome to my YouTube channel. So guys, I'm super excited to announce this amazing course that is generative AI for everyone specifically focusing on professionals, leaders and for all those who do not know or do not have any idea about AI. So in this particular video I will be talking about this boot camp. uh what all things we will learn in this boot camp and who are the target audience who should basically opt for this particular boot camp. So just to go ahead and talk more info out provide a more brief about this particular boot camp. This boot camp will be starting from September 14th 2025. The timing will be 8:00 p.m. to 1000 p.m. IST. Okay. Along with this the course duration will be somewhere around 2 to 2.5 months. The price of the course is 6,500 rupees INR. And for some foreign audience who are in US or European countries, the charge will be little bit higher. The reason is very simple because we have some payment gateway charges, right? So let's me go ahead and talk more about this particular course step by step. We'll understand each and everything and then we will understand about the detailed syllabus. Now this Gen AI for everyone is specifically focusing on professional leaders and for those people who are just starting with AI. Okay, starting with AI now right now in 2025 right any reports that you specifically see from bigger companies AI adoption is really really important. Okay, if you do not know how you can use AI for your task specifically in the IT companies, then trust me, you'll not be able to be much more productive. So here based on this particular focus, we have launched this particular batch and the reason is very simple. There was a lot of demand and request for this particular batch itself. Okay. Now when we talk about AI adoption the main concern that people usually have kish what is the prerequisite what is the prerequisite if I really want to start with AI do I need to know coding okay do I need to coding no coding let's say that I want to go ahead and implement a rag so for rag do I need to always learn python or is there some specific way if I'm not a fresher if I'm a professional if I'm a leader is there a specific way that I can probably go ahead and learn these AI concepts and later on move towards coding. Right? So this is the major question that usually comes from every one of you here in this particular batch. Our focus is very simple to teach you all these concepts without much coding knowledge. That is our main target over here. So if you are experienced professional, if you are a leader, let's say you are in a director position, you are in a project manager position, you may be senior, you are a professional who have never worked in AI and want to get started, you want to you are a fresher, you want to get a very clear idea about AI itself, then this course is definitely for you. Okay. Now concept wise, we will learn each and everything. I will also go through the detailed syllabus as we go ahead. Whatever things will be available with respect to coding also the same thing we will be learning over here but practically we will try to implement with the help of no code tools. Okay. So there are different different no code tools which we can actually use and implement all these things what I have written over here. So here concept wise we will try to understand about AI generative AI how generative AI is specifically used in the companies. How does LLM word LLM models work? What is exactly prompt engineering? What is agentic AI? How does a ra what is rag? How a rag application is basically created. I will also show you the examples wherein we try to integrate even our editors with github copilot cloudy code you know and we see that how AI will actually help us to probably write the code by its own and even execute the code by its own right. So that kind of knowledge also I'll try to give it so that whenever you have any kind of P or any kind of MVP product and the kind of idea that you have in your mind you will not even require a team and you will be able to start and implement things by your own along with that we'll also be trying to integrate different different kind of no code tools right there are no code tools like n we can definitely use nitin right now many many people uh many many companies are demanding people who knows about nin because Here you will be able to even do the deployment in the production you'll be able to do the entire workflow you'll be able to build the entire workflow in ease right so this way that criteria which was there before right I need to have a prerequisite to learn AI that prerequisites we are just trying to cover up with the help of no code tools and techniques that we use specifically AI things in there right to build proper applications that is our main aim so by this way you will be able to just say like let's say that you are a manager you are probably working in a company tomorrow a use case specifically comes into AI you know the concepts right you you have an idea how things are basically built so working in that specific environment will probably add more values in that project or whether you're talking to the client whether you're thinking of building some new application you can also put more inputs as you go ahead right so that is the main aim behind the specific batch and this was requested. We have been teaching from past five to six years. I have thought over every solution that is available in the specific market. What demand is there and based on that we launch our courses. Right? So that is the main aim. I hope you have understood who this batch is specifically for, how you can use this particular batch and how what all things you can build after this specific batch. when I probably talk about workflows any complete workflows like automation everything you can be you will be able to do it with the help of no code tools that we are going to make sure now I'll probably go to the detailed syllabus and make you understand like what all tools also we'll be specifically using over here but concept wise this all will be more than sufficient to crack any interviews as we go ahead right so now let's go ahead and talk more about the syllabus and all and uh what all things we'll be learning in this batch. So here you can I have I've already shown you all the information over here. September 14th, 2025 is the badge date. Night 8:00 p.m. IST to 10 p.m. IST we'll be having the U class and after that we'll have the doubt clearing session course details everything is mentioned over here. But if you just go ahead and click on enroll now. So let's say I go ahead and click on enroll now. So this is what is the page over here the payment page. And the best part is that this 6,500 is inclusive of GST, right? So if you say like what will be the price for this? It is 5,58 and GST is 991. Let's say you are from a company, you want to probably go ahead and apply for GST. Just let our team know for that. Okay. Now the next thing over here is that I've shown you that this is somewhere around 2 to2.5 months of comprehensive AI program designed for nontechnical technical professionals across various domain engineering product manager sales marketing HR operation consultant and entrepreneurs. Now you just don't have a idea see before we used to have a idea to implement things. I need to have a team to implement that. But now you know just you have a idea you will definitely be able to develop an MVP product and from this batch you'll be able to do that. Okay. The key highlights is very simple. It is beginner friendly. It starts with visual explanation of fundamental AI concepts. 100% no code uses practical no code AI tools that anyone can help uh can anyone can apply. Hands-on application content creation to data analysis to research workflow and process automation. We'll cover that. learning outcomes all these things you'll be able to do it right you'll be able to implement any use cases with the help of AI tools without writing any code so yes to make it a production level things and all you definitely require a team but that main MVP product to just to pitch an idea in front of everyone this will be more than sufficient to get started okay who should join first-time AI users team leaders manager executive decision maker anyone looking to apply AI in the work business or career without coding okay and this is the detailed syllabus I will also to go through the detailed syllabus and we'll discuss more about this. So this is the entire syllabus AI for professionals and leaders. So here you'll be able to see all the information is there with what all things and these are all the tools that we are going to specifically use right I will be showing you the example of GitHub copilot we will be talking about you know cloudy code we'll be talking about Google geiny gamma notion each and everything and nain is also there you know we'll also be showing you something with respect to cloud so that you can go ahead and do the deployment over there each and everything so all these tools will be basically there here you can see this program focuses on practical no code AI tools that professional leaders can immediately apply right what all things we'll be knowing generative AI basic prompt engineering no code automation AI ethics and government data analysis with AI workflow optimization AI security basics change management and all who this program is for I've already mentioned it but here you can go ahead and see it right in detailed firsttime AI user definitely go ahead with this if you're a leader manager who who do not really want to do the coding over there and you want to learn this concepts and even apply in the practical sense then this course this is definitely for you. Instructor will be only two people myself and my we both will be dividing the classes between us. Initially I will be taking from introduction to building something and then my will be taking over it. Okay. Then here you'll be able to see what all things you'll be learning. Generative AI fundamentals, AI tools mastery, professional AI tools, no code automation, advanced AI techniques, AI workflow development, end-to-end marketing, AI personal assistant, business transformation, AI leadership, each and everything will be covered over here. So this is the detailed syllabus which everyone can probably have a look onto it. Okay. But yes uh since u you know hardly I think let me check uh how many seats are basically left. So around 92 seats are left still. Okay you can go ahead and use it and uh I will also provide you a 20% coupon code. You can probably see in the description of this particular video. Go ahead and apply it. you know uh mostly next week Sunday this batch is getting going going to get started uh I hope um anybody your friends your family anybody who requires this please go ahead and share this particular video with everyone and yes I will see you all in the next video uh this was it all the information regarding the batch will be given in the description of this particular video so yes this was it from my side I'll see you all in the next video thank you take",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Anúncio do bootcamp de IA Generativa para profissionais e líderes, com foco em aprendizado prático sem código e aplicações reais.",
            "resumo": "Este vídeo apresenta o bootcamp 'Gen AI for Everyone' voltado para profissionais, líderes e iniciantes em IA. O curso começa em 14 de setembro de 2025, das 20h às 22h (horário IST), com duração estimada de 2 a 2,5 meses. O preço é de 6.500 INR, incluindo GST, com variação para EUA/Europa devido a taxas de gateway de pagamento. O objetivo é ensinar conceitos de IA Generativa sem exigir conhecimentos avançados de programação, usando ferramentas sem código para construir aplicações como pipelines de dados, RAG e aplicações com LLMs. Serão cobertos tópicos como LLMs, engenharia de prompts, IA guiada por agentes, RAG, integrações com editores (por exemplo, Copilot) e demonstrações de como a IA pode escrever e até executar código. O curso atende profissionais de diversas áreas e foca em criar MVPs sem depender de uma equipe. O instrutor Krishna tem entre 5 e 6 anos de experiência ensinando soluções de IA.",
            "assunto_principal": "Bootcamp de IA Generativa acessível para profissionais e líderes, com abordagem prática sem codificação e foco em MVPs e automação.",
            "palavras_chave": [
              "Inteligência Artificial Generativa",
              "Curso Intensivo",
              "Sem Código",
              "Modelos de Linguagem de Grande Porte",
              "Engenharia de Prompts",
              "IA Agencial",
              "Geração Aumentada por Recuperação",
              "Produto Mínimo Viável",
              "Automação",
              "Copilot",
              "Ferramentas Sem Código",
              "Profissionais",
              "Líderes"
            ],
            "resumo_em_topicos": "- Objetivo: anunciar o bootcamp de IA Generativa voltado para profissionais, líderes e iniciantes em IA.\n- Detalhes práticos: início em 14/09/2025, horário 20h–22h IST, duração de 2 a 2,5 meses, preço 6.500 INR (GST incluído); EUA/Europa com valor ligeiramente maior devido a taxas de gateway.\n- Abordagem pedagógica: foco em ensino sem codificação, usando ferramentas sem código para construir aplicações e MVPs.\n- Conteúdos-chave: IA Generativa, LLMs, engenharia de prompts, IA guiada por agentes, RAG, construção de aplicações RAG, integração com editores como Copilot, demonstrações de escrever e executar código com IA.\n- Casos de uso: desenvolvimento de MVPs, automação de fluxos de trabalho e implantação de soluções com pouco ou nenhum código.\n- Público-alvo: profissionais de diversas áreas (engenharia, produto, vendas, marketing, RH, operações, consultoria, empreendedorismo).\n- Benefícios: aprender a aplicar IA em tarefas reais, comunicar com clientes sobre IA e criar soluções sem depender de equipes.\n- Sobre o instrutor: Krishna possui 5–6 anos de experiência ensinando soluções de IA e ajusta cursos com base na demanda do mercado.\n- Próximos passos: instruções sobre como se inscrever e detalhes de conteúdo adicional (sí­labo) a ser abordado durante o curso.",
            "prompt_tokens": 1816,
            "completion_tokens": 3780,
            "model": "gpt-5-nano",
            "cost": 0.0066
          },
          "analysis_time": 69.49207711219788,
          "language": "",
          "view_count": 8204,
          "has_transcript": false
        },
        {
          "id": "5AfJ0N3MvpA",
          "title": "O futuro da codificação está nos agentes de IA",
          "title_pt": "O futuro da codificação está nos agentes de IA.",
          "url": "https://www.youtube.com/watch?v=5AfJ0N3MvpA",
          "published": "2025-09-07T00:53:06.327187",
          "published_relative": "há 2 semanas",
          "duration": "15:48",
          "date_published": "2025-09-05T00:56:27-07:00",
          "transcript_available": true,
          "transcript": "Hello all, my name is Krishna and uh welcome to my YouTube channel. So guys um before I proceed, I really want to wish you a very happy teachers day. I pray to God that you achieve all your goals in your life and you do well for yourself and your family members. Now in this particular video I'm going to talk about future of coding with the help of AI agents. And uh the reason why I'm making this specific video is that because you should definitely have a new perspective like how applications are being currently built. Okay? Because this will be really really helpful for you all in companies and uh definitely to improve your productivity. This video will be must okay. So uh let's go ahead and let's talk about when I started my IT IT career right in 2011. I would suggest like in 2011 if you were starting at that point of time you know coding definitely was a very difficult work you know why because you needed to refer so many things to implement anything as such you know you cannot just buy heart each and everything you had books you had some of the blogs you had stack overflow but now as things are getting evolved you know you know how AI has got evolved from machine learning to deep learning to generative AI agentic AI now you have so many different kind of LLA models you know which are able to probably do a lot of task for you generate code and you know in short it is improving your productivity so if you see from 2011 to 2025 I really feel blessed because I've seen almost each and everything I'm an experienced coder so definitely for me this will be a productivity kind of thing for me right I now if I really want to do any kind of coding all the repetitive tasks that I used to do no I will be able to do it with the help of AI only new concepts that I really wanted to do for that I had to actually put my mind right so currently the coding culture is completely different with the help of AI agents and in this particular video I'll be talking about that so let's let's go ahead and share my screen and as I said guys before let's say in 2011 12 13 right whenever we had a startup idea right definitely we needed to have some kind of team members to develop the prototype type to develop the MVP product. But now things are different you know since AI is there. Uh if you have a startup idea definitely go ahead and implement it. You know at least implement the MVB product and uh you know with that MVB product at least showcase it to the entire world like how is the idea whether it is good or bad. Many people will give hundreds of feedbacks for you right and you may be thinking Krish how that will be possible how me and for to implement this definitely you need to have some kind of coding background if you're a fresher this will not be possible right in this today's time you really need to be a very very good coder if you really want to start something of your own right because if you have that particular knowledge you'll be quickly able to develop a prototype once you develop a prototype once you develop an MVP product once you showcase that to the world if you get good feedbacks that is the stage that you should go ahead with it right so in this now I'll show you like how if you also are a starter and you're probably thinking of a startup idea you want to probably develop the MVP product now how the coding culture has completely changed with the help of AI agent so usually there are a lot of AI agents that we specifically use for coding there are like GitHub copilot we have cloudy code and all right so let's say that this is uh if are following my rag playlist. Um these were all the codes that I have explained in my previous session and all right and now you see if I have this entire code now I want to convert this into a modular structure right in Jupyter notebook you can see that quickly I have done some ideation I created something I developed the rack pipeline step by step I did it right now in order to convert this into a modular coding do you think that I will just go ahead and create keep on creating a files for myself make sure to create that folder structure do the importing this that brief before I used to do this right before I used to do this if I talk about four to five years back uh I would suggest okay I have to develop everything from scratch and go to this but now because of the AI agents what has actually changed so let me just go ahead and quickly show you so here what I will do I will just go back to my extension and here I will just go ahead and install GitHub copilot now if you don't know what is GitHub copilot so GitHub copilot is your AI pair programmer right and recently GitHub copilot have also come up with a uh agent which is called as uh GitHub copilot chat. So in the chat what happens is that whenever you open the chat right so how do you open the chat? First of all you go to GitHub copilot install it you know for me GitHub has given this for free you know for some number of request every month because I was a GitHub star. So I will just try to go ahead and use this. So let's say that I will go ahead and uh click on open chat. Okay. So here you can see open chart right and you can see over here that all the kind of instruction that I have earlier given over here. Okay. So let's say that I I uh once you open this particular chart right so this is just like a AI programmer pair programmer. So here you basically go ahead and select the agent you select what model you really want to use. Let's say that I want to use GPT41. So let's say I will go ahead and ask hey please explain me about the about the explain me about the project repository okay repository I'll I'll just go ahead and ask this particular question now here you can see that um it'll take some time it'll go ahead and explore everything that is present over here and it'll give me the answer right now I know that let's say that I want to probably go ahead and develop a rag application. Okay. So now I want to go ahead and do it in a modular coding. I am already an experienced developer. I know the concepts very well. So do you think that I really have to do the coding? Even though I know the coding. Okay, I know the coding. I can definitely do the coding over here. It will take me a couple of days to complete the project. But what if I just want to quickly test the prototype in 1 hour? I can do that. So here see what I'll do. I'll say hey inside the src folder initially initially implement logging and exception handling. So let's say that I have given this particular because I know before I I really want to go ahead and do or start any of this particular project I need to implement uh the logging and exception handling. Okay. So here all the logs should be stored in the log folder in the log folder in the root workspace. Okay. So see I've just written this now automatically what will happen it'll think what what is the question that I have actually given and here now it is going to go ahead and create a log folder. So somewhere you'll be able to see that checklist. It has said that create a log folder in this. It'll create an entire plan how the execution is basically going to happen. Now automatically a log folder is created over here. This is my logger. This is my exception. Here you can see this right here is my logging. Here is my here is my exception. Here is my logger. Right? And this code is definitely from the same thing what you have actually used in the documentation and all. So now I will just go ahead and keep this and even I can go ahead and do the testing if I want. Okay. So now what I will do I will also say update the code with the test condition inside a main function inside the main function within the file within the file. Now if I just go ahead and see the code you know I will be able to understand the code itself. So that is this reason I said that hey this is what I'm actually going to do is that the main thing is that I need to understand the code. If I'm able to understand the code I know I will be able to do the testing. Okay. Now you see this I have updated the main file. Okay. So main over here you can see test condition test flag is equal to the value error exception. This is a test exception. Okay. Now I'll go ahead and keep it. Now quickly I will if I want to go ahead and execute it then how I'll do it. I will first of all go ahead and open my command prompt. I will activate my u virtual environment and here I will just go ahead and write python main. py. So once I execute it here you can see that exception is basically getting handled right now. Do you see in app.log anything is getting updated. Yes it is getting updated right now quickly you could see right if I really wanted to implement the for my for my experience right if I want to really implement exception handing and logging it would have taken me 15 minutes. I have to probably go ahead and see the documentation. I would had probably seen what all parameters are basically required each and everything right now see logging and exception is done. Now what I can do I can again close this. See this okay I know the first step is data injection. And I'll say hey implement in a rag implement the data injection in rag inside or I'll just say that hey create a data injection dot py file data injection py file inside the source folder source folder and it should read all the PDF files inside the data folder data folder using langen document loader let's say langchen document and convert into and convert into langen documents now this is my data injection now I've given the instruction I know how to do this okay I I definitely know how to do this okay now for every instruction that I do it'll basically create a plan okay and it'll start working on it see the file is basically created now here you can see that I have all these things and it has also executed this name function and such right now here you can just go ahead and load all the PDFs right so here you can see ole directory PDF path right and PDF path is basically where uh here you can actually go ahead and see the PDF path so PDF directory PDF directory is over here if I just go ahead and see here is also given the file name that is data PDF see data Right now, if you want to quickly go ahead and execute it, I'll keep this particular code. Right? And I will just go ahead and write Python source data data injection py. Right? So here with the help of GitHub copilot, I'm able to quickly test things over here. Now this will get executed. It'll go ahead and see that how many number of PDF files is basically over here. Right? And here you can see that it is being able to read it. beautifully right now before just imagine if I did not use coding agent right how much time this was basically taking yes I can go and write this code I'll do some kind of Google search I'll see the documentation how to read from a PDF di because I cannot buy the code itself right so these are all my code that is redundant all the times I keep on writing if I really want to go ahead and write data injection I definitely had to probably go ahead and do it again and again because these agents have already been trained with huge amount of data itself self right now let's say that next step I will go ahead over here and I'll say after data injection what do we do let's go ahead and implement the chunking so I'll say hey uh create chunker py file inside the source folder source folder and create and uh perform chunking perform chunking perform chunking perform chunking after the data injection pipeline. Okay. Now see I'm just doing this okay I I've just written in a very vague manner create chunker. And so I'm perform chunking after the data injection pipeline. So this is basically planned my chunker.py has been created. Now I'm also using model structure. Okay. So here you can see definition chunker. So here we have basically called load pdf and then chunking is basically there. I can also go ahead and tell them hey please use modular coding please use classes automatically. Okay so let me say hey can you use classes inside chunka py. So here what I'm doing is that if I want a function I can go ahead and this is for starters. If I want to make it more complex I can tell uh my GitHub copilot agent uh specifically the chat agent to probably go ahead and refactor the code. Right. So here you can see that now I will go ahead and keep it. So these all things are basically getting update. I'll go ahead and keep it. And here you can see now I have a class and I have an init method. And then the same thing is basically happening over here. Now if I want to quickly go ahead and execute this, right? I will clear the screen. I will clear the screen and I will say hey let's do one thing. Let's do just go ahead and execute python src/chunker. py. Now what will happen? Both the pipeline will get executed. Now see overall the main thing is that you need to know the concept. If you know the concept you can create a plan and you can keep on executing and this is how the future of coding is going to look like. Okay. This is definitely how the future of coding is going to look like. Now here you will be able to see that let's let's go to uh one of the courses that see my main aim of launching anything that you see around yourself is for a specific reason if I go to krishna.in Right? If I go to live classes, so here what we are doing generative AI for everyone. We are bringing up this specific course and we teach all these things over here. Right? We say people that hey how you can go ahead and probably do this. You need not even have a coding knowledge but at least some basic idea of coding is more than sufficient to get started. Right? Here we are saying that how we can use these all amazing tools and how beautiful things you can actually do with this. Here we show you that how you can use all these tools along with this. I also use cloudy cloudy code. So if you know about cloudy code so that is also a very good handy AI agent for useful for integration with the code and all right I use that part. But I hope you're getting an idea like how now the coding is basically going to change. This is really important. Now let me talk about some of the pros and cons in this. Now you may be thinking can a fresher start with this? No, you become a good coder and then try to use this for your productivity. That's it. You know before any projects that I really wanted to build. See, I have a lot of knowledge. I have a lot of architecture knowledge. I've done a lot of different kind of projects. I've seen different different complexity. Just imagine for implementing a project I will definitely say that hey I know all this stuffs. Now I'll tell my agent to specifically do that. People lack that thing. If you do not have that knowledge how you will be able to use the productivity a so for that you need to be a better coder you need to start from scratch you need to get a better handy knowledge for person who are very highly experienced if they have some kind of MVP ideas in them they can directly go ahead and implement this and that is what the future looks like with respect to coding so I hope you like this particular video this was it from my side I'll see you on the next video thank",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo explora como agentes de IA estão transformando a codificação, aumentando a produtividade e permitindo prototipagem rápida de MVPs com ferramentas como o GitHub Copilot e o Copilot Chat.",
            "resumo": "Krishnaik06 discute o futuro da codificação com IA, destacando a evolução desde 2011 até 2025 e como agentes de IA podem incrementar a produtividade. O apresentador compara a antiga necessidade de buscar informações em livros, blogs e Stack Overflow com a era atual, em que IA, aprendizado de máquina, aprendizado profundo e modelos de linguagem ajudam a gerar código, estruturar projetos modulares e acelerar prototipagem. Ele exemplifica como startups podem ir direto para o MVP com a ajuda de IA, em vez de depender de grandes equipes. O vídeo também demonstra um fluxo prático com GitHub Copilot e GitHub Copilot Chat, mostrando como pedir ao agente para criar estruturas de pastas, logs, tratamento de exceções e testes, tudo para validar rapidamente uma ideia de projeto. Conclui que codificar bem continua importante, mas a IA facilita tarefas repetitivas e a criação de protótipos.",
            "assunto_principal": "Futuro da codificação com IA e o papel dos agentes de IA na produtividade, prototipagem rápida, MVPs e fluxos de trabalho com Copilot.",
            "palavras_chave": [
              "inteligência artificial",
              "agentes de inteligência artificial",
              "codificação",
              "produtividade",
              "GitHub Copilot",
              "Copilot Chat",
              "produto mínimo viável",
              "startup",
              "prototipagem",
              "desenvolvimento de software",
              "modularização",
              "automação de código"
            ],
            "resumo_em_topicos": "- Introdução e objetivo do vídeo: discutir o futuro da codificação com IA.\n- Evolução da codificação desde 2011 até o presente, com IA aumentando a produtividade.\n- Startup e MVP: como a IA facilita prototipagem rápida sem depender de equipes grandes.\n- Fluxo de trabalho com GitHub Copilot e Copilot Chat: gerar estruturas, logs, tratamento de exceções e testes.\n- Importância de ter boas habilidades de codificação, mesmo com IA, para validar ideias rapidamente.\n- Conclusão: IA como catalisador da prototipagem ágil e da produtividade no desenvolvimento de software.",
            "prompt_tokens": 1836,
            "completion_tokens": 2960,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 47.28566789627075,
          "language": "",
          "view_count": 25079,
          "has_transcript": false
        },
        {
          "id": "MykcjWPJ6T4",
          "title": "2-Construindo um pipeline RAG do zero - Ingestão de dados para o pipeline Vector DB - Parte 1",
          "title_pt": "2 - Construindo um pipeline RAG do zero - Ingestão de dados para o pipeline Vector DB - Parte 1",
          "url": "https://www.youtube.com/watch?v=MykcjWPJ6T4",
          "published": "2025-09-07T00:53:06.327205",
          "published_relative": "há 2 semanas",
          "duration": "59:07",
          "date_published": "2025-09-02T21:42:54-07:00",
          "transcript_available": true,
          "transcript": "Hello guys. So we are going to continue the discussion with respect to rag. Already till now we have understood what is rag. Then what are the main drawbacks we are fixing with rag and along with that we have also understood how the rag pipeline is right. It usually consists of two important pipeline. One is the data injection pipeline and one is the retrieval pipeline which includes this two box. Okay. Now we are going to go ahead with some kind of practical implementation. Now the major thing that usually comes in my mind right whenever we go ahead and start any new series that is how should we cover a specific topic you know so that we understand the coding from basics and we move towards modular coding so that is how I'm going to implement this entire pipeline initially we will go ahead with some basic code we'll try to understand the fundamentals and then we will start writing more complex code we'll be using modular coding also. So initially we will write all the code in Jupyter notebook then we'll increase the complexity we'll write uh code in terms of class reus reusability and then we'll try to see that how we can actually create the pipeline. So that is how the agenda will probably go ahead as we go ahead right. So two important things that we'll think about the first important thing is to understand about the document structure. Now whenever we work with any external knowledge database any data that needs to be feeded into the vector DB you definitely need to know about this document structure. Why? Because inside this data injection pipeline the first step is data injection. Now whenever we talk about data injection here we can have any kind of files right we can have PDF files, HTML file, DB file, Excel file. Our main aim is to read all this particular file content and probably convert into a structure wherein we can additionally do uh we can apply strategies like chunking embedding and store it into the vector DB. That is what this entire pipeline is all about. So for that you really need to understand this document structure. So if you see this diagram right so since uh these two are the main topics that we are going to cover in this particular video initially we will go ahead with document structure understanding this and then we'll try to build our complete rag pipeline in our complete rag pipeline we have two important step one is the data injection pipeline and the other one is the query retrieval pipeline now whenever we talk about the data injection pipeline let's let's talk about this in complete depth right so initially you have this data injection pipline pip line in the data injection pipeline the first step is data injection that basically means let's say that you have you may have different kind of files like PDF HTML right excel you may have uh DB file you may have unstructured file any kind of file format so in data injection what is our main strategy is that how to proceed with reading this particular file how to perform data parsing how to perform from data parsing and then finally how to convert this into a document structure document structure so that is the reason in this video right as I said we're going to first of all understand about document structure how to build this document structure what is metadata now inside this document structure uh you will be learning about important components like metadata you'll be learning about content you'll learning about how the structure of the metadata exist each and everything right so we will be covering completely in depth like how these things actually work okay once you understand this that and this data parsing is really really important step because of this you know later in the retrieval pipeline that is the query retrieval pipeline based on this parsing it can become much more efficient right you'll be able to get the results much more accuracy see much more accurate. So that is the reason you need to really focus on the data parsing. Now after doing the data parsing the next step usually is something called as chunking right. So here in the chunking we we convert this entire data into chunks multiple chunks. So this chunks is like let's say this is my chunk one. This is my chunk two. This is my chunk three. This is my chunk four. Okay. Then as we go ahead after applying chunking. So chunking basically means and why do we apply chunking? Chunking strategy is very simple. Whatever documents we have, we are just dividing this into smaller parts or smaller chunks. The reason we do this because whenever we consider with respect to any LLM model or any L embedding models let's say here the next step is all about embeddings okay in embedding with respect to every LLA model there is a fixed context size okay let's say if I take the complete 100 pages PDF and I directly try to give it to an LLA model for performing the embeddings like uh if I give it directly to a embedding model for performing the embeddings and embedding basically means you convert text to vectors it will not be possible it will say that hey you have you you you are providing data more than the context size and that will not be possible in order to convert the text into vectors so within the limit of the context size you really need to give the data and this is for both embedding models and even in the later stages whenever we use any kind of LLM model because for every LLA model there is a fixed context size. Yeah, different LLA model may have different different context size. So that is the reason and it is always a good strategy that we try to divide our data into chunks so that we fit them in a way that we uh in the later stages we'll be able to efficiently put them into the vector database which is this. So after chunking for every chunk we go ahead and apply embeddings. Okay. So we go ahead and apply embeddings and from the embeddings we finally store that into our vector DB. Now inside this vector DB all this will be stored in the form of vectors like let's say this is my record one record two record three record four like that right so this is one record two record this is my third record then fourth record fifth record this you have right now from this particular vector DB you will definitely be able to apply any kind of similarity search similarity search now in this specific video what we are going to do is that I will be using any of this file and I'll create this entire pipeline. Okay, I will I'll just create this entire pipeline and you also need to probably work along with me later on. For any other files, I will give you an assignment. Okay, I will show you with couple of files. Let's say I'll take PDF file and I'll show you this entire data injection. Then what you do is that as an assignment you use any of the other files format. let's say Excel, CSV, whatever file format you want and you try to complete the same pipeline. Okay. So that is what is my strategy and please make sure to complete the assignment also and we will go step by step completely from scratch so that everybody will be able to follow. So first of all I will go ahead and open my empty folder and in this remember I will be using langin uh and this is just a traditional rag right now in the later stages we will move towards a genic rag. So from this particular command I will just go ahead and open my command prompt. I will open my VS code. So let me quickly go ahead and open the VS code. Now from the VS code the next step will be that I will quickly open my terminal terminal and let me just go ahead and write uv uh I'll just go ahead and initialize this particular workspace as my repository. So yt rag is my workspace. Now I will just go ahead and also go ahead and create my environment. So if you're using UV package so you can just write UV env. So my Python 3.13.2 will be the recent uh Python version that I'm specifically using for this particular project and then I will go ahead and create activate this particular environment. Okay, perfect. Till here we are good enough. Now I will go ahead and create my requirement.txt. Now from this requirement.txt let me quickly go ahead and install some of the packages like langchain lang chain core uh core lang chain dash community uh the all things are there. Let's me quickly go ahead and install these packages. So uv add minus r requirement txt. Okay txt. So this is done and along with this I will also go ahead and install some of the libraries like pi pdf pi mu mu pdf. Okay so these are all libraries I'll be using. I'll talk about why I'm using pi pdf pi mu pdf right. This is specifically to read my pdf documents. So one example that I'm actually going to show you is with respect to PDF and then you should also try to create the same pipeline with the help of any other uh data types. Okay, data formats types like let's say it will be it can be JSON, it can be anything as such. So uh my requirement txt is filled. Now what I will do is that I'll quickly go ahead and create my data folder and here I will also go ahead and create my notebook folder quickly so that I can start working on it. And then along with this I will also go ahead and add UV add ipi kernel. Okay. So that I will be able to work along with my Jupyter notebook. So ipi kernel has got executed. Now quickly I will first of all start with my Jupyter notebook and at the first thing that I told you it's related to document data structure right document what is document and what is how document can be very very helpful if we are using in the document data uh in the data injection pipeline. Okay. So I'll quickly select my kernel and these all things you really need to be a good at Python programming language. See there cannot be anything that you uh you can skip Python programming language. So my suggestion would be never do that. Okay. So Python is must and this time I'm just going to use some more advanced coding and it'll not be possible for me to write line by line. So definitely I'll go a little bit fast to in order to explain you. Okay. Now as I told you if I go back over here in the data injection our main aim is to load some data apply some chunking then convert into embeddings and finally store it into the vector DB. That is what my entire data injection pipeline is all about. Right? For understanding this we need to understand a document structure because all this chunking that is done you know the final output will be documents. Now what exactly is a document data structure? So here I will go ahead and write what exactly is a document data structure. So for this I will go ahead and import from langchain or to probably show you this I will be showing you some kind of uh file so that you'll be able to understand it. Okay let me put this file over here. Okay, I have some file over here and then we'll try to understand okay what exactly is a document structure. See langchen document structure. So langchen uh document is a kind of a data structure which will be able to save some data in some format where we have two important things. One is the page content and one is the metadata. the page content will basically have the content that is present inside that particular file. Okay. So if you are reading the file inside my page content all those detail all those content that is present inside the file will be available over here and metadata will be some more additional information of the file like it can be the file name it can be how many number of pages are there how what is the time stamp of the file each and everything. So this way whenever you read any kind of data and you convert them right in a document data structure this format will be very very important because at the end of the day we will be doing the embedding on this particular data and pushing it into the vector DB and when we do that specific task pushing into the vector DB we will be able to apply different different uh algorithms like similarity search cosine similarity and we'll be able to retrieve the results. So here you can see that all the information regarding this is given over here. So usually langchen document structure it has two important core components. One is page underscore content and one is metadata. And here page content will be the actual text uh content where all it will be very very handy in research papers if you want to probably create a rag application or research papers product manual. So you can specifically use this in langchain you definitely have different different loaders. Okay, loaders like you have something like PDF loader, you have CSV loader, you have web-based loader, you have directory loader. Now see all these loaders what it does is that for PDF loader will be used to load the PDF files and once it loads the PDF file right it will be giving you the output of the documents in the form of a document structure. Okay, I will show you practically also why I'm specifically saying and stressing on this. Okay, it will definitely give you all the output in the form of a document structure. Similarly, in the case of CSV loader, here we are giving the CSV file, but it will try to convert the entire content that is present inside that CSV into a document data structure. Similarly, with respect to web-based loader, clically loader. Similarly, there are so many different different loaders over here, right? You can use any of this particular loader to load the data and at the end of the dec uh this loader will finally give you the output in the form of document structure. Okay. So I hope you got an idea about what exactly is document structure itself. Okay. So now quickly what I will do I will go ahead and u start explaining you about like how we can start with the document structure. So for the document we need to import from langchen langchen dot there's something called as text splitter and uh sorry langchen core it is present inside underscore core dot documents import document. Okay now this document you will be able to see that if you just hover over here you'll be able to the class for storing a piece of text and associated metadata. Okay. Now if you really want to understand a document structure so first of all I will go ahead and create one document let's say manually I'll go ahead and create so I will use this document and inside this we will be using two parameters one is the page content let's say this page content I'm writing this is the main text content uh content uh I'm using to create rag okay so I I've just basically written some some basic content over here. Let's consider that this particular content is coming from a txt file. Okay. But along with this content, if you really want to improve the source query retrieval from the vector DB, you need to also go ahead and write metadata. So the second parameter that you'll be able to see is something called as metadata. Now inside this metadata, you can write different different information because at the end of the day, this is text. You can write like okay fine, this is my source. The source is basically coming from example.txt file. Okay. Then let's say the number of pages are uh equal to one. Okay. Total number of pages are like one. Uh I can also go ahead and write some more information like okay who is the author for this? Author is nothing but question. So this is the additional details that you'll be able to see it. Okay fine. Let's go ahead and write date created. So date created. Right. Date created. And here I can go ahead and write 24 uh -01 - 0 like it's like first 2024 or first 2025. Now why these all metadata will be really really important because once we consider this document right once we do the chunking once we do the embedding and once we store into the vector DB when you're doing the similarity search you can also apply filters that is the most important thing of this and when you apply filters let's say that I am applying a filter uh I'm searching what is the main text content for building the rag some information is there let's say there's some information related to the rag if I ask that particular question and I say by author Krishnaak I just add that particular filter then it knows from which document to probably pick up because it is going to apply a filter by using the name of author right and that is why this metadata will definitely play a very important role now if I just go ahead and execute this doc you'll be able to see that fine I'm getting this particular document here you can see metadata is there and as you go ahead you'll also be able to see page_c content right so these are the two main important parameters with respect to this which everybody can probably go ahead and use it. Okay. Now I hope you got a very clear idea about it. Uh now what I'll do I will just go ahead and create a simple simple create a simple txt file. Okay. Now for creating a simple txt file what I will do I will just go ahead and import OS. Okay. And I'm saying OS domake directory data/ext file. So I'm trying to create this particular inside this fle folder I'm creating this particular folder name okay and if it already exist I'll say that don't do anything right so as soon as I go ahead and execute it you'll be able to see that okay it is going inside the notebook file I'll remove this and let me go ahead and write double dot slash let's see now you can see over here text file is present okay so text file I'm I've just done that inside this now let me go ahead and manually create a text file with the help of Python code. Okay. So I will just go ahead and use a Python code. See guys, this is all our basic Python code. I don't want to write each and every line of code and make it very very big. Our main aim should be that understand concepts quickly show you multiple use cases and then try to implement this. Okay. So now you will be able to see I have created this simple text. I've given the file name something like this. So let me go ahead and write this to it. Data text files python intro.txt. And this is some content that is present inside that particular key name. Okay. So this is my file name. You can see this is key is my file name. And then here I have specifically my Python content. Okay. Here I'm saying for file content in sampled text items. I'm telling to open the file name. I'm saying that write the content. Okay. So this file path is nothing but my file name. Okay. So if file is not there, it will try to create python intro.txt. So now if I go ahead and execute this. So it is saying me no directory. Okay, let me just go ahead and create one file. Okay, python intro um text file. Okay, I have to give the path because there are two files that is over here. One is okay, one file is also over here. Okay, so I'll just go ahead and write dot. Okay. So now here you can see my sample files has got created machine_arning.txt and python intro.txt. Now what I will do? See I've created some sample file. I could have also manually created it instead of doing the code. Okay. But I really wanted to show you all the things. Now what I will do I will show you how to read this particular text using text loader. So one of the loader that is present inside langin is something called as text loader. So here I will go ahead and write from langchen dot document loaders import text loader okay text loader so here we have imported text loader and uh along with this uh see if you don't want to also use this if I execute this this is also there before if I talk about it right when langchain keeps on changing its library here and there so there we used to use langchain community dot document loaders this also we used to use import text loader so any of them you can actually use unless and until you get a deprecated warning okay now the question is that how do we go ahead and read the text so I'll write loader is equal to I will initialize text loader give let's give the path the path is nothing but parent folder we go to the parent folder data / text files / python intro.txt. So here I have actually given my file name whatever file name we have actually created and we can also go ahead and use encoding UTF8. Okay, encoding UTF8. So once I do this okay and now once I go ahead and read this loader now what it is giving it is giving me an object of um text loader. Right now in order to get the content inside this I will be using loader.load load. Okay. And here you'll be able to see that I will be getting the document. Okay. Now let's go ahead and print the document. So I will write print document. So let's say this is my document. I'm going to print it. So here you can see in the document you are getting metadata. You're getting the entire information and this is your page content. Now this is what it is doing right. This text loader is by default giving you the data in the document structure. as soon as it is reading. And here the best part is that you can also see some of the metadata information has also got updated like what is the source right you can still go ahead and manually change more information inside the metadata but by default the best part is that whenever you're using this all libraries then also it will be able to give you the content in the document structure which is really really good because in the document structure you have two important things one is the metadata and one is the page content. So this is with respect to text loader right I have just read the text loader and I am able to get this in this way. Okay. Now one more way what I will do I will show you with the help of directory loader like if I have all the important files in my directory. Can I read it like that also or not? Okay. So for doing this let's use uh one more library which is called as directory loader. Right. So here you can see lang community.d document loader import directory loader now inside my directory loader you can see that I'm giving this particular file again this file should be uh parent folder does this and here I given the pattern to match see this function basically you can give a pattern to match all the files then you can use loaderclass loaderclass basically means which file you are planning to load if it is a PDF one you can directly go ahead and use PDF okay so what I can actually do is that I can also go ahead and insert PDF files over here. I can also provide this in the form of list so that it'll be able to read both the content. Okay. So once I go ahead and execute this, you can see here also I'm using the encoding and all these things. And here you can see uh once I go ahead and write directory loader dot load. Okay. And here you will be able to see documents. Okay. And then now if you just go ahead and print the documents you should be able to see this. Okay. I'm getting an error to log the progress. Please install P pip install TDK. Okay. So here we have enabled the parameter show progress is equal to true. Let me make it as false. So that I don't need to probably go ahead and install this. Now here clearly you can see that there were two text txt file. I got two documents. Yes. Now further you can do chunking and all right based on the number of documents over there I was able to get it. Right. So this is the most amazing part uh about this. Now what I will uh quickly do is that let me go ahead and create uh a PDF file also. Okay. So here I have some examples of the PDF file. Okay. So let me quickly go ahead and copy this and paste it over here. Reveal explorer data. I have text files. I have PDF files. Now inside this PDF file now my main aim is to read both the text and PDF files. Let's see. So here I have attention PDF, this PDF, this PDF. Okay, so this is my one document. Okay, let me go ahead and write the same code. Copy and paste it over here. And this will basically be for the PDFs. So for PDF I will be having from lang chain langchain core dot document loaders import pipdf. I think pi pdf is not available over here. Let's see where is this specific library. I'm just checking out the documentation. Uh PI PDF. Oh yeah, it should be there. So it should be here in the inside my community dod document loaders. I have two different types of library. Pi PDF and PIMU PDF. PIMU PDF is better when compared to PI PDF. You can see uh PIP PDF shows load and parse a PDF file using PI PDF library. And similarly if you go ahead and see pime mu PDF it loads and parse PDF file using this provides method to load this this this is there all the information you can see the differences which one is better which one is not better in the later stages. Okay now what I'm doing is that I will give the path over here. So from data / data and here you can see the path is nothing but PDF. Here I will go ahead and write PDF. Instead of writing text loader I will go ahead and write py mu PDF. Let's go ahead and use py mu pdf. I can also include encoding in this. And here what I will do I will quickly write pdf documents is equal to directory loader dot load. Okay. And then if I just go ahead and see pdf documents, you should be able to see there are so many different PDFs. Okay, I'm getting an error. Uh, get text got an unexpected argument. Okay, let's remove this. I will not be requiring anything. We don't need to apply any encoding by default. Okay. So, here you can see I have got all my documents. Yes. So, how many different files were there inside PDF folder? One is attention. PDF, embedding. PDF, object detection. These are some of the research paper. And with respect to this all we are able to see this. And now the best part is that when you're using Pymo PDF here the metadata information is completely different. See creation date source file path total pages right format. See total pages is 15 for the first one then 27 then 21. See you can see it so beautifully it is there. See I have also created some of the PDFs there also. You'll be able to see some kind of author's name also. Right? It tries to bring up all the entire source information and this is your page content right so beautifully you are able to see the entire content quickly right so that is what this all PDFs is all about and here at the end of the day even though we use this specific libraries we are getting this in the form of a document structure it is a list of documents so if I go ahead and say what is type of PDF document of zero you'll be able to see okay it is of a document type right now that is the most important thing. If you now see that we have understood about document structure, we know how to read PDF and TXT. Now, don't you think you can actually easily find out how to probably go ahead and read the Excel, DB, any kind of files. And this is the task that you really need to do. How you'll do it? Just go to lang chain document loaders, right? And you will be able to find out everything over here. Just go in and try it out. Try it out. Try it out. side to see if the document structure that you're getting is good or not. So here there are so many different things you can go just go ahead and try it out. If you want from AWS S3 you you want from AWSS3 directory go ahead and just install this particular library give this but before that you have to do the authentication and all right once you do this and uh once you're able to do it you can use any kind of document loader size as you add but at the end of the day what is what is the best thing about this at the end of the day you are able to convert everything into a document data structure right now if you see with respect to data injection here you have actually completed created. Now the next step is that I will move towards chunking. Okay, I'll move and show you how the chunking can be specifically done. What are the different ways of chunking um that you can actually do you know and then finally we'll see that how we can even convert into embeddings. We'll try to use an open source embeddings for this and then finally a vector DB. So yes, I hope you have understood about the data injection part. Now let's move towards the chunking part where we will understand uh how we can actually performing chunking and I have also told you what is the importance of chunking. Quickly let's go ahead and see the embedding part. So for the embedding I will just go ahead and write a markdown. So let me quickly write embedding and vector store DB. Right. So we are going to specifically go ahead and implement these two important modules. Now first of all what I do do is that I I definitely require some kind of libraries over here right for embeddings. So for embedding uh we are going to use sentence transformer. Uh we are going to use a model that is available in hugging face and for that I will be using the sentence transformers library. Along with this uh I also want to use some kind of uh you know vector store. So this is the vector store I may use that is fires CPU. You can use fires or you can also go ahead and use chromadb. So these are some very good open-source vector store that is available. Um now these all libraries will be more than sufficient to get started with. So quickly let me go ahead and install it. So I will write uv minus r requirement.txt. So once I do the installation you'll be able to see that. Okay the installation will get completed. So once the installation gets completed, it'll take some amount of time because we are loading the entire transformers. So here you can see that quickly it has got installed. Now I'll go again back to over here. Now once I go over here, what is the first step that I'm actually going to do is that I will quickly go ahead and import some of the libraries that I require like this. Right? So I'm importing numpy from sentence transformer. I'm importing sentence transformer. My embedding model right will be available inside this. Then I'm importing chromadb. Then uh we are also importing the settings from this. We are importing uyu id. The reason of creating this uyu ID is that because every record that we specifically insert into the vector dv will have some kind of id over there. We'll generate that. Then along with this we will also be importing list dictionary ne and tupil. And uh since we are going to apply cosine similarity while doing the retrieval from the vector db I also will be importing this and this is available in skyit. So let's quickly execute this. Okay. And till then I will go ahead and create more number of cells. Now as I said for embedding I will go ahead and write one different class. So I will say embedding manager. So this will be responsible in doing the embedding part. So for first thing is that once I am creating this uh for every class that we specifically create we need to write an init function. Okay. So init. So this is my constructor. You'll be seeing that it handles document embedding generation using transformer. Here we are initializing the embedding manager and the model name that we are giving is all mini LM L6 V2. So this is available uh in uh hugging face this specific model all mini L6 V2 and this is responsible in specifically converting a text into vectors and you get somewhere around 384 dimensions. Okay. Then uh we initialize the embedding manager. Then model name is nothing but hugging fist model name for sentence embeddings. We are going to use this. Okay. So here we are initializing the model name. Uh we are saying self domodel is equal to none. Okay. Because here uh later on we'll initialize this value. This function is very important. Load model. So that basically means my next function will be load model. And this model work is very simple. This function work is very simple. it is going to load this model that is all mini L6 V2. Okay. So I will create another function which is nothing but underscore load model. Why we write underscore? Uh this is just like a protected function. Uh if you know about classes we use something called as a protected function and within this protected function within this class only it will be accessible. So here uh what we are doing we using the sentence transformer and whatever model name we have we are loading it. Okay we are loading it. So cell broad model of sentence transformer model cell broad model name then this will be modeled uh loaded and here you'll also be able to get the dimension for that we use a function called as get sentence embedding dimension and by default it will be uh somewhere around uh 384 dimensions. Okay that basically means every text will be converted into 384 dimensions. So once we have this init function we have the load model. Now one more function that we require is generate embeddings right. So here uh you'll be able to see that I will be seeing this generate embedding function. Okay. So generate embedding is nothing but it takes the text that is nothing but list of string and it returns a numpy array. Okay. So here it generates a embedding for list of text. Very simple. So here what we are doing we are basically using the self domodel dot encode is the function that we have to use on text. whatever text list of text we give and we also giving show progress bar is equal to true so that we should be able to see the progress bar and we return the embeddings. Okay. Now generate embedding is one function load model is one function. We have also used get sentence embedding dimension just to get the dimension. Okay. Now for this you can either get I can you can either create this particular function or you can also remove this. it is not necessary but what I did is that to show you much more in a better way we will create this function get sentence embedding dimension so here is my get embedding dimension self so here what we are doing we just written model dot get sentence embedding dimension see instead of doing like this also I can write like this only over here okay I can just quickly write this particular function over here okay so sometime it is not required you can also so I will just go ahead and remove it if you want okay I will just remove Perfect. So I have these two three important function. Now we can initialize the embeddings. Okay. Uh sorry we can initialize the embedding manager. So here we will write embedding manager is equal to embedding manager. So I hope this is the class name. It should not be underscore. It should be like this. Okay. Now once I go ahead and write this and once I execute it, this will just go ahead and initialize the constructor. Right? So here you can see it is loading the embedding model all mini LM V62 model loaded successfully. And here you can see the dimension is 384. Right? So it has been loaded. So when we're calling this particular function, this is basically getting loaded, right? So my embedding manager now has the model information over here. Great. So I have my model ready. So if you see from this particular graph, this entire class has been created. Now we go to the next step and create this specific class. That basically means over here we have our model embedding ready. We just need to use it. Now similarly we'll go ahead and create it for the vector store also. Okay, vector store is just like a vector DB database where you can store all the vectors that is being converted by the embedding layer inside it. So that you can apply any kind of similarity search into it. Right? So first of all let me quickly go ahead and define a class for this also. So here I will go ahead and write vector store. Okay vector store. Uh remember guys the code that I'm showing you is very simple if you just see you need to have some coding knowledge if you really want to become better in rag. Okay. Now we'll go to the next step with respect to the vector store. Now in the vector store we are creating a class vector store. Again here we are using a init method. We are giving a collection name. What should be the collection name for the vector store itself. And uh here the collection name we are giving it as PDF documents. We are also giving the persistent directory which will be this particular directory that is inside my data folder. Persistent directory means whatever vector store is basically created we are going to save it that in the hard disk. So here uh first of all I'm giving the collection name. I'm giving the persistent directory. Collection is none. Self.colction is equal to none. Okay. And then we are initializing the store. Now whenever we initialize the store that basically means this function will be initializing the vector store itself. Right? So for this we need to create another function again and see the code. Okay. Just observe the code. Here we are initializing chromadb client and collection. So here we have written osmake directory of self.persistent directory whatever directory path is there. If it already exist we are just going to keep it like that. Otherwise it is going to create a new directory. Then we create a client self.client client wherein we are using chromadv.persistentclient function and we are given the persistent directory over here. So what it is going to do it is basically going to create a client which will be having a reference to the chromadv vector store. Okay then we go ahead and create a collection. So here we write self.colction then self.client dot get or create collections. We're giving the collection name and we're giving some metadata information like what is the collection information and here we basically create a collection uh collection basically means it's just like uh where we are going to store the uh vector uh where we are going to store the uh vectors inside my vector store. So it'll be stored inside this particular collection name. Then we are initializing this with the collection nameolction count. Okay. So as soon as we execute this that basically means my chromob client will be ready and my collection will be created. Okay. Now the next function is that usually whenever we create a collection we need to add the documents right. So for documents we will be creating another function. So quickly let's go ahead and create this because whenever I have a document I will go ahead and create this particular connection. Okay. So here you can see I've created another function which is called as add document. Here we give the list of document. We apply the embeddings. Very simple. Add documents and the embeddings to the vector store. And here you can see if length of documents is not equal to length of embeddings. Here you can actually see this. Now we are preparing the data for Chromma DB. We require ids, metadata, document text and embedding list. So now whatever documents I have over here, whatever documents I'm getting, I will be zipping it. Means I will I'm creating a tupil with embeddings and then I am creating a UYU ID. Why I require UYU ID because it's just like a ID for a specific record, right? And that will be my doc ID. Okay, doc id variable and I'm appending it over there. Then we are preparing the metadata. Whatever doc dot metadata we get. Remember we are iterating through these documents. So we have all the information. So that all metadata we are putting it over here. Doc index content length. We are just adding some more metadata information to put it inside my vector DB. Then we get the document content from doc.page_content and we also get the embedding where we are converting this embedding to list. Okay. See two information is basically required right over here if you see uh from this particular function. One is embedding which is my MP. ND array right and this embedding is coming from where from the previous function right generate embeddings where we have done it. So it's all linkage. See the reason of creating this particular in the form of class because I want to link each and every pipeline right so here we are writing embedding list dot append embedding tool list so we have the page content we have this list so what I'm doing I'm adding that entirely in the collection so for this we require ids we require embedding list we require metadata we require document text so whatever we have prepared we're just adding it over here based on the parameters right and finally you'll be able to see the how many number of documents has been inserted Now quickly let's go ahead and initialize let's go ahead and initialize my vector store. So I'll write vector store is equal to uh vector store and I'll initialize this. Okay. So quickly I will go ahead and write vector store. So now this is basically going to initialize the entire vector store itself. Right. So here you can see this is my collection name and existing document in collection is zero since we did not add any number of records. Okay. Now if we want to add any number of records we have to call this function add documents right. So let's uh go ahead and do that and let's call it. Okay. Now first of all uh you know that I've already done the splitting of the chunks right. So here if you go ahead and see this this is my split chunks right? Uh sorry that was the variable. Let's see which variable it has got saved. Okay, it should be chunks right. So these are my chunks right now chunks what I am actually going to do is that I will extract all the text from that particular chunk and we'll generate an embedding. Okay. So for that what I will do I will say I will put a list comprehension. So here now let's convert the text to embeddings. Okay, we're going to go ahead and do this. And here we are basically going to write chunks. First of all, I'll iterate. Okay, I will say that hey for doc in chunks. Okay. And we are just going to take this doc dot page_c content. Okay. So we are going to take all this page content and basically go ahead and create my text text variable. Okay. So once I go ahead and do this you should be able to see this is my text right all the text that I have and this text I will pass it to my embedding manager right embedding manager which I have actually created. So what I will do quickly, I will just go ahead and execute this once again. I have all my text. Okay, I have all my text. Now from this we will go ahead and generate the embeddings. Now once we generate the embedding, how do we generate the embeddings? Very simple. We use this embedding manager which object we have actually created. What object we have created earlier? If you see over here, this is my embedding manager, right? So we are using this embedding manager dot generate embedding and here I have to give the text in the form of a list list of strings right. So here quickly I will call this particular function dot uh dot generate generate embeddings. Okay. And here you will be able to see that I'll be giving my text. Then let's store store in the vector database. So after we convert that into M embedding we store everything in the vector database right. So here I will use vector store vector store the variable that we have created dot add documents and this is a small letter add documents. This is a function that we have used and inside this if you remember we have to give our we have to give our entire chunks okay whatever embeddings we are specifically applying okay so once we do this uh you can see this embeddings whatever we have got and the chunks the documents the entire documents we're going to do this okay so let's quickly execute this and I think now my embedding will happen now you can see that for 359 text this is happening and it has got converted into so many number of batches uh vector store is not defined why it is not defined let's see what I have defined over there okay it should be vector store so this should be the spelling of my vector store instead of that okay so now let me quickly go ahead and execute this now inside that same vector store it'll get it'll get executed okay Perfect. Now you can see that the total document in the collection is 359. So if you see over here uh inside my u notebook file inside my data file here there is something called as vector store and we have done the persistent over here right. So persistent basically means the now now f the it is saved in this particular hard disk. We can just load this hard disk and we can probably go ahead and execute anything as such. Okay. Now perfect. Now you can see that we have completed this entire pipeline. Now we have all the data available over here in the vector store DB right in the form of vectors. But now the main thing is that how do we perform the retrieval? Because the retrieval see in retrieval what happens is that whenever we have a user query we have to take this query we have to convert that into embeddings again. Okay. And then we basically go ahead and hit the vector store in the form of a retriever and then only we get the context. So in our example first of all we'll try to get till here. Okay we have a user query. We convert that query into embeddings. Then we hit this particular vector store and we get the context. So let's go ahead and create this specific pipeline now. Okay. And for this pipeline we will try to create a rag retriever. Okay. So we will try to create a rag retriever. So let's quickly go ahead and do that particular thing. Till now we have created all the amazing pipelines. We have created this embedding manager. Now we also have this vector store. Now what I will do is that I'll create another pipeline which will be a rag retriever. Okay, just to get the specific context. So let's go ahead and discuss about that. So guys, now let's go ahead and create the rag retriever pipeline. So first of all what we are going to do is that I will go ahead and create a class which is called as rag retriever. Now this rag retriever class you will be able to see that it handles query based retrieval from the vector store. So inside the constructor we will be giving two important parameters. One is the vector store and one is the embedding manager. And if you remember we have created both this. We have created the embedding manager. We have created the vector store manager. Right now after giving this we will be initializing two class variables that is vector store and embedding manager and we'll be assigning with this. Now whenever we create a retriever one thing you really need to understand this retriever is actually built on the top of a vector store and retriever is nothing but it is a simple interface based on whatever query we get. This retriever is just going to give you the response back. Okay. And this retriever is basically a kind of interface which is connected to the vector store and chart. Okay. Now uh the next step that we are going to create is another function which will be called as retrieve function. Now this is really important because this retrieve function main work is to retrieve based on a specific query. So let me go ahead and define the specific function. Now this function again see to write it will definitely take a lot of time. So we will try to understand this particular function. Okay. So here a retrieve function you can see we are giving query we are giving top key results. How many top key results we want and there is also a threshold value. By default it is 0.0 and this function is basically going to return a list of results. Okay. So here you can see retrieve relevant document for a query. Arguments are the search query top K documents and score threshold. and it returns a list of dictionaries containing the retriever documents and metadata. At the end of the day, this function is actually help us to get this specific context. So you'll be able to see over here we are using that same self embedding manager and we are calling this generate embedding function. Now if you remember this generate embedding function is already defined in my embedding manager, right? So if I go on the top, so here is my generate embedding function and this is nothing but this is basically uh you're just using model.enccode and you're giving the text and it is converting into embeddings. Yeah. So that is the reason we are basically using this because at the end of the day first of all whenever we get a query right. So let me go down over here inside this retrieve whenever we give this query first the query needs to be converted into an embedded right. So this query that is given we need to apply embedding for this also so that we can do a um similarity search in the retriever itself. Right? So the first the query is basically converted into a vector by the help of embedding manager dot generate fun embedding functions. Then we are going to use the vector store dot collection and we are going to use this dot query and here we are going to give our query embedding which is nothing but this embedding in the form of a list and then we are also going to give the top key results. So by using this this is basically going to hit the vector DB whichever vector V DB we have initialized and it is going to give you the results. Once you get the results the results internally there will be a key which is called as documents. Okay you can get document information the me metadata information the distance information and some of the ids information. So all the specific information we are using it and here you can see very similarly what we are doing we are using all these parameters like ID documents metadata and distance we are zipping it zipping it basically means we are just trying to create a pupil over here and then for every values we are just trying to calculate the distance right one minus distance 1 minus distance will basically give you the similarity score like how similar those text data is basically coming up outside this vector store. So we are getting the similarity score and if the similarity score is greater than the threshold then what we do we basically add this inside my text context documents and context documents is basically created in this particular variable which is nothing but retrieve docs which we have kept it empty over here. Okay. So all the information we are just trying to add it over here so that we'll be able to see it. Okay. And finally we return that retrieve docs. So if you say step by step we're not doing anything we like not very complex thing we are getting the user query we're converting this into embeddings we are hitting the vector store right then we are getting the response okay once we get the specific response that context we are putting it in the form of a list if you just go ahead and see the code that is how things are happening okay so this is one of the very important function uh that you'll be able to see now here what I can do is that I can quickly go ahead and create a variable called as rag retriever and I can call this same class. So if you see over here I will use this same rag retriever over here and let's give our vector store vector store which I have defined it earlier which is my vector store manager and then my embedding manager. Once I do this I should be able to see this. Okay. uh it should be vector store file right so now you'll be able to see this is my rag retriever rad retriever it is an object of this now if I call this particular function with a query right I can call dot retrieve with a query so let's go ahead and do this okay so here I will write rag retriever dot query sorry dot retrieve is my function fun. Okay. So here you can see quickly this is my function retrieve, right? And I need to give a query. Now let's test for a specific query. I'll say hey what is attention is all you need because I know inside my data there is a PDF file which is called as attention or I have also created some kind of proposal over here or embedding some files are there. So we'll try to execute this. So here you can see as soon as I asked what is attention is all you need. Now it is giving me the top K for all it is printing all the information and it is generated embedding for one text right and the text shape is 1, 384 because I have used the embedding that is called as all mini LMV6 that creates a 384 dimension. Now once we go ahead and apply this particular function right this function it is basically getting the results over here and we are printing that same thing right and at the end of the day we we we can also go ahead and return this retrieve docs okay so in short this is basically this function is going to give me all the retrieve docs so this is the retrieve docs you can see content metadata author so these are my context information so here you can see attention function can be described as a mapping a query as a set of this one and this entire thing is basically the context. So from this particular diagram here you can see easily we are able to get the context right and this is nothing but this is your context. Now let's try some more things. Okay I will just go ahead and open some PDF. Okay. Um this is some very new research paper embedding technical report. Okay. Uh we'll search for any topic over here. Uh embedding model training. I'll just go ahead and search for unified multitask learning framework. Okay. because this information also we have put it over there. So here I'll go ahead and create one more this one and I will copy this entire code. Okay, quickly and this is the query that I'm actually going to give that is nothing but unified multi multitask learning framework. So if I go ahead and execute this you can see that I'm able to get this and then you can see content benchmark ranking over on both the leaders effective of our approach. So we are able to get the response very very much quickly right and this response is basically coming from the vector store right in a very similar way very easy way uh we are able to get the specific response over here right and let me tell you right this is the most easiest way like how things are basically happening over here right now uh what we can do is that see if you know if you have created all these things right till here you have created now the further step is that you to just integrate LLM with the uh with this specific context. Okay. Now for this LLM with this specific context, what you can do is that you can directly take this particular context and give it to the LLM and that is what we are going to see in the next video. But in this particular video, we saw the entire thing the complete rack pipeline from data injection to the vector DB pipeline. Right now you can go ahead and write any kind of queries and definitely with all these information here you can see similarity score is also coming up right distance is also basically coming up all the information you're putting it over here and we have also used modular coding right now in the next step what I'll do I will take this vector store and uh we will go ahead with the next integration that is llm and output which I will say it as a retrieval pipeline but this entire data injection pipeline with this uh query retrieval we have actually created. Now the next two steps will is this one. And after doing this we will try to convert the same code whatever same whatever code we have basically written over here in the form of modular coding. Right? We'll try to see that how we can put this inside our source folder. So here what I will do I will quickly create a source folder and inside this source folder I will show you that how we can take this entire pipeline and how we can actually create it in such a way that we have a kind of pipeline over here right pipeline basically means from data injection to vector embedding how in a sequential way we can actually go ahead and call it but I hope uh you got an idea with respect to this entire code and I hope you are able to understand So yeah, this was it from my side. I will see you all in the next video. Um, this was it. Uh, please make sure to hit like, share with all your friends. I'll see you all in the next video. Thank you. with the",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Guia prático para construir um pipeline RAG do zero, cobrindo ingestão de dados, estrutura de documentos, chunking, embeddings e armazenamento em vector DB, do notebook à implementação modular.",
            "resumo": "O vídeo continua a discussão sobre RAG (Retrieval Augmented Generation) e apresenta a arquitetura de um pipeline com duas fases: ingestão de dados e recuperação. O apresentador planeja abordar o tema de forma prática, começando com conceitos básicos em Jupyter Notebooks e evoluindo para código modular em classes. O foco inicial é entender a estrutura de documentos: metadados, conteúdo e a transformação de diferentes formatos (PDF, HTML, Excel, banco de dados) em um formato adequado para o pipeline. Após a análise, vem a segmentação em trechos, dividindo o conteúdo em partes menores para respeitar o contexto dos modelos, seguida de embeddings e armazenamento no banco de vetores. Com isso, entende-se a possibilidade de buscas por similaridade. O vídeo usa um PDF como exemplo e propõe exercícios para outros formatos, com LangChain e passos progressivos.",
            "assunto_principal": "Construção de pipeline RAG (Retrieval-Augmented Generation) com ingestão de dados, estrutura de documentos, divisão em blocos, representações vetoriais e busca por similaridade em banco de dados vetorial.",
            "palavras_chave": [
              "Geração com Recuperação Aumentada",
              "pipeline de recuperação",
              "injeção de dados",
              "análise de dados",
              "estrutura de documentos",
              "metadados",
              "fragmentação",
              "representações vetoriais",
              "banco de vetores",
              "busca por similaridade",
              "LangChain",
              "Jupyter Notebook",
              "modularização",
              "contexto do modelo"
            ],
            "resumo_em_topicos": "## Contexto\nO objetivo é construir um pipeline de RAG do zero, cobrindo ingestão de dados, análise, fragmentação, vetores de embedding e armazenamento em banco de dados vetoriais.\n\n## Estrutura do pipeline\nDuas partes principais: inserção de dados (inserção e análise de dados) e recuperação (busca por similaridade).\n\n## Etapas principais\n- Ingestão de dados (PDF, HTML, Excel, BD)\n- Análise para transformação em documentos com metadados\n- Fragmentação em partes compatíveis com o contexto dos modelos\n- Geração de embeddings (vetores de embedding) e armazenamento em banco de dados vetoriais\n- Busca por similaridade entre os vetores\n\n## Abordagem de implementação\nInício em notebooks Jupyter, evoluindo para código modular e classes; uso do LangChain.\n\n## Prática e próximos passos\nExibir um PDF como exemplo e propor exercícios com outros formatos (Excel/CSV).",
            "prompt_tokens": 1745,
            "completion_tokens": 4225,
            "model": "gpt-5-nano",
            "cost": 0.0072
          },
          "analysis_time": 87.52905082702637,
          "language": "",
          "view_count": 28377,
          "has_transcript": false
        },
        {
          "id": "fZM3oX4xEyg",
          "title": "Introdução à compreensão do RAG (Recuperação-Geração Aumentada)",
          "title_pt": "Introdução à compreensão do RAG (Recuperação-Geração Aumentada)",
          "url": "https://www.youtube.com/watch?v=fZM3oX4xEyg",
          "published": "2025-09-07T00:53:06.327219",
          "published_relative": "há 2 semanas",
          "duration": "20:40",
          "date_published": "2025-08-31T00:07:59-07:00",
          "transcript_available": true,
          "transcript": "Hello all, my name is Krishna and welcome to my YouTube channel. So guys, I am super excited to start this new series on one of the most important technique which is right now being used in genative AI and agentic AI field that is nothing but rag. If you don't know the full form of rag, it is called as retrieval augmented generation. In this specific video, we will try to understand what exactly is rag. uh what are the disadvantages of just using the LLM model and how we are overcoming those disadvantages with the help of rag when should we use rag and what are the important pipelines that we should take a note while developing a rag application okay so all this topics we will be discussing and as we go ahead we are going to implement each and every important pipelines with the help of Jupyter notebook and I will also show you with the help of modular coding Right. So both the ways we will try to implement it. Now why I'm stressing on this specific series because nowadays every companies are looking for professionals who are who knows how to build rag applications because if you see various AI engineering reports there many of the companies around 60 to 70 projects percentage of the projects are specifically on rag application. So let me quickly go ahead and share my screen and start discussing about rag. This is just the introduction video of rag. Uh and as we go ahead we'll be implementing more amazing examples. So let me quickly go ahead and show you. So this is a simple definition that uh I've put up over here and uh in this definition first of all we'll try to understand rag. Okay. So first of all let's go through the definition and then I will give you a brief idea what exactly rag is all about you know. So here you can clearly see that rag is the process of optimizing the output of a large language model. Okay. So it references an authorative knowledge base outside of it training data set source before get generating a response. LLMs are trained on vast volume of data as we all know and use billions of parameters to generally original output for task like question answering, translating and completing sentences. Rag extends the already powerful capabilities of LLM to specific domain or an organizational internal knowledge base all without the need to retrain the model. Okay. It is cost- effective approach to improve LLM output. So it's relevant, accurate and useful in various context. So this is just a basic definition. You can refer to this particular definition. So guys, now let's go ahead and understand about rag. So let's consider that I have a generative AI application. And as you all know in a generative AI application, usually let's say that I have an LLM. So this is my LLM. Now usually whenever we have a LLM what happens is that let's consider that I have a user a user is asking a query. So this is a my query from the user and before it is sent to the LLM we do add a prompt right we do add a prompt and this prompt is just like an instruction to the LLM like how the LLM should work okay and then based on this we actually get an output now this is a simple generative AI application wherein the LLM is used to generate the content Okay, generate the content. So obviously by using this specific technique we give a query and this LLM you know that it has been trained with billions of data okay different kind of data that is available in the internet and based on this it will be able to generate the output. One of the disadvantage of this let me talk about the disadvantage of this particular approach. As you know that every LLM that is trained you know it will be trained for a specific set of data. So let's say right now it is 31st August. Okay 31st August. Let's say this is my LLM model and this is basically GPT5 which is the recent model from OpenAI. Now as you know that when this model was launched this model may be trained by may be trained with data till 1st August. Okay. So this LLM will not have any idea what has basically happened in the current world between 1st to 31st August. Right? And let's say if I go ahead and ask a specific question to the LLM which is between this specific dates for any kind of events the LLM will start hallucinating. So one of the major disadvantages of only using the LLM is that it will hallucinate. Okay. When we say hallucinating what does this basically mean? It means that even though it does not have the knowledge what has happened between 1st August to 31st August any events even though we ask any question the LLM will try to generate it own answer because it does not want to look like a fool. Okay, that is the best example. It does not want to look like a fool. So it will try to generate some answers and it will make sure that it will it'll show you answer that you may also have to believe it. that is how it will be written you know in in terms of the output that we get so usually this condition is basically called as hallucinating okay so this is one of the major disadvantage the second disadvantage that you have so let's say that I'm using this LLM and you know this LLM has been trained with huge amount of data now what happens is that I'm running a startup let's say now in my startup I'm solving a specific use case and I have some data which again I need to use this particular data along with my LLM. Okay. So let's say that I have some other data like you know um policies policies of my company I have HR policies of my company I have finance policies you know and this policies all will not be available in the it will not be available publicly because it is my startup so these all data has been protected now I also want to use this specific data and probably create a chatbot okay now how do I do this now one way is that many people will say hey kish we can take this particular data and we can fine-tune the model right we can simply fine-tune the model yes this is a very good solution but understand fine-tuning a model is a very expensive process very tedious process because this LLM whichever LLM we are using it has billions of parameter and tweaking this billions of parameter usually takes a lot of time Right? So obviously this is a solution but this is a very expensive solution. Okay. Now do we have any other way any other way and remember these all policies and these all data will also keep on getting updated as we run the startup. Right? So every time we cannot just go ahead and fine-tune it like every day we not fine-tune it. Right? So we should try to find out a solution like how do we prevent this? So this can again be prevented with the help of rag. Right? Now how it will be prevented with the help of rag I will talk about it. Okay. So here instead of fine-tuning I'm saying that hey I will go ahead and implement the rag. Now you'll understand only when we understand the pipeline of the rag which I will discuss in this specific video. Okay. Now these are the major two disadvantages that you see right over here and yes there are some more disadvantages which we'll just deep dive more as we go ahead. Okay now what happens in uh if we use rag and how we are preventing it. See rag is nothing but it is it is saying that is a process of optimizing the output of a large language model. So it references an authorative knowledge base outside of his training data. Now how do we solve this hallucinating and this problem that we have okay so let me just go ahead and draw the diagram again okay so here is my llm okay and here is my query so let's say that uh I am coming up with an user query so let's consider it over here okay and here I'm drawing a user I'm user okay and this user will first of all give a query. Okay. Now what happens is that there will be two important pipelines that will be created. As I said over here we are trying to optimize the output of a large language model. So it references an authorative knowledge base outside of it training data source. So as you all know this is my LLM right? This LLM is already trained with huge amount of data. Now along with this I will be having an external database and this database we basically say it as vector database. Okay external vector database. Now you you know that this LLM is already trained with some amount of data and any additional data let's say my startup data my policies HR finance whatever data is there we will try to create a data injection pipeline over here data injection pipeline over here now what will be this data injection pipeline so let's say I have my data from this data we will do some kind of parsing and from this parsing we will do embeddings embeddings and then we finally store it into the vector store. Okay. Now whenever we talk about this specific data this data can be in any format. It can be in PDF format. It can be in HTML format. It can be in Excel format. It can be even in SQL database format or unstructured format any format. So what we do initially we take this data and we do data parsing. Now here data parsing is a very important step. I think if you crack this step then developing a rag application becomes very easy. Data parsing is all about how do you read the unstructured data or the structured data that is present inside this and how do you chunk this data right how do you chunk how do you divide this specific data into chunks chunking is very important because you need to save this data inside some kind of vector store this is nothing but vector store or vector DB okay now vector store and vector DB is nothing but it will actually help you to save vectors inside this. Okay. So once you do the chunking after doing the chunking you pass it to the embedding models. Now here in the embedding models you basically convert text to vectors. Okay. Vectors is just like a numerical representation for text so that you will be able to apply algorithms like similarity search cosine similarity techniques that are already available right wherein similar kind of results based on a specific query can be retrieved from this particular databases. Okay. So here whenever I talk about vector DB this is my vector DB or vector store here we are storing embeddings. Okay. And this embeddings will get applied to every chunks. Embeddings is nothing but we basically use we convert text into vectors. Here we can use different different embeddings like Google Germany embedding models. We can use open AI embedding models. We can use hugging phase embedding models and each and every embedding models exist with different different cost and there are also open-source embedding models which will actually help you to convert the text into vectors. Now this is one specific pipeline which we call it as data injection pipeline. At the end of the data injection pipeline you are able to store the text into vectors inside your vector DB. Now how rag is different from the previous one. Right? So initially you had this data injection pipeline where you are converting all your data into vectors. Right? And this data is specifically for this particular startup. And now I have created a knowledge base. So this is my knowledge base. External knowledge base or internal knowledge base whatever knowledge base I have and this knowledge base does not exist with this LLM. Right? Yes, some amount of information may be available but not the entire part. Now see the definition. It is a process of optimizing the output of a large language so that it references an authorative knowledge base outside of this training data. Now what will happen when user gives a query? Now this query instead of directly going to the LLM will go to this vector database right and before going here also we need to go ahead and apply embedding right because this query will be converted into vectors right why we need to convert into vectors so that when we are hitting this query to the vector DB this similarity search is basically applied and based on this we get some kind of context we get some information from the vector DB and now whatever query I'm asking okay if I ask hey what is the leaf policy of my company right now what will happen first of all it'll go to the vector store it will gather all the related information that is available over here and that information when it is sending it to the llm it is called as context Now we use this context along with we go ahead and write a specific prompt. Now this prompt is an instruction to the LLM and it says that you can use this context to answer the question and finally you get a output. This is the entire pipeline. This pipeline is basically called as retrieval pipeline. Retrieval pipeline. And this is a very good example of a traditional rag. Now you may be thinking kish what about other types of rag. Don't worry thumb don't worry I will explain it completely from basic to advanc with implementation each and everything because later on we'll be discussing about agentic rags. We'll be discussing how agentic rags actually work each and everything. But I hope you got an idea with respect to this. Now here you will even not be seeing this particular problem like you'll not completely remove hallucination but some amount of hallucination if any queries that is asked related to the data that is present in the vector DB I will definitely get some kind of context and my LLM will give me the output as let's say that if that data is not present over here then LLM can hallucinate right but here we are doing this see one best example that you can do is that you can use perfectly Perplexity. Perplexity is nothing but it is based on rag. It is completely developed based on rag applications. Okay. Rag it is it is a kind of a rag application. In perplexity you have connected to various retrievers. You are connected to tools. You are connected to web search right and then it is summarizing the output and giving by the LLM. Right? and it also uses various LLMs itself. I'm also planning to mostly start a startup soon enough within a couple of weeks I guess and the kind of application that I'm developing is a rag application only and it solves a very good problem for a developer. Okay. So that is the reason I'm not being able to upload a lot of videos because I'm pretty much involved in those startups and working and developing a product that India can definitely remember. Okay. And this is how you know this is this is this is how things are and you can basically see how good uh you know the pipeline actually works and this is basically a traditional rack. Now you may be thinking what all things we'll be discussing. Okay fine we have discussed about a traditional rack in the future classes what coding we'll be doing. Okay so let's go ahead and talk about it. As I said two important pipelines we'll go ahead and create one is a data injection pipeline and one is a retrieval pipeline. Okay. Now in the data injection pipeline you'll be see seeing that we will be performing data injection. Along with the data injection we will go ahead and do data parsing. Then we'll perform embeddings. Then uh we will store everything into the vector store. Then we will create a retriever for this and whenever a user ask any queries it will be able to give the context to the LLM and then finally we will be generating the output. So here this is retrieval this is auggmentation right this is augumentation over here augmentation basically means what you're giving a context to the LLM along with the prompt to generate the output right so this is basically called as augmentation and finally you're generating the output right which is nothing but generation so here you are basically generating now in the next session how we are going to implement it first of all I will show you how to perform these two steps in a very efficient way. Okay, sorry not these two steps. I will show you how we can perform these all steps, right? Data injection, data parsing and embedding. Here we are going to consider different different files like PDF, HTML. Okay. Um PDF, HTML, you can consider Excel, you can consider SQL database, you can consider any kind of files. Then we'll do document parsing and we will try to convert this into document. So document is an amazing data structure which you can basically use it and you can even parse this do the chunking and store it in the vector embeddings sorry vector store. Then we'll perform embeddings. Here we will use both open source and we are going to use paid embeddings for the same. Okay. And then finally we go to the vector store. Then based on a user query, how do we go ahead and apply the same embeddings we are going to see that okay and then finally we'll be developing this. So mostly I really want I'm I'm focusing more on making bigger videos so that you don't just follow a playlist. Okay. I want to basically cover a lot of stuff in one video so that uh you should also be able to efficiently cover it instead of covering 50 different videos. Right now when we are doing data injection and data parsing right there are various techniques see we are going to see about optimization we are going to see about various chunking strategies context engineering these all kind of topics will be coming up when we talk about data parsing you know u what is semantic chunker you know how do we go ahead and do the chunking in those strategies and all everything we'll try to discuss as we go ahead but I hope you got a very super cool idea about what exactly is rag um Yeah, this was it from my side. Uh please make sure to like the video, share with all your friends and uh soon within couple of days we'll come up with the next video wherein we will be starting the coding tutorial and we'll start building this data injection pipeline and I will try to build it in the form of a project uh that it'll be looking good for you so that you'll also be able to completely implement things right. So yes, this was it from my side. I'll see you in the next video. Thank you. Take care.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apresentação do Rag (Recuperação Aumentada por Geração) como técnica central para IA generativa, abordando o que é, por que usar em vez de apenas LLMs, pipelines essenciais e implementação prática com notebooks e código modular para aplicações com bases de conhecimento externas.",
            "resumo": "Este vídeo introdutório apresenta o Rag (Recuperação Aumentada por Geração) como uma técnica-chave na IA generativa. Define Rag como o processo de otimizar a saída de um LLM referenciando uma base de conhecimento externa, eliminando informações desatualizadas ou inventadas. São discutidas duas grandes limitações do uso exclusivo de LLMs: a possibilidade de alucinações e a dificuldade de incorporar dados internos de uma empresa sem re-treinamento do modelo. O Rag resolve isso ao consultar fontes externas relevantes e combinar essas informações com a resposta do LLM, sem a necessidade de retratar o modelo. O vídeo aborda cenários de uso, incluindo políticas e dados internos de uma startup, e compara opções como fine-tuning versus Rag. Também são mencionadas pipelines essenciais e a implementação prática em notebooks Jupyter com código modular, preparando o terreno para exemplos futuros.",
            "assunto_principal": "RAG (Recuperação Aumentada por Geração) e pipelines para integrar bases de conhecimento externas com modelos de linguagem de grande porte, reduzindo alucinações e evitando o re-treinamento.",
            "palavras_chave": [
              "Geração Aumentada por Recuperação",
              "Modelo de Linguagem de Grande Escala",
              "alucinações",
              "fluxos de processamento",
              "Jupyter",
              "codificação modular",
              "base de conhecimento externa",
              "dados internos",
              "ajuste fino",
              "casos de uso empresariais",
              "produção de IA"
            ],
            "resumo_em_topicos": "- Definição básica de Rag como otimização da saída de um LLM por meio da referência a uma base de conhecimento externa.\n- Principais limitações de depender apenas de LLMs: alucinações/informações desatualizadas e incorporação de dados internos sem re-treinamento.\n- Como o Rag mitiga esses problemas ao consultar fontes externas relevantes e combinar os resultados com o LLM.\n- Cenários de uso e demanda do mercado por profissionais capazes de construir aplicações Rag.\n- Pipelines essenciais do Rag (recuperação de informações, integração com o LLM, verificação de fontes, geração de respostas).\n- Abordagens de implementação: notebooks Jupyter e código modular para facilitar a construção de aplicações Rag.\n- Considerações sobre dados internos, políticas da empresa e produção de soluções de IA com base em conhecimento específico.\n- Expectativas para os próximos vídeos com exemplos práticos e implementações detalhadas.",
            "prompt_tokens": 1844,
            "completion_tokens": 2143,
            "model": "gpt-5-nano",
            "cost": 0.0041
          },
          "analysis_time": 54.6261682510376,
          "language": "",
          "view_count": 46961,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@matthew_berman",
      "name": "@matthew_berman",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "UgNPfD-bZgU",
          "title": "AI News: Meta Raybans, Gemini 3, World Labs, Grok 5, and more!",
          "title_pt": "Notícias de IA: Meta Raybans, Gemini 3, World Labs, Grok 5 e muito mais!",
          "url": "https://www.youtube.com/watch?v=UgNPfD-bZgU",
          "published": "2025-09-19T01:02:09.070576",
          "published_relative": "há 2 dias",
          "duration": "14:47",
          "date_published": "2025-09-18T12:13:12-07:00",
          "transcript_available": true,
          "transcript": "Yes, I'm in a hotel again. I'm in Meta Connect, but I needed to bring you the news. The first story is the Meta Ray-B band glasses, which I've had for a long time. The demo video, which was leaked earlier this week, shows what the future of Meta Rayban glasses are going to look like. So, you'll be able to talk to your AI. Your AI will be able to see the world. It'll be able to hear the world, and it will be able to project things onto a clear screen that only you can see. It truly is incredible technology. Meta is definitely going allin on the glasses form factor, which makes a lot of sense given their history with ARVR and the Oculus. And if you've watched this channel at all, if you follow me on X, of course, Matthew Berman, you know that I'm more bearish on the glasses form factor. But it turns out a third of the world wears glasses on a daily basis. Now, I can't imagine a world in which I'm wearing glasses all day, every day, but maybe I'll be proven wrong. We'll see. Okay, next. Open AAI's reasoning model just accomplished superhuman intelligence. It got a perfect 12 out of 12 score during the 2025 ICPC World Finals. Listen to this. The ICPC World Finals, the premier collegiate programming competition where top university teams from around the world solve complex algorithmic problems. This would have placed it first among all human participants. They had a 5-hour time limit in which they had to solve all 12 problems. These are the most difficult coding problems in the world. We received the problems in the exact same PDF format as humans. And the reasoning system selected which answers to submit with no bespoke test time harness whatsoever. For 11 of the 12 problems, the system's first answer was correct. For the hardest problem, it succeeded on the ninth submission. Notably, the best human team achieved 11 of 12. So they competed with an ensemble of generalpurpose reasoning models and did not train a specific model for this competition. They had both GBT5 and an experimental reasoning model generating solutions. So there's maybe a new model coming. We'll see. And if you think this is just OpenAI tooting their own horn, listen to this. This is Scott Woo, CEO of Cognition. So insane you guys have no idea how hard this is. And for those of you who don't remember, Scott Woo is basically a math genius. He was competing in crazy difficult math competitions at a very early age. So if anybody is to say how incredibly difficult this is, it's him. And just to wrap it all up, Mark Chen, chief research officer at OpenAI. We wrapped up this year's competition circuit with a full score on the ICPC after achieving sixth in IOI, a gold medal at the IMO, and second in the AT coder heristic contest. The core intelligence of these models are incredible. They are more than enough. We just need to build the scaffolding now. And next we have our first paper by Meta Super Intelligence Labs. In this paper, they optimize rag retrieval augmented generation. That is the system that allows AI to store information and to retrieve information from natural language documents. So give it all of your PDFs, give it all of your internal documentation from your company and it can easily pull that context out of all that documentation, put it in the context window and then answer any questions you have. So in this paper they make Rag faster by swapping most retrieved tokens for premputed and reusable chunk embeddings called refrag. This method improves its speed by 30x and fitting 16x longer contexts without accuracy loss. This is just another feather in the cap of building incredible scaffolding for these models. And speaking of scaffolding, tool calling is an incredible part of that. And Zapier, the sponsor of today's video, has over 8,000 tools that you can call. Let me tell you about them. We use Zapier for so many automations at my company. Let me show you how we take a news story and convert it into a fully formatted social media post. The first thing we do is create a new record in Asauna with just the URL of the news story and then it automatically creates a record in air table again all through Zapier. Then we have two paths in Zapier, one for X and one for Instagram. We use chat GPT to create a short headline based on the content of the article. Firecrawl to grab additional assets and information and banner bear to create the header image for the story. And it will also put text on that image very easily. And then we take all of that and we push it to Buffer for publishing. All of this saves us a tremendous amount of manual effort and it's all powered by AI orchestration by Zapier. This is just one of dozens of the different workflows that we use with Zapier. So if you want to try this out or other automations, it's super easy. I'll drop a link down below to Zapier. Check it out. Let them know I sent you by clicking the link. And thanks again to Zapier. Now back to the video. Next, AI chip builder Grock, GRQ, has secured $750 million in new funding at a postfunding valuation of $6.9 billion. The funding round is led by Disruptive and includes Black Rockck and Newberger Burman, unrelated to me. The company will use the funds to expand its data center capacity, including new locations this year and next, according to Jonathan Ross, CEO, who've I've interviewed in the past on this channel. And Grock plans to announce its first Asia-Pacific location this year. It seems like the overwhelming thirst for inference for tokens is unquenchable. Nvidia is selling everything they have. Gro is selling everything they have. Cerebrus is selling everything they have. And so all of these companies are just spending as much money as they can building out this AI infrastructure. And I'm here for it. I'm so excited for all of this buildout to happen. All right. Next in the rumor mill, it seems Gemini 3.0 O might be right around the corner. A keen eye by Liam breaking Gemini 3.0 Ultra spotted in Google's Gemini CLI repo committed 4 days ago. And take a look at this. Here it is in the repo. Model Gemini 3.0 Ultra. So, we'll see when we're actually going to get the model. Maybe it's going to show up as an anonymous model on LM Arena or somewhere else. And you know, I'm going to be testing it out. So definitely if you're not already subscribed, subscribe so you can see that when I drop it. He follows up with more on the Gemini 3.0 Ultra leak found in Google Gemini Gemini CLI main branch. Remember Gemini CLI is open source. Committed 91225. CLI prep means beta is near. I cannot wait. Next, there is a new state-of-the-art benchmark on the ARC prize for V1. 79.6% 6% at $842 per task and on V29.4% at $3040 per task. Custom submissions by Gerber 888 and Eric Pang. Both are open-source use Gro 4 and implement program synthesis outer loops with test time adaptation. If you're not familiar with what that is, drop a comment below and if you want me to explain it, just let me know. Now, the full blog post by Jeremy Berman, again, unrelated, weird that two times this has happened in a single video, but he explains how he was able to achieve it. And all of this is based on the kind of dream coder method, which basically as the model learns things, it stores what it's learned and then it's able to generalize from there. That is an overly simplistic way of explaining it. And of course, Elon Musk had to drop in and say something. He reposted with Grock 5 training starts in a few weeks which is great news to hear but what does Grock 5 actually mean? Is that just every time they do a major training run they have to iterate on the version number? I don't know. Next do you remember Google announced agentto agent? It was a protocol that allowed agents to communicate with each other. Now they have AP2 agent payment protocol. This allows two agents to transact with each other. So announcing agent payments protocol, an open shared protocol that provides a common language for secure compliant transactions between agents and merchants. So not only can the agents actually pay each other, but the agent can pay different merchants as well. AP2 can be used as an extension of the ADA protocol and MCP learn more about how it works. And as you can see here, they already have a ton of partners lined up. So your agent is going to be able to pay for these services soon enough. So I see Adobe, Accenture, One Password, Into it, Red Hat, Salesforce, Octa. These are the biggest of the big names on the internet right now. And next, we're starting to get glimpses into what FE Lee, also known as the godmother of AI, has been working on at World Labs. So check this out. This is a 3D fully generated environment that you can play with right now. I'll drop a link down below. Now, they still have a wait list to be able to generate your own worlds and all you have to do is load up a single image and it will generate an entire world based on that image. But again, it's still on weight list. So, get your name on the wait list if you're interested in trying it out. But just from that single image, as you can see here, it is a massive world that has been generated and you can traverse and navigate through that world to your heart's content. All the details are there. It is truly incredible. I cannot wait to see what they do with this technology. And next, Tongi Labs has launched Tong Yi Deep Research. According to the post, first fully open-source web agent to achieve performance on par with OpenAI's deep research with only 30 billion parameters and only three billion of them activated. It demonstrates state-of-the-art results, scoring 32.9 on humanity's last exam, 45.3 on browser comp, and 75 on the Xbench deep research benchmark. Let's take a look. So, here it is. Here's Deep Seek. We have Kimmy, I believe that is Gemini, Open AAI, and so on. And this is just performing so so well. Humanity's last exam, Gaia, Frame, Simple QA, Browser Comp. So, you can check out the benchmarks yourself. I'll drop a link down in the description below. And continuing our Tong Yi deep research agents capabilities are built upon a novel automated multi-stage data strategy designed to create vast and highquality agentic training data without relying on costly human annotation. This seems to be the trend of really being able to scale up. You have to remove the human from the loop in the training and the reinforcement learning steps. So, it's fully open source. You can download it right now and try it out. Again, I'll drop everything in the description below. And a quick thanks to Dell Technologies for sponsoring this portion of the video. Dell Technologies has a family of incredible laptops called the Dell Pro Max featuring Nvidia RTX Pro Blackwell chips, which are portable AI workh horses. It comes in 14 and 16in screen sizes and up to 32 GB of GPU memory. Perfect for onthe-go AI workloads. Check them out. Link in the description below. All right, next in what seems like a no-brainer, Whimos are coming to SFO. That is San Francisco International Airport. Whimos I have fallen in love with. But one of the big problems is when you fly into SFO, you can't get them at the airport. So you're using an Uber and then in the city you can use Whimos. But now, according to the mayor of San Francisco, the airport has approved a pilot permit to begin autonomous rides. This roll out will happen in phases and we'll keep you updated every step of the way until anyone can request a Whimo ride right from SFO. And if you're in the San Francisco Bay area, you may have seen Whimo's competition Zuks, the company by Amazon, has been really going hard and testing their autonomous vehicle very futuristic all over San Francisco. And apparently GPT5 Codeex was much more popular than OpenAI ever thought. I feel like this is a recurring conversation we keep having. Every time OpenAI drops something, they're like, \"Oh, we didn't think it was going to be so popular.\" And well, why not? It's amazing. And so, it's much more popular, which means they actually had to slow it down. So, Alexander and Bericos, who runs Codeex at OpenAI, says, \"Demand for GBT5 codecs is higher than forecasted. We need to stand up more GPUs.\" In the meantime, Codex is running 2x slower than targets. Working on fixing this ASAP. Now, remember when we were talking about tokens? Remember when we're talking about infrastructure buildout? This is the reason we need it and we need it now. The infrastructure investment is not slowing down anytime soon. Every time a new product launches, people eat it up and that is only going to increase in velocity. All right, in the next story, I'm not sure how I feel about this. YouTube announced that they are rolling out the ability for creators to create YouTube shorts with AI. The V3 fast model is now going to be available in YouTube and so you can easily just generate clips and I feel a tsunami of AI slop coming to YouTube and so it's going to be interesting to see how Google handles this. Some of these AI videos that have been created with VO have gone absolutely viral on YouTube, on Instagram, on Tik Tok, but it's just once the novelty wears off, I suspect it's just going to be seen as slop. They're going viral now and people love them now because again it's novel, but at a certain point we're going to need taste. Somebody's going to need to create a great experience, a great video, a great song from all of the AI output. Next, Hunan announces Hunan 3D 3.0 featuring 3x higher precision, a higher geometric resolution, 3.6 billion voxal ultra HD modeling for stunning details. What does that actually mean? Well, you can create 3D models. Creates faces with lifelike facial contours and natural poses, creating truly realistic highfidelity models. Precisely interprets input images to reconstruct complex structures using a layer generation strategy and generates ultra clear professional-grade details with enhanced texture fidelity and alignment for immersive true toes visuals. So, if you are a designer, if you are a creator, go check this out. All right. And in another example of humanoid robots blowing my mind, look at this video. So, not only are we seeing the robot be abused by a human, but the speed at which it gets up off the ground is really stunning. So, it doesn't seem like we're that far away from really actually having a robot UFC type thing. And I just not a huge fan of kicking and punching all these robots, you know, just in case they can actually remember these things and become sentient in the future. So, that's it for today. If you enjoyed this video, please consider giving a like and subscribe.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Resumo em uma frase: o vídeo reúne novidades e rumores do ecossistema de IA, desde o Meta Ray‑Ban AR com IA até avanços de Rag, Grock, Gemini 3 Ultra, benchmarks ARC, automação com Zapier e protocolos entre agentes.",
            "resumo": "Neste vídeo, Matthew Berman compila novidades e rumores do universo da IA. Primeiro, destaca os óculos Meta Ray-Ban com IA integrada, capazes de ver, ouvir e projetar informações em tela invisível; ele comenta o apetite da Meta pela forma de óculos, mesmo sendo cético quanto ao uso diário. Em seguida, cita que a OpenAI atingiu superinteligência de raciocínio, com 12/12 no ICPC Finals, superando equipes humanas com um conjunto de modelos. Também menciona o trabalho da Meta Super Intelligence Labs para Rag, aumentando velocidade e contexto com embeddings chamados refrag. O vídeo traz demonstrações de automação com Zapier, mostrando como transformar uma notícia em post com várias ferramentas. Avanços de infraestrutura chegam com Grock, que levantou US$750 milhões; rumores sobre Gemini 3.0 Ultra; benchmarks ARC; e menções a protocolos entre agentes (AP2) e comentários de Elon Musk sobre Grok 5.",
            "assunto_principal": "Novidades, avanços e rumores no ecossistema de IA, com foco em AR/IA, Rag, Grock, Gemini 3 Ultra, benchmarks ARC, automação e protocolos entre agentes.",
            "palavras_chave": [
              "Meta Ray-Ban",
              "óculos de realidade aumentada",
              "inteligência artificial integrada",
              "OpenAI",
              "Finais Mundiais da ICPC",
              "Geração aumentada por recuperação",
              "refrag",
              "Laboratórios Meta de Superinteligência",
              "Grock",
              "Gemini 3 Ultra",
              "teste de referência ARC",
              "Zapier",
              "automação de IA",
              "AP2",
              "Protocolo de Pagamentos de Agentes",
              "Elon Musk"
            ],
            "resumo_em_topicos": "## Visão geral\n- Síntese das novidades discutidas: AR, Rag, Grock, Gemini, benchmarks ARC, automação com Zapier e protocolos entre agentes.\n\n## Destaques por tema\n- Meta Ray-Ban: óculos AR com IA integrada, capazes de ver, ouvir e projetar informações para o usuário.\n- OpenAI: raciocínio de IA atingiu 12/12 nas finais do ICPC, superando equipes humanas; menção a possíveis novos modelos.\n- Rag e Meta Super Intelligence Labs: melhoria de Rag com refrag, aumentando velocidade e contexto.\n- Zapier e automação: demonstração de fluxo para transformar notícia em post, usando várias ferramentas (X, Instagram, Banner Bear, Buffer, Airtable).\n- Infraestrutura/Investimentos: Grock levantou US$750 milhões; planos de expansão de data centers e primeira localização na APAC; tendência de aceleração da construção de infraestrutura de IA.\n- Gemini 3 Ultra e ARC: vazamento de Gemini 3 Ultra; novos benchmarks ARC com avanços de desenho de soluções.\n- Protocolos entre agentes: Google Agent Payments Protocol (AP2) e menção de Elon Musk sobre Grok 5.\n\n## Observações finais\n- Tom otimista sobre a construção de IA e próximos lançamentos, com ênfase no ritmo de desenvolvimento e investimento em infraestrutura.",
            "prompt_tokens": 1916,
            "completion_tokens": 7399,
            "model": "gpt-5-nano",
            "cost": 0.0121
          },
          "analysis_time": 95.1539740562439,
          "language": "",
          "view_count": 51961,
          "has_transcript": false
        },
        {
          "id": "biwwQw0248w",
          "title": "Is AI Killing the Economy? (Anthropic Report)",
          "title_pt": "A IA está matando a economia? (Relatório da Anthropic)",
          "url": "https://www.youtube.com/watch?v=biwwQw0248w",
          "published": "2025-09-18T01:02:09.070652",
          "published_relative": "há 3 dias",
          "duration": "16:29",
          "date_published": "2025-09-17T14:30:06-07:00",
          "transcript_available": true,
          "transcript": "Artificial intelligence is spreading faster than electricity, PCs, and even the internet. This is all from a new report that Enthropic just dropped with how AI is affecting everything from jobs to different states, different countries, how they're using it, what they're using it for, everything. And it's fascinating. Let me show you. And this video is brought to you by Code Rabbit. More on them later. AI differs from prior technologies and its unprecedented adoption speed. In the US alone, 40% of employees report using AI at work, up from 20% in 2023, 2 years ago. So we have doubled the usage, doubled the adoption in the US in just 2 years. And listen to this, historically new technologies took decades to reach widespread adoption. Electricity took over 30 years to reach farm households after urban electrification. Now there's a lot of differences between AI adoption and electricity. First of all, it was necessary to have huge infrastructure buildout for electricity and the electricity really had to reach the last mile which is the home. Now with AI, obviously there needs to be huge infrastructure buildout, but it's much more concentrated and a lot of these companies already had some infrastructure buildout, but we're talking about decades compared to single-digit years. The first mass market personal computer reached early adopters in 1981, but did not reach the majority of homes in the US for another 20 years. So again, this is being adopted. This is moving more quickly and evolving more quickly than any other technology in history. And AI isn't just automating existing tasks anymore. It's actually creating whole new categories. And listen to this, the share of tasks involving creating new code more than doubled, increasing by 4.5 percentage points. So from 4.1% to 8.6%. 6%. And interestingly, debugging and error correction tasks actually went down. This may suggest that models have become increasingly reliable, such that users spend less time fixing problems and more time creating things in a single interaction, and educational institutions and research institutions seem to be using AI more and more, which is fantastic. While computer science and mathematical tests still dominate overall usage at 36%, we're seeing sustained growth in knowledge intensive fields. Obviously, if it's very knowledge intensive, that's exactly what AI does very well. Educational instruction and library tasks rose from 9% to 12%. Life, physical, and social science tasks increased from 6 to 7%. Meanwhile, the relative share of business and financial operations tasks fell from 6 to 3% and management dropped from 5 to 3%. And so, you might be asking, why are those things decreasing? their explanation. This divergence suggests AI usage may be diffusing especially quickly among tasks involving knowledge synthesis and explanation. This was really besides for code generation the first use case in the business world. That means I'm going to load up a PDF and ask it to explain it to me. I'm going to have it create some kind of document. I'm going to have it look through all of these documents and ask questions to it. And this is just such an easy, straightforward, high-value use case that everybody adopted it super quickly. And here we can see the trends itself. So you can see life, physical, social sciences, business and financial operations percentage decreasing. And remember this is the usage share trend. So of the overall pie of use cases, this is how each one is trending. Architecture and engineering decreasing quickly, management decreasing quickly, education, instruction and library increasing and computer and mathematical staying pretty consistent. And how people are using AI is changing. Automation versus augmentation. At a high level, we distinguish between automation and augmentation modes of using Claude. Automation means interaction patterns focused on task completion. You give it a task and you expect the AI to complete it entirely with no human in the loop or very little. Augmentation means you're working with AI to complete a task. Collaborative interaction patterns, learning, task iteration, and validation. And what do we see? Augmentation is decreasing and full automation is increasing. And that's also reflected in what they call directive conversations, which means you're telling AI what to do. So, for example, write me an essay about pickle ball versus here's an essay that I wrote. Can you make some improvements? That is collaborative versus directive. And because learning AI tools is so critically important for your future, let me tell you about today's sponsor, Code Rabbit. Code Rabbit is the AI code review platform, transforming how engineering teams work by allowing them to ship faster with AI without sacrificing code quality. Quality code reviews are critical but time consuming. Code Rabbit acts as your AI co-pilot, providing instant code review comments and potential impacts of every pull request. Beyond just flagging issues, Code Rabbit provides one-click fix suggestions and lets you define custom code quality rules using a GP patterns, allowing Code Rabbit to apply those to your pull requests. That'll allow you to catch subtle issues with your code that traditional static analysis tools might miss. Code rabbit is available in VS Code, Cursor, and Windsurf. And the best part, Code Rabbit is free for all open source projects. So check out Coderabbit today. The links are down below. coder rabbit.link/matthew and that'll let them know that I sent you. So please check them out. And thanks again to Code Rabbit for sponsoring this video. And now back to the video. And you might be thinking, okay, well, if automation is increasing, that means we're going to start seeing a lot of job loss. Now you know how I feel about that. I am very optimistic. I think there's going to be a lot of job transformation, but I still think if you learn these tools and if you're watching this channel, you're probably already ahead of the game. But if you learn these tools, you will be well ahead of the game. And according to their research, you will be higher paid. Workers most able to adapt to new AI powered workflows are likely to see greater demand and higher wages. In other words, AI may benefit some workers more than others. Now, what people have been saying from the very beginning of this new AI wave is AI is not going to replace you. A person who uses AI is going to replace you. So, just keep that in mind. Learn these tools. And from all of the AI leaders that I've spoken with, the common sentiment is yes, the best thing you can learn right now is how to use these AI tools. It may lead to higher wages for those with the greatest ability to adapt to technological change, even as those with lower ability to adapt face job disruption. And according to a paper referenced here, clear evidence that entry-level workers with high AI exposure have had relatively worse employment prospects since late 2022. Setting aside questions of causality, the straightforward interpretation is that this is due to AI substituting for work previously done by early career workers and relatively faster employment growth for experienced workers reflects AI making such workers more productive and thus in high demand. So if you're early in your career, you might have more trouble getting a job. But I don't think that's going to last forever. I think once all of the dust settles, once companies really learn to adopt AI, they're going to need more humans to prompt to verify, to review the work. And even though that takes more experience in the niche that somebody's in and whatever category of role they're in, just being knowledgeable about how to use the AI tools is probably going to set you up for success. So, if you're early in your career, once again, I'm going to say it, go learn these tools. All right. What about by country? Which countries are benefiting the most? Which countries are falling behind? Well, look at this. These are the top 20 countries by anthropic AI usage index. And this is per capita. Israel by far has the most per capita usage of claude. Singapore also. And basically what that means is smaller, very technically advanced countries seem to be adopting AI much more quickly. According to the paper, the results reveal a striking pattern of concentration among small technologically advanced economies. Israel leads global per capita claude usage with an anthropic AI usage index of seven. Meaning its working age population uses cloud seven times more than expected based on its population. Then Singapore and Australia, New Zealand and South Korea round out the top five. Now in global share of usage, of course, the United States being more technically advanced and also having a huge population sees the highest percentage of usage across the globe. India being number two. Clot adoption overall is highly geographically concentrated in terms of total global usage. The United States accounts for the highest share 21.6% with the next highest usage countries showing significantly lower shares. India 7.2, Brazil 3.7. However, concentration is affected by population of the country. All right. But how are people actually using it? What are the trends for how they're using these tools? As we move from lower to higher adoption countries, claude usage appears to shift away from programming dominant tasks, which is really the most dominant task for AI right now, to a more diverse mix of tasks, though the overall pattern is noisy. You can see per country how people are using it. So, check this out. In the United States, provide comprehensive cooking, nutrition, and meal planning assistance. That is number one. Help with job applications, resumes, and career documents. So of the top over represented requests, none of them in the US are for coding which is very interesting. Look at this. Provide personal relationship and life guidance support. But then if we look at India, India fix and improve web and mobile application UI. Half of all of India's AI usage is for coding. Brazil provide translation service and comprehensive language learning assistance across multiple languages. Vietnam help with cross-platform mobile app development, debugging and feature implementation. So you can see India and Vietnam all about coding. Brazil and United States more general use cases. Now here's another interesting finding. Markets in which have higher adoption rates for artificial intelligence, specifically Claude, tend to use Claude more as a collaborator versus just handing it the wheel and making it do everything. Markets with less adoption are the opposite. they have AI and specifically Claude take the wheel and do everything. And so that gives me even more hope that as people learn to use AI, as we kind of get to the cutting edge of use cases, they're figuring out, okay, humans are needed in the loop. Now, here's AI usage in US corporations. And as you can see, it's increasing and increasing pretty quickly, but it's still a very small number. At its current point, it is nearly at 10%. That means one out of every 10 companies is using AI. That screams to me that there is so much potential for somebody who knows AI to go in and implement it at a company, whether as a consultant or an employee. If you're an employee at your company and you see your company as not using AI, go learn the AI tools and show them how to do it. You will become insanely valuable. Now, of course, if your company is in the information sector, there's a much higher adoption rate, but it's still only 25%. One in four information sector companies are using AI. It's insane to think about. But remember, we're in this little bubble where everybody knows about AI. Everybody talks about AI, but outside of our little bubble, really, nobody knows about it. People hear about chat GPT and that's about it. They don't know what's possible. And so, it's our job to go help them figure out what's possible. It's our job to go implement AI at businesses. So, some more data about how companies are using AI. 77% of AI transcripts show automation patterns, especially full task delegation, versus just 12% for augmentation. But, of course, that makes sense. If you're going through the API, there's probably going to be much less human interaction. Based on a sample of conversations from Claude AI, so that's the UI, the split between automation and augmentation is nearly even. Looking across economic tasks, the degree of cloud automation through the API is even starker. 97% of tasks show automation dominant patterns in API usage compared to only 47% in cloud AI. Programmatic API access naturally lends itself to automation. Businesses provide context. Claude executes the task and the output flows directly to end users or downstream systems. And it turns out companies don't really care about cost all that much right now. They just want good results. Overall, we find a positive correlation between cost and usage. Higher cost tasks tend to have higher usage rates. When something's working, you're going to double down. I believe this is just Jevon's paradox being highlighted. The positive correlation between cost and usage suggests that cost plays an immaterial role in shaping patterns of enterprise AI deployment. Businesses likely prioritize use in domains where model capabilities are strong and where cloudpowered automation generates enough economic value in excess of API cost. And what is the biggest bottleneck? Well, you can probably guess it's context. How do you provide these models with the context of your business, of your personal life in the most effective way? Context constrains sophisticated use. Our analysis suggests that curating the right context for models will be important for high impact deployments of AI in complex domains. This implies that for some firms costly data modernization and organizational investments to elicit contextual information may be a bottleneck for AI adoption. So we have all of this unstructured difficult to use information and we need to get it to a place in which we can provide it to AI really well. This is probably why they changed the term prompt engineering to context engineering because providing the context is the hard part. Writing the prompt is kind of the easy part at this point. But it's not all good. What does this mean for the earth as a whole? If the productivity gains are larger for high adoption economies, current usage patterns suggest that the benefits of AI may concentrate in already rich regions. Rich regions are adopting it more quickly which means they will be gaining the benefits more quickly and then it's kind of a snowball effect at that point. The rich countries will get richer possibly increasing global economic inequality and reversing growth convergence seen in recent decades. Their study also suggests that as I said earlier, if you learn AI, you will likely become more valuable. If AI automation improves the productivity of workers with tacit organizational knowledge, as some of our evidence suggests, then more experienced workers could see rising demand and higher wages even as entry-level workers face worse labor market prospects. And so, it does seem according to this research, it's not just enough to know the tools to make you more valuable. You also have to have the organizational knowledge. And so I think this is one of those problems we're going to have to figure out for entry-level workers. How do you make them more valuable? How do you make them attractive in the job market when they don't have that organizational knowledge just yet? My guess is that if they become even better at using AI, that's the skill they're bringing in the company and then they will learn the organizational knowledge. And ultimately the economic effects of transformative AI will be shaped as much by technical capabilities as the policy choices societies make. So the policies we choose are going to be critically important for AI adoption and AI value. Now this same research paper has a really cool interactive section and you can basically segment all of this data really easily, visualize it really easily. So for example, let's look at California. And within California, we can see how people are using Claude, the different job groups, the usage rank, usage index, most frequent topics, everything. And that's broken down by the US, the state, and job type. So definitely check it out. I'm going to drop all of this in the description below. And thanks again to Code Rabbber for sponsoring this video. I'm going to drop all of their links down below. Click them, let them know I sent you, try it out. They've been a great partner. Let me know what you think. If you enjoyed this video, please consider giving a like and subscribe.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo analisa um relatório da Anthropic sobre a adoção acelerada de IA, seus impactos na economia, empregos e setores, e as diferenças de uso entre automação e augmentação ao longo do tempo.",
            "resumo": "A IA está se espalhando mais rápido do que a eletricidade, computadores pessoais ou a própria internet, segundo um relatório recente da Anthropic. Nos EUA, 40% dos trabalhadores já utilizam IA no trabalho, o que representa o dobro do ano anterior, evidenciando uma adoção sem precedentes. Ao contrário de tecnologias anteriores, a IA está criando novas categorias de tarefas: a participação de tarefas de geração de código quase dobrou, enquanto a correção de erros caiu, sugerindo maior confiabilidade. O uso oscila entre áreas como ciência, educação e bibliotecas, e cai em operações de negócios e gestão; isso indica uma difusão mais rápida de tarefas de síntese e explicação de conhecimento. Em termos de uso, a automação cresce enquanto a ampliação diminui, com conversas diretivas se tornando mais comuns. O vídeo também discute impactos salariais, potencial de maiores salários para quem se adapta, e a importância de aprender a usar ferramentas de IA, além de considerar variações entre países.",
            "assunto_principal": "Impacto econômico da IA, adoção acelerada e implicações para empregos, setores e salários, conforme relatório da Anthropic.",
            "palavras_chave": [
              "Inteligência Artificial",
              "Anthropic",
              "adoção rápida",
              "automação",
              "aumento",
              "mercado de trabalho",
              "setores",
              "codificação",
              "educação",
              "confiabilidade de modelos",
              "economia",
              "países"
            ],
            "resumo_em_topicos": "### Resumo em tópicos (Markdown)\n- Contexto: IA está se disseminando rapidamente; comparação histórica com eletricidade e a internet.\n- Adoção nos EUA: 40% dos trabalhadores já utilizam IA, dobrando desde 2023.\n- Mudanças de uso: IA gera novas categorias de tarefa; aumento da codificação, queda na correção de erros.\n- Distribuição setorial: educação e ciências ganham espaço; negócios e gestão diminuem.\n- Tendência de uso: automação cresce, aumento diminui; maior incremento em interações diretivas.\n- Implicações para o trabalho: trabalhadores que adotam IA tendem a obter salários maiores; iniciantes podem enfrentar desafios.\n- Considerações por país: há variações na adoção e nos benefícios entre países.",
            "prompt_tokens": 1732,
            "completion_tokens": 2432,
            "model": "gpt-5-nano",
            "cost": 0.0045
          },
          "analysis_time": 61.73663401603699,
          "language": "",
          "view_count": 51055,
          "has_transcript": false
        },
        {
          "id": "CZeEAgE5xGA",
          "title": "Ex-OpenAI CTO Reveals Plan to Fix LLMs Biggest Problem",
          "title_pt": "Ex-CTO da OpenAI Revela Plano para Corrigir o Maior Problema dos Grandes Modelos de Linguagem",
          "url": "https://www.youtube.com/watch?v=CZeEAgE5xGA",
          "published": "2025-09-17T01:02:09.070670",
          "published_relative": "há 4 dias",
          "duration": "08:47",
          "date_published": "2025-09-16T15:34:02-07:00",
          "transcript_available": true,
          "transcript": "We finally know what Mirror Morati, the exCTO of OpenAI, is building at Thinking Machines. It has been a total mystery, but now we have a clue and it's interesting and complicated and I'm going to try to break it all down for you. Let's get into it. So, just quickly, Thinking Machines. Today, Thinking Machines Lab is launching our research blog, Connectionism. Our first blog post is defeating non-determinism in LLM inference. If you don't know what that means, don't worry. I will explain it all. So here is the paper. Now what is non-determinism? In the context of artificial intelligence, you've probably noticed this. If you give the same exact prompt to a model twice, three times, four times, you're going to get back different responses. And that is non-determinism. The same input does not always lead to the same output. In fact, it's frequently different. But as they say in the very first sentence, reproducibility is a bedrock of scientific progress. However, it's remarkably difficult to get reproducible results out of large language models. And that is what they're looking to solve. They want to be able to prompt an LLM with the same exact prompt and get back the same exact response to it every single time. Now, there are a large number of use cases where this would be extremely valuable, but also some in which it's not valuable. Think about creative writing, for example. I don't necessarily want this same exact response if I'm trying to write a cool fun story. And not only are they trying to defeat randomness in responses, but they actually think they've identified the cause of it. You might observe that asking Chad GPT the same question multiple times provides different results. This by itself is not surprising since getting a result from a language model involves sampling. Sampling basically just means looking at all the potential results and choosing the one that it has the highest confidence in. But even when we turn the temperature of the model's response down to zero, and if you haven't seen temperature, it basically means reducing the randomness of the sampling of the choosing of the next token. With a temperature of zero, it should be deterministic. But again, it's not. But why aren't large language models deterministic? It might just seem like, well, of course, that's the way they are. But of course, there's a reason they're the way they are. One common hypothesis is that some combination of floatingpoint nonassociivity and concurrent execution leads to non-determinism based on which concurrent core finishes first. And so this sentence has a ton of very technical terms. Let me just break it all down. So floatingoint numbers are numbers that have decimals. So think like 5.23. But how do you know the floatingoint precision? And how many numbers of precision do you go after the decimal? At a certain point, you can't go infinitely. And so you do need to round and that rounding causes randomness. And second, concurrent execution. GPUs. When you give them math, they are executing a bunch of calculations all at the same time and you don't know which one generally is going to finish first. Now, I believe companies like Gro GRQ really fix that issue because their chips are completely symmetrical and you know when you put in a calculation exactly how long it's going to take to get back. But when you don't know that randomness in which result comes back first also adds to the overall non-determinism of the response. But thinking machine says while this hypothesis is not entirely wrong, it doesn't reveal the full picture. For example, even on a GPU, running the same matrix multiplication on the same data repeatedly will always provide bitwise equal results. We're definitely using floatingoint numbers and our GPU definitely has a lot of concurrency. Why don't we see non-determinism in this test? But according to the paper, the real culprit is the batch size. So, think of it like this. You are posing a question and your question gets put into a carpool with other people's questions. The carpool is called a batch. When the system is really busy, the carpool is really big. It's trying to get more done. And when it's quiet, it's very small. And that size quietly changes the order of the tiny add-ups, the math that it does inside of the AI. So, different order, slightly different totals, and sometimes a different next word. Remember, all LLMs are just predicting the next word. Sometimes the next word differs because of this. Little changes, little variances in the ordering of things changes everything. And I know this is all so complicated, but you know what isn't? The sponsor of today's video, Lindy. Lindy is the best way to vibe code agents and apps. Imagine you want to build a fully functional online education platform in under 5 minutes. You can do that with Lindy's new build feature. So, first you describe what you want to build. So, let the agent know who you are and then tell it, \"Build me an online education platform.\" Lindy isn't just generating code. It's researching best practices, building the front end, and here's the key part. If you've watched any of my tutorial videos on Vibe Coding, you know testing is everything. And of course, Lindy writes all the tests for you. Lindy also runs QA on all the features that it builds before deploying. So, look at this. In under five minutes, you can have a fully deployed education platform with working user registration, free course access, premium upgrades with Stripe checkout and a user dashboard. This might have taken you weeks previously and cost thousands of dollars built by developers, but Lindy built it in minutes because of their built-in QA process. Lindy not only builds code, but it ships working code. Sign up using my link in the description, get $20 worth of credits. absolutely free. So, what are you going to build with Lindy? Let me know in the comments. Thanks again to Lindy. Now, back to the video. All right, so what is the actual fix? Well, it turns out at least to explain it is pretty simple. Regardless of the size of the batch, you keep the carpool going at the same speed. And so, even though if you're keeping everything the same, you might go a little bit slower, the consistency that you gain is actually much more valuable. Now, this paper goes into the actual math for how all of this gets done. and it goes into a lot of the technical details which to be honest are a little bit beyond my comprehension. So I'm just kind of breaking it down in general terms for you. And so with these two fixes, let me just try to give you an analogy. Imagine you're a restaurant creating bowls. And so for this first fix, you need to make sure each bowl is weighed the same. So even if the kitchen is crowded or the kitchen is empty, no matter what, you're weighing the bowls the same. Now, you're going to lose out on a little bit of speed, but the overall consistency that you gain is going to be far more valuable. Then, you keep the mixing step the same also. So, mix the ingredients in the exact same way. Choose one stable setup regardless of how crowded that batch is. Then, there's a third fix that we'll talk about. Taste in the same order. So, we're going to keep on this kitchen analogy. Even if you bake things in chunks, you want to taste them in the order that you put them in. So in AI, the model looks back at what it wrote. That's the attention part of attention is all you need. And if you cut the text into different chunk sizes, the order of those tiny add-ups can change. So use the same slice every single time. All right. So did it actually work? Well, they used Quen 235B and sampled a,000 completions at temperature zero with the prompt, tell me about Richard Fineman generating a,000 tokens each. Surprisingly, we generate 80 unique completions with the most common of these occurring 78 times. That's the kind of baseline. Then when they enabled their batch invariant kernels, all of the thousand completions are identical. So the answer is yes and it was perfectly effective. And why is defeating non-determinism so important? Well, if you get the same output from the same input, it becomes much easier to trust, to debug, to audit, to verify. If you know what you're going to get, it just gets easier to use. Plus, if you're running benchmarks now, you actually have stable inputs and outputs, and thus your benchmarks become more trustable. Your users can trust the outputs better. And when you go into audit and figure out why a model thinks the way it does, it becomes easier to do that. So, I'm going to drop the link to the full paper down below. I will say it is very complex. So, if you can read it, congrats. You're way ahead of the curve in AI. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do ex-CTO Mirror Morati sobre como a Thinking Machines planeja reduzir o não-determinismo na inferência de LLMs, por meio de processamento em lotes estável, ordens de processamento consistentes e ajustes de pipeline, com testes iniciais e menção a um patrocinador.",
            "resumo": "Neste vídeo, o narrador explica o não-determinismo em LLMs (modelos de linguagem de grande escala) — quando entradas idênticas podem gerar respostas diferentes. Discute que a reprodutibilidade é fundamental para a ciência, mas os LLMs não são totalmente determinísticos devido à amostragem, à temperatura, à concorrência e, principalmente, ao tamanho do lote (carpool). A Thinking Machines propõe três ajustes: manter a velocidade do carpool constante (kernels invariantes de lote) para melhorar a consistência; pesar igualmente cada entrada do prompt (a mesma 'tigela' de ingredientes); manter a ordem de processamento e de fatiamento das entradas (mesmo tamanho de trechos). Em testes com o Qwen 235B, 1.000 completações a temperatura zero geraram 80 completações únicas, com a maior repetição ocorrendo 78 vezes. O vídeo ainda inclui um anúncio patrocinado da Lindy e encerra convidando a comentar.",
            "assunto_principal": "Redução do não-determinismo na inferência de LLMs por meio de batching estável e ordenação consistente, explorando causas, soluções propostas e resultados preliminares.",
            "palavras_chave": [
              "não determinismo",
              "inferência de LLM",
              "processamento em lote",
              "carona compartilhada",
              "concorrência",
              "temperatura",
              "precisão de ponto flutuante",
              "kernel invariante de lote",
              "Thinking Machines",
              "conexionismo",
              "Qwen 235B",
              "determinismo"
            ],
            "resumo_em_topicos": "## Contexto\n- Mirror Morati, ex-CTO da OpenAI, é citado como responsável pelo trabalho na Thinking Machines.\n- A Thinking Machines lança o blog Connectionism e discute o artigo Derrotando o não-determinismo na inferência de LLM.\n\n## Problema\n- Não-determinismo na inferência de LLMs: prompts idênticos podem gerar saídas diferentes.\n- Reprodutibilidade é essencial para o progresso científico, mas difícil de alcançar em LLMs.\n\n## Causas discutidas\n- Hipóteses comuns: precisão de ponto flutuante, execução concorrente em GPUs, e a ordem de operações.\n- O papel do batch (tamanho do lote) na variação de resultados, conforme o tamanho do conjunto de prompts.\n\n## Soluções propostas\n- Três ajustes principais:\n  1) Manter o lote na mesma velocidade (kernels de lote invariantes) para consistência, possivelmente sacrificando um pouco de velocidade.\n  2) Pesar igualmente cada entrada (mesma 'tigela' de ingredientes) para evitar variações na contribuição de cada prompt.\n  3) Manter a ordem de fatiamento/processamento (mesmos tamanhos de blocos e a ordem dos fragmentos) para evitar efeitos da variação de ordem.\n\n## Experimentos\n- Teste com Qwen 235B: 1.000 respostas geradas, temperatura zero, resultados de 80 respostas únicas; a mais comum ocorreu 78 vezes.\n- Demonstração de que ajustes de processamento em lote podem reduzir a variabilidade, ainda que envolvam compromissos de desempenho.\n\n## Considerações finais\n- A consistência do processamento pode ser mais valiosa do que a velocidade máxima, segundo a abordagem apresentada.\n- O vídeo inclui uma seção de patrocínio da Lindy e encerra com convite para comentários sobre usos potenciais.",
            "prompt_tokens": 1844,
            "completion_tokens": 4126,
            "model": "gpt-5-nano",
            "cost": 0.0071
          },
          "analysis_time": 112.19412779808044,
          "language": "",
          "view_count": 45836,
          "has_transcript": false
        },
        {
          "id": "t09WttAGaag",
          "title": "Genie 3 Team: Agents, Training Genie, Simulation Theory, Text vs Video, and more!",
          "title_pt": "Equipe Genie 3: Agentes, Treinamento Genie, Teoria da Simulação, Texto vs Vídeo, e muito mais!",
          "url": "https://www.youtube.com/watch?v=t09WttAGaag",
          "published": "2025-09-17T01:02:09.070686",
          "published_relative": "há 4 dias",
          "duration": "52:19",
          "date_published": "2025-09-16T11:18:17-07:00",
          "transcript_available": true,
          "transcript": "Here's my interview with two of the leaders of the Genie 3 team. Genie3 came out just a couple weeks ago and it is an incredible text to fully 3D controllable world and it is highly accurate and has so much potential for video games, agent training, world simulation, and so much more. So, in my interview, we talk about what went into training Genie 3, what their plans are, the future of world models, and of course, we talk about simulation theory. Here's the interview. All right, so thank you, Jack Schlomi, for joining me. Jack Parker Holder is a research scientist at DeepMind. Schlommy Fer, am I saying that correctly? Yeah, close. Okay, research director at DeepMind. Thank you guys so much for joining me. Um, I'm really excited to talk about Genie today. Awesome. Thanks for having us. Yeah, absolutely. So, okay, when I first saw Genie, I was pretty blown away. I'd never I've never really seen fully controllable um textto world models before. First is what is the long-term goal for Genie? Is it more of a research tool for agents? Is it for creators? Is it for general simulations? Like what is your overarching goal? Yeah. So the way I'm thinking about is the capability to generate the world um just from text. Um it is kind like a fundamental capability that can be used for many things basically everything that you've mentioned. Um in a way um if we can create uh a realistic world that is you know you can interact with and you can walk around and maybe um it simulates all of the uh physical phenomena that we have in our own world. Then based on that you can use it for um training agents for reasoning about what might happen if an agent takes an action in the world for entertainment you know very long list of applications. So basically the answer is pretty much everything you can think about. Yeah. Okay. All of the above. Is that when you first started this uh the Genie family of models was that the intention or was it more of just hey let's explore this research area and see what's possible? Uh yeah so I'd say when Genie models research first started roughly 3 years ago um it was very much focused on the AGI and agent centric angle. So a few of us had been working on like automatic curriculum learning for agents uh with reinforcement learning. So agents that can learn from their own experience in simulation. Um, and we basically been trying to find different environments where we could generate diverse range of different kind of worlds and tasks, typically procedure generated worlds, right? And we basically got to the point where um we couldn't really design or or like handcode an environment that was rich enough that you could basically even if you sold everything in it, it would get an agent that was able to transfer and do diverse things in the real world. And so there were multiple different paths to try and do this. One was maybe to keep building richer simulations. One was to maybe start using real real video games because they're quite can quite realistic. Um but at the time sort of language models had really emerged as something that were becoming quite useful and quite effective. Text image models were just starting to be pretty pretty good. And so it kind of seemed like a it would take a bit of a bit of bit longer, but like maybe if we could do full world generation that would basically solve the environment problem for agents and then we would get like much much richer agents than we would do any other any other way. So it actually seems like the fastest way to get general agents was to not work on them but to work on the environment model first. Um so that was the original motivation. I think it's it's not the case that that interest has gone away. I become increasingly convinced uh and as a team I think we're all pretty convinced that this is like a really exciting direction but it's just sometimes when you pursue interesting research you don't know necessarily what it's going to be used for right um and there's been a bunch of other things that have emerged like I I I wasn't as in the know with sort of the interactive human like use cases but those have become like pretty obviously the case in the last year or so right so um and actually even with with Genie free. There's been a bunch of use cases that we would weren't even really thinking about that people have asked us about that sound pretty exciting as well. So, I think it's one of those ones when you do something new, you often get some unintended consequences that could even be more interesting than your original intent. So, so, so my understanding is to scale up to reach AGI, we need some kind of reinforcement learning feedback loop that doesn't have maybe a human in the loop limiter to it. And and that's really where Genie 3 and the Genie family of models comes into play. It generates these environments. Agents can go into the environments and explore and learn what kind of signals is the environment giving to the agent because you know, forgive my my lack of understanding here, but the the output is is still maybe a black box or how it's generated as a black box. So what kind of signals are is the agent actually able to um retrieve from these worlds? So today you know basically we're operating only in the visual domain right. So the output of the world model is just the pixels um observations right. So the focus on on visual outputs was just out of um because there is a lot of progress in this space right we see video models that really made a lot of progress in realism. So we have models such as Velo and and others that are able to take text and just output something that looks very realistic. Um and and we we thought that we can push um on what's possible in terms of the ability to actually walk around in like walk into a video and actually explore what's what's the world that's generated, right? Um so I think this is still limitation when it comes to maybe training agents but we can go pretty far just by using visual um visuals because for example um by looking at the world we can know if like how fast something's moving. We can uh an agent can understand um if it can if it has to maybe get from one point to another what are the obstacles in its way. So even without you know more um kind like physical responses that you might expect for robots we can still do a lot like start exploring the capabilities of of such environments and we're very excited about that as kind of the first modality from many that can be simulated in a realistic way. Okay. And and just to clarify agents when they are training within the environment of a G3 world they are simply looking at it. It's through the pixels presented to what we would see on the screen. Yeah. Maybe to clarify a little bit. So I I I think right now we are posing G3 as one one of the potential application is to train agents in it. Right. We are this is something we're just starting to explore. Um and we built on on a very line very long line of work by Deep Mind and other others that used simulations to train agents. Right. So we can you know starting from uh Starcraft and Go and Alpha Go and then and then basically using some game simulation or environment to train an agent to solve the game, right? Um and that's that's kind like the initial what what kind of like one of the h seeds um that led to to investments in simulation for for Google deep mind and um now we're trying to build simulations that can you said before like taking the the the like removing a human in the loop but I think it's more about removing the um the need to actually go out into the real world to train an agent right because it's very expensive to deploy for example a robot in in in some uh like in a factory, right? Let's say that you want to train a robot to to handle a new environment um that it was never able to explore. One way is just to put it in this environment and it will make mistakes, right? But maybe it will be much cheaper and much more safer if it can still first experiment learn in in this simulated environment before it gets deployed into the real environment. So that's kind of like in a nutshell what we're having in mind. Okay. And and Jack, you mentioned you were a bit surprised at the use case of of the human interaction, right? First of all, are you are you guys gamers? Do you play video games? I used to play a lot of strategy games actually in the past like uh um few my my background is mostly in programming 3D engines. That's kind of where so it was mostly a a hobby to develop uh the games, but today I'm less of a gamer. Yeah. Okay. Yeah. as a kid I played a lot of that especially the driving games but um honestly it's been quite a while so that's and I guess this is quite different to gaming like it's kind of a new it's a new type of thing like it's interactive world generation uh rather than there being like a hours long like I remember playing games for hours right like exploring all of the like side quests and all of things and like clearly our models can't do that so it's not obviously a drop in for those things but I think it it's surprising that how kind fun and engaging it is to play with it already. Um, so and I think we've seen that reaction from quite a lot of people that they just have fun like interacting with it. Um, and that obviously when you're so focused on the work, it's hard to understand how much someone else who doesn't get the context if they get put it in their hands, how compelling they'll find it. And we have had like pretty nice feedback. People do find it quite like interesting to to play with. I think that's actually something quite exciting um as well. Um but yeah, and and and Jack, I mean it's it's not a drop in replacement for video games today, right? So let's say you know a a standard video game, 20 hours of gameplay, lots of different levels, uh a lot of rules, not just an open world typically, but there is at least you're starting to see hints, especially with with Genie, where it could eventually evolve into that. it could grow into that. Do you is is there kind of a clear path yet to getting to a point where it's going to maybe not replace but supplement traditional games and is is that something that you're excited about? Yeah. So, I think on this one like I wouldn't say we're really considering it as a path to replace games in terms of being an additional an additional tool for sort of prototyping things. I think that's kind of where it's already at, right? Right. So, I think if you're someone who's like, \"Oh, imagine if I could, you know, um what were some of the examples? I could be an origami lizard, uh with a kind of platformer style, then instead of spending some time to create that, you could have it in 10 seconds, you know?\" Um and like that's pretty pretty cool, right? Because you can immediately see things. Um, we had someone in our like initial cohort of testers, um, Julian Tagalas, who, um, I think is far more of an expert to me on AI and gaming, and he wrote a really nice blog post, and he said like from his time playing with it, and he had a great time, uh, afternoon playing with it, um, is it's kind of already there for prototyping, like you have an idea of a random thing that like you maybe wouldn't want to invest much time in, and straight away you can try and interact with it. Um, now I think to really like narrow it down almost to being sort of looking at existing existing games and think it's trying to target towards that. I think it's like maybe maybe one path that but for us I think we're most interested in the more general capabilities of the model and um there's quite a few new things that we can try and do with it. I think yeah I'll just I'll just add that you know we um simulating games or like specifically requests much more than than genius capable today. I I think if you look at the game um as you said there is logic there is maybe a plot there is some so what we have today is basically a a sim a word simulator that can take text and just let you walk around and interact with with the environment right um it's definitely a potentially a comp a component that can later on be used to build various experiences right it can be a game it can be maybe exploring some you know in an educational setting. So I think at this point it's still very early to know exactly how people will be using it. Um and we actually have some collaborations with we've enter we've been in the entertainment space with with various companies and we're exploring that and also hearing from researchers as as Jack mentioned that give us some kind of like a feedback of what they think uh such systems can be useful for. Um I think for um specifically for simulating maybe environments that are um engaging I think there is like there is a lot of like space to explore how we can use those systems for that. Um for example for making it more interesting as you walk around you can you but but I think the key is that we can use it already for things that you cannot achieve it in in any other way. And for me this is the most exciting thing. Not just to try and do something that's already existing, right? But creating in a way a new media, a new experience, for example, something that is not exactly a film and it's not exactly a game, something that you can maybe do only using generative models. That's a slightly better way of saying what I was hoping to get at. So I'm glad I'm glad that's why it's good to have two of us. Just everything that the stream just said also applies to agents as well, right? Because what you were basically saying before is is actually kind of a similar question. It's like what's the the goal of the agents like how what's the feedback they get like is there any sort of like progression metric or these kind of things is kind of similar to what a human might want as well. And then also the richness of the worlds for as a as a limitation right now the richness of the worlds for humans is also a critical thing that if we want agents to learn about human interaction and these kind of things in the model then that's another area that we need to improve. So I think the nice thing is by building this new thing we actually make it more interesting for these use cases but I don't think we're like targeting one like we're kind of trying to just build the new thing. Yeah. and and Shalomi the as you were explaining it I realized I kind of fell into the trap that a lot of people do when a new technology comes about they try to fit it within kind of the the framework of of an existing piece of technology so um you know when the internet first came about it was like okay put the magazines on the internet it's like well actually there's probably a lot more and and novel things we could be doing with it and so I I certainly fell into that trap of thinking okay what can we do with movies what could we do with video but you're right like maybe there's something completely completely different, completely new that we haven't even thought of yet. And that's super exciting. Um, I want to I want to talk about the capabilities for a moment. So, uh, Genie 2 to Genie 3 was a pretty big uh pretty big leap. Um, and, uh, correct these numbers. I have them written down. So, Genie 3 24 frames per second, 720p consistency for a few minutes. Um, what hardware latency, budget, batching tricks made that possible? whether kind of independently in Genie 3 or as compared to Genie2. So a lot of you know I think overall what we try to do with Genie 3 is to push um all of the dimensions of of you know the the system to to the next level. So you know I tried to think about you you can think about the resolution um the um the memory and and along all of and how many actions you can do every second right so we have a few actions that you can you can so every all of those dimension if you multiply them it's like so almost a 100x kind of improvement and and this is you know this is in a way one way to think about the sleep right so like to quantify it a little bit um And I think the lot very key kind of key element in our research was to try and balance in one way the quality and the latency. This is something that we worked on a lot uh because because low latency is a challenge right as you said you know there hardware we are meeting hardware limits that we have to work with and really leverage a lot of the kind like best-in-class uh hardware and and kind like architectures that Google has across the different models and we invest a lot in trying like this is some even like building on multiple years of of um learning what makes models moreffic efficient. So I I you know without going into all of these details I can just say that this allowed like leveraging all of this work that happens across different modalities um really made a difference in terms of the efficiency of the system. Okay. Um, and then like by the way, I saw there's like a demo that you guys released and it was of a jet ski at night on on this uh I don't know like a a huge river and you see this jet ski bumping into things and the physics look incredible. I remember pointing out in one of my videos where I covered Genie 3, the jet ski was going past one of the lights and the lights clearly moved out of the way as the jet ski was going past it. And I it was such like a minor thing, but it just made the entire video um and and worlds look so real. When you first saw things like that, like what did you think? What was your initial reaction? I It's Yeah, I mean probably similar to yours. Like I think we obviously set these goals for ourselves that were pretty ambitious, right? Like coming after Genie2 and and V2 at the beginning of the year. Um Shomi obviously was co-leading V2 and myself on on Genie2 and we were talking about what we thought thought was possible and we kind of had this sense that a model like this would be achievable but it it's still like quite a like it was quite a surprising thing when you actually end up achieving it, right? because obviously during the project you have ups many ups and downs right research is not a straight line um so you get to the end and you're like kind of you're happy it's like looking pretty good right and then suddenly you keep seeing these new things and you're like oh actually this is really good um and some of the things you see like cuz obviously other people play with it too right um um and you almost kind of kind of forget it's your own work sometimes because you see someone create something like for me the painting one was one of those yeah where I just like found it really hard to believe that the model did it like like really cuz obviously like it's we're going for quite a general thing right we're really seeing it's like a new kind of foundation model rather than targeting one application so it has a lot of abilities that are we we overly use this word emergent but it has a lot of abilities that we didn't directly train for that um it's pretty amazing that it can do right so I think we were kind of almost every day there was a couple of weeks where someone did something really cool with it um that we didn't know it could do. There's a bunch of others as well, but we could talk about those maybe later. Um sure. Um okay, you mentioned V3. Uh Nano Banana came out uh just about a week ago. How much of the research efforts for V3 and potentially Nano Banana intersected with what you were doing with Gen3? Is it like some parts of it are incorporated into it? Was it just you kind of took learnings from it and like Yeah. How do you how do you think about those different research tracks coming together? Yeah. So the the story, you know, it goes back a little bit to to the story of, you know, how Jack and I kind of started uh working together. Um so I was mostly coming from Conver and Jack from the you know really awesome line of work for for Genie. And at some point um we were just we just realized that you know like that it's it's just it could make go very far if we kind of like combine the learnings that we have across the board and you know the teams you know obviously we're not very far uh physically and and you know in in in organizationally and we thought it's really something that we can um try and um and combine and try to push to the next level. Um so in a way um I think there are a lot of similarities between video generation and word simulation. There are also some differences. Um in in a way it was challenging to try and understand what should be similar, what should be different, what we should try and explore different approaches that we than we used for veil for example. Um and and yeah so definitely there there are similarities. Um, specifically you mentioned Nano Banana and which I I I I feel like the team is just it's just a trick to get us say this this ridiculous name, right? But but yeah, it did catch up. Um, so there are definitely a lot of similarities at the fundamental levels, but it's a different product after all. Uh but I think what unifies all of those you know maybe systems or models is the ability to just take something that is very sparse like some text from some from from the like the the user and build something that is so so elaborate and creative and if it's an image if it's if it's a video if it's a world that you can walk around um all of those things are really very creative and in a way to me it's it's every time I see it I'm very pretty much amazed sometimes like as just like I'm like forgetting that you know forget all of the work that we've put into it and just kind like surprised by it because there is something very surprising about the fact that a system um like a model is able to generate something that is so spectacular that any other way to generate that would require so much work right I used to work on um 3D engines as I mentioned and it it's so much work just to get the lens flare to to look re realistic, right? And now it just works, right? That's mind-blowing to me, right? So, yeah. Yeah. Um and and I I want to talk about um Google's custom hardware with the TPU. How how integral was having custom silicon like the TPU to the training and the actual inference uh running Genie 3? So I think I mentioned it before and and every you know all of the models that we develop are basically uh running ultimately on on Google's uh TPUs. Um and and I think having this good synchron synchronization and alignment between the hardware and the software gave Google like a really good advantage and um and you know we're basically able to optimize across the stack. So that's the very good and then I think it also translates to um to other to the ability to ship models fast but also you know make this hardware available to others um and potentially let allowing them to build their models to run on TPUs. So yeah I think I think you know GPUs and TPUs ultimately try to do the same thing. Um I think that if know there are a lot of I won't go into all of the technical differences uh but definitely having our own hardware and the teams that build it and and that's that's something that opens a lot of uh optimizations uh directions and um as you're training this model like if you're training a textbased model you have certain benchmarks that you can uh compare it against but like with a world model what kind of benchmarks would you be testing against? How do you know during the training process if things are working well? If if the product is baking and it's going to come out how you think it is? And then finally, when it is actually delivered, what kind of tests are you running? Is it all just vibe testing? Um, yeah, I think it's probably, as you would imagine, it's really a mixture of many things. Um, I think it's not just it's not just the comparison of text versus world model. It's probably also comparison of an established field where there are just existing benchmarks versus something that's kind of new, right? So, it's not necessarily obvious what you should expect um when you're doing something completely new. Obviously, we we we worked very hard on trying to get some like quantitative things we can trust. Uh and I think we've done have some pretty good ideas here and like we've been able to use some stuff but ultimately different capabilities of the model will require different metrics and so um you you really have to like all as a group be sort of discussing the pros and cons of some things and like um looking at like you can't necessarily have one there's not like one leaderboard you can necessarily climb as easily as you can with I don't know like a chess ELO or something like that you know um It's definitely a complicated picture, but I think in the end we managed to make make sense of it. So, um it's also really depends on how we use it. I I think the the more it's the more early the research is and and you know in this case as suggested we're not trying to necessarily improve an existing capability but we also added new capabilities. So for these we had some internal benchmarks but we definitely know it doesn't mean that those are um the best uh that's possible or like you know some some some uh golden stand gold standard right so unlike um you know maybe I think even for but I would say that even for text models right LLMs and and video models image models it takes quite a lot of time it took quite a lot of time for you just recently video models became maybe first class citizens in all of you know in LML arena for example right it takes a lot of time because there is no it's it boils down to human preference all of these models eventually yeah you can measure on some some task but people care about how they use it and I think for because it's still early in in the in the kind of in for world simulators to be interfacing with with users and that's so it's a bit hard for us to define the metrics so we're going to do it we'll do it probably as we as we go and as more people can use it uh we will have better understanding of how they're going to use it and we'll be able to create metrics that will be more useful to guide further development. Okay. Can you can you envision even if it's not possible today a a more kind of direct benchmark that isn't just based on user preference. I think predicting the future is a good one, right? Like in in a way predicting the future few seconds into the future, right? This is a bit of a typical um benchmark, right? But if you can predict the future of like given so that's something that we also you can also use for video models, right? Um if you can wait you have to break that down a little bit. Predicting the future. Please please explain what you mean by that. Sure. Sure. Sure. Of course. So when I think about predicting the future, I'm not predict I'm not thinking about predicting the stock market tomorrow. Although that's going to be useful. Maybe we'll get there. Um but but predicting maybe imagine that you have um a ball a ball on on the floor and somebody is kicking it right now. You can just stop at this second and just let the model guess what's going to happen next. Right? So as a person you can imagine that the ball is probably depending on the angle of of the of the kick maybe um you can imagine where it's going to go and land and a good model that can simulate an environment will probably be able to predict the trajectory right and this can be a really like a bit it can be just a fil video that you're taking in the real world and you can actually compare what happens next. So those benchmarks exist and and they're useful um for for basically understanding how well the um the model is able to predict the the the next set of of frames. Right? So that's one one way to consider it. But it doesn't cover a very important aspect of Ford's models is that it doesn't get the input from uh the user or agent. Right? So if you want to walk around and or interact with that's where we are hitting usually challenges in evaluation because there is no obvious way to to evaluate it. Uh I guess another interesting angle which we've been talking about uh a little bit is like obviously we designed the environment to be useful for training and evaluating agents but then we can use the agents to evaluate the environments too, right? So can the agents achieve goals in the world, right? If they can then maybe the worlds are sufficiently consistent um to to like enable enable that that means that must be a good thing. You can also say to the agents things like, you know, pick up a feather and drop it on the floor and does it kind of like float down. You can say like like throw the ball. You can say put mentos in Coca-Cola and see what happens, you know, like um and you can maybe then say like if you had if you had an intelligent agent, you could even ask it like did the world behave how you thought it would or something like that. Um, so I think this really like sort of twoway thing of like agent environment being a duality and like both kind of depending on each other and evaluating each other. Um, I think is something that could be really powerful. Uh, and it kind of at a meta level goes back to your previous kind of questions like does it benefit you from having these other teams like Nano Banana? Does it benefit you from having TPUs? Does it benefit from you having agents to evaluate? I think that's the really cool thing about building a model like this at GDM is without being too much of a of a Kool-Aid person, but like having all these amazing teams with other things that can integrate with the model, like clearly we benefit from all of this. Um, so I think it's pretty exciting. Yeah. And okay, Schlom, I have to go back to the predicting a few seconds ahead. I'm sure you've had this conversation internally, right? Immediately when I hear that, I think, okay, let's talk simulation theory. Um yeah, like it just if we if a world model can sufficiently predict the future like isn't isn't that proof of simulation theory at that point. So the okay you know uh it it depends how how deep you want to go but you know predicting the yeah yeah the future I think the f future given is not that I don't I think we we know that the future is not necessarily deterministic right uh based on on our understanding of physics um so not necessarily there is a single like single trajectory uh but at the macro level uh if you sufficient understanding and knowledge of of like the trajectory of the ball right so kind like Newtonian mechanics can give you the the the right like if you know everything if you know the mass etc you can actually predict so I think it depends on the phenomena right um and and the time horizon already today there are simulators that simulate physical environments and that's you know if you if you play a game you typically um games have some kind of a physics engine that just you know computes some some the force and maybe velocity and gets you some um some prediction. So I don't think the term of predicting like some some physical phenomena necessarily is very powerful on its own. I think the the the power of world simulators that are maybe learned is that they're very diverse. So you can do things that are that go much beyond a specific formula such as a ball you know going in one direction or the other. It can be I think for example um fluid simulation is something that is often being mentioned as as a very complex phenomena. um you know there their equations never stop that kind of like govern the behavior of of fluids and we can see that sometimes our the models video models and genie are able to simulate fluids and or in a very sophisticated and realistic way like I think we have this kind of like ocean kind of like someone got walking around next to the beach in in some kind of a hurricane I think one of the samples that we have and that's just it looks very realistic Right. So if you want to create a simulator for that, it's going to be pretty hard. Um, so I think what's exciting is that if we have simulators that can do that and learn to simulate to simulate physical phenomenons for example um such as fluid dynamics without doing any explicit calculations we don't you know we don't teach uh the model I don't know enough physics so I can't even if I want I can't teach them all to do right. So, so this is something that I it's in a way I don't think it necessarily leads to any conclusion such as simulation theory or anything but it just means that it is possible to simulate some aspects of the reality at some fidelity with maybe less compute than we would have thought before. Um whether we live in a simulation or not it's I'm happy to say what I think but just like it's a bit of a different question. I I would like to know what you think. Um so every time I get asked this question I'm like I'm making it more elaborate and and uh far-fetched. So let's see but um my current thinking is first I don't think we can know because in a way um you know I think there is like there is no actual way to answer this question uh for us even if we are if we do live in a simulation but um I think one interesting thing is that um physicist physics who test our reality and run experiments you know they observe some limit limits of of like you know quantum mechanics And if those are being able like if there is some machine that is able to simulate all of that I I think it's it's there is a question of how much compute is needed to actually being able to simulate that and and I think this is like if you apply it in some like I I think that's actually in a way counter the the argument right like because you need a very elaborate machine to to to um to pro to make all of those simulations and then the next level of reality also requires that. So, you know, I I basically believe that we don't we do not live in a simulation. Yeah. It's interesting though because as you're describing what Genie 3 is capable of simulating fluid dynamics, for example, it's not actually calculating atom by atom. It's calculating enough to render something that is believable by the viewer. And so maybe it doesn't require such a monstrous machine to actually do those calculations. But you can still I think this is the point that you can still run an experiment like so if you take the simulation you actually try and and and you walk like you will hit in a way the limits of the simulation right and I think and and it's not that hard to to see like that's my point like I think um while um maybe we can take video models as an example um they're very realistic like when we see like some some of the videos are just like you know I worked on free and sometimes like you asked what we think about the outputs of Genie. So Genie and V like sometimes like I I can't believe this is generated like sometimes it's just you're truly mind-blowing. And um I think the key is that it's still even though though it looks very realistic, you can still pretty easily prompt it in ways that will break, right? Like even the best models in the world at the moment can still break in some settings. And I think that's just the fact. And it does highlight that our simulations are still limited. I I there is a question how far we can fetch push it and and if at some point it will actually be as realistic as our our experiences. Yeah, I I have no answer for that. We went pretty far on the Yeah, I know. I'm going to I'm going to bring it back to Genie, I promise. But I just want to close. Jack, I want to get your thoughts. Uh are we in a simulation? Do you think it's possible or or just a hard no against? I thought I'd avoided this one. Um I took it usually. Uh yeah, you always take this one. Um, I actually don't have a strong answer. I'm going to I'm probably going to say no. Um, exclusively because I just feel like there's far too much going on and it's consistent. Um, it's so consistent everywhere. I feel like there would be at least one glitch somewhere and maybe you can identify some things that would have been that, but like having worked on these models like they're they're really good, right? But like to get the complexity of the real world and had pretty much zero things that like look obviously go slightly wrong. I'm like everyone makes a little mistake, you know. Uh so so that's my only real thing I can see that this proves it. But ultimately I think Shane made the point before that we wouldn't really know, right? So yeah, it's maybe maybe the mistake is like a deja vu from the Matrix, right? if you remember that scene like that was no mistake in the simulation. Exactly though. So like even in the even in the most compelling movie about living in the simulation, there are some glitches, right? So I'm like where and and I haven't spent a great deal of time like researching times when people have been like had conspiracy theories about glitches in the world. Maybe there are some and like no and no one paid attention, but like I'm not aware of any. So all right. All right. I promise we'll get off the simulation topic now. Um I just it's it's hard once I start thinking about it I want to talk about it. No but we know we do have the joke that the next version of Genie will be developed in the simulation. So we we perfect. Yeah. Genie will develop Genie will develop and infinitely on from there. Okay. Um one of the most impressive things that I I hadn't even thought of uh uh when Genie 3 launched and I saw it was the ability to have promptable world events during inference. Is that correct? Is it during inference? How does that work? What does the actual user interface look like during that exchange? Because obviously from from the outside all we got was the demos, but like what does it actually look like uh interface wise? And then what did it take to accomplish promptable world events during inference? Yeah. So I think there's kind of two things here. So in terms of the user interface, um we didn't really have one, right? So like Genie 3 is not like at this point a product, right? So it's still sort of a research preview. So in this case like the actual way that the text gets sent to the model for those things like it wasn't like there was some shiny widget or something like that or someone speaking into it or anything. It was more just like someone sent sent the commands to the to the model via like a research researcher worked on that. Um, but in terms of the mechanics of it, it it really is just like sort of the model's just receiving a text prompt like during the generation. So the frames before that prompt haven't seen it and the frames after have, right? So um so interesting. Um essentially the model it's each frame is conditioned on an action but then sometimes it will be um have the text. So um essentially then it has this like causal nature, right? So like the event happens and then from that point onwards it can impact the world. Right? So if we if we think about this uh as an analogy to text generation it would like it would be almost as if you can insert new text during each token that's being generated. Yeah. Yeah. Exactly. In a way in a way think of it like um if a text generation model tries to predict the next token, right? So Genie is trying to predict the next frame based on a sequence of inputs and and here we're just allowing the user to say okay that's what's going to happen next. It doesn't say exactly when. So the model can interpret it in in some way. And and it's a very interesting if you think about it like it's very interesting because it doesn't say exactly how something should should be materialized in the world. And and it's you know it's it's actually quite an open like the model can decide for example if you ask it okay a camel comes into the view right or something like that then it does it is are you going to see it when you look to the left or just going to materialize like there is a bit of like it's underspecified so so I think this is part of the challenge is to figure out the right and that's why you know when we you mentioned evals or ways to evaluate models benchmarks I think we're still trying to figure out the interfaces even right like how what what what goes in what goes out uh to the model and this is one idea that we had that we really wanted to explore and I think you know we have some other ideas how we can how can you can integrate interact with this world right it's not obvious text like when you walk around you don't just like we interact physically with the world so I think text is in a way a proxy for that and and yeah and and so let's say you have this initial prompt and it generates the world and then during the generation of the world you give it a conflicting prompt. Let's say it's a simple example in the original prompt ball is red. In the subsequent kind of in in um in in generation prompt you say ball is blue. How how does the model handle those conflicting instructions? Um my guess is that the model would try and make it happen. Right? So we didn't try that exact kind of thing where like events change change what was in in the world already. Um, we tried more things that were like adding to the world, like a a dragon appearing or like the person in the chicken costume for instance. But if you if you said now the river turns like red or blue, um, I think it was already a bit brown. It was in London. Uh, he said it said it turns crystal clear like the Caribbean. That would be nice. Um, I think it would just I think it would just do that, right? like it would just do what it like it would follow the text that it's given. Um now the question there's another cool example where um obviously the model takes text as as the world description but actually you can also prompt it with a video as well right so you can prompt it with frames um and there was an example that um we posted on social media where someone in the team had gave it some frames of of like one world and then actually prompted with text that was not consistent with that. Um, and so we have evidence that the model what model does is try to make it work, right? So it it just like in the most natural way possible, it kind of blends these two worlds together, right? So you get examples um like the one where I think it's in a room watching people playing actually with the genie model. Uh I remember that. Yeah. And then and then the prompt is about like a jungle with dinosaurs and something like that and then you turn around and you're in the jungle, but then you look back and you see the room. So the model just kind of makes the text work in the world. And that's I think kind of what show me was getting to before is that like you don't tell it, oh by the way your your video frames may show a room, but blend it this way. It just kind of does it and makes it work. And like that's kind of the exciting magical part in a sense because it's sort of like creating something that you didn't really know what it was going to do exactly. Um, like even the one where it's like the dragon lands in the canal and like the way it just kind of plunks down and splashes the water everywhere. I think it's like when it actually happens, you kind of all like, well, that's really cool. I didn't know what it was going to do, but that's really cool. Um, so I think yeah, you're I think you're right to highlight that feature as like probably one of the most open-ended exciting parts of it. And and so for for what you can share, um, what does the underlying training data look like? What format is it? Meaning is it is it just all video game simulations? Is it uh movies? Like kind of broad strokes from for what you can share. What does the training look like? What does that training data look like? Yeah. So we train on uh mostly on publicly available uh video data sets. Um and and that's pretty you know pretty much what we we can share at this point. Um but the model I think the the interesting thing is that the model is able to really learn from very diverse video models about the world. I think this is something that's a little you know maybe again a little similar to how LLM's learn from just web you know text on the web potentially or other sources um to predict the next token and from that it can infer a lot about how the world works how people express themselves and how maybe even how to think and how to solve problems and I think in a way what we're seeing is that learning from kind of those you know sources of video data also allows the model to learn um like representations that are very useful potentially for creating this interactive environments. Right? So I think I think this is a very surprising kind like result. There are a lot of people who say that text generation models aren't necessarily generalizing that far outside of their data set. Do you uh think that video or textto world models can generalize more effectively than text models? That's a really cool research question to be honest. Um I think it's quite hard to quantify that one. Um, but like intuitively, so I'm not actually super expert on language models, so probably don't want to talk too much about what they can't do or can do. But in our space, like I think it's certainly the case that a lot of things that the model can do already are things that don't I I don't think it's seen before. I think it's generally a new thing that it's creating. Like the dragon and the canal um or even the origami lizard, I think is a pretty new idea. And then like there was the one with the skiing and I think and the the deer and like I don't think these things have really existed before. Uh and then I can say this a bit more like objectively cuz I mean I wasn't part of the V3 team. And obviously Shomi was uh one of the leads of the project. Like some of the things video can do absolutely incredible, right? So I think there's many things there that like did not exist like all of the this this the vlog videos, right, of like different animals I don't think can speak English. Uh talking about stuff and I it's it's really amazing and like that's that's what makes them so magical is that you can you can create completely new things, right? Whereas I'm not so convinced that like maybe other kinds of models it's about creating new things. It's more about doing things that we already want pretty well. Um so I think that's maybe the like more creative element that comes from these models is from the fact they can generalize. It kind of reminds me I had a debate I think it was a few years ago when LMS were still just beginning uh to to get traction then um there was this argument that maybe you know okay they're just we're just predicting next token you don't really learn anything new and just kind like repeating the the training data. I think ultimately the test is whether to me is whether it's useful right we can debate how much you know some like maybe it's repeating the training data maybe not and we can try and come up with some um tests that are outside of the training data which is obviously very difficult the larger the training data is um but ultimately if a model is useful I think that's that's to me the the bar right and and I think for video models we see that they are useful like people are creating things that they couldn't have done before. So I hope that with world simulation models and like Genie we will also see like people just using it and researchers using it for useful stuff and I think that will be a success for me. Yeah. Another thing that's been kind of uh trending in text generation models is using synthetic data. So generating data with one model, using it to train another, and potentially like debate on whether that can actually scale up to more capable models. Do you see Genie 3 generating uh worlds to uh to to train Genie 4? Uh that's a great great question again. Uh I think so I think there's a different angle to this. Obviously we we're very focused on using Genie 3 to generate synthetic data for agents, right? Um and so I think that in some sense the initial design of it was actually ahead of its time. It was always about synthetic data generation for training other AI models. Um now indirectly if if I said if you combine that with what I said before and those AI models then are used to evaluate future versions of the genie models then indirectly that has contributed. Um, in terms of the specific method of like Genie3 to Genie4 uh data generation, I'm I'm not sure can really speculate on that one too much at this point. Okay. Um, and then and then I have to ask, so G3 limited research preview, small cohort of people get are getting it. What are the specific milestones that would unlock broader access uh or andor an API to specifically people like me and me me in particular actually want to use it. So we definitely um we definitely want to bring it to more to more people, right? Like it's it's it's not um we while it's a research preview, it's definitely something that we're exploring. Uh we don't have a concrete timeline at the moment. Of course, once once we know we we'll share it. Um but um it's definitely the goal is not to build something that cannot be used, right? that like from we are we were build like I think now general theme for us is that we want to build things that people can ultimately use and make and build on top of okay but without speaking about specific dates or timelines are there specific milestones or achievements internally that you'd like to see whether it's safety scalability that would you know lean more towards general availability um yeah I don't I don't I there definitely we need to get some feedback that's why we we started with a smaller cohort and I think generally when there is a new you know application or a new kind like capability set of capabilities we first want to test and and hear from from people in as you said smaller cohorts um and uh potentially diverse cohorts as much as we can um to hear what they think what are the risks what are the the potential applications and I think that's pretty much the the main part of it just to to to get this feedback and to be able to process it before we expand. All right. Uh Jack Schlommy, I want to thank you so much for chatting with me today. This has been a pleasure, especially talking about simulation theory with you. Yeah. Yeah. Yeah. It left me pondering. Yeah. Thanks for your time. Thank Thank you guys.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Entrevista com dois líderes da Genie3 sobre Genie3, geração de mundos 3D a partir de texto e suas aplicações em jogos, treino de agentes e simulações, além de planos futuros e teoria da simulação.",
            "resumo": "Neste vídeo, dois líderes da Genie3 discutem o Genie3: um modelo capaz de gerar um mundo totalmente em 3D a partir de texto, com alto realismo e várias aplicações, como jogos, treinamento de agentes e simulações. Eles explicam que o objetivo é criar uma capacidade fundamental de gerar ambientes a partir da linguagem, que possa ser usada para diversas finalidades. A origem do projeto, há cerca de três anos, foi centrada em AGI e no treinamento de agentes por meio de simulações, buscando mundos ricos o suficiente para transferir habilidades para o mundo real. Com o avanço de modelos de linguagem e de imagem, a equipe aposta que gerar ambientes completos pode acelerar o desenvolvimento de agentes gerais, explorando, inicialmente, sinais visuais (pixels) como principal modalidade de feedback, com futuras extensões a sinais físicos e outras modalidades. Também discutem o papel da simulação e teoria associada.",
            "assunto_principal": "Desenvolvimento da Genie3 e geração de mundos 3D a partir de texto para treino de agentes e simulação, com visão de teoria da simulação e caminho para AGI.",
            "palavras_chave": [
              "Genie3",
              "Gênio",
              "mundo 3D a partir de texto",
              "simulação",
              "treinamento de agentes",
              "Inteligência Artificial Geral",
              "modelos de linguagem",
              "ambiente virtual",
              "pixels",
              "DeepMind",
              "teoria da simulação"
            ],
            "resumo_em_topicos": "- Apresentação do Genie3: geração de mundos totalmente em 3D a partir de texto, com aplicações em jogos, treinamento de agentes e simulações.\n- Origem e motivação: aproximadamente 3 anos de foco em AGI e ambientes de simulação para treinamento de agentes com transferência para o mundo real.\n- Abordagem tecnológica: avanços em modelos de linguagem e visão para criar ambientes completos; saída visual (pixels) como modalidade inicial.\n- Treinamento de agentes: o Genie3 pode servir como ambiente de treino, conectando pesquisas de simulação da DeepMind com o objetivo de reduzir a dependência de ambientes reais.\n- Perspectiva de longo prazo: expansão para sinais físicos e outras modalidades; relação com a teoria da simulação e o possível caminho rumo à AGI.",
            "prompt_tokens": 1802,
            "completion_tokens": 3440,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 58.41979217529297,
          "language": "",
          "view_count": 11135,
          "has_transcript": false
        },
        {
          "id": "yqtujbev9zI",
          "title": "GPT-5 Codex is nuts...",
          "title_pt": "GPT-5 Codex é insano...",
          "url": "https://www.youtube.com/watch?v=yqtujbev9zI",
          "published": "2025-09-16T01:02:09.070700",
          "published_relative": "há 5 dias",
          "duration": "07:04",
          "date_published": "2025-09-15T15:31:47-07:00",
          "transcript_available": true,
          "transcript": "OpenAI just dropped GPT5 Codeex. If you thought Codeex was a great product, now it's powered by GPT5. It was only a matter of time. So, if you click the little get started button, look at this. VS Code Cursor, Windsor, VS Code Marketplace, Codeex Web. Today, we're releasing GPT5 Codeex, a version of GPT5, further optimized for agentic coding in Codeex. It was trained with a focus on realworld software engineering work. It's equally proficient at quick interactive sessions and at independently powering through long complex tasks. And its code review capability can catch critical bugs before they ship. And you don't have to use codeex directly in the chat GPT interface. It goes wherever you want. Codeex now works where you develop in your terminal or IDE on the web in GitHub and even in the chat GPT iOS app. It's included with ChatGpt Plus Pro business edu and enterprise plans. All right. So here are some benchmarks. Here is SWEBench verified and as you can see GPT5 high 72.8 GPT5 codeex high 74.5. So a couple point bump not enormous but definitely an improvement. Code refactoring a massive improvement. GPT5 high 33.9. GPT5 codeex high 51.3%. We've been talking a lot about longunning tasks. Replet just announced that their agents 3 product goes for 200 plus minutes. But listen to this. During testing, we've seen GPT5 codecs work independently for more than 7 hours at a time on large complex tasks, iterating on its implementation, fixing test failures, and ultimately delivering a successful implementation. 7 hours. That's nuts. So, I think there's two factors here, and I've been speaking about this a lot over the last week. The amount of time that an agent can work autonomously successfully is really important, but it's also important how quickly they get work done within that time frame. So if Codeex is able to think for 7 hours and get something done, that's great. But if it's able to think for 7 hours and get more done, that's also great. So there's really two levers at work here. How long it can go for and how much it can get done within that length of time. So more on how codeex actually works. So we see that for the bottom 10% of user turns sorted by model generated tokens GPT5 CEX uses 93.7 fewer tokens than GPT5 and conversely for the top 10% so the more complex use cases it thinks more spending twice as long reasoning editing and testing code and iterating. GPT5 Codeex has been trained specifically for conducting code reviews and finding critical flaws. When reviewing it and navigates your codebase reasons through dependencies and runs your code and tests in order to validate correctness. So check this out. more benchmarks of GBT5 versus GBT5 codeex. So this is incorrect comments 13.7% of the time for GPT5 high and only 4.4% for GBT5 codecs. High impact comments GBT5 high 39.4 and GPT5 codeex high 52.4 and we all know AI loves to comment. So high impact comments very important. and comments per PR. It's actually lower, which is good cuz I don't want overly commented code. It's not necessary. I want the right comment at the right time. And if you want to try out GPT5 codecs right now, do it with the sponsor of today's video, Windsurf. Windsurf is today's most powerful agentic IDE where developers are carrying out their best work from solo projects from tinkers all the way up to enterprise organizations with millions of lines of code. Windsurf is built to keep you moving fast, but without sacrificing security. Especially after being acquired by Cognition, the creators of Devon, the Windsurf team seems to be shipping faster than ever. Windsurf is faster. It's also gotten a makeover, and it's more reliable. They also ship features like deep wiki and vibe and replace. Windsurf also comes with a one-click MCP store and a really sophisticated memory feature. And now, a deep integration with Devon makes it even more powerful. So, if you've watched this channel at all, you know I'm a fan of Windsurf, so definitely check them out. I'll drop a link down below. Thanks again to Windsurf for sponsoring this video. Now, back to the video. So, Codeex CLI has also been updated. The terminal UI now has tool calls and diffs that are better formatted and easier to follow. Approval modes are simplified to three levels. read only with explicit approvals, auto with full workplace access but requiring approvals outside of the workspace and full access with the ability to read files anywhere and run commands with network access. It also supports compacting conversation state to make longer sessions easier to manage. And as I mentioned, it's now available wherever you develop. It has a new IDE extension and GitHub integration. They've also improved their cloud infrastructure performance by caching containers. We've slashed the medium completion time for new tasks and follow-ups by 90%. I always thought that speed is highly underappreciated. Everybody wants quality, obviously, but speed is nearly as important. And now you're getting 90% lower latency. It now also automatically sets up its own environment by scanning for common setup scripts and executing them. And with configurable internet access, can run commands like pip install to fetch dependencies as needed at runtime. Codeex can spin up its own browser, look at what it built, iterate, and attach a screenshot of the result to the task and GitHub PR. It also now comes with code review capabilities. So unlike static analysis tools, it matches the stated intent of a PR to the actual diff, reasons over the entire codebase and dependencies, and executes code and tests to validate behavior. And this is kind of a dig at human reviewers. Only the most thorough human reviewers put this level of effort into every PR they review. So Codeex fills the gap. So once turned on for a GitHub repo, Codex automatically reviews PRs as they move from draft to ready, posting its analysis on the PR. You can also explicitly ask for a review by saying at Codex review and a PR and give it extra guidance like review for security vulnerabilities. So at OpenAI, Codex now reviews the vast majority of their PR. So they are dog fooding this completely catching hundreds of issues every day often before a human review begins. So definitely check this out. Let me know what you think. It's available for chatbt plus pro business educational and enterprise plans. This is an interesting way to price it. Plus edu and business seats can cover a few focus coding sessions each week but pro which of course is $200 a month can support a full work week across multiple projects. So, it is literally like having an additional developer on your team. Business plans can purchase credits to enable developers to go beyond their included limits, while enterprise plans provide a shared credit pool so you can only pay for what your developers use. So, I love it. I think this is awesome. Go try it out. Let me know what you think. If you enjoyed this video, please consider giving a like and subscribe.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "OpenAI lançou o GPT-5 Codeex, versão otimizada para codificação orientada por agentes, com integração em várias plataformas e melhoria significativa na revisão de código e na produtividade.",
            "resumo": "OpenAI lançou o GPT-5 Codeex, uma versão do GPT-5 otimizada para codificação orientada por agentes no Codeex. Além de sessões rápidas, também executa tarefas longas, com capacidades de revisão de código para detectar falhas críticas antes da implantação. Pode operar onde você desenvolve: terminal, IDE, web, GitHub e o aplicativo do ChatGPT. Disponível em planos ChatGPT Plus/Pro, para negócios, educação e empresarial. Em benchmarks, Codeex supera o GPT-5 em algumas métricas de desempenho e mostra grande melhoria na refatoração de código. Em testes, utiliza períodos autônomos de até 7 horas em tarefas complexas. Destaques incluem redução de tokens em usos simples, maior qualidade de comentários de alto impacto, e um conjunto de ferramentas de revisão que compara o objetivo da PR com o diff. CLI atualizado, modos de aprovação, configuração automática de ambiente, cache de contêineres e integração com Windsurf, patrocinador do vídeo. Disponível agora.",
            "assunto_principal": "Lançamento e capacidades do GPT-5 Codeex para codificação orientada por agentes, benchmarks, integrações e impacto no fluxo de trabalho de desenvolvimento.",
            "palavras_chave": [
              "GPT-5 Codeex",
              "codificação orientada a agentes",
              "revisão de código",
              "integração com IDEs",
              "referenciais de desempenho",
              "tarefas de longa duração",
              "tokens",
              "interface de linha de comando",
              "ambiente automatizado",
              "windsurf"
            ],
            "resumo_em_topicos": "- Lançamento do GPT-5 Codeex: versão do GPT-5 otimizada para codificação orientada por agentes.\n- Integração ampla: funciona no terminal, IDE, web, GitHub e app do ChatGPT.\n- Desempenho e benchmarks: melhorias em refatoração de código e ganhos modesto em algumas métricas.\n- Capacidade de tarefas longas: testes de até 7 horas de funcionamento autônomo.\n- Economia de tokens: menos tokens em cenários simples, mais esforço em casos complexos.\n- Revisão de código: foco em detectar falhas críticas e validar comportamento via execuções de código e testes.\n- Novidades de CLI e fluxo: modos de aprovação, ambiente automático, cache de containers.\n- Disponibilidade e planos: incluído em planos do ChatGPT e opções para negócios/educação/enterprise.\n- Windsurf: patrocinador do vídeo, integração com Devon.\n- Impacto no fluxo de trabalho: equivalente a ter um desenvolvedor adicional na equipe.",
            "prompt_tokens": 1639,
            "completion_tokens": 5476,
            "model": "gpt-5-nano",
            "cost": 0.009
          },
          "analysis_time": 72.66843104362488,
          "language": "",
          "view_count": 41770,
          "has_transcript": false
        },
        {
          "id": "dZF9wHqrTRw",
          "title": "AI News: Qwen3-Max, OpenAI for Profit, Claude Updates, New Models, and more!",
          "title_pt": "Notícias de IA: Qwen3-Max, OpenAI com fins lucrativos, Atualizações do Claude, Novos Modelos e muito mais!",
          "url": "https://www.youtube.com/watch?v=dZF9wHqrTRw",
          "published": "2025-09-16T01:02:09.070715",
          "published_relative": "há 5 dias",
          "duration": "18:05",
          "date_published": "2025-09-15T11:33:24-07:00",
          "transcript_available": true,
          "transcript": "This video is brought to you by Spotter. More on them later. I'm up in San Francisco, so different background, got the bird behind me, but there's tons of AI news. Let's get into it. First, seemingly from the future, we have a near telepathic wearable that allows you to effectively think and it will know what you're thinking. According to the post, this enables silent communication at the speed of thought. So, here's how it works. You put on this little device and you kind of almost mimic talking, but you don't actually talk. And it's somehow able to determine what you meant to say. Here's how it works. Alter Ego passively detects the downstream subtle signals your brain sends to your speech system before words are spoken aloud. It captures only what you intend to say. It never reads your thoughts, only picks up what you want to communicate. Now, I've been lately talking a lot about voice AI as the main interaction layer between humans and AI, but I didn't know this is going to be coming right around the corner. I'm going to assume it's not going to work great right out of the box, but assuming this kind of tech can work, this would be an even better replacement for typing. I still think voice is really important, but if this works, this would be great for if you're in public spaces. This technology is normally called silent speech, but we've made a breakthrough called silent sense. Silent Sense picks up the entire spectrum of speech from the mouththing of words all the way to motionless intent to speak. I cannot wait to try this. Stay tuned. As soon as I do, I'm dropping a review next. Do you remember Oasis 1.0 from Deck Art? That was a system to use Diffusion to transform games into different styles. Now we have Oasis 2.0. So, here's Minecraft in the Swiss Alps or Burning Man. And you can swap these game worlds by using the game mod. This looks really cool. Try it out. Let me know what you think. Next, Chinese models are taking over, and you're going to see that even more in a moment. Alibaba has released Quen 3 Max, the second most intelligent non-reasoning model over a trillion parameters. It's Alibaba's largest model to date, but it is not open source, and it is not open weights. Here's where it falls on the artificial analysis leaderboards. So number one still GBT 5 high all the way down here quen 3 max preview right below gro code fast one right above quen 3 235 billion so it is a pretty good model but it is closed source and it is a relatively inexpensive model as well so congratulations to Alibaba on that release next apparently openai might be dropping a competitor to Nano Banana very soon has found GPT image0721 won mini alpha that is strawberry verse banana battle of the fruits and of course we don't know much more about it but we shall see and of course the kind of rule of artificial intelligence is as soon as you see one company do something just a few weeks later you're going to get a really highquality competitor next apparently Apple is building out a perplexity competitor this is an AI powered search engine now I haven't seen a single AI powered anything from Apple that makes me think they're going to be successful with this. But again, they're Apple. They have all the devices. They have billions of users. They have all the cash that they can ever dream of. And don't think Apple is down for the count. They're definitely behind, but they have enough cash to make it work. We'll see what happens there. I actually think maybe a better plan would be just to acquire Perplexity. Han has released a new image model. We've officially released and open- source Hunan 2.1, our latest textto image model. New in 2.1, advanced semantics supports ultraong and complex prompts of up to a,000 tokens and precisely controls the generation of multiple subjects in a single image. Precise Chinese and English text rendering, rich styles, and high aesthetic, high quality generations at 2K. But that's not it. Bite Dance released Seeddream, which apparently we've been doing some internal testing on my team, is quite comparable to Nano Banana, which is really kind of the gold standard of image models right now. I'm going to be testing it out. Let me know if you want to see a full testing video. And if you like creative AI endeavors, check out the sponsor of today's video, Spotter. I frequently get asked what my process for creating videos is, and I want to share something I've been exploring. So, this is Spotter Studio, and I want to show you how I've been testing it out. So, the process starts from Spotter Studio. And if I'm feeling stuck on an idea, I can use the ideas for you feed to give me inspiration and it is tailored to my channel. And even if I have a half-baked idea, I can use the AI brainstorm within Spotter Studio to help me ideulate through it. Once I have a strong contender for an idea, I put it in the idea bank. From there, it helps me prioritize by showing me keywords that are trending for my specific topics and ones that historically have performed well specifically for my channel. And it even gives my draft titles a title score to help me figure out which one is going to work best. From there, the winning idea moves into projects and I can use AI to help me generate thumbnail ideas. And it's incredibly important to really focus on the packaging. That's the title and the thumbnail for a video. And so that's why Spotter really comes in handy to help me visualize the idea before I commit to it. And right now, Spotter is running a limited time summer deal. You can get a yearly membership for just $99 to Spotter Studio, which is 80% off the original price. I'll drop the links in the description below. Check it out. Let me know what you think. Now, back to my video. Next, OpenAI is still having trouble converting to a for-profit company. I thought they stopped doing that. They actually put out a blog post a little while ago saying they dropped their plans to do that, but here we are again. According to the Wall Street Journal, OpenAI executives rattled by campaigns to derail for-profit restructuring. They have been talking about leaving California, which would be insane because they have such a massive office and so many people in the San Francisco area in a single building. And if they leave, they would have to move all of them. Open AAI executives are growing concerned that mounting political scrutiny in California could styy their efforts to become a for-profit company and have discussed a lastditch option of moving out of the state. Some of California's biggest philanthropies, nonprofits, and labor groups are joining forces to push back on the startup's highstakes restructuring plan. And remember, for those of you who are not familiar, OpenAI started as a nonprofit and then became one of the most important companies in the entire world. And then, of course, they want to become a for-profit to pay back investors to incentivize employees to work hard, work long for them. And because OpenAI is controlled by a nonprofit, they are asking the state's attorney general to ensure the new company it creates doesn't violate the state's charitable trust law. Failing to restructure could be catastrophic for the world's most valuable startup, imperiling its future fundraising efforts and a potential public listing. Open AAI's financial backers have conditioned roughly $19 billion in funding, almost half of the startup's total in the past year, on receiving shares in the new for-profit company. So, a lot of moving pieces, a lot of constituents, very complex. They're trying to find a way to be forprofit, and we're just going to have to follow along and see what happens. And in more OpenAI business news, according to the information, OpenAI says its business will burn $115 billion through 2029. And if any of you are saying, well, that's surely the signal of a bubble, no, it's not. This is par for the course for Silicon Valley. companies burn a ton of money until they find profitable economics and then they become insanely profitable. Look at Amazon. Look at Meta. Look at all of these companies Uber that have just burned tons of VC dollars in the path to dominance. Revenue growth for OpenAI is accelerating faster than they predicted at the same time. But computing costs are also accelerating. OpenAI projected its cash burn this year through 2029 will rise even higher than previously thought to a total of $115 billion. That's about $80 billion higher than the company previously expected. A massive jump. But look, ChachiPT is still the gold standard in terms of artificial intelligence for consumers. Everybody knows Chachi PT that is the verb. Go Chachi PT it. So I have a lot of hope for the company and I'm pretty sure they will be all right. Next in kind of news out of left field, the company ASML now is Mistral's biggest external owner. So according to ASML themselves today, leading semiconductor equipment manufacturer ASML, one of the most important companies in the entire world for semiconductor GPU chip manufacturing, says them and Mistrol will be having a strategic partnership based on a long-term collaboration agreement. In addition, ASML is investing€ 1.3 billion euros in Mistral AI series C funding round as lead investor. And you know what? I am glad there's competition because the more competition, the more consumers benefit from the AI race both in terms of overall intelligence and cost. We want cost to go down. We want intelligence to go up. Competition does both of those things. Next, Google released Embedding Gemma, a brand new state-of-the-art embedding model that is designed for ondevice artificial intelligence. And if you're not familiar with what an embedding model means, it basically just means converting data like natural language, unstructured data into an embedding which goes into usually a vector database. Then it's easily searchable by artificial intelligence. This entire process is also known as rag retrieval augmented generation. Embedding Gemma can work together with models like Gemma 3N to power advanced generative AI experiences and rag pipelines. The model is the highest ranking open multilingual text embedding model under 500 million parameters on the MTEB leaderboard offline first by design. I love companies pushing the compute to the edge. So here are the MTEB leaderboards. You can see embedding Gemma right here. I'll drop a link down below so you can see this benchmark in more detail yourself. Next, two new stealth mode models made its way onto Open Router. Soma Dusk Alpha and Soma Sky Alpha. Context: 2 million tokens, which makes me think maybe it's a Google model, but we don't know for sure. I haven't actually tested it myself. I've heard other people test it and say it's just okay. But with 2 million tokens, there's a lot you can do. And it is completely free. Go try it. Let me know what you think. How does it perform? Drop a comment below if you've already used it. Next, Cognition, the company behind Devon and acquired Windsurf a month or so ago, has just announced a massive new fundraising round. We have raised over $400 million at a $10.2 billion post money valuation to advance the frontier of AI coding agents and social media personality and boxer Jake Paul is actually in the round and had an interesting post about it. an AI content creator and engineer and he puts on a fantastic AI conference. Swix is also joining Cognition full-time. So, great for them. Congratulations on that big raise. All right. And remember, I said Chinese models are starting to enter the leaderboards. Check this out. This is Ella Marina and we have at number six, Quen 3 Max Preview under GPT5 chat. And according to Ella Marina, Gemini 2.5 Pro is still number one. Here's GPT5 High. Here's 03, which is surprisingly still up in the top. Claude Opus 4.1. But look at this. Just a few spots below, we have Kimmy K2, which is an openw weightights model. And I am just so happy to see all of these open- source models in the leaderboard. So really appreciative of these Chinese companies putting out these open- source models. We need open- source, and it's fine to have closed source, but it's good to have open source as competition as well. Next, Unitry is eyeing a $7 billion IPO. If you're not familiar, Unitry is the Chinese company behind incredible humanoid and dog form robots that are really on the cutting edge of robotics. Now, you look at companies like Tesla with Optimus. You look at Boston Robotics and Figure Robot, and these are all American companies building robots. This is a Chinese company building a far cheaper robot. I don't know how they compare. I don't really have a benchmark to compare them against, but again, competition is good. Hopefully, they raise some money. And in news that probably everyone saw coming, Microsoft is going to start buying AI from Anthropic. The great decoupling of Microsoft and OpenAI continues. Microsoft just about a week ago released their own in-house baked model, and now they're also going to be buying from Anthropic. This has really been Microsoft strategy from almost the beginning of their company. partner with everybody, buy from everybody, build with everybody, and provide the platform for everybody else to build on top of. They have no allegiances greater than the dollar. So, according to the information, Microsoft is taking its biggest step to lessen reliance on OpenAI's artificial intelligence by embracing the startup's bitter rival, Anthropic, to power its most important software business. Microsoft will pay to use Anthropics technology for some AI features in Office 365 apps. According to two people involved in the effort, the move will blend anthropic and open AI technology in the apps after years in which Microsoft primarily used OpenAI for the new features in Word, Excel, Outlook, and PowerPoint. This is a great decision. Why have platform risk? Especially when you're one of the biggest companies on the planet. It also can be seen as a negotiation tactic. Again, remember Microsoft owns, I think, 49% of Open AAI, and Open AAI needs Microsoft to sign off on the conversion of forprofit. Of course, why would they do that? Because then they're going to start cutting Microsoft out. So, all of this is just insane negotiation tactics and business strategy, and it's a lot of fun to watch. So, I'm going to keep reporting on it. Stay tuned for more. All right, next quick story. The Claude app on your phone can now connect to different apps. So, according to Claude's blog post, with your permission, Claude can find nearby spots, check your calendar, and schedule events, all without leaving the app. So, here it is. You give it location access, and now it can use maps. It can also dig into your calendar and so on. As I mentioned, cool little feature update. Very nice. And also, Claude can now create and edit files. So, this is on your computer, but turn conversations into Excel spreadsheets, documents, PowerPoint, slide decks, and PDFs directly. The more that these AI applications are able to put their tentacles into your computer, the more valuable they're going to become. And of course, the more of the primary application that you go to all day, every day they become. So, another quick update from Claude. All right, Apple had their big event this week. They announced the new iPhone, iPhone 17 Air, iPhone 17 Max, and they have new AirPods. I've been saying for a little while, I think AirPods are probably Apple's best chance to dominate artificial intelligence. They are highly personal. They excel at voice AI. Obviously, they need to update Siri or get someone else in there like chatbt voice, but it's the perfect form factor. You put them in your ears. You can wear them for hours on end, no problem. They last all day. And now they also come with real time voice translation. So, you just speak to somebody in another language and you hear it back in your native language instantly. It's super impressive. And it's kind of a weird time we're in where I think a lot of people look at this and say, \"Okay, that's cool.\" and don't realize how insane this technology truly is to be able to get live translation. So, it's a cool update from Apple. That's about all they announced that was AI related, though. And then Nvidia made a big announcement. So, Nvidia unveils Reuben CPX, a new class of GPU designed for massive context inference. This is a GPU made for large context windows, which is incredibly important. So, Nvidia Ruben CPXGPU is purpose-built to handle million token coding and generative video applications. It packs eight exoflops of AI performance and 100 terabytes of fast memory in a single rack. And they even talk about the ROI of the model, so companies can monetize at an unprecedented scale with $5 billion in token revenue for every 100 million invested. It's kind of insane that they're promoting it like that. And next, Oracle shares have surged. I didn't have this on my bingo card. Apparently, Oracle is powering a ton of AI inference. I think they came out of left field on this one, or at least I wasn't aware of it. Oracle Corp shares gained the most since 1992, a very old company, after the company gave an aggressive outlook for its cloud business, cementing the software makers place in the race to support demand for artificial intelligence computing. The stock surged as much as 43%, bringing its market valuation to nearly a trillion. Again, where did Oracle come from? And it made Larry Ellison, the founder, the world's richest person. And Salesforce released their own model. And apparently, it's really good. Check this out. Meet SFR Deep Research, our reinforcement learning trained autonomous agents that can reason, search, and code their way through deep research tasks. They have SFRD 20B achieves 28.7 on humanity's last exam text only, which is really good. SFRD agents are trained to operate independently without predefined multi-agent workflows. They're trained with end-to-end reinforcement learning and they're trained to manage their own memory. So, here it is. Look at that. Outperforming Kimmy Researcher 04 Mini and Deep Research with 03 on humanity's last exam. Again, another surprise story cuz I did not have Salesforce dropping a cutting edge frontier model. And once again, thank you to Spotter for sponsoring this video. Check them out. I'll drop all the links down in the description below. Let them know I sent you. So that's it for today. If you enjoyed the video, please consider giving a like and subscribe. and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Resumo em uma frase: o vídeo reúne novidades e rumores sobre IA, desde fala silenciosa e Oasis 2.0 até modelos chineses, planos da OpenAI como empresa com fins lucrativos, novidades na geração de imagens e ferramentas de criação de conteúdo com Spotter.",
            "resumo": "Neste vídeo, o apresentador traz novidades do ecossistema IA. O destaque é a interface de fala silenciosa Silent Sense, que supostamente capta sinais do cérebro para comunicar sem palavras. Em seguida, Oasis 2.0 transforma ambientes de jogos com mods. No front chinês, Alibaba apresenta Quen 3 Max, um modelo enorme, fechado; há rumores de lançamentos de competidores de geração de imagem pela OpenAI. O vídeo comenta planos da Apple de entrar no espaço IA com um motor de busca alimentado por IA, além de Han 2.1, modelo de imagem com prompts extensos, e Seedream da ByteDance, comparável ao Nano Banana. O apresentador divulga Spotter, patrocinador, mostrando como usa Spotter Studio para brainstorm, priorização de ideias, seleção de títulos e thumbnails. Por fim, discute o impasse da OpenAI em virar empresa com fins lucrativos, pressão regulatória na Califórnia e projeção de gastos de US$ 115 bilhões até 2029.",
            "assunto_principal": "Principais novidades em IA: avanços em interface de fala silenciosa, modelos chineses, disputas sobre lucratividade da OpenAI, novas soluções de geração de imagem e estratégias de criação de conteúdo.",
            "palavras_chave": [
              "Sensação Silenciosa",
              "fala silenciosa",
              "Oásis 2.0",
              "Quen 3 Max",
              "Alibaba",
              "OpenAI com fins lucrativos",
              "GPT Image 0721 mini alfa",
              "Apple Inteligência Artificial",
              "Hunan 2.1",
              "Seedream",
              "ByteDance",
              "Estúdio Spotter",
              "Spotter",
              "despesas até 2029"
            ],
            "resumo_em_topicos": "- Introdução e contexto do apresentador\n- Fala silenciosa: Silent Sense como interface comunicando sem palavras\n- Oasis 2.0: transformar jogos com mods\n- Avanços chineses: Quen 3 Max da Alibaba (modelo grande, fechado)\n- Rumores de concorrentes de geração de imagem: GPT Image 0721 mini alpha\n- Apple e IA: possível motor de busca de IA\n- Han/Hunan 2.1: novo modelo de imagem com prompts extensos\n- Seedream da ByteDance: comparação ao Nano Banana\n- Spotter Studio: uso da ferramenta para geração de ideias, títulos e miniaturas\n- OpenAI: debate sobre tornar-se lucrativa, pressão regulatória na Califórnia\n- Projeção financeira: gastos de US$ 115 bilhões até 2029",
            "prompt_tokens": 1847,
            "completion_tokens": 5563,
            "model": "gpt-5-nano",
            "cost": 0.0093
          },
          "analysis_time": 70.12020897865295,
          "language": "",
          "view_count": 45267,
          "has_transcript": false
        },
        {
          "id": "s6TKlCdKbIs",
          "title": "Amjad Masad: Vibe Coding, Platform Risk, Agentic Future, Permanent Underclass, and more!",
          "title_pt": "Amjad Masad: Vibe Coding, Risco de Plataforma, Futuro Agênico, Subclasse Permanente e muito mais!",
          "url": "https://www.youtube.com/watch?v=s6TKlCdKbIs",
          "published": "2025-09-12T01:02:09.070730",
          "published_relative": "há 9 dias",
          "duration": "56:45",
          "date_published": "2025-09-11T15:44:42-07:00",
          "transcript_available": true,
          "transcript": "The goal should always be is to take automation as far as possible with the current limits of technology. And and I think there's no reason for us not to go all the way. >> As you make it easier for people to just get in and start building, you're you're going to see an explosion of builders across the world. And I I believe you've mentioned this many times like that is very much part of your mission. You can create a vibe coding platform in an afternoon. I think people will lose their jobs. I think not saying that is being dishonest. I think any CEO working in the space will be able to intuitit that. And if you're trying to build something, just don't worry about learning to code first. Go build it first. If you have to learn to code, you learn it along the way. All right, Amjad, thank you for joining me today. It's my pleasure. >> All right, I'm excited to talk to you about Vive Coding and everything Replet. I have been a fan for a while. I've been vibe coding a ton, so I I'm really excited to get your take on uh everything vibe coding. Um let's let's get right into it. I I I want kind of set the scene first. Does Replet serve vibe coders or traditional software engineers or both? Mostly vibe coding. So we we have uh quite a bit of software engineers on the platform. uh but when our mission since the start of the company was to make programming more accessible the sort of insights I had uh back even when I was a teenager is that there is a difference between having ideas and really good ideas to to be able to build businesses or write software programs or write games or what have you versus the minutia and the drudgery of all sorts of things it related to programming are two separate things and it's a tragedy that we have to spend so much time whether it's software engineers or others dealing with that stuff you know they um it's traditionally called uh essential complexity versus accidental complexity and that was coined by I think John Brooks in the in the book the mythical man month uh and and and basically like there's so much nonsense we have to deal with So when we started replet even back in 2016 we were solving the development environment nonsense but then we start you know solving the deployment nonsense and and ultimately the biggest source of pain of it all is coding and syntax and all of that and so I don't think of it of uh in in terms of like who's supposed to be using it more as like who has ideas that they want to build really quickly without worrying about all that stuff. >> Yeah. Okay. That's that's a good definition and we're going to talk about this transition from kind of traditional coding to vibe coding, what the future of software might look like. We're going to get to that in a moment, but you Replet just launched a a suite of new features. I want to talk about those a little bit. It seems like they're aimed at making vibe coding more powerful, kind of u sanding off the rough edges and and where the limitations are. Maybe you can just speak briefly to what you guys launched and how it helps a non let's say traditionally non-s software engineer build more code and and take their ideas to production. >> Yeah. So the idea of vibe coding came from uh Andre Karpathy and his >> experience with it tweet >> the famous tweet was that I'm sitting in front of cursor and I'm not reviewing code at all. I just tell it to like do certain things and I accept the code. I'm just vibing, right? >> Uh and that became the term to describe not just like engineers doing AI coding, but also uh everyone else who's kind of willing to trust the AI to generate the code on their behalf. Uh and that's a that's a useful term. I think it created a lot of excitement and and buzz. Naming something turns out to be very very important. Uh but but I think it undersells the vision. Kind of the vision again is you have a problem you want to solve. You have an idea for a product you want to build and you should be able to express those ideas and have have it be done for you or have it be built as as as as far as it can be. and um and and the solution to that that Replet has uh innovated is is agents and to specific uh autonomous software development agents. So in September 2024, Raflet agent was the first kind of true agent on the market. The the modality at the time was that I am you know sort of coding and copilot is autocompleting my code or I'm in cursor doing composer and sort of editing pieces of code. But the idea of like an agent provisioning a development environment, installing packages, provisioning databases, deploying for you, that wasn't a thing back then. So we sort of created that and and and you know, uh it sort of supported this vibe coding modality. But the thing we want to get to is actually working with raffle agent as if it was a teammate, as if it was um you know, some an engineer you've you've hired. Uh, and so agent three really embodies that. And the idea behind agent three is that you should be able to offload entire tasks and have the agent be able to work for hours if you if you give it like a really big task. It should be able to test its uh its code by really opening a browser and going around and clicking and testing and making sure everything works. It should be able to look at the logs. It should be able to create test case scenarios. It should be able to review its code. should be able to refactor. And so that really goes from the idea of like an coding with an assistant to really delegating work to to to an agent. >> Yeah. And it's interesting because if you're familiar with software engineering, if you've built code in the past and then you started to get exposed to vibe coding, the things that you mentioned are what you figured out you need to do with an Aenta coding assistant. Right. So being really vigilant about git um being very vigilant about writing tests and testing thoroughly having to-do lists and and all of these things. It seems like Replet is becoming more proactive at helping the traditionally non-software engineer uh write great code. >> Yeah. And it's it's just a question about technology. What is the separation between what's the responsibility of the user, the human, the driver in the example of a of a car versus how far we want to take automation. In reality, the goal should always be is to take automation as far as possible with the current limits of technology. So, we've seen that with driving car, self-driving cars. Initially, it was the the you know, assisted driving, right? like it should just like maintain the speed and then it was lane assist. It should be able to go left or right, you know. Uh and then it was able to go off ramps and on-ramps. It wouldn't drive in the city, but autopilot was pretty good at that. Now we have self-driving uh where it still needs supervision, but it can go from point A to point B all the way in itself. And I think we caught up to that on the, you know, on the agent side, on the software development agent side. Um and and and and I think there's no reason for us not to go all the way. So actually the the first time we felt like agents are are possible. There's this u very popular uh venture capitalist. His name is Yohi. You might have seen him on on Twitter. He's he's like vibe coder par excalons. He built one of the earliest >> we have him on the show on Friday actually. >> Oh great great. Uh so he he I I don't think he gets enough credit for one of the earlier uh developers of agent. So he built Baby AGI. That was a really great demo. >> That's right. I remember that. >> What's possible? And so I we he's a he's a rapid user uh been for a long time and remember inviting him over to the office and we're like okay you know can you build something in front of us? I I just want to see how you code cuz I know you don't know how to code but you're able to build these amazing things. So what he was doing is he opened claude on the side and he opened replet on another side. And so he would type a prompt, he would get a piece of code, he would paste in a replet, he would run it, he would get an error, he would copy that error, go back to claude, paste that error, get an updated code. And I was like, we could just automate that, you know, and so every step of the way, you find the kind of gaps that people are filling in. For example, you mentioned Git or a to-do list or any of those things or architecture diagrams or architecture um you know uh markdown files and we're just you know uh we're just uh making the agent we're programming all of that into the agent. >> Okay. Um and it's interesting because I've been thinking about creative endeavors as the entry point into artificial intelligence lately. Like I think Google just said they onboarded something like 11 million new users because of nano banana and v3 kind of did the same thing. I remember when uh chatbt40 image came out it was very similar. Um and it's like if you can make software creation as easy as it is to now create images or create videos. There is that creative outlet that people want to really build incredible things. But again, they they don't really want to get into the minutiae, as you said, of of the code. And so, I think as you make it easier for people to just get in and start building, you're you're going to see and continue to see an explosion uh of of builders across the world. And I I believe you've mentioned this many times, like that is very much part of your mission. >> Yeah, it's interesting. AI grows in these series of hype bubbles. It's sort of like not different from crypto. uh you know I've been Bitcoin for a long time and you saw the 2013 bubble which was like a $100 to $1,000 and then you had the 2017 bubble which was like $1,000 to $10,000 and so on so forth. I remember like my dad back in Jordan learning about Bitcoin from the 2017 bubble, right? And he's probably a little bit not an early adopter but definitely not like a super late adopter. He's he's kind of sort of plugged in and want to see what's what's happening in the world. But you know that now we're in a you know crypto bubble that it is like reaching you know your grandma and and people is really not interested in technology and the same thing is happening in AI you know in the 22 call it 21 GPT3 bubble I don't know if you were part of that community back then but you know it felt like you know it was exploding and everyone knew about it and everyone was in the openi playground with the green text and like doing all these experiments and And in retrospect, that was so small relative to the chat bubble, right? And so the 2023 chat bubble and so on so forth. And yeah, Nano Banana is another one. Uh I think the vibe coding bubble is actually I think winning down a little bit. uh and there's there's you know it grew really fast and a lot of the companies grew fast and now we need to go to the next evolution and I think you need to and I think that the principle is reducing the barrier to entry and getting as close as possible to a true prompt to app experience and this is you know that this is the vision behind Asian 3 and we think we're going to be able to on board an entirely new set of folks that wouldn't otherwise wise be bothered to look at this stuff because it's still too difficult. >> Yeah. And look, like I I love vibe coding. It's a lot of fun, but it still has very um severe limitations to it. And hopefully some of the new features you're launching um lifts some of those limitations. But and I come from a software engineering background, but if you if you think about it for somebody who's never been exposed to this stuff before, I I you know was following along when Jason Lmin had his issues on on Twitter and was was complaining and um like what is the hardest currently reliability problem for Vibe coding? Where are those edges currently, including your your new release? Hey, by the way, it's impressive that Jason kept with it and now he's built like six apps and he's he's like a huge >> it's addictive and it's fun, you know. Yeah. >> Yeah. So, I I I do think it's all learnable, but it is I think the part of the problem is like a little expensive as well. So, I think if people keep with it, they'll be able to get through it and eventually create tremendous value for themselves and their uh their businesses. But um the question is is about difficulty or um >> yeah like where are the current edges of vibe coding? I found maybe like a month ago it was a a few thousand lines of code or some kind of complexity threshold. What is it today? >> Yeah to to to get a little technical because I know a lot of people watching your audience are are technical. Um the right now the way models have been improving is uh you know we go from the era of of pre-training scaling put as much data in comput into the base model to the era of like post- training and more importantly sort of runtime scaling inference compute test time scaling there's so many names for the idea of like spend as much tokens as possible in order to try to solve the problem. Now one thing crucial there once you have verification then that becomes really possible. I think Nvidia showed that maybe like last year where they had um an NVIDIA kernel optimizer using DeepSseek or earlier this year using Deepseek R1 and the insight they came up with is if you put a verifier in the loop they're able to kind of verify whether the kernel works or not then uh then you can just run the AI for as long as possible until it solves the problem. And uh in their case, they were like, \"Oh, we're able to run Deep Seek for 15 to 20 minutes and was able to do all this amazing stuff.\" And in our experience, yes, if you have a good verifier in the middle and you have good architecture around the system and you've done good prompt engineering and you've done some like important things such as context management, context compression, all of that, you can run LMS right now for as long as needed to solve any particular problem. like theoretically speaking there's probably no insurmountable software engineering problem right now given that you have the right environment to test this in place. So the main thing when I mean that that's like a big statement and there's like a lot of nuances to it but it's truly my belief that uh we're at a point if you can afford the tokens you can let it run as much as possible break through a lot of walls for you. Um so the the based on this insight we spent a lot of our time on testing. So uh the first thing we tried was computer use models. The cool thing about replet being so focused on building applications as opposed to running your enterprise repo. Um we're like okay we we have a constraint problem. The AI needs to open up a browser window and go around and test around test the elements and make sure things are work. Submit a form you know use the app. Uh so naturally we went for computer use models and we were very disappointed. Uh you know I was so bullish in computer use models when they first came out. I was kind of the first sort of like as big of a magical experience as GPT3 was like seeing a model use a computer like a human would. >> But they're so expensive. They're so errorprone. They're kind of bad in general and they haven't been improved. And that's worth kind of thinking why there's not a lot of progress there. So we kind of put down this this this problem, focus on other things. But it kept coming back to this idea of like if we want to be able to run the agent in a more autonomous way, in a self-driving way, there needs to be verification. There needs to be feedback from the environment. Um so we went in and we built our own uh computer use framework because it's a constraint problem. we're able to innovate and I think you know we're sharing some data um the the sort of computer use framework that we built is um about three times faster than traditional computer use and it's about 15 times cheaper to to run. So, we're able to kind of really put it in the loop and have uh have the agent decide to test its code uh every time it makes a a major change. Um so that was one of the first steps. The second step was a major architecture change uh in creating those to-do lists. Cloud code kind of innovated this idea uh and the idea of sub agents uh as well. So when you combine all these things we are able to run like our our marketing is saying we can run up to 200 minutes but we actually run replication for for 4 and a half hours and it was actually able to build an application end to end that would take an engineer you know previbe coding about like a week to build. Uh it was like an amazing experience and when you look at the log you can see it's it struggled in a way that like you know two months ago the vibe coding tools of two months ago if a nontechnical user sitting in front of it they would just rage quit it like it would struggle with like >> you know websocket connections for example websockets is you know notoriously hard for all because it's zudu distributed uh systems problems it's hard to create a test environment for it but with replet's kind of browser use. It creates multiple browsers. It kind of tests different uh users and make sure the real-time thing is working and it was able to um really punch through through a lot of doors and a lot of technical problems and get to a soft solution. So I think that's the main insights and the main innovation why we think replet is will you know when people start to use agent 3 they'll find out that it's the most autonomous agent on the market. You know, I'm I'm a big believer that these models are already incredibly good and and really, as you're describing, scaffolding is kind of all you need to to use the famous paper meme. Um, >> but if you were a model provider, if you were creating a model yourself, if you, you know, OpenAI, Anthropic, Google, what would you focus on to optimize? Because running for 4 hours sounds great, but you know, maybe you can compress that down to an hour. So maybe it's speed. You also mentioned cost as a huge limiting factor. So what would you optimize for if you were creating a model yourself? Speed, quality, agentic ability, something else. Yeah, I mean I mean uh look the uh best thing to do um it might not be feasible, but the best thing to do is to be able to oneshot every problem. Like that four hours could be, you know, 10 minutes if they're able to like oneshot the code exactly to what you want, right? Right. So that's like a function of quality then. >> Yeah. >> Intelligence level. >> Intelligence level. Code quality. But I assume we we are sort of at a plateau in in so far how much they can oneshot. uh I think uh 3.5 sonnet 3.5 was a major leap forward where you go from 40 being able to write a you know file tops to 3.5 max being able to like spit out megabytes of code and like scaffold an entire project. Uh with 3.7 and you know four we start seeing diminishing returns. It's not really able to kind of really oneshot that impressive an application. maybe a front end and and a little bit of back end. So, let's assume that's somehow harder of a problem. Then the thing that I would fall back on is uh is is you know a genic benchmark such as a SWE. So SWEBench I think we're at like 70% now. I would definitely try to get to 100 just like climb that beast you know. Uh and it's a lot about a a lot of it is about tool calling. A lot of it is about uh responding to feedback from the environment which again is what we focus on. Can you kind of run a set of commands, run tests, get feedback from that and then generate hypotheses for why it's not working. So this art of debugging and I think that's one area where it seems very possible to make more progress. And I think the bottleneck, look, I'm speculating at this point. It feels like the bottleneck there is good RL environments, environments that allow the agent to generate a lot of code, test that code, get feedback from that code and and sort of iterate on that and train uh throughout this process. All right, let's let's um let's talk about competition a little bit. There there are a lot of five coding platforms out there and and when all of them have access to the same top-of-the-line models from anthropic from from uh OpenAI from Google how does replet differentiate itself uh is it uh UIUX is it scaffolding around it what do you say there >> um I I think that depth of the platform is is very important so you can you can create a vibe coding platform in in the afternoon. Uh you what you need literally what you need is uh you need to call claude uh generate some react code open an iframe put that react code in an iframe and it will like render it. So so if you want to start >> sounds so easy >> it is kind of like to to do like a basic vibe coding platform which a lot of them are kind of you can just do that. Um and then obviously UIUIUX matters but I tend to think that UIUIUX is a sort of a public good. The moment you innovate on UIUIUX is like immediately copyable and like people have copied rapid left and right and um and I love it like when we release something immediately like the competition for example like we just released like plan mode and I saw someone from like cursor team was like oh what do you think if we release plan mode? uh which I don't really think of them as direct competition but like UIUX is not something that you can truly have a moat around. However, I think technical depth of the platform is perhaps not an a a forever mode but it is something that might take years for people to catch catch on and you can have a an innovation or set of innovations there uh or just simply really hard problems that you've dealt with for a long time that takes takes a while to catch up to. I'll give you one example. Um, Replet, we've always wanted to build a a platform that's inherently collaborative, uh, that is really fast to start up virtual machines in the cloud that is very easy to fork and remix and do like get operations on. Uh, and so for all these reasons, we we had to build a file system. We had to build a distributed file system uh, that has one important property which is copy and write. So the idea behind copy and write is when you have a data structure um and you want to make a clone of that data structure. Typically uh you have to copy every data item to this new uh new array or new file system or what have you. Um in copy and write you say copy it says okay copied you know it lies to you but it says copied and then the moment you want to write an element it will actually copy that element and change it and then all the other elements are still maintaining references to the original sort of file system or data structure. Um and so what that unlocks is immediate like you know git forks uh and and also you know we we can have like a base uh template uh and every time we want to start a virtual machine to run you know uh ReactJS or Nex.js or whatever we can just like immediately start the virtual machine linking to the to the like one base file system that all the machines are linking to. So it just it just made the the platform a lot more collaborative and fast and all of that. Now what we're seeing in terms of uh the downstream effects on uh the kind of things we're building with agents is is really profound. For example, every time we start a test environment, that test environment is a fork of the entire environment because you don't want to test in the same environment as you're running the user's code because you end up corrupting the environment. you end up doing a lot of, you know, bad things to it. And so the ability to just like immediately fork an environment, do the test, throw away that environment, bring back the results to the main branch of the code, to the main branch of the context. Uh is is uh you know, I think it's crucial to build an experience like that. Um you can also, you know, things that are working uh we're working on down the line is parallel agents and parallel execution. For example, you have a really hard problem, you can generate, you know, five, 10, 20 trajectories. And by the way, this is how you get your sweet bench number up is is the idea of being able to sample. >> Uh, so we can we can we can fork 100 environments in 200 milliseconds and be able to sample multiple agent trajectories and then pick the the the correct one. So there's so much depth to replet compute uh and virtual machine infrastructure that we built over 10 years and I think that's a differentiator that will continue to show up. I think agent 3 is the first time that people will say holy like okay this this will take us a really long time to replicate in our sort of iframe based environments. Uh and I think agent 4 and so on will will be pretty obvious. Yeah, it's it's it's interesting because people see your ARR growth over the last, you know, year, year or so, um, and think, oh, wow, you're, you know, Replet's an overnight success, but it's it's really a 10-year overnight success. And it's very clear in the depth of the platform as you're describing, but I I want to just touch on one more thing on the competition front. I think about platform risk quite a bit and you know replet is built on top of the core maybe not built on top is the best way to describe it but it's essentially using the core models of let's say anthropic open AAI and they're building their own coding agents um coding products Google CLI sorry Gemini CLI cloud codeex how do you see or like how do you think about that risk of building on top of them when they're maybe not competing today but maybe soon we'll be competing directly with you. >> Yeah. Uh that's a very important thing. I think that's the biggest strategy question for anyone like us uh in in the market. There are two different ways of of thinking about it. One way to say it's not an immediate threat because any of those CLI products you would have to be fairly technical to understand how to use. You would have to have >> it's a different audience. >> It's a different audience. That's one. No, but it's a trap to think that they're not going to move into our space. I think they will. It's obvious, you know. So, you know, they're going to be like, \"Oh, that's that's a nice ARR you have there. Would be bad if something would add into it.\" Which is what what they looked at cursor be like, \"Oh, that's nice. Maybe we should take it.\" Um, >> yeah. And so the the other uh you know answer there is what's really interesting is they they have this fundamental disadvantage which is they're tied to their own code models. >> Uh are you watching the migration from cloud code to codeex right now? >> Yes I am. >> If you've noticed it I've I've noticed and that's what I've been sort of telling investors and others. I was like these tools the the migration path is like near zero cost is just calling a different CLI. >> There's no loyalty either. It's whatever the best cheapest fastest that is what I will be using in the moment. >> That's right. And for us we'll be like we're going to go to the best cheapest models possible. Right now Replet uses every model on the market essentially to to run uh to run our agents. The backbone is still sonet. We think it's still the best sort of agentic tool calling uh model, but we're starting to use GT5 in all sorts of places, especially GT5 thinking in terms of like reviewing code and thinking really hard about about problems is important. We're big fans of Gemini. Gemini Flash and Flash Light as like long context, cheap, fast models. We use it for for code search and all sorts of things. So that ability is is actually quite an advantage for app layer companies. >> Yeah. Okay. Um, let's let's go on to the future of software engineering. You you said something spicy and I want to bring it up. I no longer think you should learn to code, right? This this was a little while ago that you said a little while ago in in AI land. Um, do you still believe that? And and if so, maybe just speak to why that is such a strong belief. Is it is it this transition to vibe coding? >> Yeah. So, the the context I I'm typically talking to our audience, right? I I mean the the thing you start to realize as your profile grows is that there's like a lot of low context people that are going to be reading and watching your stuff. So I'm starting to kind of really try to adapt to that. But I'm talking to our audience. So who who's our audience? People who want to get done. They're not trying to be specialists. They're trying to actually build things. And if you're trying to build something, just don't worry about learning to code first. Go build it first. If you have to learn to code, you'll learn it along the way. And we we hear so many stories of Replet users learning to code just by being in it. >> Yeah. And and so just to clarify, so I I have two young kids. A few years ago, I would have said to them, the most important skill you can learn, and the most important skill I learned was learning to code because I could build things. Um, would you tell uh high school students going into college to study computer science? Would you tell uh the the person who's interested in building things to learn to code today? Or is is that like give me some nuance there. >> If if they have a gift for computers and they want to become a specialist, they should learn to code and they should go to computer science school. If they have a gift for building things, if they have a gift for being uh able to generate a lot of ideas, if they have a gift for being in having quality of being entrepreneurial, if they gift for business, then no, I wouldn't spend their time learning to code when their time could be better spent learning to build and learning to market and learning to sell. And I think those are the qualities of the future. By the way, just to give you some historical nuance the other day, I just like went through the the just like history. I'm a huge like computer history nerd. Like I I think that stuff is important underappreciated like Alan K says like computer science is pop culture because we don't really pay attention to history and you know the inventor of the compiler uh Grace Hopper and she invented you know before um before compilers before the ABC compiler uh you know people used to code in machine code um they didn't even call it coding they used to just like you rewire the machine essentially to run a certain different type of software and and and the way she described high level programming as English. She said I want people to program in English. >> Yeah. >> And the specialist will continue to exist but I want to introduce uh programming to millions of people. She's talking like a vibe coder, right? She's saying that the next hot new programming language is English. And for her, C programming looked like English relative to machine code. And it is this a constant move towards higher levels of abstraction. And getting the computer to speak more human human language is an old trend. It's nothing new. And I think every point of time you're going to see push back because the specialists fear for their jobs and they're like, I learned I put so much m time and money and it's a it's a you know understandable human response that hey you're just going to you're just going to tell people to like come take my job without like the hazing that I went through. Uh and so so that's why you get a lot of strong emotions there. >> Yeah. And and so like let's continue down the future of what the software stack might look like. I I made a video a while ago commenting on something Sati Nadella, Microsoft CEO said essentially that the application layer is going to collapse down into agents. And you said something similar. You said agents all the way down. And so let's talk a little bit about that. What does the the future architecture of the web look like when agents are all the way down? What does that look like in your mind? when I see especially enterprises using Replet uh what they're trying to do is not build software they're trying to solve problems especially in the internal tools space you know there's two primary use cases for replet one is like building products and prototyping and all of that and the others the other is um actually solving problems so what we call internal tools is ultimately I'm going to build uh this piece of software and then I'm going to use it or someone else in the organization is going to use it to solve a problem. For example, I have this workflow of getting a sales request, generating a purchase order that someone on the team was doing all the time manually. All right, let me make an application that does that. And now instead of them doing it manually, uh they're going to just like go input the things and and click generate. Well, you can go a step further. I was like, you don't even need that person to use the app. uh the agent will monitor the inbox for the you know sales sales uh kind of requests and it will run the software itself so use the software and then respond with a purchase order whatever I'm just you know making up a use case here um and you go down the line and actually I can't find that many use cases of people people building apps that couldn't be satisfied with agents and that might sound sound weird because we're selling people the idea of making apps Right. And but I do think this is a disruptive force that going to disrupt us at some point. Um and I think we want to get ahead of it. And so the um uh so we started exploring this internally. We're actually working with some governments and big enterprises. uh and we found that if we build like a very basic agent framework for them where a repular agent can create more domain specific agents sales agents HR agents what have you they'll be able to automate a lot of work >> what happens to SAS companies in in this agentic future where let's say replet is providing the agent or open AI is providing the agent agentic frameworks are providing the agents what happens to these especially verticalized SAS companies >> I I think the more point solution, the more vertical they are, the more in trouble they are. I think that the SAS companies that are um more crosscutting, more uh sort of uh they they're more like the trusted record. For example, Salesforce, it's the CRM is not going to go away. It has a huge developer community around it. uh they they can build agents as well, but you you're going to see a new industry emerge in that industry is maybe vertical agents. >> There's still there early attempts at it, you know, with you know 11x SDR agent with few other things. I don't think they're working very well, but we're going to get to a point where uh you know a company will emerge around this idea of like we're just going to build the best accountant agent possible. Replace is not not going to be able to do it or OpenI is not going to be able to do it because we're just going to hire the best uh you founder themselves might be an accountant and they're going to integrate into all the accounting systems and then we're going to sell you an agent. We're not going to sell you SAS and the business model for that is going to be interesting and I think more novel. You can't charge per seat on it because you're actually displacing seats. Yeah, >> usage based charging is interesting and for a while I thought that usagebased model might be the way to go, but I think it undersells the value of this thing. I think we're gonna go back to early enterprise software with value based uh model >> task completion kind of >> but you know you look at Palanteer I think Palanteer perhaps has a business model that's more future facing than other people than otherwise we thought it felt like Palanteer is more of like a solutions company in reality I think agents will be more like that could be task completion could be negotiated based on value created I'm not entirely sure but I'm very sure it will be value based Okay. And then if if you continue into the future looking at software, there's this potential for software to transition to fully endto-end neural networks, including the operating system. I know Elon Musk has talked about that. Do you believe that's possible? Um I I asked Satia Nadella directly about this. He thought there was always going to be a place for the traditional operating system. But what happens or first of all do you think that there's a potential to have uh endto-end neural networks for all software and then what does that world look like? >> No. And the reason I think no is because we already see it that uh neurosymbolic systems uh are better than purely neurobased uh systems. I think I think Elon is inspired by the Tesla V13 uh rewrite where they got rid of a lot of the these rules. >> The bitter lesson >> the bitter lesson. Uh but but I think what we increasingly find is >> not that you need human programmers, but that we need more deterministic environments for these neural networks to be able to write programs in. So um that that's like a really important thing program synthesis because programs are really useful tools and LLMs will find them useful as well because the idea of like us solving all of computations in in LLMs that are fundamentally sarcastic I think is is not realistic nor is I think is desirable just because we need determinism, we need correctness, we need completeness, we need uh provability and for all these reasons I think that classical computers will continue to exist that is not to say the programs will be written by humans but I think certainly LMS will continue to do program synthesis >> interesting interesting okay okay I guess we'll have to check in in in you know 15 years or so and we'll see we'll see what happens um I want to I want to talk a little bit about the future of white collar work I actually going into this interview with you I I thought I knew where you you were going to come on the spectrum of you know let's say anthropic CEO saying it's a white collar blood bath and then on the other side it's utopia and everybody's hyperproductive. So let me just ask you directly where do you fall on this spectrum of of uh where white collar work is going to end up in the next 5 years. >> Yeah I I think there's there's going to be tremendous uh disruption for sure. I think people will lose their jobs. I think not saying that is I think uh is being dishonest. I think any CEO working in the space will be able to intuitit that. Uh that being said, I I do think I don't think it's the end of jobs. Uh I don't think it's the end of work. I think uh uh those who adapt, I think those who learn how to use these tools will be still will have still tremendous value. >> Do you think there are going to be less jobs? Let's I mean let's look at replet. Let's say all of a sudden each of your engineers is 10x more productive. Are you thinking, \"Okay, then I'm not going to hire anymore. I'm going to let people go.\" Or, \"Hey, everybody's so productive. I'm actually going to double down and invest more and hire more people.\" So, where would you like how would you approach that situation in which hyperproductivity comes to replet? >> Uh, you you need to think about it through the lens of uh the communication tax. So, uh will AI solve the communication tax? So the problem is the uh uh adding people uh if it was purely um uh a creative to productivity without taking away from anything else uh then obviously you just like would hire people especially as the more productive they are you just keep adding them. uh the the problem and that's the problem with uh bigger companies is the more people the more communication issues there are the more meetings there are the the more I mean at some point a lot of companies end up you know hiring people and taking away from productivity um will AI solve that and I think that's a big question like will AI solve the communication bottleneck and if it did then yeah companies will expand until like they're able to cover every piece of the mark part of the market they're able to to kind of in. Uh but if not, then they're going to be always kind of limits to how many people you want to add. And then you want to actually constrain your growth and you want to uh you want to be able to to to just keep the the the most productive people possible because in that scenario, uh letting people go is is probably more accurative to productivity because then you can just focus your best people on doing their their best work. So So I think it's uncertain. I I don't think it's quite known yet whether um what what the answer to this question is. >> Yeah, it's interesting. I I spoke to Aaron Levy, Box CEO, and and he, you know, put it plainly. If I have one team that's using AI and they become incredibly productive and my the ROI and the dollars spent on that team come back 1000fold, why wouldn't I either double down the investment on that team or build out similar small parallel teams just like that? >> Yeah. I mean I mean again you run into to limits of organizations. uh that team will have a headcount limit where things will start gettinga chaotic and then let's say you add more teams like that there's going to be an organizational limit uh on how collaborative these these teams are. So the these are these communication limits that I don't think people are really thinking thinking about and I think it sounds good that like okay if I can supercharge my employees with AI then can add endless amounts of employees and still get the same benefit. Uh I remember uh when we first started scaling replet uh employees headcount so I I had this measure where it's like the best way I can get an idea for our productivity is um number of per requests uh uh per per capita right so how many close per per request does an engineer do average um and as we're adding people there there was a point where we're uh where the growth growth in per quests were super linear. So it was like actually accelerating. Um and then at some point it became uh sublinear. So we we need to add ever more people to get an additional person of productivity that we added you know a few months before. And when I looked at it it was clear that we have these communication bottlenecks and these organizational bottlenecks. And often time you do reorgs and you change the culture or how you work and and things will get better. Uh but a lot of times it is just like almost like a natural law of of how humans are able to work. You know we have these Dunbar numbers and a lot of uh you know things that anthropologists have have observed over time. And so I think it's it's worth thinking about these things. It's interesting. Maybe that's where there are markets to be created with AI solving some of these communication tax issues. I hadn't thought of that. That's a really interesting point. >> So, there's this this interesting economist, I think his name is uh Tom Co, and he he he uh he came with this idea of like the theory of the firm. Um, and the idea behind the theory of the firm is like, um, what is a full-time employee really? Like if if a firm can go out to the market and get that service done in the market, why would you need to hire someone? In in essence, a full-time employee is a bug, not a feature of capitalism. In a truly efficient market where the transaction cost, which is the bottleneck, is really low. you would go out to the market to do to get anything done, right? And anytime you're hiring someone, the market has failed you, you know, I mean, obviously there's a lot of new nuance, but it is a very compelling idea. And so I think thinking through that lens maybe that doesn't mean that uh you know companies are are expanding very quickly because you can add hyperproductive AI people but it might mean that there's a lot more freelancers a lot more entrepreneurs on the market either offering their services or offering their agents that they imbued with very specific domain knowledge uh that they're able to hire and rent out and and maybe the the maybe the the the the sort of the company, the person of the company contracting out to that agent is not even a person, it's another agent. So perhaps that is the the economy of agents as well. >> Okay. So let let's continue on that for a second. I'm sure you've seen these the the memes about the permanent underclass, right? Lock in for the last uh you know x number of months before you get consigned to the permanent underclass. Do do you believe that's going to be a thing when AGI comes? I mean it's it as you're describing this um this kind of economic landscape it it sounds like it was heading in that direction but I maybe give you a chance to to comment on that. >> There's there's two things there's uh you know inequality uh which is a problem and and there's also another important thing is is economic dynamism. The interesting thing is um you know people will say that America is has more inequality than than Europe. Uh I think Nasim Talib kind of shared these numbers like a while back and shared um thoughts about this is if you look at America there's a lot more economic dynamism. So the top uh 10% actually circulate very very quickly. So people get rich and then they're not rich anymore or you know they they die off and the next generation are not as rich for various reasons and then new kind of rich kind of emerge and you see that happening very quickly and that is a sign of a market that's truly meritocratic and I think from an ethical perspective I think that's more important than um distribution of uh of resources because I think that gets into also the problem that we've seen with communism and socialism. and all that stuff. So I think that's the metric that I would look at. Uh does it make it so that uh the rich will continue to ever more be richer? It is impossible for you to get rich. Is that the case? I don't think it's the case right now. I think since AI arrived on the scene, it's never we have more equal opportunity than ever for people to be able to improve their economic situation thanks to AI. So far that's not the case, but AGI might change that. Yeah, I think I think the context is once AGI happens, once AI is better than all humans at any cognitive task, then capital is the only thing that matters because it's effectively your ability to leverage that AGI and and so if you don't have capital, you can't leverage AGI and thus stuck in in the permanent underclass. I would question the the premise perhaps like that that might be a detour but like what what are the limits of of of AI and and AGI? Is there anything um special about humans? Um and I I believe there's something special about humans. Um I think the way we do AI today is that AI uh is good at things that's already been done. It's not very good at things that's never been done. I think human ingenuity is better at things that's never been done like truly generating new ideas. Will that continue to be the case? I think it's a philosophical question. I think it gets into the question of of consciousness. Uh perhaps religious beliefs as well. I don't think I think Silicon Valley takes it for granted that like that human consciousness is replicable or human level intelligence is replicable in the machine. I don't I think it requires some intellectual humility to know our our our limits of understanding of of reality and and and and the world. And I think we're sort of early in our understanding of of reality. I think it is hubris to think that we've we've sort of we know everything and we're able to build these these we're able to build the the most magnificent thing possible in in machines. And by the way, if you look at the if you talk to some of the AI researchers, like more traditional AI researchers, they don't think that LMS are is even intelligence. Um, >> yeah, >> I I might disagree with that a little bit, but there's some truth to the idea that uh LMS are like really fancy compression machines that we're putting to use in all sorts of interesting ways, but they lack the very important crucial uh property of being able to efficiently learn on the fly. I I think it's it's like an hour-long discussion that we can have, which I'm willing to have, but but I I I just like I wouldn't take the premise just as a as a done deal. >> I I like the question that you pose, which is is there something fundamentally special about humans? And if if the answer is yes, then the pre you're right, the premise of AGI equals permanent underclass pretty much goes away. Um so yeah, I I can appreciate that sentiment. Um I want to maybe you can just speak briefly. This is uh I I I I wonder what it was like during your let's say 10 night overnight uh 10-year overnight success, right? All of a sudden you release this agent product and you go from what took 10 years to reach I I believe the number was 10 million ARR and then in like the next 6 months you correct me if these numbers are wrong. You you hit 100 million. What was it like internally? What was the feeling? I I I think that um companies before commercial success rely on uh collective delusion uh in a way and I think you want to embrace that because like just the act of creating startup is sort of an irrational belief in in oneself or in in in the team. And what bounded us together is this mission that anyone can program, that anyone can create software. And everyone that came to work at Replet really really believed in that. And um and uh actually the first time I felt like that that dream that bubble was was kind of popped is when we did a layoff in 2024 because in 2024 we we've we we were burning a lot of money. Um we've we've tried a lot of things to commercialize the platform, but we weren't growing revenue fast enough. I knew that agents was the thing to get to to for the company to kind of take off. We needed to we need to again lower the barrier entry even more so we get access to more and more more people that want to make software. Um and then after we did that it was a very dark time like in summer 2024 because everyone suddenly was faced with actual reality that hey like you know that the dream is is there but it's not happening. How long is it going to take to happen? uh is it is it another 10 years like I don't have another 10 years in me like we've been working really hard and a lot of people started leaving so we did the layoff and then like even more people left and so we're like 130 people then we got down 60 people now the interesting thing about it is that there's a group of people we call the agent task force at the time that we're tasked with like you know uh we got to we got to succeed in building an agent because that's the thing that's going to save the And when we launched it in September and the revenue immediately grew, there was still disbelief actually people continued to leave uh at the time because ah it's like not working which is weird and I kept telling them look I don't think we appreciate what we've built here and I don't think we appreciate where the world is headed like >> and then that again that you it was a very interesting uh filter because the the true believers were left of the company and uh and and and those believers not only thought that we're on the right track and everyone still thinks that we're we're not even we just got started like it's going to be so much more magnificent what we're going to be able to build and the kind of value that we're going to be able to deliver to to to the world. Um and and so there was like a there was another dream that that was brewing and and and that was growing. Um now now that I think that the quality that I've been trying to build in myself and by extension of the company is actually feeling is not focusing on what's on the problems or what's going wrong and and actually celebrating because you know I'll tell you that you know I it like I've become so stoic that the bad things or the good things do not affect me anymore and I'm so focused on the future in what's possible and how far we can take this that you know whatever happens I just don't care. I'll just like keep the the the kind of the driving force is I'll just keep going because the prize is still really in the future. But recently I've been reflecting and I was like we need to celebrate and we need to talk about what we've been able to build and and and and so the the feeling as of the past couple of months in the company have been the morale is super high. Everyone's super excited. everyone's working really hard, but it feels effortless because it it really feels like we're achieving something and doing something good for the world. >> Yeah, that that's amazing. Um, thanks for sharing that story. I I'm so appreciative of what you're building because first of all, I love builders. You're a builder, but you're building something that allows builders to go build. So, I'm like doubly appreciative. And thank you so much for your time today, Amja. This has been a pleasure. >> Of course, Matthew, it's been my pleasure. And it's been amazing to also watch your rise. Like uh I don't know where you came from, but all of a sudden I'm seeing interviewing all these CEOs and your your show has been really great. I uh yeah, really appreciate it. It's it's one of the one of the best shows that's come out uh recently. >> I I thank you. That means a lot. Thanks, Amod. Um and uh we'll talk again soon hopefully. >> My pleasure. Yeah. All right.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Visão de Amjad Masad sobre vibe coding: tornar a programação mais acessível, automatizar o máximo possível e usar agentes de desenvolvimento para levar ideias rapidamente à produção.",
            "resumo": "O vídeo apresenta a visão de Amjad Masad sobre vibe coding, uma abordagem de programação mais acessível que reduz a fricção entre ideia e código. Replet evoluiu de ambientes de desenvolvimento para implantação, e agora foca em agentes autônomos de desenvolvimento, especialmente o Agente 3, que podem criar, testar, refatorar e gerenciar tarefas como se fossem colegas engenheiros. A ideia central é empurrar a automação até o limite das capacidades tecnológicas atuais para que pessoas com ideias possam construir rapidamente sem dominar toda a codificação tradicional. O bate-papo compara vibe coding com a codificação tradicional, discute o progresso da plataforma, casos de uso e referências relevantes, como André Karpathy e Yohei, e aponta para um futuro onde software é criado com maior apoio de IA e automação.",
            "assunto_principal": "Vibe coding, agentes de desenvolvimento autônomos e o futuro do design de software com automação e IA.",
            "palavras_chave": [
              "codificação de vibe",
              "agentes de desenvolvimento",
              "Agente 3",
              "Replit",
              "automação de software",
              "IA na codificação",
              "desenvolvimento acessível",
              "teste automatizado",
              "refatoração automática",
              "casos de uso",
              "André Karpathy",
              "Yohei"
            ],
            "resumo_em_topicos": "Contexto\n- Amjad Masad discute o vibe coding como forma de tornar a programação mais acessível e reduzir a fricção entre ideias e código.\n\nConceito-chave\n- Diferença entre ideias e o trabalho tedioso de programação; o objetivo é automatizar o máximo possível dentro das capacidades atuais.\n\nProgresso da Replit\n- Evolução do ambiente de desenvolvimento para implantação e, agora, agentes autônomos de código (Agent 3) que podem criar, testar, refatorar e gerenciar tarefas.\n\nAgentes e visão\n- O Agent 3 atua como um colega engenheiro; pode testar código, executar cenários, revisar e refatorar.\n\nComparação com codificação tradicional\n- O vibe coding reduz as barreiras; a automação é levada o mais longe possível com a tecnologia atual.\n\nCasos de uso e referências\n- Menciona André Karpathy, Yohei; exemplos de experimentação com agentes.\n\nFuturo\n- O objetivo é transformar a forma como o software é criado, aproximando ideias da produção com o suporte de IA.",
            "prompt_tokens": 1879,
            "completion_tokens": 2890,
            "model": "gpt-5-nano",
            "cost": 0.0053
          },
          "analysis_time": 85.17253398895264,
          "language": "",
          "view_count": 11951,
          "has_transcript": false
        },
        {
          "id": "uVDaNvKUOtM",
          "title": "This Anthropic Settlement is massive...",
          "title_pt": "Este acordo da Anthropic é enorme...",
          "url": "https://www.youtube.com/watch?v=uVDaNvKUOtM",
          "published": "2025-09-10T01:02:09.070744",
          "published_relative": "há 11 dias",
          "duration": "11:17",
          "date_published": "2025-09-09T12:43:01-07:00",
          "transcript_available": true,
          "transcript": "Anthropic, the company behind Claude, faces at least a $1.5 billion settlement for their copyright infringement. If approved, this would represent the biggest copyright settlement in history and really has major implications for artificial intelligence going forward. So, what happened? What did they do? Did they do it intentionally? And what does this mean for the rest of the industry? Let's get into it. And this video is brought to you by Sokumi. More on them later. So here is the case document. As you can see here, we have the plaintiffs and anthropic public benefit corporation, the defendant. The first sentence, the largest publicly reported copyright recovery in history, larger than any other copyright class action settlement or any individual copyright case litigated to final judgment. This is massive. And so here's the gist of what happens, but I'm going to dive into the details. Anthropic took pirated books that they thought would be fair use and used it to train their models. Turns out it wasn't fair use according to the judge. It will set a precedent of AI companies paying for their use of pirated websites like Library Genesis and Pirate Library Mirror. So basically, if you're an AI company, you're using a pirated website that is not free use. And listen to how severe this is. Anthropic's use of pirated material inherently irredeemably infringing. There is no doubt in the judge's mind they did something wrong here. And the plaintiff's core allegation is that Anthropic committed largecale copyright infringement by downloading and commercially exploiting these books from allegedly pirated data sets. So the breakdown is they downloaded books from pirate websites without permission. They did that to obtain a huge amount of training data for their claude family of models. Now, Anthropic argued it was fair use, but the court rejected that argument. And how did they even find out? Well, the plaintiffs figured it out through discovery. They had a sense this is what's happening. And they went into discovery and looked in the data set and yes, there it was. Over the course of the case, plaintiffs took and defended 20 depositions, reviewed hundreds of thousands of pages of documents, conducted inspections of at least three terabytes of training data. That is not a small task. So the depositions, the data set inspections and metadata tracing tied anthropics data set back to those illegally downloaded book data sets. And because of that, they are going to have to pay at least $1.5 billion. That is a massive amount. And for context, Anthropic literally just raised a ton of money. And in fact, all of the investors likely knew about this settlement. So they just raised $13 billion series F at a $183 billion post money valuation. So at least 1.5 billion of that is going straight into the plaintiff's pockets. But of course, the investors don't care. They just see that as the cost of doing business, I suppose. But it's not over. Anthropic doesn't just get to have that data and have the models. It goes a little bit deeper than that. But first, let's get into the details of the payment. On a per work basis, the settlement amount is four times larger than $750 statutory damages amount that a jury could award and 15 times larger than the $200 amount if Anthropic were to prevail on its defense of innocent infringement. And here's how they have to pay. 300 million due within five business days after the court's preliminary approval order. 300 million due within five business days after the court's final approval order. 450 million plus interest due within 12 months of the court's preliminary approval. So they are also paying interest which amounts to above $100 million. continuing 450 million plus interest due within 24 months and the interest earned by the time of Enthropic's final payment may be as high as 126.40 million. And let me just pause for a second and thank the sponsor of today's video. Finally, we have an AI agent marketplace that makes sense. Soosumi just launched and it is your place to hire your next AI agent teammate. So, if you're building or hiring AI agents, listen to this. SOSUMI is easy to use and solves real problems. You can set up company accounts and instantly deploy AI agents for your business and instantly deploy highquality AI agents for your enterprise. And if you're a builder, you can build AI agents and monetize them by selling them to other enterprises. And you can be an indie coder or enterprise developer to do so. And here's what makes Soukumi special. It is completely agnostic. OpenAI, Gemini, Mistral, whatever LLM you want to use, it'll work. And you can also use the frameworks that you're already familiar with from Langchain to Crew AI and any other orchestration or tool that you want to use. Plus, it is fully open source, which you know, I love. So, you get all the transparency you want. And every agent already uses MCP through the Msumi protocol. This is the marketplace for AI agents at scale. So register at sookkosumi.com and get 200 starting credits right now. Use the code in the description below. So if you're building agents, managing agents, definitely check this out. Let me know what you think of this and let me know how it helps your business. Thanks again to Soassumi. Now back to the video. Now this is not a small amount of books. That is why these settlement amounts are so large. Listen to this. If the works list ultimately exceeds 500,000 works books, then Anthropic will pay an additional $3,000 per work that Enthropic adds to the works list above 500,000 works. The 1.5 billion is the minimum size of the settlement. And by doing the settlement, they get a release. But the release is restricted in itself. Listen to this. The release is limited in three critical respects. First, the release extends only to past claims and does not extend to any claims for future reproduction, distribution, and or creation of derivative works. Of course, that makes sense. If they continue doing the bad thing, they will continue to get dinged for it. Second, the release does not pertain to output claims at all. So, imagine this. You've trained your model. you don't have to destroy the model, but if the model reproduces work from one of those books near verbatim, they will get sued again. And third, the settlement only releases claims for works on the works list. And so if one of the plaintiffs owns multiple works and only one of the works is on the list, another one is not, they're not liable for the one that is not, at least not yet. That's a separate claim. Now, here's the interesting bit. Anthropic must destroy the pirated books, the files, any copy of those files, and make sure that there's proof that they destroyed it. Here, Anthropic has committed to destroy the data sets within 30 days of final judgment. So, this really prevents Anthropic from reusing those copyrighted works, but Claude remains trained. You cannot untrain it from a specific part of the data set. And lucky for Anthropic, they didn't make them destroy the model and create it again. That would essentially sink Anthropic overnight. All right. So, who's actually going to get paid here? All beneficial or legal copyright owners of the exclusive right to reproduce copies of the book in the versions of LibGen or Palei downloaded by Anthropic. And here's the thing, this wasn't accidental. Anthropic intentionally downloaded these pirated books thinking that it was actually fair use, but it wasn't. And why did they do that? Well, of course, to save a bunch of money. Imagine Anthropic having to purchase the rights to all 500,000 books. It would have been insanely expensive. But they're not the first ones to do this. Google Books was a project that Google had obviously where they went out, bought used copies of books, scanned them, and then put them online for free. And that was completely legal because they didn't download pirated versions for free. They went out and actually purchased the books. Now, whether or not they were reproducing the books for commercial purposes, which I'm not a lawyer, but I believe is part of the fair use or not fair use determination is up for debate. Google wasn't charging for the books as far as I remember, but just getting more eyeballs to Google, it definitely benefited them. All right. And where do we go from here? The settlement is not final yet. They still need preliminary approval. Then the notice goes out, then the final approval hearing, and then payments start only after that. All right. So, what's the bigger picture here for AI? This is definitely sending shock waves through the AI industry. And again, let me go back to this quote. This settlement will set a precedent of AI companies paying for their use of pirated websites like Library Genesis and Pirate Library. This settlement would also be the first major recovery in any of the copyright actions pending against large AI companies nationwide. Remember, the New York Times is, I believe, still suing Open AI for similar reasons. Now, this is all a fair use argument, and it's really going to change the economics of building a foundation model. If fair use becomes more difficult to argue, these AI companies are going to have to pay a lot more to train their models, and that's going to have downstream effects to all of us, the consumers of these models. So, we're going to see a shift away from these gray market data set acquisition paths, and we're going to see much more licensed data being used. And we're also going to see probably price increases for really valuable, important, and legal data sets. Think Reddit, Twitter, all of the userenerated content, New York Times, Washington Post, all of the publishers out there. These works will become just so much more valuable. AI model companies will also spend a lot more money looking through the data sets and making sure that the data sets are all legal. And even a single work didn't make it accidentally into a data set that they acquired legally. This also puts more risk on the investor's plate because they're plowing money into these AI companies. But if there are these multi-billion dollar settlements ahead and it all of a sudden becomes so much more costly to build these models, investors have to do different calculus to make it make sense for their ROI. So in closing, Anthropic definitely acquired these books illegally. They did so thinking it was fair use. It was judged that it wasn't, and now they're paying the biggest settlement of all time for a copyright claim. Let me know what you think in the comments. And once again, thank you to SooSumi for sponsoring this video. Links down in the description below. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Resumo em uma frase: o vídeo descreve o acordo de pelo menos US$ 1,5 bilhão com Anthropic por treinar Claude com obras piratas, rejeitando o fair use e estabelecendo um precedente sobre uso de dados pirateados na IA.",
            "resumo": "Este vídeo analisa o acordo colossal envolvendo a Anthropic, criadora de Claude, com uma soma mínima de US$ 1,5 bilhão por uso de obras piratas para treinar seus modelos. A corte rejeitou a alegação de fair use, demonstrando que o download e a exploração comercial de livros de sites como LibGen e Pirate Library Mirror constituem infração de direitos autorais. O caso foi descoberto por meio de descobertas legais, com 20 depoimentos, centenas de milhares de páginas de documentos e inspeções de terabytes de dados de treinamento que ligam o conjunto de dados às obras pirateadas. O acordo prevê pagamentos escalonados, com multas por obra além de limites, e exige a destruição das cópias piratas após o julgamento, embora o modelo permaneça treinado. O episódio cria precedente para IA e direitos autorais na indústria.",
            "assunto_principal": "Acordo de mais de US$ 1,5 bilhão contra Anthropic por uso de obras piratas para treinar IA, definindo precedentes sobre fair use e dados de treinamento de IA.",
            "palavras_chave": [
              "Anthropic",
              "Claude",
              "direitos autorais",
              "acordo",
              "pirataria",
              "uso justo",
              "treinamento de IA",
              "dados de treinamento",
              "Biblioteca Gênesis",
              "Espelho da Biblioteca Pirata",
              "descoberta",
              "depósitos",
              "precedente"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto do caso: acordo de pelo menos US$ 1,5 bilhão envolvendo a Anthropic pela violação de direitos autorais ao treinar Claude com obras piratas; estabelece precedente sobre uso de dados pirateados na IA.\n- O que aconteceu: Anthropic baixou livros de sites piratas (LibGen, Pirate Library Mirror) para treinamento; a corte rejeitou fair use.\n- Processo: descoberta revelou o dataset; 20 depoimentos; centenas de milhares de páginas; inspeções de terabytes de dados que ligam o conjunto de dados às obras pirateadas.\n- Pagamento e termos: estrutura de pagamento escalonada; 300 milhões no imediato após aprovação, 300 milhões após aprovação final, 450 milhões + juros em 12 meses, 450 milhões + juros em 24 meses; adicionais por obra acima de 500 mil; juros podem totalizar dezenas de milhões.\n- Limitações do release: cobre apenas alegações passadas, não cobre futuras, não abrange saídas, só obras listadas.\n- Destruição de dados e impacto no modelo: Anthropic deve destruir cópias piratas e datasets em até 30 dias após julgamento; o modelo treinado permanece.\n- Beneficiários: proprietários de direitos das obras na lista; obras não listadas não liberadas.\n- Implicações para a indústria: cria precedente para IA e direitos autorais, desencoraja uso de dados pirateados, reforça necessidade de licenças; comparação com o Google Books.",
            "prompt_tokens": 1829,
            "completion_tokens": 5791,
            "model": "gpt-5-nano",
            "cost": 0.0096
          },
          "analysis_time": 62.86781167984009,
          "language": "",
          "view_count": 26719,
          "has_transcript": false
        },
        {
          "id": "xGO5Q94XXf0",
          "title": "Did OpenAI just solve hallucinations?",
          "title_pt": "OpenAI acabou de resolver as alucinações?",
          "url": "https://www.youtube.com/watch?v=xGO5Q94XXf0",
          "published": "2025-09-09T01:02:09.070759",
          "published_relative": "há 12 dias",
          "duration": "13:13",
          "date_published": "2025-09-08T08:18:04-07:00",
          "transcript_available": true,
          "transcript": "Open AAI may have just solved hallucinations. They just put out a paper which identifies the root cause of hallucinations and a potential way to fix it. And when you hear the reason why models hallucinate, it's going to be super obvious in retrospect. And this video is brought to you by notion. More on them later. So, here's a paper just released a couple days ago, why language models hallucinate. I'm going to break down everything you need to know about it. According to the paper, language models are known to produce overconfident plausible falsehoods which diminish their utility. So if a model confidently gets something wrong, it is hard to trust that model. And so where in the creation of a new LLM, where in that process do these hallucinations actually come from? Well, we have to assume in the immense corpus of training data used to train these models, there has to be some inaccuracies. There has to be some mistakes. And here's the thing, even if you had perfect data, meaning not a single thing wrong in the entire data set, which again isn't even possible, that alone wouldn't be enough to prevent hallucinations. According to the paper, the distribution of language is initially learned from a corpus of training examples, which inevitably contain errors and halftruths. However, we show that even if the training data were error-free, the objectives optimized during language model training would lead to errors being generated. So, here's the key phrase, the objectives optimized, meaning how the model is being told whether it's getting something right or wrong or this is a good response versus a bad response. That's where the problem lies. That's where the hallucinations come from. And an interesting thing they point out in this paper is that generating valid responses is actually more difficult than figuring out if it is a valid response or not. Imagine you're given an answer and you're asked, \"Is this valid or not valid?\" That's usually pretty easy to answer. But now imagine if you're asked to produce the answer yourself. That is much more difficult. That's what they've pointed out in this paper because you not only have to produce the right answer, you have to avoid all the potential wrong answers which could be unlimited. Essentially, there are far more wrong answers than there are right answers. And thus, it is much more difficult to produce a right answer than to determine if an answer is right or wrong. And actually, if you think about how you probably use LLMs, that makes a lot of sense intuitively. How many times have you prompted an LLM, gotten an answer back that was clearly not correct, and then you simply said, \"No, that's not right. Fix it.\" And then the model in return said, \"Oh, you're absolutely right. Let me fix it in this other way.\" That's also why multiple agents working together typically produce better results because an agent reviewing the answer of another agent is much better than just having an agent produce one answer the first time. And so why does this matter? It actually shows that hallucinations are baked into the way models are built today. They're not just bugs, they're features. But does that mean we have to live with hallucinations? Does that mean they're inevitable? No. And you know what's not a hallucination? How awesome the sponsor of today's video is. I'm so excited to tell you about the sponsor of today's video, Notion, which I have been using for so many years. And now they have just launched Notion AI for work. It is a suite of AI tools built into your notion workspace. So, first they have AI meeting notes. Notion will automatically detect that you're in a meeting, start taking notes, of course, with your approval, and then at the end will summarize the notes and send you follow-up items as well. It also has research mode. It's exactly what it sounds like. It is deep research except now it has access to all of your documents inside of Notion. And you could chat with your favorite models like the latest open AI models and the latest anthropic models directly from notion. And the best part, it is unlimited usage when you have notion AI. So give notion a try. I personally love it. My team loves it. We use it for everything. So I highly recommend it. So get started with notion AI. I'm going to drop the link down in the description below and I'm also going to put it right here on the screen. So thanks again to Notion. Now back to the video. An example of an area of information which models get wrong often, they hallucinate often is birthdays. If a model sees a person's birthday once in the training set, it's not going to be able to remember it. And so if you ask later, hey, what was that person's birthday? It's probably going to guess. Listen to this. If 20% of birthday facts appear exactly once in the pre-training data, then one expects base models to hallucinate on at least 20% of birthday facts. Okay. So then what happens after pre-training? Well, we have post-training. And at that stage, we should be able to catch hallucinations. That's actually where a lot of the industry tries to make the models hallucinate a lot less. The second stage, post-training, refineses the base model, often with a goal of reducing hallucinations. But why don't the models just say, \"I don't know.\" rather than trying to guess. It turns out it's kind of very similar to what humans do on multiplechoice tests. Think about it. If you have a multiplechoice test and you don't know the answer, you have a higher likelihood of getting it right by just guessing. Let's say there's four potential answers. You guess one of them, you have a 25% chance of getting the answer right. But if you abstain from answering, if you just say, \"I don't know.\" and don't even attempt it, you are guaranteed to get a zero. And that is the crux of why models hallucinate. Here it is in the paper. When uncertain, students may guess on multiplechoice exams and even bluff on written exams, submitting plausible answers in which they have little confidence. Yeah, certainly it makes no sense to leave a multiplechoice question unanswered. In both settings, guessing when unsure maximizes expected score under a binary 0ero to one scheme that awards one point for a correct answer and none for blanks or I don't knows. And when you bluff, the bluffs are typically very specific. You're trying to give a specific answer rather than giving more handwavy guesses at an answer. Here's an example. Bluffs are often overconfident and specific such as September 30th rather than sometime in autumn for a question about a date. Again, because the evaluation, the feedback mechanism for models rewards no points for guessing rather than trying to give a very confident specific answer that is wrong. Many language model benchmarks mirror standardized human exams using binary metrics such as accuracy or pass rate. Here's an important part. Humans learn the value of expressing uncertainty outside of school in the school of hard knocks. I don't know why they use that phrase, but fine. Basically, it looks really bad if you confidently give wrong answers often. But if you say I don't know or if you try to roughly guess at an answer, you are actually more highly rewarded in the real world. And so let's stop for a second. The ultimate problem, the ultimate reason models hallucinate is because we have no way to tell them good job for saying I don't know and good job for roughly guessing in the right area. We just haven't been doing that to date. But can we? First, an assertion that they use in this paper is that hallucinations are inevitable only for base models. Many have argued that hallucinations are inevitable. However, a non-h hallucinating model could be easily created using a question answer database and a calculator which answers a fixed set of questions such as what is the chemical symbol for gold and well-informed mathematical calculations such as 3 + 8 and otherwise outputs I don't know. And this is the key. If it knows the answer, great. If it doesn't, just say you don't know it. And so the very simple solution put forth by this paper is answer only if you are above a certain threshold of confidence. Let's say 75%. Only answer if you are greater than 75% confident. Otherwise say I don't know. And yes you can post-train the model to do that. Look at the current evaluations also. GPQA, MMLU Pro, Wildbench, Math, Swebench. These are all benchmarks that you know if you've watched this channel at all. And look at this. Do they have binary grading? Almost all of them do. The only one that doesn't is Wildbench. And do any of them give I don't know credits? Again, the only one that does is Wild Bench. So, it's kind of a two sides of the same coin problem. During the post- training, models are rewarded only for getting the answer right. and they're penalized for wrong answers. They are also penalized for saying I don't know. And then on the flip side, when run against the evaluations, the evaluations are doing the same exact thing. The models then understand that the best strategy isn't bluffing. It isn't hallucinating. It is giving the right answer or saying, \"I don't know.\" They call this in the paper behavioral calibration. Rather than just checking the probabilities of the answers, you're checking the probabilities, but it's also looking at a certain threshold of confidence. So at 50% confidence, are the answers right half of the time? And at 90%, are they right nine times out of 10? And that's how you test if the model is behaving honestly. All right, so let's look at figure two because this shows what happens with reinforcement learning. It's actually possible for base models to be pretty well calibrated, but then the reinforcement learning pushes them in the wrong direction. Check this out. So on the left side, we have a base model. On the y ais we have the accuracy of the model and on the x-axis we have the predicted confidence. And when these two things line up along the dotted line, that's a good thing because when it says I'm 70% confident, it should get it right 70% of the time. When it says 30% confident, yes, it should get it right 30% of the time. But then look what happens after reinforcement learning, which is teaching it to bluff. All of a sudden, we have a very different graph. The model might think it's 80% confident, but get it right much fewer. Let's say 45% of the time. Reinforcement learning is pushing the model to be more helpful, more decisive, and sometimes more confident than it really should be. And even with reasoning, with search, rag, all of these tools, which can certainly help hallucinations, the hallucinations are still there. So, it really needs to be solved at reinforcement learning time. And we also need to fix the evaluations of the models. All right, so let's break it down. How do we fix this? If you are a benchmark creator, you should be adding confidence thresholds. You should also be rewarding, abstaining from answering the question if the model doesn't know. An example, give a plus one for a right answer, a zero for an I don't know, and a negative score for the wrong answer. So, you're penalizing the wrong answer, but you're neutral on I don't know. And it turns out GPT5 is actually starting to do that already. Check this out. This is from a Twitter user. Cole GPT5 says, \"I don't know. Thought for 34 seconds. Short answer, I don't know, and I can't reliably find out. Wouldn't you rather see that than a hallucination?\" Even Elon Musk said, \"Yeah, that's an impressive response.\" And that is the right response. And it's funny because this isn't the first time we've heard of this. Anthropic put out a paper a few months ago talking about a lot of new ways that they discovered that models work internally. And one of the things that they talked about is why hallucinations happen. They said these models essentially have momentum. They want to give a full and complete answer. They want it to be grammatically correct. They want it to be syntactically correct. They want the spelling to be correct. And once they start responding to a prompt, it's let's say painful for the model to stop responding or to change their response mid response. So they have this momentum. And the anthropic paper talked about the symptom of hallucination, but they didn't actually come to the cause of hallucination like the OpenAI paper did. So, it's interesting to see how both of these companies attacked the hallucination problem from both sides. Hallucinations come from pre-training because generating the right response is much harder than checking if it's correct. Post-training keeps the hallucinations alive because benchmarks reward bluffing. not saying I don't know. So, the answer, we need to fix how we grade these models. We need to fix how we do reinforcement learning. And once again, thank you to Notion for sponsoring this video. Links for Notion down in the description below. Check them out. I found this fascinating. Hopefully, you did, too. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Um artigo recente argumenta que as alucinações em modelos de linguagem decorrem principalmente dos objetivos de treinamento e da pressão para fornecer respostas plausíveis, não apenas de dados imperfeitos, oferecendo caminhos de mitigação.",
            "resumo": "Neste vídeo, o autor comenta um paper recente que afirma que as alucinações em modelos de linguagem não vêm apenas de dados imperfeitos, mas principalmente dos objetivos de treinamento. Mesmo com dados perfeitos, as métricas que avaliam se a resposta está correta incentivam respostas plausíveis e com confiança, levando à produção de erros. É mais difícil gerar a resposta certa do que apenas julgar se ela é válida. Em avaliações binárias, adivinhar supera abstinência; por isso bluffs específicos costumam vencer respostas incertas. O vídeo discute que alucinações são, em grande parte, uma consequência do design atual, não apenas bugs. Propõe caminhos de mitigação, como bancos de perguntas com respostas fixas ou ferramentas (ex.: calculadora) para reduzir erros. Também aborda pós-treinamento, casos como birthdays, e a necessidade de recompensar dizer 'não sei'.",
            "assunto_principal": "Alucinações em modelos de linguagem e suas causas no treinamento, avaliação e mitigação",
            "palavras_chave": [
              "alucinações",
              "modelos de linguagem",
              "modelos de linguagem de grande porte",
              "dados de treinamento",
              "objetivos de treinamento",
              "avaliação binária",
              "não sei",
              "adivinhação",
              "blefes",
              "pós-treinamento",
              "mitigação",
              "ranking de respostas"
            ],
            "resumo_em_topicos": "### Visão geral\n- O estudo discute por que LLMs alucinam e afirma que isso vem dos objetivos de treinamento, não apenas dos dados.\n\n### Causas das alucinações\n- Mesmo com dados perfeitos, a tarefa de gerar a resposta correta é mais difícil do que julgar validade.\n- Avaliações binárias incentivam adivinhação e blefe, levando a respostas específicas e erradas.\n\n### Implicações\n- Alucinações são, em grande parte, uma consequência do design atual, não apenas bugs.\n- Dados de avaliação que privilegiam acurácia podem favorecer respostas não confiáveis.\n\n### Mitigações propostas\n- Bancos de perguntas com respostas fixas.\n- Utilização de ferramentas como calculadoras.\n- Incentivar o modelo a dizer “não sei” quando inseguro.\n\n### Observações adicionais\n- O pós-treinamento busca reduzir as alucinações.\n- Exemplos como fatos de aniversário ilustram a fragilidade do armazenamento de dados específicos.\n- Menção ao patrocinador Notion AI, presente na apresentação.",
            "prompt_tokens": 1800,
            "completion_tokens": 3633,
            "model": "gpt-5-nano",
            "cost": 0.0063
          },
          "analysis_time": 45.76621103286743,
          "language": "",
          "view_count": 123185,
          "has_transcript": false
        },
        {
          "id": "axLs1urvr3o",
          "title": "AI News: xAI Sues OpenAI, Microsoft's MAI, Anthropic Funding, OpenAI Acquisition, and more!",
          "title_pt": "Texto: Notícias de IA: xAI processa a OpenAI, MAI da Microsoft, Financiamento da Anthropic, Aquisição da OpenAI e muito mais!",
          "url": "https://www.youtube.com/watch?v=axLs1urvr3o",
          "published": "2025-09-07T01:02:09.070774",
          "published_relative": "há 2 semanas",
          "duration": "15:26",
          "date_published": "2025-09-04T10:46:47-07:00",
          "transcript_available": true,
          "transcript": "Elon Musk and XAI are suing a former employee for allegedly taking secrets and going to OpenAI. According to Reuters, Musk's company said in the complaint filed on Thursday in California federal court that Shuchin Lee stole confidential information related to cutting edge AI technologies with features superior to those offered by Chad GPT to bring to his new job at OpenAI earlier this month. This is just one of a number of lawsuits between Musk and OpenAI/Sam Alman. Obviously, given the history between Sam Alman and Elon Musk, Elon is very sensitive about leaking any secrets to OpenAI and really anything OpenAI is doing. Here, the article continues, \"The new lawsuit said Lee began working as an engineer for XAI last year, where he helped train and develop Grock. The company said Lee took its trade secrets in July shortly after accepting a job from OpenAI and selling $7 million in XAI stock. And Elon even replied with he accepted an offer at OpenAI and then uploaded our entire codebase. That is crazy. If true, this is going to be a big problem for Lee and Open AAI. All right. Next, Microsoft is getting into the foundation model game. If you thought they were already in it, they weren't. They own a large percentage of OpenAI and they're close partners with them. But of course, the CEO of Microsoft, Satia Nadella, playing 4D chess, realized how platform dependent Microsoft is on OpenAI. And OpenAI has grander plans to essentially compete with a lot of what Microsoft does today. So what do they do? They need to create their own model. Mustafa Sulleman, the CEO of AI at Microsoft said, \"Excited to share our first Microsoft AI in-house models. MAI Voice 1 and Mi1 preview.\" Let me give you some more details. MAI Voice One, most expressive natural voice generation model I've ever used. Might be biased. Super efficient. Generating a minute of audio in less than a second on a single GPU. Live now in Copilot daily and podcasts. Then MAI1 preview. This is the textbased foundation model. Our first foundation model trained end to end inhouse. In public testing on LM Marina and if you want to try it out, you can right now. And according to LM Marina, Microsoft has entered the top 15. It debuted MAI1 preview at number 13. That is right below Gro 3 Preview. So definitely far from the top, but at least they put something out. At least they're starting to get the ball rolling. Here's an example of MAI voice. >> On a sunny afternoon, a spirited four-year-old named Jamie approached a grizzled pirate. >> And another one. >> Under a sprawling Texas sky, a skeptical cowboy and an enthusiastic techie met outside a diner. >> All right, both of those sound very good. I do still need to do extensive testing. Right now, ChachiPT advanced voice mode is still the most realistic voice I've ever used, but I need to give this a try. Now, their text generation model is a mixture of experts model pre-trained and post-trained on 15,000 Nvidia H100 GPUs. They don't really give much information beyond that. So, we're just going to have to wait and find out more. We don't know the size of the model. We don't know how it was trained, anything else besides its mixture of experts. And if you're using the new Microsoft AI model, you definitely should give it a try with Zapier, the sponsor of today's video. Check it out. With all of the models getting so insanely good, saturating all of the benchmarks, it probably feels like we can't get much better than we are getting right now. But as I've said, the key to unlocking the true value of AI lies in the tooling. That's why I'm excited to tell you about Zapier Agents. Zapier Agents gives you the best of everything. Frontier models, plus over 8,000 different apps, aka tools, that can easily be plugged into your agents. This is true AI orchestration. Plus, with a tight integration into Claude, Cursor, and Windsor via MCP, you can take your tools and agents anywhere you want. Gmail, Slack, Calendar, Notion, Docs, anything. It is dead simple to connect them to your agents and give them access to the tools they need. Try Zapier's AI orchestration platform for free today. The link is in the description below. They've been a fantastic partner. I've been using Zapier for years and I love it. Thanks again to Zapier. And now back to the video. All right, next. Anthropic has raised an enormous round, $13 billion. Series F valuing them at $183 billion. This is still much smaller than what OpenAI is valued at, but it is a massive amount of money and a massive valuation. I believe it makes them the fourth or fifth biggest private company in the entire world. Series Funding has been led by Iconic and co-led by Fidelity Management and Research Company and Lightseed Venture Partners. Also participating, Altimter, Bailey Gford, Black Rockck, Blackstone, CO2, D1 Capital Partners, General Atlantic, General Catalyst, Growth Equity. Basically, everybody who's not invested directly in OpenAI. Anthropic has seen rapid growth since the launch of Claude in March 2023. At the beginning of 2025, less than 2 years after launch, Anthropics run rate revenue had grown to approximately a billion dollars. That is absolutely crazy growth. Then by August, just 8 months later, our run rate revenue reached 5 billion. That is 5x growth from just eight months ago. But it's not 5x on a small number. It is 5x on a billion dollars. Now they're at 5 billion. Congratulations to Anthropic for their raise. And another story on Enthropic. Apparently, they're going to start training their models on user chat transcripts. Now, they are forcing users to opt out of training on their chat transcripts. And they're also extending their data retention policy to 5 years. So, not only are they going to train on your data, they're going to keep it for longer just in case they want to train on it in the future. But according to The Verge, you should be able to opt out of it. All users will have to make a decision by September 28th. So, if you don't want them training on your data, go ahead and opt out. All right. Next, my dream has come true. The figure robot can now do dishes. Just a few weeks ago, we saw it doing laundry. And now, look at this video. It is doing dishes. My most hated chore, much more so than doing laundry. And anybody who thinks that laundry is worse than dishes, you're wrong. So, here it is. Obviously, still moving very slow. Still lots of little mistakes here and there, but overall incredibly impressive and such an improvement from just a year ago. Look how delicate the hands need to be with the dishes. Putting it exactly in the right place. I'm just so so impressed by this. Next, Google avoided being broken up in their antitrust case and their stock went up 9%. So, Alphabet does not have to divest its Chrome browser or Android operating system as part of the Department of Justice antitrust case against the company. Now, both the Chrome browser and Android are incredibly important to Google's AI future. Being able to control the browser with an agent similar to what Perplexity Comet does and being able to control the operating system on the phone with AI with an agent is going to be so important in the coming years because you will actually be able to get realworld things done when AI can actually control your browser and control your phone. Next, a new model from Hunan, the Chinese company that has been releasing incredible open source models. Listen to this. Today we're announcing the open source release of Hunan Video Folly, our new end-to-end text video to audio framework for generating highfidelity audio. Essentially, load up text, load up a video, and you're going to get audio from that. So, this tool empowers creators in video production, filmmaking, and game development to generate professional-grade audio that precisely aligns with the visual dynamics and semantic context, addressing key challenges in videoto generation. So key innovations, exceptional generalization trained on a massive 100,000hour multimodal data set, balanced multimodal response. So here are a few examples. Sounds good. Let's hear what snowboarding sounds like. Okay, pretty good. Of course, let's hear what the lion sounds like. decent skateboarding. Okay, very good. And it even aligns with the physics. So when the skateboard hits the concrete, you can actually hear the kind of crack of the skateboard wheels hitting the concrete. And that is very accurate. So give it a try. It's open source. Open Weights. Download it now. Let me know what you think. Next, Artificial Analysis is updating their benchmark index to V3, which now includes a Gentic evaluations for different models. That is terminal bench hard and bench telecom. Artificial analysis is one of my favorite ways to see how a model is performing against the benchmarks because it is an independent index of the different benchmarks, meaning they run it themselves and it is an index of multiple different benchmarks. So as you can see here, here is the current scoring. GPT5 high number one, Gro 4 number two, 03 number three. Next, Microsoft is on a roll. They published a paper RSR 2 agent, which is a 14 billion parameter model that beat a 671 billion parameter model on math reasoning. So it is incredible at math. And look at this. This is Amy 2024 accuracy on the Yaxis and then training steps on the Xaxis. As you can see in this kind of green color right here, our star just accelerates to 80% on Amy 2024 accuracy with a fraction of the training steps. And on the purple line, we see DeepSeek R10. So, if you want to learn more about it, I'll drop the link down below. Next, Korea AI releases something new with AI video. This is a real-time video generation model. So, here's an example of what it actually looks like. you have a fish, you can move the fish. Then it generates the realistic version of it using AI. And so you can move it around in real time as it's moving and adjust what it's doing. That's pretty crazy. Here's another example. So you can see it moving the flower in real time as you're adjusting what looks like Microsoft Paint on the left side. It's weight list only right now. So go ahead, join the weight list and let me know what you think when it is released. Next, in a play that I actually agree with strongly, Chinese social media companies have started rolling out labels for AI content. I have been a proponent of this for a while. If something is AI, it should be labeled as such. According to Ingadget, major social media platforms in China have started rolling out labels for AI generated content to comply with a law that took effect on Monday. WeChat has told users they must proactively apply labels to their AI generated content. But it's not only WeChat, it's Doyen, Waybo, Rednote that all are required to label AI content. I think US-based social media companies should be doing this as well. Next, in nature.com, they published a fascinating article in which AI was able to detect covert voluntary facial responses in coma patients before doctors. So, a little bit more information, many brain injury patients who appear unresponsive retain subtle purposeful motor behavior signaling capacity for recovery. And so all of these tiny movements can now be read by AI to see, hey, are they actually trying to communicate something? It's called see me and it detects eye opening in comeomaosse patients 4.1 days earlier than clinicians. And it detects it more often than clinicians. We should be using AI in all health. There is no reason not to. There is no downside to it. As long as it's led by a human medical practitioner, there is no reason they should not be augmented by AI. Next, Elon Musk posts this graph showing that Grocode increased in usage 60% higher than Claude Sonnet. Now, here's the thing. This graph is from Open Router. And Open Router measures the total usage of each of these coding models or really any model. But what Elon forgot to mention is they're essentially giving away Grock code for free. And of course, if you're giving something away for free, granted it is very good, but if you're giving it away for free, everybody's going to try it. Everybody's going to use it. So there's two factors going on here. One, it's for free. Two, it just got released, so everybody wanted to try it. So this graph plus his context is a bit misleading. Still, Grocode is fantastic and it's fast and it's cheap. So definitely give it a try and compare it to all the other models you're probably using for coding. Next, Chat GPT is rolling out two new features that are meant to help both people in need and parents. So, if you're in a mental health crisis and you're turning to Chad GBT for help, which by the way, I think is actually a pretty good idea within reason, then they're launching four initiatives. One, they're expanding interventions to more people in crisis. They're making it easier to reach emergency services to get help from experts. They're enabling connections to trusted contacts and strengthening protections for teens. They're also going to be partnering with experts. that includes the expert council on well-being and AI and their global physician network. They're also going to be leveraging reasoning models for sensitive moments. We'll soon begin to route some sensitive conversations like when our system detects signs of acute distress to a reasoning model like GPT5 thinking so it can provide more helpful and beneficial responses regardless of which model a person first selected. They're also adding parental controls which will control how Chat GBT responds to their teen with age appropriate model behavior rules which are on by default. Manage which features to disable including memory and chat history and receive notifications when the system detects their teen is in a moment of acute distress. I like these features especially as a parent between AI psychosis sick fancy because of acute distress plus exacerbated by conversations with AI. So, I'm happy with any of these controls that parents can get. And next, continuing on OpenAI, they just acquired a new company. It is called Stats Sig, and they acquired them for $1.1 billion. It is in an all stock deal, and it is one of the largest acquisitions OpenAI has done to date. According to Bloomberg, Statsig, founded in 2021, builds tools to help software developers test and flag potential new features. Its services have been used by employees at OpenAI, Eventbrite, SoundCloud, and other tech firms. It raised $100 million in a funding round earlier this year, valuing it at 1.1 billion. Statsig CEO will join OpenAI as CTO of applications. And last, Whimo is expanding to more cities. Next up, Seattle, which I just got back from, and Denver, too. So, two new cities for Whimo. I love Whimo. I love riding in it. I trust it. It is an awesome experience. If you've never done it, try to get into one at least once. It's just such a unique experience to have. That's it for today. If you enjoyed this video, please consider giving a like and subscribe.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Litígios entre Elon Musk/XAI e OpenAI, avanços de IA da Microsoft com MAI, financiamento maciço da Anthropic, novidades em robótica e questões regulatórias envolvendo dados e antitruste.",
            "resumo": "O vídeo aborda várias atualizações no ecossistema de IA. Primeiro, Elon Musk e XAI entraram com processo contra um ex-funcionário por supostos furtos de segredos para a OpenAI, envolvendo dados de IA. Em seguida, a Microsoft lança MAI com modelos internos, MAI Voice One e MAI1, apresentando demos de voz natural e testes públicos. O relato também menciona a parceria de ferramentas de IA com Zapier para orquestrar aplicativos. A Anthropic levantou 13 bilhões de dólares em uma rodada Série F, com avaliação em cerca de 183 bilhões de dólares e crescimento acelerado de receita; há notícia sobre treinamento de modelos com transcrições de chats dos usuários, com opt-out obrigatório até 28 de setembro. Por fim, o vídeo comenta o robô Figura fazendo tarefas domésticas, o caso antitruste contra o Google (Chrome/Android) e o lançamento de código aberto da Hunan Video Folly para gerar áudio a partir de vídeo.",
            "assunto_principal": "Atualizações no ecossistema de IA: litígios envolvendo XAI/OpenAI, avanços de modelos institucionais, investimentos maciços, progresso de robótica e implicações regulatórias e antitruste.",
            "palavras_chave": [
              "Elon Musk",
              "IA Explicável",
              "OpenAI",
              "processo",
              "MAI",
              "Microsoft",
              "MAI Voice One",
              "MAI1",
              "Anthropic",
              "Série F",
              "transcrições de chat",
              "opção de exclusão",
              "Zapier",
              "Agentes Zapier",
              "robótica",
              "Figura",
              "antitruste",
              "Google",
              "Chrome",
              "Android",
              "Hunan",
              "Video Folly",
              "código aberto"
            ],
            "resumo_em_topicos": "- Litígio entre Elon Musk/XAI e ex-funcionário por supostos furtos de segredos para a OpenAI.\n- MAI da Microsoft: MAI Voice One e MAI1, com demonstrações de voz realista e avaliações públicas.\n- Parceria de IA com Zapier para orquestrar ferramentas e aplicativos.\n- Anthropic levanta 13 bilhões de dólares em Série F, com avaliação próxima a 183 bilhões de dólares e forte crescimento de receita.\n- Debate sobre treinamento de modelos com transcrições de chats de usuários, com opção de exclusão obrigatória até 28 de setembro.\n- Robô Figura avança em tarefas domésticas, demonstrando melhorias na delicadeza e na precisão.\n- Google evita a fragmentação no caso antitruste; Chrome e Android são estratégicos para o futuro da IA com agentes.\n- Lançamento de código aberto da Hunan Video Folly para gerar áudio a partir de vídeo.",
            "prompt_tokens": 1898,
            "completion_tokens": 3927,
            "model": "gpt-5-nano",
            "cost": 0.0068
          },
          "analysis_time": 91.0231261253357,
          "language": "",
          "view_count": 43119,
          "has_transcript": false
        },
        {
          "id": "v2tK0fMWeuA",
          "title": "Reid Hoffman: AGI, Agents, Memory, White Collar, Global Competition, AI Companions, and more!",
          "title_pt": "Reid Hoffman: IA Geral, Agentes, Memória, Colarinho Branco, Competição Global, Companheiros de IA e muito mais!",
          "url": "https://www.youtube.com/watch?v=v2tK0fMWeuA",
          "published": "2025-09-07T01:02:09.070794",
          "published_relative": "há 2 semanas",
          "duration": "01:02:47",
          "date_published": "2025-09-03T12:08:21-07:00",
          "transcript_available": true,
          "transcript": "As soon as we reach AGI, capital is all that matters. The permanent underclass. I don't think because we make AI, we necessarily make class stratification. Do you think that banning the sale of specific chips to China helps the US? I think it's a good idea to then provide previous generation of chips, the generation before because then it makes it challenging. The Intel acquisition 10% ownership. Does Intel want this capital or not? Is it being forced? Like is this socialism? Is this Mauism? As you're looking at the Trump administration and their approach to China's AI, what would you say you disagree with in their approach and what would you say you agree with? Reed, thank you for joining me here today. My pleasure. I appreciate it. So, we're going to get right into the deep topic first. We're going to talk about AGI. I've been seeing more and more technologists, especially younger technologists, talk about the permanent underclass and having a certain amount of time before being consigned to the permanent underclass effectively because AGI as soon as it as soon as we reach AGI, the capital is all that matters. Have you heard this? What do you think about it? If you agree, what can we do to prevent it? And if you disagree, why? So, I tend to think societies that don't allow genuine and fairly broad upward mobility are unstable. And, you know, you could go to the kind of dystopia movie Alisium where you have an upper class with a bunch of, you know, militaristic robots. Great movie, you know. Yes. Exactly. Great movie. You know, excellent. Matt Damon, you know, the whole crew. Yeah. And I think that would be a dystopia and we bad. I don't think because we make AI we necessarily make class stratification. Technology can be used for class stratification. technology can be used against for example on the against it side is if you allow upper mobility then the fact that everyone gets an educational agent to like not just the wealthy people who have educational agents today they're called tutors other things but everybody has that then you have much more uh potential educational upward mobility so I am I am not worried intrinsically based on technology techology for a permanent underclass for, you know, kind of uh a shift towards an autocratic society. I'm worried about kind of the political system in terms of getting there. And you could say, well, but the AI could actually in fact further destabilize our destabilized political system. And the answer is yes, our political system is destabilized. And AI can go can can go in a negative direction, but can also go in a positive direction. And so my view is what we should be doing as opposed to like hey how do I get as much capital as possible in the three years is how do we get to a political system that enshrines the kind of humanist values that we want that is uh broadly you can make progress and that you have upward mobility and frankly geographic mobility for people. Yeah. Is that going to be facilitated with AI? Do you think governments should be adopting it much more quickly than they are right now? Um I I just I'm I'm wondering how we can actually achieve that. Well, it can be facilitated. Um you know, educational to one thing I do think governments I mean roughly speaking part of the reason why I wrote super agency early this year. Roughly speaking, we're in a cognitive industrial revolution. Uh Britain did not invent the industrial revolution but embraced it most fully early. that led to a centuriesl long empire of otherwise this kind of small island right you know kind of you know kind of as part of Europe and I think that we as society need to do that too and I think it's the how do we make our industries you know kind of AI enhanced and robust how do we help the transitions with workers because by the way it will be lots of job transitions it's not going to be easy like the whole lite movement in, you know, kind of uh powered looms in England. That's just kind of the beginning of the kind of adoption issues that we'll have. But by the way, part of like when people say, well, why should I bother like I I'm happy with my job the way it is. Why shouldn't I just resist the use of AI and not have it? And the answer is well because your children your grandchildren will be the kind of the the non-industrial rural children that the others countries had. You don't want that for your children. Two what government should be doing is saying how do we get you the benefits of AI as much as possible. Yes, there's going to be job transition, but a medical assistant, I mean, think if everyone who has access to a smartphone has access to a, you know, kind of better than a GP today in terms of navigating health health issues. say that you get into kind of the issue of triaging what goes on with emergency rooms or other things and say hey I don't just have to go to emergency room because I don't know what to do but actually that's triage to the people whose lives need saving versus the take two ibuprofen and you know check in again in a couple hours that kind of thing those are all things but also an education assistant a legal assistant etc you bring those benefits to people then they go okay I get it my job is going to be in transition that'll be scary. That'll be difficult. I'm not going to enjoy it. But but I understand that that's what's important for, you know, my family, my community. Yeah. So, we I'm going to get into education and health and integrating AI into that, but I want to zoom in a little bit and let's talk about agents specifically. Um, you know, a agents increasingly are browsing the web on behalf of humans. Uh, but the web still is made for humans. Do you think that there are or what are the major fundamental changes that need to be made to have the web be more agentfriendly? Well, um we want the web to continue to be also very human friendly as it is because you know humans use even as we get mediated even as we have agents for us and agents in the other people and other organizations that we're talking to. Um so I think that that will be um that'll be important. Now uh anthropics MCP protocol will be key like you know agents talking to agents. So it'll be less I think the web per se becoming agent friendly as much as a as an entire new channel of communication on the internet uh which will be agents talking to each other calling APIs and services and other kinds of things. And I think we're already beginning to see some of that. Yeah. Now, of course, part of when you get to, you know, kind of agentic mode, um, and what you see kind of working as agents, whether it's, you know, anthropic, open AI, others, um, is like we're already like, you know, part of the thing I've already started using is I go, hey, just as I use, you know, deep research to to research things, when I go, hey, I would like to get an an understanding of what's going on, say, for example, in social media, um like I will actually use you know agentic mode uh in order to do that. I'll say hey what like what's trending as opposed to the kind of the the kind of uh call it polluted melee that is Twitter when I want to understand stuff on Twitter I ask the agent to give me a summary. Yeah. Okay. I'm glad you brought that up because I've been thinking about this a lot. As AI creates a kind of skewed ratio between signal and noise on the web. It just seems like your agent is going to have to filter the web and provide you with information as you said, but like what does that look like? If you're entrusting a single AI to essentially filter all information coming into you, isn't there going to be this risk of inherent bias or some of the you know your founder of LinkedIn, social media um went through echochamber issues and um amplification of fear and hate. Doesn't AI or an agent on your behalf filtering information from the web um potentially suffer from those same issues? Well, it can. Um but by the way, there's biases everywhere. There's, you know, you have biases, I have biases. And so the way you navigate biases is by getting multiple, you know, kind of angles and points of view. It's part of what's made the scientific method. It's part of what you know the reason why you know things like you know understand germ theory of disease because we actually have multiple people reproducing experiments and so forth. So what I think um the most natural lazy course for people to do is to have one agent that they use they'll have some risks from that. Does that agent make mistakes? Does that agent um reflect the bias of the whatever organization you're is you know technologists talk about well it should be agent I'm paying so it's responsible to me responsive to me versus responsive to advertisers. I think that's going to be far more complicated because if you have human nature people prefer free or cheaper with advertising it's it's been demonstrated for you know over a century in terms of how this works. So I don't think that I think that you have to you have to presume that advertising is actually in fact going to be part of it. Um but uh but like for example today when I do deep research on something um I actually in fact generally speaking do deep research not just on chat GBT but also on Gemini and also anthropic and actually I'll take the outputs and I'll freed the three of them into sometimes one of the models or three of the models and compare and contrast and and so forth and get some understanding of where those biases are across them as a way of operating. I think that's what's going to happen in agents, too. I don't think we're just going to have one agent that says la, it's only through my one agent in the web. I think we're going to have a couple agents. And what's more, part of I think the people who are the at the edge of learning how to use these are using saying, hey, it's not just generic like, you know, like the the 1.6 six words I type into, you know, pick your favorite search engine. But actually, in fact, uh, you know, part of what I do when I'm prompting an agent is I say, hey, I'm when I'm when I'm looking at this, I'm particularly interested in this from an a global perspective. So, can you make sure that you're representing Asian, African, European, you know, perspectives in your in reflection to me. And by giving it a role, you're actually prompting it to try to see around blind spots and all the rest. And I think all of that will be part of it. So actually, in fact, I think ultimately this kind of agent um uh this kind of a trusted agent mediation should help me relative to biases from today rather than hurt me. Yeah. Um Okay. So you you mentioned publishers uh or or you mentioned like as as agents are browsing the web on your behalf, you're not necessarily giving the eyeballs to the publisher, your human eyeballs, the monetization model might have to change. Have you had any thoughts as to what that new monetization model might look like as more agents are browsing the web? So I've given some thought to it. um you know what my hope is like I think there will be various forms of advertising advertising you know um uh you know has a whole bunch of things where Google's adwords is the current you know kind of uh leading contender although you know meta with its you know kind of social networks is also doing uh quite well and I think those two will be baseline but I think we will invent new ones it's like when Google launched its website it thought it going to be selling ads or sorry it started it thought it was going to be selling enterprise services then it thought it was going to be doing doubleclick and then there was a there was a drop in the in like the whole advertising internet market dropped out and it had to invent adwords by you know using inspiration from overture and other things right I actually think there will be a unique new model that one of the leader leading contenders will figure out and that will that will essentially create the equivalent of the the Google power for how that works. And and what I hope for the characteristics of that new model are that it has some of the characteristics that like Adwords had which is well be clear in distinguishing what is advertising be clear in in kind of saying hey here is what um your participation in this advertising ecosystem does in terms of here's where your your data and your agency plays into it. But my guess is there's going to be something new. And that's one of the things I've been paying attention. One of the things I like as a as a investor is, you know, you get thousands of entrepreneurs who are all thinking about this. And so I might come up with an interesting idea, but I think it's much more likely that some really interesting, bold entrepreneur will do it. I hope to see it. Yeah, me too. I I just um you know, if it were up to me, I would just simply pay Chachi PT and and they wouldn't have advertising in it. But I understand the vast majority of the world probably prefers a free product and service. So advertising makes sense. Do you foresee uh model providers integrating advertising into their model responses? I think all of them will. Yeah, there's going to be a free tier for all of them. Yeah, exactly. It just it just makes economic sense. Okay. Um I want to talk about agent memory for a minute. Uh it's something I've been thinking a lot about. It's really it brings these models uh value to really an incredible level but it also provides a moat for the model providers right you're building up a memory with chachi pt it gets better it develops a shorthand with you but if you want to go somewhere else you essentially have to start over um do you think there's a need for kind of a open protocol like MCP but for agent memory do you think like h how much investment should companies be making into making the agent memory more portable since it goes against what their incentives are. It does indeed. I think that the companies will naturally basically try to make portability of memory hard. They're they're not going to invest in making portability of memory easy. um it's the natural economic incentive and the balance is to some degree it's like well like say for example I like and and and they there will be good call it reasons and rationalizations which are like wow but my memory format is special and and and and I can't like I don't want to export my my secret sauce by which I'm providing such amazing you know kind of uh persuasion or engagement or or creativity. Um, and so I, you know, I I I I I'll say sure, I'll export, you know, Reed Hoffman as a name. I'll export, you know, kind of biographical details, you know, kind of things. I'll I'll export a summary of things we've talked about like, oh, you seem to have been doing a lot of a lot of um um relationship between AI and art and AI and creativity. So, well, say and Reed really likes AI and creativity. Great. great, you know, new model, you should use that as your prompt and go. And so that will happen. Then of course, by the way, if one if one particular uh uh agent becomes dominant, governments will then start trying to poke it to to make the the the the make the memory portable. But then the question of course will be um well like well what do you mean by portable? Like like for example, I will have gone to you and I'll have said as an AI as an agent provider and I'll have said hey um you know would you like me to keep exact records of all your chats or would you like me to to to to to delete them and you'll probably say well actually I'd prefer privacy so I'll delete them. Well then hey there's nothing to port right we we're remembering what kinds of things we have in the conversation but there's nothing to port anyway. So that will be an ongoing challenge. Now what I hope is that we already see multiple significant AI agent providers. Um so it's obviously ever like like chatb is the most known one but you know there is anthropic and claude there is copilot there is gemini there will be others um and so when you have a lot of competition and contention between them the the needs to enforce portability is somewhat less. Now, by the way, part of portability, like this is where you get to the really advanced game is like say, well, can um um like for example, what I'm doing today is I'm using two agents. Well, could one agent, you know, help remember the things from the other a like both agents are are doing memory by syncing all of them? Very difficult. So, and then it gets well but then it gets to as that happens then I have more ability. I already have multiple agents and I have some portability already because I have multiple agents. Yeah. Yeah. And it seems like if you're competing with these top model companies, but you're not necessarily in first place, you're probably going to be a much bigger proponent of open standards. It's same thing we saw with Llama and Meta. Yes. Like you know, Scorched Earth, open free. Yes. And so, um hopefully we do see that. Um we'll see some some parts of it for sure because of that. Yeah. So, so let's let's continue down the path of memory. When you think about like personal memory versus work memory, this is also something that I've thought a lot about. Um, the agents are going to be best when they have both. When they have the context of you as a person, how you like to work, maybe even, you know, your your personal life information. And then when you bring that into a company, you're starting to develop all of the memories around the context within the company. Um, but now we start to get into complex IP issues. like the company is certainly going to own anything you build there. So, does that mean the company is going to be less likely to want you to bring your personal agent to work? How do you see that playing out? Well, this is uh great question. I think relatively too few people are thinking about this right now. um you know I um from my early days you know 20 plus years ago with LinkedIn I'm a huge proponent of individuals kind of in the 20 year ago like you own your address book whereas a company would tend to say I own your address book because it's on my computer right right and it's like no no individuals own the relationships own their address book you know company might have a copy or something but like the individuals do it I think we're going to want to be to allow how uh you know kind of uh freedom of economic and talent mobility. We're going to want as much uh you know like that just that history of LinkedIn that that transitivity following the individual and as much on the individual side as possible. Now that of course will be you know have some challenges because the the most expensive AI agents will generally be provisioned by the company will be interled with a whole bunch of different company IP right and so the question is when I leave what kinds of things can I take with me right because today we basically say you can't take anything that's the company IP with you so Sure. Understandably. Yes. Understandably. So, what's the interface point between these two? And I go, and you already see little points of it. Like, for example, well, if I'm in a work meeting, can I have my personal notetaker be taking notes? That seems to be not okay because the other people are working for the company. The question is, is we're doing this in a shared company space. So, what will be the things that will be part of the the personal space versus the company space? And I think it's a unknown as yet. Yeah, it it's definitely going to be difficult to figure out because all of these things are coming together in the same place and um the companies are incentivized both to have your personal AI in the company and not to at the same time. Um, if you're looking at a team that is using AI agents and using AI heavily, how do you tell when they're outsourcing too much of their judgment to AI, specifically within the context of the enterprise? So part of what you need to to generally kind of have people have is is make sure and this is part of the you know AI work you know AI work in the age of AI is there's a lot of metacognition that we provide as human beings even with these amazing agents today. So, and part of metacognition is the context, awareness and judgment of you like is this answer does it make sense? Are there things there are there things that you're missing? Right? Because the agent don't really have common sense right now. like if they if if they don't they don't necessarily realize what like we're like for example you know uh and agents are getting better on this but you go hey um give me the answer to this prime number problem and and you know the agent gives you a bad answer and you say nope that's wrong and goes oh I'm sorry I was wrong here's another end you go nope that's wrong a human by the third time goes okay I'm  this up I will figure it out the agent just keeps giving you wrong answers as they're going and So you got to have you have to own that kind of metacognition. You have to kind of own that context awareness. And so part of what you want to be doing is you go sure I'm using AI to accelerate to parse information to to work more quickly to to do a bunch of things, but I still have to own the result. And like for example, when you look at good people using coding agents today, they don't just plug in the coding agent and go to town or whatever, right? They look at the results, right? and they kind of they're they're applying that metacognition to it and I think you know you asked how do I check it's like okay so like part of what I do is say how did you use AI in doing it now if they said I didn't use it at all he's like well that's foolish right because you can be greatly accelerated in how you work I push people into using AI but then they say oh I used to do a whole bunch of it great how did you cross-check the work how did you how did how how were you thinking about making sure the work outputs were right. And if they just said, \"Well, I just trusted you.\" Like, well, okay, you got to do more than that. Now, you could cross-check with different agents. You could say, \"Hey, I had agent one produce some work. I had agent two cross-checking it. I asked agent two the following kinds of questions in terms of cross-checking it.\" Great. Now, you're in much more in the metacognition area. Yeah. Okay. Um, I want to move on to global competition obviously. Uh, let's let's talk about China a little bit. Um, you've said that the AI race with China is game on. You've also said AI should remain American intelligence, both of which, yes, I agree with. Um, do you think that banning the sale of specific chips to China helps the US or is that putting us in a position where US infrastructure isn't the default, isn't the standard at that point? So ultimately, what matters is the software. So slowing down the provisioning of scale chips that matter for the training of this does help um maintain something of our investment edge in the software. And so I think playing to to saying hey we as the US are going to provide um less numbers of scale chips to people who we are in direct kind of geopolitical competition with. Yeah. You know and you could you could say China but you could also say well the extreme is like Russia and all the rest we're we're in we're in competition with. And so we will on the the top leading chips provide fewer slashzero. That being said, I think it's a good idea to then provide the the the previous generation of chips, the generation before because then it makes it challenging for uh competitive chip industries to get created, right? That's so you want to say not the latest but the old ones. That's okay. Yeah. But doesn't that incentivize China to invest? I mean, they're going to do it anyways, I suppose, but like they're they're looking and they're getting previous generation chips and they're they're thinking, okay, well, not only do I have to build the chips, I have to build the software uh ecosystem as well. Maybe they're going to do it either way, but it seems like if we're giving them the latest chips, they may be less inclined to do so. Well, um this it's a software race, not a hardware race. Mhm. So other than hardware enabling software. So um and yes they may eventually end up creating their own and you know for example they've they've created some they're exploring different chip architectures in China because yeah of limitation. By the way ultimately this is one of the benefits of competition. That might be a good thing that that other chip architectures come out. Um but uh I think that that gives our software an edge over some number of years. Some people think the only thing that matters is the next two to five years. But if you keep that edge, that's the kind of thing that that can be very helpful for the cognitive industrial revolution. So I'm in favor of of that. Now that being said, the reason it's not just block all chips is because you say, well, are they going to then go create their own leading edge chips? They're gonna try, but by the way, it's harder for them to do that when they can also buy the last generation of chips. Right. Right. So, it's like the sure they're going to try to create that leading generation anyway. Um, you know, you'll hear, you know, our chip manufacturer saying, \"No, no, we should just provide them all because that's what's good for their business.\" But the thing that matters is is which AI software will be defining the future of h of human society, human work, you know, kind of human industries and um you know part of what we want as western democracies is we want that to be our AI. Yeah. And so then um as you're looking at all of these incredible open source models coming out of China and then you look in the US where it seems like the trend is Frontier Labs are going to have their Frontier model closed source and then maybe previous generations open source. How do you compare and contrast those approaches? Is it more of well if you're trailing you're going to do Scorched Earth open source as we talked about earlier? Um do you think the US's uh US uh Frontier Labs posture towards kind of closed source frontier and then everything else can be open source is the right one? I do for a couple reasons. So, first I mean I thought you know OpenAI's release of its two open models this month was epic relative to um like all other open source models including the Chinese ones like the the the the open AI models are I think in many facets the best and that's that's interesting and useful. Now, part of the reason I've been a proponent of large scale proprietary models is because of alignment and safety issues. So, for example, part of what you want to do is say, hey, um, let's not provision the best models for cyber crime, for bioteterrorism, you know, these kind of things. And and and aligning them is really important. And open AAI has been doing that for for years investing in you know kind of safety groups by the way Anthropic is as well Google is as well Microsoft is as well and those are on a proprietary models basis that means they work that a lot and when open gets to open source its models it's trying to do with as much safety and alignment as it can in those open sourcing and so that's what's that's that's why I think this combination in as much as people have any worries about regulating the front of AI prot proprietary models are uh lead to much more easy regulatory conversations with governments. Well, problem is once you open source a model everybody has access to it and that includes the criminals that includes the rogue states that includes the terrorists. So you have to be careful about that. Doesn't mean like I'm pro open I was on the board of Mozilla for 11 years. I'm pro open source in all kinds of different ways. I think LinkedIn has open sourced more um uh kind of fundamental technologies that have led to new public companies than than many other companies. And so I like I'm very positive on it, but you have to be careful about how you're doing it. Yeah. I mean there's the argument that opensourcing the models will get more eyeballs on it. And there's been a history of technology that has been open source. The more eyeballs you get, the hard the more hardened it becomes. And so h how do you counter that example? Is it Yeah. How do you counter that example? But that's actually uh for open source, that's why open source and open weights actually makes a very big difference. So for open source, that's absolutely the case. It's part of the the the central way that you know Linux and Mozilla and other folks have played to being very useful because uh cyber security hardening is useful when you see the code and you can do stuff. The problem is when you release open weights that doesn't kind of go back into the common pile. Even as you you you might discover a vulnerability with an open weights model that doesn't necessarily help anyone else. That may only just help you. And so um and so that kind of benefit that you get from collective open sourcing doesn't actually happen in any current configuration with open weights and no one knows yet how to make that configuration work for open weights. Okay. And then as you're looking at the Trump administration and their approach to China's AI and and restricting chips, what would you say you disagree with in their approach and what would you say you agree with? Um well, so what I um what I agree with is let's see because they've been it's a little bit trying to pinning down exactly what they're doing is a little challenging because they're a little random and there's the governance by tweet and a bunch of other things that are that that that make it hard to assess where the competent play is. But but roughly speaking, let's say that they say, \"Hey, um providing the leading edge chips to China is something that we are going to continue to restrict um either entirely or in volume. That's something I agree with. Um that we're going to provide it broadly across the Middle East is something I think needs to be a little bit more challenging because the question of where where does that bleed to, right? because you go great, we we provide it to the Middle East and by the way in the modern world it's about software. So you say hey we're going to build all of the biggest new data centers in the Middle East. Well they're going to rent them to whoever including the Chinese right in terms of doing this. So you have to be much more careful about that. And I don't think they are being careful because it's being more you know kind of the question of you know who's giving you the $200 million plane you know that kind of thing is as a way of operating. So, so I disagree with that sort of thing. And I also disagree that the like they're seem to be most focused on woke AI, which is almost laughable as a as an issue versus well, actually the real issues are like bioteterrorism, cyber crime, rogue states. Woke AI is not the most fundamental issue. Like um like if if AI were making woke mistakes, okay, that's easy to fix. that's that's not something that creates an ongoing problem. Um whereas bioteterrorism, cyber crime, rogue states, those are ongoing problems and that's what I would focus on. Yeah. And it seems especially seeing like what happened with uh Xi's models um just changing a single line in a system prompt is enough to completely change the personality of these of these models. So, it's almost like um focusing on the personality of the model seems like okay, just leave it up to the companies to decide how they want to run it and then of course competition is going to see it out and whichever model's best will win. Yeah, it's been very entertaining to watch Grock say the biggest spreader of misinformation on Twitter is Elon. Then they put in this the prompt, then people reverse engineer the prompt and see that they put it in like don't answer Elon to that question. and you're like, \"Well, it's it's actually got it's got the most privileged access to Twitter data, so you presume it would know.\" Yeah. Yeah. Um Okay. And then like let's talk about the Intel acquisition, you know, or not acquisition, but you know, 10% ownership by the US government. Do you agree with that? I I It's hard for me to see the benefit in that, although you've been a huge proponent of onshoring chips. How do you see that investment um helping us achieve that goal? So the thing that I think all the way back to TARP that's actually an underutilized uh place of public money is to use public money for stimulus but to also recover it in you know kind of um is don't make it just an expense make it something that you can recover the capital of making money from it. I don't think government needs to, but if you could say, \"Hey, we're putting in we need to stabilize the financial system. We're going to put in a hundred billion dollars to stabilize the financial system.\" Not just giving it to banks, but having it come back out as equity when you're doing it, I think was a very good and smart play for, you know, like we can't allow the financials fail. So, imagine if they did it with Tesla and their loans to Tesla, they would own a piece of Tesla. Exactly. And so it's like if you're providing that if you're providing public money to private companies you should try to get at least the capital return basis. I think that's a good idea. Now it's a little confusing to know does Intel want this capital or not? Is it being forced like like nationalization of industries is is a socialist thing like it's been entertaining to watch the critique of is this socialism is this Mauism because actually in fact you know um like that is what socialism is. If you're if you're if you're if you're you know kind of slippering the brain it's not like wokeism is not the only socialism it's nationalization of industries. So so this it should only be given as options to these companies unless it's a it's a necessary you know infrastructure. Now I do think that we want to have good competent efforts at building up uh onshoring manufacturing of chips. I think that was a mistake over the many decades as to offshoring it you as much as we have. Um I would like to see more competence by the administration and government doing this. So far governance by tweet doesn't really seem to be doing it. Is it feasible in the next few years to really onshore chip manufacturing? I mean TSMC owns it, right? They they own the vast majority of chip manufacturing. it it like did the economics work bringing it here in let's say the next 3 to 5 years um not without uh some very directed and smart governance. So for example you know in prior administrations I had been kind of recommending hey can we set up uh partnership deals in this with Mexico and Canada for doing this. I actually think that would be a very good way of doing this. Now, you might do special economic zones in places like um you know, New Mexico or or Texas or other things and making that kind of partnership work. Now, under this administration, which seems to be trying to declare war on everyone that was our previous, you know, friends and allies, I'm not sure that will work, right? Because you know it doesn't work when you're going, \"Hey, we're going to try to extort as much from you in a trade agreement as we can versus let's how do we make 1 plus 1 five and then you know sure maybe in five you get two, we get three, right?\" As a as a way of of kind of playing this out. That would be the kind of way to do it. I think you know uh because you're going to have to answer the questions around do you have the competence in the workforce? Do you have the the ability to do the the cost-effective manufacturing? Do you have the technology and knowhow to do this? There's a whole bunch of problems you're going to need to solve which is going to grow higher competence in doing this. And that's not, you know, like that's not governance by tweet. Yeah. Well, uh let's let's continue on the topic of uh the economics of artificial intelligence. I don't know if you've seen this meme. it was uh going around X in the last few weeks, but essentially hundred million in ARR, take off the mask, $120 million uh anthropic bill, and then in the third pane, take off the mask, $150, $150 billion uh Nvidia bill. Um is this part for the course? Is this like analogous to Uber and VCs subsidizing Uber in the early days until they became profitable and you know, a great company now, or is there something else going on? No, I think that's broadly the case. Um and you know it's one of the privileged positions that Nvidia has which is it is it can command great margins because everyone needs the they have amongst the the best chips in the business and CUDA the software. Exactly. Exactly. And CUDA. Um, and yes, uh, if you factor in hardware cost and amortization, training cost and amortization, things are being priced at at below their costs. Yeah. But by the way, that's part of why Silicon Valley like, you know, so Silicon Valley has, you know, kind of call it depends a little bit on how you parse it, but I think a good parsing is like five million people in it, which is just a little bit bigger than Ireland and over half NASDAQ. And part of the reason why Silicon Valley does this is because they've learned to say, hey, revenue today is not what matters. Revenue in the future is what matters. And so how do you get to strategic position for that revenue in the future? And it's especially true in network effect businesses. And that's part of the reason why I wrote Blitzcaling because that that was kind of lessons from this in terms of how to play out. So like people going that's that's that's just that's just you know like this will never be profitable. It's like no of course it'll be profitable, right? But investing in that future market because revenue in the future is what really matters is the thing that everyone's doing intelligently. Yeah. So this just feels normal. We're going to get that. Yeah. Okay. Um and then you know the anthropic founder a few weeks ago Daario said you know he talked about the white collar blood bath coming in the next three to five years and it that that quote went viral obviously. Um blood bath quotes always do of course. Yeah we should just put that in everything. Um uh do you like where do you fall on the spectrum for white collar jobs? Are you more towards the pessimist bloodbath or you more towards the optimist utopia? Where where do you fall and why? So I'm generally speaking more optimistic, not just you know super agency possible podcast etc. But also like I would be willing to take the bet that we don't have a white collar blood bath in you know even 24 months from today let alone when he did that that was eight that was eight that was six months ago. So it would be 18 months from today that would be even an easier bet. And the reason is because I actually think we're going to be finding a lot of different forms of human amplification. Now with that, I do think the transitions will be difficult. So I think Eric Benolson at Stanford has done some good work saying, \"Hey, we're seeing um some slowdowns in junior hiring positions for customer service jobs and software engineering jobs. Right? I think the software engineering jobs will get refixed because I think there's infinite demand for software engineering. But I think customer service is actually one of the ones where will be most most replaced, right? And could actually in fact like like if you said blood bath for customer service jobs in the next 18 or 24 months, I think that's that's very possible. And so so there's going to be a lot of job transitions and that transition I don't mean to to to sugarcoat it, that's going to be difficult, but I do think just as we were talking about metacognition and talk about like what do I like what do I see happening? I don't I think that the notion of an individual contributor who doesn't deploy with a swarm of AI agents that's the disappearing job. Yeah. Right. And so it isn't so much that the job will disappear as much as the job without AI agents. It'll be a person plus AI agents that will be doing the jobs. Well, but then there will just be fewer jobs. It's like, well, not necessarily. A lot of jobs are competitive. like my marketing against your marketing. It's competitive. And so we want to be like if if we just say, \"Hey, we're just gonna all outsource our marketing to chat GBT.\" Well, like I would like you to outsource your marketing chat GBD. I'm going to use ChatgBD plus humans and I'm going to try to win and beat, right? And there's a lot of jobs like that. And then for software engineering, for example, there's infinite demand for it. There's so much infinite demand that this is part of what I see as the future of of information and knowledge work. You even doing podcasting are going to have a software co-pilot. You're going to be using software, custom software for things that you're doing for your own competitive edge that you will be doing yourself. That's the reason why there's a lot of demand for it. And we're all going to have software co-pilots in terms of how we operate. So, I'm also an optimist and I I made this video a few months back where I talked about infinite demand. I'm so glad you mentioned that. Um, a lot of the comments I got said, \"No, actually there is not infinite demand, especially if you look at the market more broadly, maybe not part like specifically software.\" Um, when a company has hyper productivity and there isn't infinite demand, then they're not going to be hiring as many humans. Um what what is your counterargument to people who say there is not infinite demand? Well, I think they're right that a company will not have there'll be some paro curves even on the hypers scale companies behind management costs and hiring you know kind of new engineers. So for example if you said look I'm an Oracle and I guarantee you that the hyperscalers will be employing 20% less software engineers than they are today. trust me on this. And I'll go fine, other people are going to hire them, right? There's a competition, right? That that was always my argument. Yes. And so, and by the way, um like uh and now with vibe coding and everything else, there's going to be a lot more like like essentially software for just this task. Right. Right. That's part of where the infinite demand comes from because it's like no no actually this t like for example I want to create like for example when you think about create creativity like creating software for CG for movies well that was super expensive and so only a small number of very high-end very big budget Hollywood films can do that now the like for example documentaries are going to have access to all this because of vibe coding and so it's it's it's there's a ton of of of kind of software everywhere, right? Like like there's going to be like how do we make these mics more intelligent? Like as opposed to, oh, we have to be exactly this distance away from the mic in order to get the sound. It's like no, it's actually going to be having uh software that's going to be like I move a little bit away and it goes, oh, I pick it up a little bit. Right. Right. Like there's going to be software everywhere. Yeah. You talked about smart toothbrushes and super agency. Exactly. Yeah. Yeah. Totally. and and there's this long curve of problems that weren't economically viable before, but when all of a sudden the productivity per human skyrockets, all of those problems become economically viable. And then also as you build out the world, you have new problems. And I there was a CEO I was speaking with a week ago who said, \"Is the world in a perfect place? Is it perfect? Is it ideal?\" And if the answer is no, there are more problems. And and I really liked that framing of it. And the world's never perfect. There's always more problems, right? And especially when we go out to the stars and start exploring space even. Yeah. So, it's I'm I'm definitely an optimist like you. Um, all right. Let's talk about companionship. You have spent a lot of time thinking about this. You have Reed AI, uh, digital twins, AI companions like Meta's Celebrity AI, Gro's, Annie, and Valentine. Um, what specifically should platforms do to make sure that these AI companions are augmenting human relationships and not replacing them? There will always be some humans who will naturally head towards replacement. And the fact that there's some does not invalidate the overall technology. It's just like there's some human beings that will get in a car and go deliberately hit somebody. And that doesn't mean no cars for anybody, right? We try to make it so that as few humans do that and then make it hard for using cars as weapons etc. Similar kind of thing there will be some individuals who will go I'm engaging with the agent I'm doing something like suboptimum for me suboptimum for other people that will happen. The fact that there is some doesn't invalidate it. Now that being said, part of what want to say is like on the macroeconomic you know basis there will be a set of different companies that will go hey I just want you to orient and talking to me and my bot and not going out being an a human in society in your community and everything else and I want to make that happen and that's actually in fact a bad thing whether that's you know the most obvious example as Twitter and Elon and you know creating you know kind of AI girlfriends and you know kind of pornography through the agent and all the rest of this as ways of doing which they are the leaders in in terms of doing and and frankly actually in fact I think what's see what's happening is a lot of of the other labs are going well look if you go work there we think you don't care about human welfare and so we don't necessarily want to hire you to our to our companies. It's almost becoming like a litmitness test is if you go work there that means that you're you're you're doing you don't have the right human alignment values that we want to create for folks because for example you should of course create AI companions. AI companions can be useful for all kinds of things and not just hey help help me figure out this medical condition help me figure out this legal issue. Help me learn things. Of course there's all that but by the way it's 11 p.m. I'm lonely. I'm unhappy. Hey, talking to the companion can be a perfectly good thing, right? It might it might help stabilize me. Now, you want it to be if you're think I'm thinking about self harm, it says, \"Hey, um let's let's try to help you find people and and talk about like why you shouldn't do health self harm.\" Um and so, so I think a broad range of AI companions is a very very good thing, but it should be with a theory of how do you live a good healthy happy life? How do you connect with other people around you? How do you connect with your community? And I think that's the kind of standard that we're going to want to see. Yeah. So, I mean, let's use your last example, um, of of like, hey, it's 11 p.m. I'm lonely. Let me talk to an AI companion. It's hard for me to see the the the broad benefit given global population decline, loneliness epidemic, which I don't, you know, maybe it helps in the short term to have an AI companion, but it's certainly or or close to certainly going to take away from human companionship. How how do you kind of like u align those competing uh incentives? Well, so the thing you have to track it will take away from some human companionship, but there's a lot of times where people the reason I said 11 p.m. is a lot of times where people don't have that human companionship on tap. It's like if I'm sitting at my in my apartment by myself, it's 11 p.m. Would I be waking you up as I call you? Will you be, you know, is that going to be okay? I'm not quite sure if I'm ready to do that yet, etc. A companion can fit a very good night. Now, part of what we did in inflection and still does it. If you go to inflections pi, personal intelligence, and say, you know, you're my best friend. It says, no, no, no, I'm your companion. Let's talk about your friends. Have you seen your friends recently, etc.? So you like when you'd want that companion that you might start with you might start with pi at 11 p.m. and goes hey you know are your friends like in a time zone like maybe you're on the east coast and maybe you can call one of them who's on the west coast and it's only 8:00 p.m. and and and make that connection that might be helpful to you. Like you want the agent to be doing that like a lot of times like a teenager might go, \"Oh, I have no friends.\" Hey, actually, in fact, maybe you do. Let's help you think about who you're on the path to friendship with, who you could be building that with, etc. That's what you want the companions to be doing. And so it's not just the hey look I I had my best friend you know you know Mike or Sarah and I'm not going to call them because I'm going to call the agent. It's like no no no you want the agent kind of provoke gonna say hey have you talked to Mike or Sarah? You know like that kind of thing and and that's a useful think of it as a set of different interface services. Those are useful interface services. doesn't mean it won't go wrong sometimes, but you want it to go right much more often than it goes wrong. Yeah. Yeah, that makes sense. And but I think to the movie Her, if if you saw that right, and when you're speaking with an AI that is literally built to reflect the exact type of personality that you want, the exact type of companion you want, you you might get sucked into that and you might start foregoing the human companionship aspect and maybe not all companies are going to be as responsible as inflection. And so, um, Should there be maybe governmental oversight or or like how do how do you think about that? So part of the thing I advocate on regulation is to start with measuring like too often what happens like let me tell you how to design this like none of us know how these things are going to be designed even the leading experts don't know how to design it perfectly for the 5 10 year future which is what you're looking for in kind of regulation but you say hey um I'd like to have a set of measurements on is your agent um like for example this is one of the things you could do as a government regulatory agency today, you'd say, \"Hey, um, we want you to propose to us some measurements of are your agents taking away from quality human interaction. We would like you to be running those measurements, right? And we'd like to know if those measurements are going up or going down. And if they're going up, then we're going to start engaging with what's going wrong, right? And by the way, we'll rei we'll re revisit every couple years, are these the right measurements or should there be other measurements for this particular challenge. And once we see them starting to go up and think the measurements are real, then if you're not fixing it, we're going to start imposing regulation. Yeah. A lot of what we're talking about requires a a severe amount of AI literacy, right? And so I I want to talk about that a little bit because um schools are changing. I have uh you know two two young kids in in uh school right now and I'm I'm conflicted and so as a parent uh like what would you tell me are the best skills for me to uh tell my kids to learn and to help them learn whereas maybe it was something different but now AI can do a lot of uh you know writing and and math and so how how what would you tell me what would you tell parents out there to have their kids focus on? Well, one AI literacy is going to really matter. So forbidding the use of AI is a bad mistake, right? And so engaging whether you're a school, a parent, etc. I think getting them to engage with AI is part of how learning now uh chat GBT already has a learning mode which is I think I think I don't know might be as simple as or study mode or whatever they call it as don't give the answer, help them find their way to the answer. And if you do that as a metapar prompt, all of a sudden even that basic thing makes these things into amazing learning agents. Yeah. And so, um, that's the kind of process that we're going to want to be on. And yes, kids will figure out how to hack it, be lazy, say, just give me the answer and so forth. But by the way, look, here is one of the things that I think is an inevitable part of our human future, which is the way that education is going to be assessed is essentially by examination by AI. So you're going to go into kind of an AI booth and it's going to say like say for example, you produce a paper, great. What's going to happen is the AI is going to ask you about the paper. The way you're going to be exam is the AI is going to say great, you produced this paper, so why did you think this? And you're going to have to say why. oral assessments. Yeah. Right. And you're going to have to say why. And so actually in fact I think the standard for learning and the ability to learn in personalized customized way much higher ways as opposed to hacking the exam is now going to get much deeper because of AI. There may be some transition issues but the end state is going to be much much better for human cognition. Yeah. Okay. Okay. So, that's that's really interesting because take-home homework is, you know, there's a lot of students right now that are just using AI to write it up for them. And so, you're saying uh oral assessment is probably going to be a gold standard for seeing how a student is doing. Okay. Which we get infinite and free from AI. Right. Right. And then I'm conflicted. Uh I I would prefer that my child's school don't use doesn't use screens or uses technology less. Yeah, but of course I'm a technologist. I use screens all day every day. It's literally my job. And and so I'm quite conflicted on this and um like I want my children to learn about artificial intelligence in the school. How how do you square these two different conflicting ideas that I don't want them using screens a lot, but also I do want them using AI in the context of the classroom. Well, if people haven't started using audio with AI, they must like it. It is it is really key. So, it's very easy to actually in fact have both devices but also interface points or that say H audio, right? So, as opposed to being locked into your screen, you know, you've got various kind of, you know, audio audio format. And so, that's that's one kind of hack that can do it. But also, I think that part of it is also the design of AI where the AI is saying, \"Hey, we're trying to um like I think we want AI that says, \"Hey, we're trying to nudge you into productive interactions with other human beings.\" That's the that's the humanist design principle we have. I gave some speeches in in Italy and Bolognia and Peruia on this. Um I actually had Reed AI give that the Perua speech in Italian and Hindi and Chinese because it's about human connection. Yeah, I want to think about what might change your mind as an optimist. So, you're an optimist now. What would you have to see? Is there concrete ev evidence, technical, social, political, that would just say get you to say, \"Okay, we need to pause even if it were were possible.\" Um, what would that look like where you would uh change your optimism? Well, the change of optimism would probably be that we can't get the right kinds of leading groups building AI to be putting most of the right values in it. Right? So for example, if you said, hey, like I would get very alarmed if it was like Russia leading AI things or other kinds of entities doing that. The reason I'm like I'm not an optimist because I'm just like, oh, I'm just, you know, I was born an optimist and it's, you know, it's just my character. It's a rational reasoned optimism. It's a question of you know I've spent the last you know over a decade talking to a lot of the heads of the kind of both the western democracy labs and also some of the Chinese labs and it's like okay there is a humanist focus in many of these that's good it's the shift of that that would make me more alarmed um uh and that doesn't mean I think it's perfect doesn't mean I think there aren't commercial blind spots and things to do. But but by the way, the way that you prevent bad AI is creating good AI, not by, you know, you know, trying to drive down the highway at 3 miles per hour. Yeah. Um, in your book, Super Agency, you talk a lot about iterative deployment, which is the approach that Open AI took. You're very early backer. Um I do you think there's potential for kind of a singular um catastrophic misuse of artificial intelligence uh or or are we on this kind of progressive curve that it's just going to get it iteratively better over time? So there's certainly possibilities of bad use, bioteterrorism, you know, other kinds of things that you want to try to maximize the the the or minimize the possibilities of, right? Maximize the the defense against. Yeah. Um but I think iterative deployment is the best way to get there. Like the normal instinct is to say like for example, you say I am building a car and I want to make sure that there are zero highway fatalities before I launched my car. You'll never launch a car. you'll create this thing that's like a five-tonon monstrosity with a with a 10-ft steel bumper, you know, that only goes 10 miles an hour, you know, etc. And I was like, okay, that just just doesn't work. You have to do it in deployment to go, oh, that's what gets us to airbags. That's what gets us to crumple zones. That's what gets us to and and you'll have some accidents. You try to have just less of the really catastrophic ones, right? But I think the point is if you are doing iterative deployment and you make one mistake where catastrophic uh instances happen then it's like um maybe iterative deployment wasn't the right way. Not saying I personally disagree but I'm just wondering how but the problem is is is there's no way some people argue I disagree with them to to go into the future without some taking of risk. But like here here's so one of the mistakes that people make and this is called existential risk exisk they make is they say can you guarantee me that humans or robots of themselves won't create like a terminator-l like robot of some sort. It's like nope can't guarantee that neither humans nor lower accidents where robots will do that. They say well then shouldn't you just stop? You say, \"Well, your intellectual mistake is looking at existential risk as a singular thing about an increase of probability that there could be a Terminator-like robot.\" Yep. In AI, there's that increase. But also with AI, it's the only way I can think of of defending against both natural and mad man-made pandemic, right? That's another exential risk. I can see it really improving like issues with climate change. I could see it tracking asteroid and asteroids like identifying the asteroids like in a time that we could do something about it. So I think the existential portfolio existential risk portfolio gets substantially improved with AI even when you have the terminator risk. Yeah. Right. And that's the reason I'm bullish on it. And that's the reason why I'm like, \"No, no, creating AI reduces overall existential risk as we steer it, even if I cannot res uh remove the terminator risk to zero.\" And that's part of the reason I'm positive on creating AI and positive on taking that existential risk because it decreases our overall existential risks. Well, Reed, thank you so much for joining me. This has been awesome. Really appreciate it. Pleasure. I look forward to it. Uh, and fun doing this here in Seattle. Yeah, thank you very",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Diálogo sobre os impactos da AGI na economia, na mobilidade social e na governança, explorando como IA, agentes e políticas públicas podem promover crescimento, educação e saúde sem engessar a desigualdade.",
            "resumo": "Reid Hoffman e o entrevistador discutem se a chegada da AGI tornará o capital o único fator de poder e se isso criaria uma 'subclasse permanente'. A conversa enfatiza que a tecnologia, por si só, não determina a estratificação social; o que importa são as instituições e as políticas que promovem mobilidade e educação acessível para todos. Aborda a necessidade de governos atuarem rapidamente na adoção de IA de forma que beneficie trabalhadores, com transição apoiada por 'agentes educativos', médicos e jurídicos, para melhorar acessos e desempenho econômico. O debate também explora o papel dos agentes de IA na web, a colaboração entre agentes e o risco de viés na filtragem de informações. Por fim, há referências à competição global com a China, à ideia de uma 'revolução industrial cognitiva' e à visão de uma governança centrada em valores humanos.",
            "assunto_principal": "Impactos da AGI na sociedade e na economia, com foco em mobilidade social, políticas públicas, uso de agentes de IA na educação/saúde e governança centrada em valores humanos.",
            "palavras_chave": [
              "IA geral",
              "mobilidade social",
              "agentes de IA",
              "educação assistida por IA",
              "saúde assistida por IA",
              "políticas públicas",
              "governança humana",
              "viés de IA",
              "informação na web",
              "protocolos de comunicação entre agentes",
              "competição global",
              "China",
              "transições de trabalho",
              "revolução industrial cognitiva"
            ],
            "resumo_em_topicos": "# Pontos-chave\n\n- Contexto central: a discussão questiona se a AGI pode concentrar poder econômico, levando a uma possível subclasse permanente, e como as instituições políticas podem mitigar isso.\n- Mobilidade social e educação: defende que a tecnologia deve ampliar oportunidades para todos por meio de agentes educacionais acessíveis, não apenas para os ricos.\n- Governo e economia: aborda a ideia de uma \"revolução industrial cognitiva\" e a necessidade de políticas públicas que facilitem a adoção de IA, apoiem transições de trabalhadores e incentivem o desenvolvimento de indústrias robustas.\n- Agentes IA e web: discute o papel de agentes que operam na internet (agent-to-agent) e como isso muda a forma de buscar informações, com foco em confiabilidade e eficiência.\n- Desafios de informação: reconhece que filtros de IA podem introduzir vieses ou reforçar bolhas; destaca a importância de governança, transparência e prevenção de vieses.\n- Aplicações práticas: evidencia usos de IA em educação, saúde (ex.: assistentes médicos, triagem, GP via smartphone) e direito, como forma de ampliar acesso e eficácia.\n- Competição global e políticas de tecnologia: menciona o debate sobre a China, controle de chips e estratégias para manter competitividade, com uma visão de responsabilidade social.\n- Conclusão: enfatiza a necessidade de governança humana centrada em valores, promovendo mobilidade geográfica e social, para sustentar sistemas democráticos diante da adoção de IA.",
            "prompt_tokens": 1869,
            "completion_tokens": 3375,
            "model": "gpt-5-nano",
            "cost": 0.006
          },
          "analysis_time": 51.56878304481506,
          "language": "",
          "view_count": 12091,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@nocodemba",
      "name": "@nocodemba",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "Dna__4QolLg",
          "title": "O que substituirá as landing pages em 2025 (+ modelo gratuito)",
          "title_pt": "O que substituirá as páginas de destino em 2025 (+ modelo gratuito)",
          "url": "https://www.youtube.com/watch?v=Dna__4QolLg",
          "published": "2025-09-20T01:15:46.243524",
          "published_relative": "há 1 dia",
          "duration": "09:25",
          "date_published": "2025-09-19T07:51:39-07:00",
          "transcript_available": true,
          "transcript": "I just built a nocode funnel in minutes and \nit's faster and more powerful than a basic   landing page. In this video, you're going to \nsee exactly how I built it, what the tool is,   and what are the powerful features that give you \nthe ability to get more customers than just a   basic landing page. Thank you to Perspective for \nsponsoring this video. And if you stick around,   I'm going to give you a link to get this free \ntemplate on Perspective that you can use for   your own business. So, I'm going to show you just \nhow easy it is to build a really high quality and   polished funnel with Perspective. And you can go \nto Perspective with the link in the description   to do this alongside with me. What's cool here \nis Perspective isn't just another form builder.   It's designed to qualify leads, score them, and \nplug them straight into your automations. you can   sign up for a free trial, so you don't have to pay \nanything to actually build alongside with me and   see if it works for your business. So, let's go \nahead and click new funnel on the top right. And   there's a lot of templates that we can start \nwith. And there's also a blank if you want to   start from a blank template. And in this case, I \nalways like to do a blank template just when we're   getting started because it helps make sure that \nyou understand everything about the product. So,   it's a blank template and we're going to be able \nto customize it and I'm going to show you how it   works. Just off the bat, I'm really impressed with \nhow clean and nice the design of just the editor   is. I really like that and I like the how just \nlike by default the funnel looks really nice. So,   let's say we want to make a funnel that is going \nto just collect email addresses in exchange for   a discount code just as an example. So, let's \ngo ahead add the headline. Let's say get 50%   off no code MBA. And I'm going to say enter \nyour email to claiming or continue to claim.   Really simple. And then you can see there's a \nresults page as well that you can customize.   And then we also can add in different elements \nhere on the page. So, if I click new block,   you can see all of the blocks that are available \nhere in perspective. There's blocks that are more   marketing blocks. You can add more information. \nThen there's also interactive blocks which   multiple choice quiz video things like that. So \nI think I'm going to show you some templates that   utilize more of these blocks in a second just \nso you can see everything that's possible. But   let's go ahead and say we want to add interactive \nblock which is a form. So let's click on form and   then just by default that's going to pop in. \nI can delete the button that was there before.   I can delete the divider. And then inside the form \non the left side, you can change the design of the   header. We have a tracking ID for the questions. \nYou can also just change the spacing above and   below it, which is really nice. And then for the \ninputs, you can also change what we're asking for.   So there's all sorts of basically preset things \nthat you can ask for here in the form, which is   great. And then we have email and phone number. \nYou can also add inputs here by just clicking   that button and you can delete inputs as well. \nEvery element here ties back to outcomes. You   launch in minute capture better data and instantly \nsee where your leads drop off. So let's say we   don't want a phone number. I can just go ahead and \ndelete that. And then one more thing we need to do   just make sure I have a second page here. I need \nto delete that because we really only have one   page here. And then it's going to the results. And \nthen just to confirm, if we click on the button,   you can go to next page or you can just by default \npush it over to the results. I guess I'm not on   the plan that can do that, but if you upgrade, \nyou can go to specific pages dynamically. But in   our case, it's fine because we're just going to \nthe next page, which works completely fine. So,   it's linking to the next page. So, let's go \nahead and click publish. Our funnel is live.   We can click preview to just view it in basically \na perspective editor. And then you can share this   with your team and leave comments. There's so \nmany little touches that have been built into   this product which I really like. Let's go ahead \nenter in a name. We enter in an email. We'll click   the button and proceed. And then we go to the \nthank you page which is great. And let's say   I want to leave a comment. Improve thank you \npage. I can post that. And then that's there   for someone else on my team to view and resolve. \nSo that's the preview. And then if we publish it,   we can now click. And then here we are on a live \nview of this page. Cookie settings cuz it's GDRP   compliant. And then we would be able to enter in \nthe information in the exact same way. And then we   can go over to metrics. We can see how many funnel \nvisits we have, how many conversions, what's the   conversion rate, pageto page conversion, device \nsplit. Honestly, this is really cool. I could see   myself using this for different lead funnels \nthat I want to use with no code MBA or other   businesses that I'm running. So, if we go over \nto contacts, we can then see, okay, now we have   a contact. But what's cool is it has a CRM that's \nbuilt in. So, if you want to use this for sales,   let's say you're a realer, for example, and you \nhave a lead funnel. And then once you have leads   come in, you can move them into different parts \nof this funnel. You can also change the name of   each of these steps. So, there's a lot of things \nthat you can do here, which is pretty cool. Next,   we have apps. So you can basically connect \ndifferent apps to perspective. So first you   have lead notifications which is that could be \nreally important sending an email with available   details when a lead is captured in a funnel. This \nis something that you would need to upgrade to   access. We also have make which allows you to \nbasically connect your funnel in perspective to   any third party. You don't need to upgrade if you \nwant to just use something like make and connect   it to make and then build your own automation. You \nhave all of these other automations as well. Also   through Zapier you have additional automations. \nNow I'm going to show you some more template   funnels in a second, but first I did promise I \nwould share the link to get this template that   Perspective made for us specifically for this \nvideo. And you can see it's a lot more built out   and polished than the one that we just created \nto show you what's possible. So to do this,   just click the link in the description, enter in \nyour information. You'll get 30 days for free on   perspective and you will also get access to that \nlead magnet template that I just showed you. All   right, so real quick before we move on, I just \nwant to show you one more funnel, but this time   we're going to do it from a template. So let's say \nyou are a coach, you have a coaching offer. We're   going to start with this template. And again, \nonce you have your free trial, you can go in   and test out all of these templates. So here we \nare in this template. You can see it's a lot more   built out. You can even add a video. It's just \nreally polished. There is line items, list items.   You can customize all of this. And then it's \nbasically a full landing page that is built in   as a funnel. So you can think of it almost like a \nwebsite landing page. It doesn't just have to be a   very simple form. This is why I like perspective. \nInstead of building a landing page from scratch,   I can take a template, customize it, and then be \nlive in a few minutes. You can also go down to   the bottom and view it as a desktop. So this \nis what it looks like on mobile. Of course,   a lot of people are going to go to your funnel on \nmobile, but you can view it on desktop as well.   So, when you're doing a more complicated funnel, \nI definitely recommend using one of the templates   because it's just so much easier, and you \nbasically just have to enter in your information,   and it's going to look really good right off the \nbat. So, there's all these buttons. All of them   are going to the next page. It's all going through \nthe funnel. So, we can see once someone clicks   that button, it goes on to this next page, which \nbasically is going to prep the user to be ready   to enter in more information. We have a quiz that \nit's starting. We have a price range, position,   budget. So, we're getting more information about \nthe user as we go. There's an optin. This is all   really cool. I really need to think about how \nI can use this inside of note. And then there's   thank you page. Really cool. And then a video as \nwell. One thing that I didn't show you before is   this messages tab, which as you can see it's in \nbeta, but I do want to mention this. So here,   when there's an appointment booked, when the \ncontact status is new, we are sending an email.   So you can build this out to basically have some \nautomations to send an email to users when certain   things happen. And of course, in this template, \nyou can customize it fully, and when you're ready,   you can publish it to your own account. Real \nquick, let's just jump into one more cuz I was   really impressed with the last one. So, let's say \nwe want to do a webinar. So, let's start with this   template, your webinar template. Webinars can be \nused for just about any business. And here we go.   We can see really cool how it just has this all \nbuilt out. Once people would click on that link,   we go to customization just to get some more \ninformation about our users. And then to sign up,   they would enter in their information and \nthen at that point they would be signed up   and then you would have their information \nto then send them through automations like   we talked about before. Send them an email. You \ncan go into messages and by default we have this   message sent. Hope you enjoy this overview. As \na next step, click the link in the description,   copy this free funnel and test perspective free \nfor 30 days. We're building apps with AI or no   code. The fastest way to get paying customers for \nthose projects. Subscribe to our YouTube channel   to get more free content like this and leave a \ncomment below and let us know what you think of   perspective and if there's anything you want us \nto cover in the future. We'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Mostra como criar um funil no Perspective, uma ferramenta sem código que substitui páginas de destino, qualifica leads, automatiza ações e usa modelos para acelerar resultados.",
            "resumo": "O apresentador mostra em minutos como criar um funil no Perspective, plataforma no-code que vai além de uma landing page: qualifica leads, pontua e se integra a automações. Ele constrói um funil para coletar emails em troca de desconto, personaliza blocos, formulários e páginas de resultado, e demonstra métricas, CRM embutido e envio de notificações. Também explora templates prontos, opções de integração com Make/Zapier, e a possibilidade de compartilhar com a equipe. O vídeo ainda oferece um template de lead magnet e 30 dias grátis para testar.",
            "assunto_principal": "Substituição de páginas de destino por funis sem código com Perspective em 2025",
            "palavras_chave": [
              "sem código",
              "funil",
              "perspectiva",
              "página de destino",
              "pontuação de leads",
              "qualificação de leads",
              "CRM integrado",
              "modelos",
              "blocos de conteúdo",
              "formulários",
              "integrações (Make",
              "Zapier)",
              "cookie GDPR",
              "rastreamento de leads",
              "ímã de leads",
              "teste de 30 dias"
            ],
            "resumo_em_topicos": "Resumo em tópicos\n- O que é Perspective: plataforma no-code para criar funis, não apenas formulários.\n- Por que substitui landing pages: oferece qualificação de leads, automação e CRM integrado, com criação rápida.\n- Como usar: criar novo funil, escolher template ou começar do zero, adicionar blocos (blocos de marketing, blocos interativos, formulário), configurar páginas e publicar.\n- Funcionalidades-chave: blocos de conteúdo, formulários, páginas de resultado, métricas (visitas, conversões, taxa), CRM, notificações de leads, integrações com Make/Zapier.\n- Experiência de uso: editor limpo, design agradável, visualização mobile/desktop, compartilhamento com equipe.\n- Casos de uso e exemplos: captação de e-mails com código de desconto, funis para coaching, imóveis, etc.\n- Ofertas especiais do vídeo: template de lead magnet e 30 dias grátis de Perspective.\n- Observações técnicas: conformidade com GDPR (configurações de cookies).",
            "prompt_tokens": 2090,
            "completion_tokens": 4001,
            "model": "gpt-5-nano",
            "cost": 0.007
          },
          "analysis_time": 66.74742078781128,
          "language": "",
          "view_count": 287,
          "has_transcript": false
        },
        {
          "id": "gYz_m6hcWys",
          "title": "As planilhas estão mortas! Criei um painel de IA incrivelmente poderoso com o Databutton",
          "title_pt": "Texto: As planilhas estão mortas! Criei um painel de IA incrivelmente poderoso com o Databutton",
          "url": "https://www.youtube.com/watch?v=gYz_m6hcWys",
          "published": "2025-09-19T01:15:46.243596",
          "published_relative": "há 2 dias",
          "duration": "06:38",
          "date_published": "2025-09-18T09:25:02-07:00",
          "transcript_available": true,
          "transcript": "DataButton lets you build AI apps that help you \nwork 10 times faster and perform way better in   your day-to-day. It's one of the few AI builders \nout there that helps you create internal apps   that actually helps you perform better in work. \nWhether that's as an owner or as a marketing lead   at your company, Databutton can help you create \ncustom tools that you can use inside your own   workflows. In this video, we're going to build a \nmarketing dashboard with an AI churn detector to   show you what's possible in databutton. Thank \nyou so much to DataButton for sponsoring this   video. I'm so excited to show you what is possible \nwhen we build with databutton. So, here we are in   the app builder. I've put our prompt in which \ndescribes that we want to build a marketing   dashboard with the churn detector. So, we're \ngoing to hit continue here. We can upload more   information about the app such as requirements, \nuser stories. In our case, I'm going to skip this   for now. We can always add more later. And then \nfor design inspiration, I've just grabbed a really   nice dashboard off of Dribble and we're going to \nuse that as our design inspiration here. So, let's   get started. So, here we are in our databutton \ndashboard and we have five tasks that databutton   created for us. It's already starting to work on \nthe first task here. And then on the right side,   you can see the agent is basically creating \nsubtasks inside of each task and marking them   off as it gets done. So that's something that's \nnice about databutton is that it is going to be   thinking through what it's building as it does \nit. It's also going to help debug any issues   automatically without you having to intervene. \nNow what makes databutton nice for businesses   is its ability to integrate with other services. \nSo one example of that is the open AI integration   we're going to add in. But you can also add in \nother data sources. So in this app we're using   dummy data just to show what's possible. But you \ncould build an integration with something like   Mix Panel, with something like Google Analytics to \nbring in your real business data into databutton   and then build apps around that. So we're going \nto mark the first task as done. And then what it   should do is automatically start working on our \nsecond task. Now what you always can do is type   messages and have a human in the loop to look at \nwhat's happening. You can modify it, but in this   case, we're just going to move on to the second \ntask and continue building this out. you're going   to want to stick around until task number four \nto build out the open AI connection cuz I think   that's going to be the coolest part of this build \nis building in this additional functionality. The   other thing that makes databutton nice for using \nit in a business context is it's flexible enough   for developers who understand all of the code and \neverything behind the code and the database and   what's happening. But it's also easy enough to use \nfor someone non-technical to build with it or get   something started and then pass it off to someone \nmore technical. Okay, so we finished that task as   well with setting up the database schema. You can \nalso go to users and data here at the top and you   can view and test this out. We have customers \nand daily metrics. This is just some dummy data.   Again, you can integrate with your own marketing \ntools using data bug and ask the AI to do that   to actually have your own data in here. But this \nis the dummy data here in the database. And it's   really cool that databutton can configure all of \nthis for us. And if we go to the preview tab here,   we can see the pages that it created already. We \ncan see the components, UI, files, APIs, library.   So everything here is accessible. You can see \nboth the preview and you can also edit the code   directly. So we finished this third task. So we \ncan complete that. And now we're moving on to what   I am most excited about is building the AI churn \ndetector. And this is where we can really show   off data buttons capabilities of integrating with \nother services. So, it's asking if I have an API   key. So, I'm going to say yes, I do have an API \nkey for Open AAI. I'm curious. I think it should   pop up here and ask me to enter it. Now I can go \nover to my other screen, go to my OpenAI account,   and if you don't have an OpenAI account, you can \ncreate one for free, and then just go to the API   keys tab, create a new secret key, and what I'm \ngoing to do is just copy that in here. And this   is basically like a password into your OpenAI \naccount. That's how API keys work. So that way   we can send messages to OpenAI and then get \na response back. So I just saved it. And what   also is nice about databutton is it saves them \nsecurely. So, it puts it into the secrets so that   your key isn't going to get leaked. So, let's go \nahead and start the task. And what it's going to   do now is start building out this AI functionality \nfeature. I'm very curious to see what this ends up   looking like. So, it says it completed this step \nfive. What I'm going to do is test this out. So,   I'm going to go to the preview tab on the top \nleft. DataButton created this authentication   component. So, the ability to sign in to our app. \nSo, let's quickly create an account. And here I   am inside of our dashboard and we can see it's \npulling in the dummy data. So it's showing us   customers MRR things like that. So we have this in \nour dashboard and then if we go over to the churn   detector and here we can see it looks like the \nAI detection is happening. We have this loading   indicator and in a second we're going to see back \nwhat the AI model is saying. So it's been loading   for a little while. What I'm going to do is send a \nscreenshot of this to our agent and just ask it to   verify if it's working. So this is where chatting \nwith the agent can be really helpful. So what I'm   asking is to add a button to start the churn \ndetection, which I think is going to be helpful   maybe in making this work, but also in helping \nus debug it if it's not running again. All right,   so now it is fixed. Something that might help \nyou if you're debugging is just to tell the AI   to review all of the code involved, which can help \nit take a step back instead of just continuing to   go down the same path that doesn't work. So this \nis very cool. Now we have a list of our customers   with a churn risk score and also a reason of why. \nSo this says very low NPS and short tenure such as   high churn risk. So a lot of it here is based \non tenure and NPS. But of course this is only   going to get better as we would add more data \ninto it. So we have this AI churn detector now   working. So I hope that you enjoyed this video \nand are thinking about how you can use databutton   for your own business. I can already see how \nbuilding these AI features on top of our data   like this churn detector or other features are \ngoing to help bring much more power to this type   of data than a spreadsheet or even other tools \nlike Google Analytics. So, you're going to be   able to customize your analysis on top of what you \nalready have. Leave a comment below to let me know   if this is something that you would use in the \nfuture. And be sure to subscribe to our YouTube   channel to get more free content like this. Thanks \nagain for watching. We'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Demonstra como criar, com Databutton, um painel de marketing equipado com um detector de churn alimentado por IA e integrações com OpenAI, para transformar dados em insights práticos sem depender de planilhas.",
            "resumo": "Neste vídeo patrocinado pela DataButton, o apresentador mostra como construir um dashboard de marketing com um detector de churn usando o Databutton. O fluxo começa com a configuração de um app, definindo requisitos e inspirações visuais, e, em seguida, criando tarefas com subtarefas que o assistente de IA vai completar automaticamente. O benefício principal é a capacidade de integrar dados de ferramentas como Google Analytics ou Mixpanel e gerenciar segredos com segurança, incluindo a chave da API do OpenAI. Após configurar o banco de dados com clientes e métricas diárias (dados fictícios), o vídeo demonstra a criação de autenticação, visualização de componentes e a cópia de dados entre telas. A parte mais empolgante é o detector de churn alimentado pela IA, que analisa clientes e apresenta um risco com razões como NPS baixo e curto tempo de relacionamento, tudo dentro de um painel personalizável.",
            "assunto_principal": "Painel de marketing com detector de churn alimentado por IA no Databutton",
            "palavras_chave": [
              "Botão de dados",
              "Inteligência Artificial",
              "detector de rotatividade de clientes",
              "painel de marketing",
              "integração com OpenAI",
              "segurança de chaves",
              "dados simulados",
              "Google Analytics",
              "Mixpanel",
              "sem código",
              "automatização de tarefas",
              "assistência de Inteligência Artificial"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto e objetivo: demonstração de construção de um painel de marketing com IA no Databutton.\n- Configuração inicial: definição de prompt, requisitos e design inspirado.\n- Execução de tarefas: IA gera subtarefas, avança autonomamente e facilita depuração.\n- Integrações e dados: conectores com a OpenAI, dados simulados e a possibilidade de ligar a ferramentas reais (Google Analytics, Mixpanel) com segredos seguros.\n- Dados e UI: criação de banco de dados, visualização de componentes, páginas e APIs disponíveis.\n- Detecção de churn: implementação da IA, autenticação, exibição do risco de churn e razões (NPS baixo, relacionamento curto).\n- Benefícios empresariais: personalização, maior poder analítico e vai além das planilhas.\n- Considerações finais: uso prático, convite para comentários e próximos passos.",
            "prompt_tokens": 1951,
            "completion_tokens": 3071,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 57.89071989059448,
          "language": "",
          "view_count": 590,
          "has_transcript": false
        },
        {
          "id": "gqqzvGvqKr0",
          "title": "A nova IA do Bubble pode vencer Lovable e Base44?",
          "title_pt": "A nova IA do Bubble pode vencer Lovable e Base44?",
          "url": "https://www.youtube.com/watch?v=gqqzvGvqKr0",
          "published": "2025-09-18T01:15:46.243616",
          "published_relative": "há 3 dias",
          "duration": "08:21",
          "date_published": "2025-09-17T08:10:01-07:00",
          "transcript_available": true,
          "transcript": "Bubble has an AI app builder and in this video \nwe're going to test it and see how it compares   to tools like Base44 and Lovable. Now, I've been \nusing Bubble for more than 3 years to build fully   functional web apps from scratch without writing \ncode. It's one of the most powerful nocode tools.   It integrates a database, logic, everything in \none. It can integrate APIs. I'm a really big fan   of Bubble. But with these new AI app builders like \nBase44 and Lovable, a lot of people are asking,   is it still worth using Bubble? And is Bubble \nbuilding the AI features that make people really   love using these new tools? So, while I still \ndo use Bubble for complex projects, I am really   curious to see how their AI app building feature \nworks. So, we're going to do it together. The   prompt we're going to use is a discovery app for \nfood lovers to find nearby restaurants and read   reviews. So, it's a little bit like Yelp. It's \ngoing to have a modern design with warm colors and   food photography. Let's go ahead and send this off \nand I'm going to pause the video so you don't have   to wait while it's generating. So, what comes next \nis Bubble gives us this screen and it allows us to   edit our app blueprint. So, it's coming up with \nthe key features. Search restaurants, restaurant   ratings, user reviews, user authentication, save \nfavorite restaurants, and view restaurant details.   And if you want, you can refine the app blueprint. \nSo, what I'm going to do is say make sure user   reviews and include photos the user uploads. So, \nlet's go ahead and add that. And then bubble in   the back end will analyze the input and update \nour app blueprint. And just like that, our app   blueprint is updated. And now user reviews with \nphotos is included in the key features. So, it's   nice that it was able to do that before we start \nactually building out the app. So, let's click   generate. And Bubble says it's going to take about \nfive to seven minutes to generate this version   of our app. Now, I do think this is the future \nof where AI app building is going. Having this   ability to have the AI generation do the things \nto get yourself up and running really quickly, but   then also having full control, visual control over \nall the logic, over everything that's happening.   So, it's not a black box. because when I build \nsomething in cursor, I don't necessarily know   exactly what's happening in the code if I can't \nunderstand it. So, you do have to trust your AI to   translate that code into English. Now, what Bubble \nis able to do is translate that code into a visual   language where you can view the workflows and see \nwhat it looks like. So, let's pause the video and   I'll come back once we have something to look at. \nAnd here we are in the MVP that it created. So,   I'm going to walk through what it created. I'm \ngoing to explain both if you are familiar with   Bubble and also if you're not familiar to talk \nabout the dashboard and what it built so you   understand if this is something that's for you. So \nright now Bubble will generate the first version   of the app. It's not like base44 or lovable where \nyou have a sidebar to keep asking for updates. I'm   hoping that this is something that Bubble creates \nin the future because I think that would be really   powerful but right now that isn't something it \ncan do. But the fact that it can create the first   version makes me think that's something it will \nbe able to do in the future. But this is really   nice because if you're just starting from scratch \nand bubble from a blank page, it actually does   take a lot of time to build out everything that \nyou see here. Like even just the sign up login   that I see it has it all branded. Like this takes \na lot of time in bubble because you have to do it   manually. There are certain like ways to have \ntemplates or plugins to help but generally this   takes a long time. So like as someone who's built \nin bubble a lot and built out these types of MVPs   with authentication, database everything like this \ncould save me like 3 hours of work and it took 5   minutes. So just getting that initial setup is \nreally helpful. Let's start with the database.   So we can see it created the initial version of \nour database. It created a favorite, a restaurant,   and a review. And we can see it did include \nthat image that we asked for. If you're used to   lovable, they have Supabase. If you're thinking \nof base 44, they have the database integrated.   Bubble has the database integrated. So, it's all \npart of the same platform. The downside of that   is you can't export the database, but it is really \neasy to get set up and use. And in my experience,   works really well. So, you also can use bubble AI \nto generate more of the database. So, basically,   if you want to build out an additional feature \nand you're not as familiar with how to set up   databases, Bubble can do this. They even have this \nability to generate privacy rules which actually   is really helpful with databases because it's very \ncommon when people are building with bubble to   not know to set up these privacy rules which will \nthen for example potentially expose all the data   to anyone who wants it who knows how to access \nthat. So that's a really nice feature. So Bubble   is starting to incorporate these AI features \ninside of their builder as well. Why don't we   start on the design tab and then talk about some \nof the logic. So if I we go to this search button   and we click edit workflow. Yeah, it created all \nof these workflows for us which would have taken a   lot of time. So it's doing this by itself. Really \ncool that it was able to do that. Of course,   you do need to understand how bubble works. We do \nhave a course on no code MBA if you want to learn   about that. But if we click on search and edit, \nwe can see all the different workflows here. This   is the workflow tab. And we also can test it \nout which I'll do in a second. But then also   we see featured restaurants. So it just built out \neverything, all the repeating groups, the groups,   the filters. Okay, that's really great. Now, if we \ngo into the database and we go to app data, we can   also see that there are test users, there are test \nrestaurants, reviews, and users. So basically,   it added in dummy data, which I think is also \nreally nice. So that way we can click preview and   see what it looks like with live data. So we're \ngoing to open this up. We can see it's showing   us restaurants. Of course, there's only a few \nfeatured restaurants right now, but let's search   for cuisine. Looks like it did just accidentally \ndo like white text over a like input, but so that   would be something to easily change. But let's \ndo all cuisines. Search restaurants by name. So,   I could say Takaria because I know there's a \nrestaurant with that here. Let's search. And there   you go. So, that's showing up correctly. And I \nwonder if I leave that blank but I put it to like   Mexican, will that work? Yes. And now it's showing \nall the Mexican restaurants, Japanese. Okay,   cool. And then if I click on view details. Okay. \nSo that's where it looks like it has not built   out more yet. So I can't click on view details. So \njust to confirm, let's go to view details. And you   can see yes, it's add workflow instead of edit, \nwhich means that it hasn't been created yet. So   it didn't create the details of the restaurant \nlike page like that doesn't exist. It does have   it looks like a favorites page that I created. It \ncreated the restaurant detail page, although it   looks like it's empty for the restaurant details. \nSo, that would be like that would be like the page   that you would go to for more details, which \nit hasn't built out yet. There's a restaurants   list that it built out a user reviews popup, which \nyou can click here to see to leave a review. So,   we'll build in some of this logic. And if we go \nto the workflow, we can see that it has, if we   click submit review, edit workflow, it has the \ncreate a new review. And so, it it did a lot of   these things for us. Now, if you are experienced \nwith Bubble, this is a really great shortcut when   you're getting started with an app. If you're \nnew to Bubble, you're going to probably get   stuck unless you are willing to put in a little \nbit more effort to learn more about Bubble. So,   in that case, what I would love to have them do \nis have like a sidebar where I could say, hey,   like I want to add the view details page, nothing \nhappens. Can we make it so we view details of the   restaurant when the user clicks it the same way \nwe would do a base44, for example? And then it   would add that. So, that's what I would love \nto see in the next step. I hope that they're   working on this and they're able to do this soon \nbecause that would be really awesome. Overview.   I'm really impressed with the first generation \nthat it built out all the workflows. I think it   saves a lot of time if you're just building \nan app in Bubble, especially if you already   understand how to keep building with it. Now, \nwhat I hope they do is add in more AI features   so that it can keep building without you having \nto node bubble yourself. So, I hope that this was   helpful. Leave a comment below. Let me know what \nyou think of this tool, if it's something that you   would use yourself. Subscribe to our YouTube \nchannel to get more free content like this.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise prática do construtor de apps com IA do Bubble, comparando-o com Base44 e Lovable, e demonstração de criação rápida de MVP de um aplicativo de descoberta de restaurantes.",
            "resumo": "Neste vídeo, o canal testa o construtor de apps com IA do Bubble e o compara com Base44 e Lovable. O narrador, que usa Bubble há mais de 3 anos, demonstra como funciona a geração automática de um MVP: um app de descoberta de restaurantes para encontrar locais e ler avaliações, similar ao Yelp. Ele descreve a criação do blueprint do app, incluindo recursos como busca de restaurantes, avaliações, autenticação, favoritos e detalhes de cada estabelecimento, e mostra como ajustar o blueprint para exigir avaliações com fotos enviadas pelo usuário. A geração inicial demora alguns minutos, mas resulta num MVP já com banco de dados integrado, regras de privacidade e dados de exemplo. O vídeo destaca o equilíbrio entre IA e controle visual, a utilidade de ter o backend automatizado e o ganho de tempo, além de apontar limitações, como páginas ainda não totalmente construídas.",
            "assunto_principal": "Avaliação do Bubble AI App Builder vs Base44/Lovable e demonstração de criação de MVP para aplicativo de descoberta de restaurantes",
            "palavras_chave": [
              "Bubble",
              "Inteligência Artificial",
              "sem código",
              "construtor de aplicativos com IA",
              "Base44",
              "Lovable",
              "Produto Mínimo Viável",
              "aplicativo de descoberta",
              "restaurantes",
              "autenticação",
              "banco de dados",
              "privacidade",
              "fluxos de trabalho",
              "teste de dados"
            ],
            "resumo_em_topicos": "## Contexto\nO vídeo analisa o novo construtor de apps com IA do Bubble e compara com Base44 e Lovable, discutindo se ainda vale usar Bubble.\n\n## O que o Bubble faz\nMostra a geração do blueprint do app, definição de recursos, integração de banco de dados, regras de privacidade e workflows.\n\n## Processo de construção\nO MVP é criado a partir de um prompt (discovery app de restaurantes); a geração leva alguns minutos e, depois, é possível editar as workflows visualmente.\n\n## Dados e banco\nBanco integrado, dados de teste são criados, privacidade configurável; exportação do banco não é mencionada como opção obrigatória.\n\n## Design e workflows\nDemonstra a interface, buscas, filtros e detalhes de restaurantes, além de visualizar as workflows geradas pelo Bubble.\n\n## Limitações\nAusência de sidebar para updates ao vivo; páginas como detalhes do restaurante ainda não totalmente criadas; é necessário conhecimento de Bubble para ajustes.\n\n## Conclusão\nA IA do Bubble acelera a configuração e entrega de um MVP rapidamente, mantendo controle visual; aponta para potencial de evolução futura e maior integração de IA no fluxo de trabalho.",
            "prompt_tokens": 2055,
            "completion_tokens": 3252,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 58.954883098602295,
          "language": "",
          "view_count": 556,
          "has_transcript": false
        },
        {
          "id": "voLsGe0Swbk",
          "title": "Você pode nunca mais usar o Figma depois de usar esta ferramenta de IA",
          "title_pt": "Você pode nunca mais usar o Figma depois de usar esta ferramenta de IA",
          "url": "https://www.youtube.com/watch?v=voLsGe0Swbk",
          "published": "2025-09-16T01:15:46.243633",
          "published_relative": "há 5 dias",
          "duration": "09:16",
          "date_published": "2025-09-15T08:30:48-07:00",
          "transcript_available": true,
          "transcript": "Once you start using Magic Path, you might never \ngo back to Figma. Magic Path is an AI designer   with some really powerful features that I'm going \nto go over in this video. You're going to want to   make sure to stick around till the end because \nthere's a really advanced component feature that   you're going to need to know about. This tool \nis changing the way that I prototype myself   and I'm excited to share it with you. Thanks so \nmuch to Magic Path for sponsoring this video.   We're going to build some custom designs in this \nvideo, but first I want to explain the dashboard   and all the different features we have inside of \nMagic Path. So, here we are in the dashboard. It's   pretty simple. You can create a new file. This is \nsimilar to creating a new Figma file. You'll see   just in a second. You have your files. You can \nshare files with a team. So, it's collaborative.   And there's a really cool community tab. In \nthe community tab, you can duplicate designs   that other people in the community have created. \nI'm going to start here because this is a really   great way to show the power of Magic Pad in \na really quick way. So, let's jump in to an   example. We'll just jump into this file that was \ncreated by the community and I'm going to show you   the different parts of the file editor. So, what \nyou can do is view it just as this view only mode,   but you can copy the files in the community over \nto your own designer. So, then you can edit it   and then now I can show you all the features \nthat it has. So, very similar to Figma, you can   drag your file around the canvas. You can use your \ntrackpad to zoom in and zoom out. If we click into   a specific element or a page here, uh you can see \nthere's an edit component and there's different   ways to edit just directly almost in a no code \nway. This is a little bit more similar to Figma.   So, you can go in and have access to everything. \nSo if you just want to make a small refinement,   you can do that. But we also have this ask Magic \nPath feature. This is what makes Magic Path a   really cool AI designer is that you can just write \na message here into the chat and then Magic Path   will use AI to redesign or make the changes \nthat you want. And you could have multiple   components here on the page. On the top left, we \nhave components. We also have something called a   design system inside of Magic Path. So, Magic Path \nhas default design systems. For example, you can   just use like the Twitter design system, Airbnb. \nThis includes a lot of details such as the color   palette, component examples, and then colors, \ntypography, effects, rules, everything that you   would need for a design system. And you can create \nyour own system and save it, which is great. If   you have your own company, you want to save it \nwith your own branding and everything. Then,   every time you design in Magic Path, you're going \nto have your own design system. Now, there's one   really powerful feature here. So, if we wanted to \neither edit a component or down here on the top,   create a new component. What you can do is \nreference each of the components inside of this   chat. So, you just type the at symbol and then \nyou can reference any of these components. So,   just to show you this, let's create a new \ncomponent here. We'll do component 4 and why don't   we say ask magic path. So I'm going to say create \na similar dashboard to and I'm just going to do   supply chain dashboard builder. So we're going to \nreference this on the top left dashboard. But why   don't we say make the inside of the dashboard show \nactual widgets as if there were widgets selected.   Let's not add a design system because we're \nreferencing this for now. And let's go ahead and   send that message. So, we sent the message asking \nit to create a similar dashboard, but I'm adding   on to it. So, we did this just by referencing \nthis component. This is a really powerful feature   that you're going to want to use a lot if you \nare using Magic Path and it's something that's   going to save you a lot of time. Here we go. We \nhave our new component created and you can see   it perfectly referenced this first component. \nIt looks very similar on the top and left side,   but then it added in these example widgets. Now, \nof course, this might not be the exact way you   would want to use it. you might want to create the \nwidgets individually, things like that. But I just   wanted to show you what's possible here with this \nreference capability of the components. Okay, so   now that we've jumped into one of these examples, \nlet's jump in and create our own file from   scratch. So we're going to create click new file. \nAnd they give you some examples here. Or you can   start from scratch on the bottom or double click \nanywhere, which is also a kind of cool feature   that they have. So we double cllicked. We have a \nnew component here. So let's say we want to create   a mobile app sign up sign in page for a music \napp like Spotify. And then for the design system,   let's go with the Airbnb design system. You can \nalso add an image if you want, but in our case,   we're going to just go with the front. So now \nwe'll just wait a second for the design to   finish. I'll pause the video and come back once \nour initial design is created. Okay, so here we   have our app screen that was just created. We can \nsee it also created some nice animations here and   we can of course edit it both with chat. So we \ncan ask magic path to make edits or we can use   the edit component. Click on any of these elements \nand make changes. And it did use the Airbnb style   that we decided. So let's do something cool here. \nI'm going to add another component. Just double   click. I'm going to say build the next page in \nthe onboarding screen and then reference music   app off page is the first page in the flow. So I'm \njust curious what it's able to do here. I'm going   to send this off. It says great. What should the \nnext onboarding page focus on? User preferences,   profile setup or something else. So cool that it \nunderstood that. So let's say profile setup. And   then there we go. Now it's designing. Okay. And \nwe have our second app screen here. One thing   to note is sometimes it might generate it in a \nwider element but all you have to do because it   did generate it as an app screen is just reduce \nthe width to make it match. Okay. So now let's   create one more component. I'm going to say here \nare the first two components in our flow. One is   the off page. Two is the profile setup. I'm going \nto say now please design a homepage for logged in   users that would show up as the third screen and \nI'm going to say make it a native app design. So   I'm going to send that off and let's see what it \nlooks like. Okay, so here we have our app screen   and it looks really good. Looks like a Spotify. It \ndid do it in dark mode which is interesting but it   still matches all of the design. So one thing we \ncan do here just to show you one more cool feature   is we can go and click create variants. So if we \nclick create variance, we can modify it with a   prompt. So I can say make a light version of this. \nThis is dark mode. And I can send that off. And   now it's going to create a variant of this same \ndesign. Okay. And now we have a variant. It's   also generating a second one at the same time. But \nwe have this one. And I actually think this looks   really good and is exactly what I asked for to \nmake a variant that was in light mode instead of   dark mode. Everything actually looks exactly the \nsame. It just changed the design of the app. And   what's cool is it'll create multiple variants \nat once. So if you want to wait around longer,   you can get multiple variants to choose from. \nHere we can see the other variant was created.   So it was cool that it was able to create two. \nAnd I actually might prefer the second one. So   it's cool that it creates multiple ones at the \nsame time. Okay. So let's go ahead and go back   out. And one more thing I want to show you is \nopening in a new tab. So if you click that,   we can now view the design in a new web browser. \nAnd this is really great for prototyping. You   could change your screen size. So view it mobile. \nThis is what it looks like on the web. But it's   great that we have that feature that we can \ngo into any of these components and view it   out of this canvas and what it would actually \nlook like. Finally, we have a share feature.   So we can go ahead and add people by email or \nadd current members of our team to share the   project and be able to work on it themselves \nlike Figma where it can be collaborative. Now,   the last thing I'm going to show you before we \nleave is just this template file that Magic Pad   has for us. I'm going to copy it into our own \ninterface just to show you what's possible.   Really, really impressive. You really can create \nanything that you can think of. Click the link in   the description to go to Magic Path and create \nyour own designs and prototypes. And this is   really helpful if you want to then build an AI \napp afterwards to get your prototype locked in.   Make sure that it's what you want. And then you \ncan feed these into an LLM like Lovable or Bolt   to actually create this and turn it into something \nreal with a back end. So here we can just see some   example designs that Magic Path created. We have \na note app, a calorie counter app, food delivery,   Instagram, weather app, all sorts of different \nthings created here in Magic Path. It's $0 to   get started. You get five component credits a day. \nSo, you can come in, try it completely for free,   and then upgrade if you want even more. Leave a \ncomment below if you have any questions at all   or if there's anything you want me to cover \nin the future, and subscribe to our YouTube   channel to get more free content like this. \nThanks for watching. We'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Magic Path é uma ferramenta de design baseada em IA que promete revolucionar a prototipagem, oferecendo edição por chat, componentes reutilizáveis e sistemas de design com geração de variants, potencialmente substituindo o Figma.",
            "resumo": "Neste vídeo patrocinado pela Magic Path, o apresentador explora o painel simples, criação de arquivos, colaboração com a equipe e a aba Comunidade para duplicar designs. Demonstra edição de elementos e componentes, uso do recurso 'ask Magic Path' para redesenhar via chat, e como os sistemas de design (padrões como Twitter/Airbnb) podem ser usados ou customizados. Mostra a criação de um app móvel: cadastro, onboarding, configuração de perfil, escolhendo o design system Airbnb, e gerando variantes (claro/escuro) com várias opções ao mesmo tempo. Também destaca a referência de componentes via @, que facilita reutilização e acelera a prototipagem, além da edição direta no editor para refinar layouts e widgets.",
            "assunto_principal": "Avaliação de Magic Path como ferramenta de design assistida por IA para prototipagem, comparação com Figma e construção de componentes, com foco em sistemas de design e geração de variantes.",
            "palavras_chave": [
              "Caminho Mágico",
              "design de IA",
              "sistema de design",
              "componentes",
              "referência de componentes",
              "comunidade",
              "edição por chat",
              "variantes",
              "modo claro",
              "modo escuro",
              "Figma",
              "prototipagem",
              "colaboração",
              "Airbnb",
              "Twitter"
            ],
            "resumo_em_topicos": "### Contexto\n- O vídeo apresenta o Magic Path, uma ferramenta de design assistida por IA, com potencial de patrocínio.\n\n### Principais recursos\n- Painel simples\n- Criação de arquivos, colaboração em equipe\n- Aba Comunidade para duplicar designs\n- Edição de elementos e componentes (sem código, parcialmente)\n- Recurso 'ask Magic Path' para redesenhar via chat\n- Sistemas de design padrão (Twitter, Airbnb) ou criar o seu próprio design system\n\n### Fluxo de prototipagem\n- Criar arquivo, escolher o design system e iniciar\n- Construção de telas de aplicativo móvel (cadastro, integração, configuração de perfil)\n- Gerar variantes (claro/escuro) e manter a consistência\n- Referência de componentes via @ para criar novos componentes a partir dos existentes\n\n### Considerações finais\n- Aceleração da prototipagem e economia de tempo com referências de componentes\n- Edição visual direta no editor e exploração de várias opções",
            "prompt_tokens": 2091,
            "completion_tokens": 4945,
            "model": "gpt-5-nano",
            "cost": 0.0085
          },
          "analysis_time": 72.04125714302063,
          "language": "",
          "view_count": 760,
          "has_transcript": false
        },
        {
          "id": "yNVkufbhpvw",
          "title": "Novo fluxo de trabalho insano que pode clonar qualquer coisa com IA",
          "title_pt": "Novo fluxo de trabalho insano que pode clonar qualquer coisa com IA",
          "url": "https://www.youtube.com/watch?v=yNVkufbhpvw",
          "published": "2025-09-13T01:15:46.243650",
          "published_relative": "há 8 dias",
          "duration": "08:34",
          "date_published": "2025-09-12T08:54:25-07:00",
          "transcript_available": true,
          "transcript": "In this video, you're going to see how I cloned \nChatGPT starting in the new build feature in   AI Studio in Gemini. I'm going to show you \nhow to use this tool. It's really powerful.   Putting it into cursor and continuing to build \nfeatures. But before we jump into how I did it,   let me show you what I built. And I did this in \nliterally 24 hours. It's fully hosted on Vercel,   so it's live on the internet. The design, I think, \nturned out really nice. And let me show you what   features we built and how it works. And you can \nsee it's really pretty close to most of the chat   apps that you may see out there. It's running with \nGemini in the back end. So I'm using the Gemini   2.5 flash model for most of things, but I also \nhave some helper models using to do a few other   things which I'll show you in a second. So let's \nsay I want to ask a question. So I'm going to say   latest Tesla news. And you can see I'm not even \nturning on web search. Just by default, what we   have is a model that's checking the input and it's \ngoing to automatically search the web. So this is   very similar to what you might see with chat GPT \nor other models. You can see the sources. It's   using the Exa API to actually do a web search and \nget information. And then we have all these inline   links as well to link to the sources. And then we \ncan see the sources below. So that shows a lot of   the features in one. Also, we have a little model \nto name the chat based on the first message. And   then you can respond and you can say, tell me more \nabout, let's say, the future of robotics. And it's   going to search the web again because it doesn't \nknow that on its own. But I'm going to show you in   a second that not every search is going to use the \nweb automatically. But this I was pretty proud of   that it worked. And in a second, I'm going to show \nyou the whole workflow that I did to build this.   And again, I built this in literally 24 hours. So \nhere we go. We have more information about that.   So cool that it did that. And now let's go ahead \nand do a new chat. So I have a few other things   here. You can also select like recipe help. And \nthat's just going to modify the system prompt a   little bit if you want to do that. Or we can do \nit just from the main chat. So we're going to   send that. And you're going to see it's not going \nto do web search for this because for this query,   it doesn't need to search the internet. So all of \nthat is just built in. We have streaming built in   as well. So yeah, those basic features. So you \ncan see where it did search the web and where it   didn't. Now, one other thing I want to show you \nis we added the ability to upload images because   Gemini is a multimodal model, meaning it can have \ntext or image. So you can do it from anywhere.   But let's just say just for fun, let's take a \nscreenshot of this. I'll paste it in. And then   the image just gets pasted. And let's say I built \nthis landing page. Any ideas for different hero   text? So we can go ahead and send this. Again, it \nis not searching the web because it doesn't need   to for this response. And then we're going to get \nthe response in a second. So, here we go. We know   it read it because it says, \"Okay, your current \ntext ask anything get into the answers is clear,   but here are some other options.\" Cool that it was \nable to do this. Again, this is all running with   Gemini in the background, and I used the Gemini \nbuild feature in the AI studio to get started. So,   this is all built out. Let me show you the \nworkflow of how I actually did it. Also, if you   want to learn more about how to do this, click the \nlink in the description to go to our SaaS building   course with AI where I'll teach you how to go from \nidea to fully functioning web app just like you   saw in the example. So, here we are in the build \nfeature of the AI studio. Just go to ai.dev. It's   totally free to use this in Google. You don't \neven need to have an account. But what I did was   I basically started by saying let's build a chat \napp similar to chat GBT, but I want to use the   Gemini 2.5 flash model for responses. So you could \ndo something just like that. Let's just go ahead   and do that just to see what it comes up with. And \nthen this is almost like a lovable clone or a Bolt   clone. It is going to help you build websites, \nbuild apps. But what's really cool about this is   because it's integrated in AI Studio with Gemini, \nyou can build AI powered apps. So apps that have   this AI functionality like the chat app I just \nshowed you, but it's going to do all of that on   its own. You don't have to worry about setting up \nan API key, setting up another service. It's just   going to do it all here. It's only when you want \nto take it off this platform and start building it   on your own that all you have to do is just get an \nAPI key and then it's just put it into the app cuz   it's going to have it ready for you. And then you \nare all set at that point. So here it's building   it out. This is very similar to what you might \nsee on something like lovable. Here it is writing   all the code. Literally just as simple as that. We \nhave a chat and let's just message. I'll say, \"Hi,   how are you?\" So I can send it and cool. We got \nthe response and basically we have a simple app.   But let's say we want to build even more on top of \nthis before we want to get off of this platform.   So why don't we say can you please build more \nfeatures a home screen where users home screen   would say chat GPT has see what it can do a \nsidebar with chat history and it's going to   build chat history into the local browser for now \nwhich is something that once you get it off this   is part of the workflow once you get off of this \nplatform by syncing to GitHub which I'm going to   show you in a second and then start using it in \ncursor or somewhere else you then would just ask   cursor to and hook it up with a database. In \nmy case, I used Supabase. And then it'll just   convert everything for you. So, just something to \nkeep in mind here. But it's nice to do as much as   you can here with Gemini because first, it's free. \nAnd it does a really good job at integrating the   Gemini AI capabilities. So, it went and created \na plan. We can see what it's doing. Three steps,   UI, layout, overhaul, sidebar, and home screen. \nAnd then it's going to proceed with the code   modifications to bring it to life. All right. So, \nwe have our next version of the app here. So cool.   It's just really fun to be able to do this and \nyou could just any idea that you had you would   be able to build it out here in the AI studio for \nfree. It has these kind of chat GBT like prompts.   We can say new chat. Say hi there. Can you tell \nme a story about basketball and let's see just   to make sure it works. And then we have our chat \nhistory here. Cool. It's working. It's streaming   in as well which is cool that it has the streaming \nadded. And then if we go back to chat, let's just   say plan a trip. And then now we have our chat \nhistory and we can click between it which is   nice to see. And we could add even more features \nif we want. We could say let the user select the   model. We could add image generation. You could \nreally build like your own personal chat right in   here. And then you would never even have to leave \nit if you want. You could just come in here. You   could deploy the app here. But what I'm going to \ntalk about next is the next workflow. So we could   spend a lot of time here in the AI studio. But let \nme talk about the workflow of how I went from this   to this. cuz that's basically what happened. It \nwent from that to this with more features and you   just keep building on in in cursor using AI. And \nI'm actually not sure how far you could get just   in AI Studio. You might be able to get really \nfar. I left maybe around this point in terms of   my workflow, but you could keep building on in in \nAI Studio especially because it's free. Okay. So,   if we click save to GitHub, that's what you're \ngoing to need to do. You're going to have to go   through some steps to connect your GitHub. But \nonce you connect your GitHub, all of the code is   going to get synced from here from AI Studio into \nyour GitHub. Once code is in your GitHub, you have   that code, you own it. You can do anything that \nyou want with it. So you want to go from GitHub   to cursor. And I have other videos on that as \nwell, which if you check out our channel, we have   other videos of going from lovable to cursor, \nfor example. It's a very similar process where   you go to GitHub, get the link that you need, and \nthen if you go to cursor, here you are in cursor.   All you have to do is click clone repo, you would \npaste in the URL from GitHub, and then now you're   working in cursor. From there, I connected my \nSupabase account to cursor so that I would have   a back-end database and then continued building on \nfeatures from there. So, I hope this was a helpful   overview. If you like it, let me know. I could go \ninto even more detail of how I built the ChatGPT   clone, more detail about the API connections, \nwhat are the workflows, how is it deciding when   to use web search and not use web search, how \nis the database set up. So, let me know what   you think in the comments and I can definitely go \ndeeper if this is a topic that you're interested   in. Be sure to subscribe to our YouTube \nchannel to get more free content like this.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Demonstra a construção rápida de um clone de ChatGPT usando Gemini no AI Studio, com busca na web automática, suporte multimodal e implantação em Vercel.",
            "resumo": "Neste vídeo, o criador mostra como clonou o ChatGPT usando o Gemini via AI Studio, aproveitando o recurso de build para criar uma aplicação de chat hospedada na Vercel em 24 horas. O backend usa Gemini 2.5 (com modelos auxiliares) e a busca na web é feita automaticamente via Exa API, com fontes exibidas. O app é multimodal (texto e imagens) e permite nomear chats, fazer perguntas que acionam buscas na web quando necessário, além de streaming de respostas. O fluxo de trabalho é apresentado passo a passo, com o código gerado pelo AI Studio, construção de telas (home, sidebar, histórico) e a possibilidade de conectar a GitHub, Supabase e cursor para evoluir o app fora da plataforma. Ao final, o apresentador convida para um curso de SaaS com IA.",
            "assunto_principal": "Demonstração de montagem de um clone de chat com IA (semelhante ao ChatGPT) usando Gemini via AI Studio, com busca na web automática, multimodalidade e fluxo de desenvolvimento rápido.",
            "palavras_chave": [
              "Gemini",
              "Estúdio de IA",
              "clone do ChatGPT",
              "busca na web",
              "Exa API",
              "multimodalidade",
              "imagens",
              "Vercel",
              "cursor",
              "GitHub",
              "Supabase",
              "fluxo de trabalho de IA",
              "geração de código"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n\n- Objetivo do vídeo: mostrar como clonar um chat IA semelhante ao ChatGPT usando Gemini via AI Studio.\n- Recursos demonstrados: busca na web automática com fontes, resposta com fontes, multimodalidade (texto e imagens) e streaming.\n- Fluxo de construção: uso do build do AI Studio, geração de código e planejamento de UI (home, barra lateral, histórico).\n- Integrações e deploy: app hospedado na Vercel, integração com cursor, GitHub e Supabase para backend.\n- Conclusão: prototipagem rápida de apps IA sem keys, com convite para curso de SaaS com IA.",
            "prompt_tokens": 2170,
            "completion_tokens": 3275,
            "model": "gpt-5-nano",
            "cost": 0.006
          },
          "analysis_time": 63.566940784454346,
          "language": "",
          "view_count": 411,
          "has_transcript": false
        },
        {
          "id": "htFdXJySysI",
          "title": "Do zero ao aplicativo de IA em 8 minutos - veja como é fácil",
          "title_pt": "Do zero ao aplicativo de IA em 8 minutos — veja como é fácil",
          "url": "https://www.youtube.com/watch?v=htFdXJySysI",
          "published": "2025-09-12T01:15:46.243667",
          "published_relative": "há 9 dias",
          "duration": "07:40",
          "date_published": "2025-09-11T10:10:57-07:00",
          "transcript_available": true,
          "transcript": "This is not a video that you want to miss. If \nyou're interested in AI app building, this is   a tool that you may have not heard of before, but \nby the end of the video, I have a feeling you're   going to want to try it out yourself. Rocket lets \nyou describe what you want to build, and it'll   use AI to build a fully functioning product. \nThank you to Rocket for sponsoring this video   and letting me show you what's possible with the \ntool. What makes Rocket different is the finished   result. It's almost like having a designer and \na developer and a product manager all-in-one.   So your output is really high quality. So we're \ngoing to build an app that generates flashcards   for students to study with as this example. Now \nyou can go to rocket.new and build this alongside   me for free. So I recommend clicking the link in \nthe description to do that. And afterwards you   can share it on socials on X, Instagram, LinkedIn \nor YouTube with Rocket. and they regularly share   publicly their favorite builds. So, here on the \nleft side, one thing that's cool right off the   bat that I haven't seen with a lot of other AI app \nbuilders is asking us what framework we want. It   has a default framework, but we can also customize \nit. But, I'm going to go ahead and use the default   framework. It's thinking and coming up with what \nit's going to do next. And here we are on the next   step. Again, this is giving us more control \nthan I've seen in other tools. It's letting   us decide which screens we want to generate and \nalso letting us know that the tokens used, which   is how you're charged, is based on the number of \nscreens that you do generate. So, I want to do log   and register dashboard. I'm going to just do all \nof them in this case and build my web app. But,   it's nice that it gives us the ability to generate \nless screens if we just want to start out and test   something out more quickly. And then here on \nthe left side, we can see it's working on all   of these pages and it's loading and just telling \nus the progress of them as it's working. And here   we are on the preview tab. And I like that it's \ntelling me just to set expectations of how long   it's going to take. I'm going to take 20 to 25 \nminutes to build. I will build a wellressearched,   designed, written, and functional solution every \ntime. Now, this is the promise that it's going   to be better and more functional and just higher \nquality in one shot compared to tools like bolt or   lovable where maybe you get some results quickly \nbut you have to iterate a lot. So, if we click   compare our 10x execution, we can see what rocket \nis promising that it creates amazing moments at   first sight. It builds the most stunning and \nwellressearched comprehensive apps for ideas   and can you can compare it the 10x execution \nwith other tools. So just as an example if we   go to this example of an office asset tracker we \ncan compare basically what it's doing. So on the   left side 19 screens generated in 19 minutes and \nwe can view it or watch the video but here versus   lovable bolt replet and v 0 they're saying one \nscreen generating it in 2 minutes. So that's the   difference here. And you can scroll through and \nsee all the different screens that were generated   in that first prompt. So really excited to show \nyou what this looks like after the 20 minutes of   generation. So I'm going to pause the video, come \nback, and we'll see if Rocket is able to do what   it claims. One more thing just to jump in before \nwe show you the final product is Rocket also does   have templates, which is really nice that you \ncan start with to save you on tokens cuz you   don't have to build up the tokens from the start. \nThese can save you a lot. If you want to do a CRM,   for example, you can start with this template. \nSave one and a half million tokens. All right. So,   we have our finished MVP. Rocket says it completed \ncomprehensive authentication system. It has   flashcard management, built study dashboard, \nand then login credentials to test it. So,   here we are in the dashboard and I will say it \nlooks really good. Overall, looks like there's   a little bit of design issues here on the left \nside. Maybe that's even just like a spacing issue,   but overall looks very good. And it also has \nsample collections. So, let's test it out.   Let's study. And it has a lot of features here. \nLet's click to reveal the answer. Cool. We can go   to the next one. Goodbye. Yep. So, it added these \nbasic ones. And this is really pretty polished.   I'm pretty impressed compared to other tools and \nwhat it claims of being able to have a much more   polished built out app. Of course, it takes a \nlot longer. Seems to be true so far. So far,   I am impressed with this. We can log out. Here we \nhave our log off page with our demo credentials   and log back in. And then you can also go up on \nthe top and just view the different pages here   that it created. So there's a lot of different \npages and it really built this out. And then we   can also see up at the top that took about 700,000 \ntokens cuz I started with 21 and now I have 20.3.   So just for reference, that's how much it took to \nbuild all of this out. A couple other features,   you can view it on different devices, what \nit looks like on desk, on mobile. So, it   fully mobile optimized this. And then if we go to \nproject settings, we can see under integrations,   we have integrations built in. So, you can easily \nadd things like stripe to accept payments. You can   add supabase to have real authentication so users \ncan log in. And maybe we'll test that in a second   to turn this into a real web app. Other things \nlike resend for sending emails, open AI. So,   all of these different integrations to help you \nadd these features. So, I'm just curious if we   click on Stripe. Yeah, you just add your API keys \nand then Rocket is going to help you add in your   Stripe payment. And for Supabase, you can go ahead \nand connect it to your Supabase account and then   disconnect it. So, I think that's what I'm going \nto do next because we've built out like a really   nice app, but I want to see if I can connect it to \nSupabase and turn this into an app that anyone can   use. So, the difference here is with Supabase, we \ncan add a real backend with a real authentication,   so anyone can sign in. Right now, it's just \na demo. It's built it all out with the setup,   but we need to connect to a backend so that it \ncan actually do it. So, I'm going to go ahead   and authorize and connect my Supabase account. And \nthen I can go down and create a new project here.   And then we just have to go into our Supabase \nproject, get the API, a nonkey that it's asking   for. Paste that in and click save. Now, I'm \ngoing to say, now that our Supabase account   is connected, can we add the full backend database \nwith real user O that anyone can use? And then on   the left side after some work basically rocket \nis now telling us our project schema is ready to   push to supabase. So just go ahead and click that \nbutton and then once that's finished the database   migration is going to be complete to supabase and \nthen it should work now with supabase. So let's   try it out. Let's publish the app. All it takes is \none click. It's going to publish directly through   Rocket. Now, I have to say everything with \nthis app so far is really polished and really   impressive. You can also add a custom domain it \nlooks like, but we're just going to start with the   default publishing right on Rocket. Okay, so here \nwe are on our publish site on our public URL that   anyone can access and we can test out our app the \nsame way we could in the preview, but now it's in   a full web browser and we can go into any of the \nexamples and we can go ahead and test it out and   see all the features and see how it works. So, I \nhope that you enjoyed this video. We built from   start to finish a fully functioning web app. \nWe even connected it to Supabase and you could   see how easy it was to do that and how Rocket is \nintegrated with Supabase to push the migrations,   set up the database, do everything that you \nneed to easily connect with Supabase and has   all of the other integrations that I listed as \nwell. Thank you again to Rocket for sponsoring   this video. Click the link in the description to \nstart building with Rocket for free. And again,   share what you're building with Rocket on \nsocial media and Rocket might just feature   your app that you built with them. So, thanks \nagain for watching. We'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Demonstra como criar rapidamente um MVP de aplicativo de IA (gerador de flashcards) com a plataforma Rocket, incluindo geração automática de telas, modelos, autenticação, integrações e publicação.",
            "resumo": "Este vídeo mostra como usar a plataforma Rocket para construir rapidamente um MVP de aplicativo de IA: um gerador de flashcards para estudantes. O apresentador explica que basta descrever o que você quer criar e o Rocket gera um produto funcional com aparência de design profissional, incluindo autenticação, gestão de flashcards e um painel de estudo. O processo começa com a seleção do framework (padrão ou personalizado) e a escolha das telas a serem geradas, com cobranças baseadas em tokens por tela. O vídeo destaca modelos para economizar tokens, além de um exemplo de CRM. O MVP final inclui autenticação completa, múltiplas telas, demonstração de estudo, compatibilidade com dispositivos e integrações com Stripe, Supabase e Resend. Ele conecta ao backend real via Supabase, publica o app com um clique e sugere testar publicamente no Rocket.",
            "assunto_principal": "Geração rápida de apps de IA com Rocket: criação de MVP, integrações e publicação",
            "palavras_chave": [
              "Rocket (ferramenta)",
              "Inteligência Artificial",
              "desenvolvimento de aplicativos sem código",
              "produto mínimo viável",
              "cartões de estudo",
              "geração automática de telas",
              "tokens",
              "modelos",
              "Supabase",
              "autenticação",
              "Stripe",
              "integrações",
              "publicação",
              "painel de estudo",
              "comparação com outras ferramentas",
              "backend real"
            ],
            "resumo_em_topicos": "- O que é o Rocket e o objetivo do vídeo: criar rapidamente um aplicativo de IA com MVP pronto.\n- Processo de construção: escolha de framework, geração de telas e controle por tokens.\n- Economia de tokens com modelos e exemplos de uso (CRM).\n- MVP final: autenticação completa, gestão de flashcards, dashboard de estudo e testes.\n- Qualidade do aplicativo gerado e comparação com outras ferramentas.\n- Integrações disponíveis: Stripe, Supabase, Resend.\n- Conexão com backend real usando Supabase para autenticação e dados.\n- Publicação: publicação com um clique e opção de domínio personalizado.\n- Impressões finais: experiência do apresentador com a ferramenta e convite para experimentar no rocket.new.",
            "prompt_tokens": 2106,
            "completion_tokens": 2973,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 54.627350091934204,
          "language": "",
          "view_count": 556,
          "has_transcript": false
        },
        {
          "id": "RQCqQIYTefU",
          "title": "O criador de aplicativos de IA 2 em 1 que você precisa experimentar",
          "title_pt": "O criador de aplicativos de IA 2 em 1 que você precisa experimentar",
          "url": "https://www.youtube.com/watch?v=RQCqQIYTefU",
          "published": "2025-09-11T01:15:46.243683",
          "published_relative": "há 10 dias",
          "duration": "04:48",
          "date_published": "2025-09-10T08:53:30-07:00",
          "transcript_available": true,
          "transcript": "This might be the best AI app building tool that \nyou haven't heard of yet. It's called Emergent.   It lets you build mobile and web apps. It has \nAI agents integrated into it. You don't have   to worry about APIs or more of the technical \naspects of coding. Emergent will take care of   it for you. And I've been really impressed in my \ntesting of this tool. Thank you to Emergent for   sponsoring this video. Click the link in the \ndescription to build alongside me as we build   with Emergent. And then for those that need to \ntake their app to the next level, Immer has a   pro mode to unlock their AI agent capability to \nstart building on your behalf. In this video,   we're building a mood tracking app and we're going \nto go step by step. So, you're going to see what's   possible with Emergent and I think you're going \nto be really impressed by the end result. Here   we are in the dashboard. We can see the agent is \nrunning. On the bottom, we have different tabs to   go into different apps that you might be building \nin Emergent. You can see the code. The agent might   ask you questions at times here. It's asking some \nclarifying questions before we get started. So   I'm going to say five basic moods works. For mood \noptions for data visualization, I'm going to say   line bar chart. I'm going to say no data export \nfor now. And for user authentication, I'm going   to say multi-user with simple username password. \nSo I want to add user authentication into the app.   So I'm going ahead and sending that off, giving \nit to the agent. Now the agent is going to process   the next step. So over on the right side, we have \nour code view. You can get access to the code. We   have our preview. So you can preview the app once \nit's ready to be previewed. You can deploy it and   you can also sync to GitHub. This is really \npowerful. So all of the code that I building,   you can take it, put it into GitHub, and then use \nit in any other builder. If you want to take it to   Cursor, you can. you're not fully locked in, but \nyou might want to stay in emergent if you find   that it's working really well. It's pretty cool \nthat the agent tests your app for you. So, we can   see here it's looking at the front end and then it \nresponds. The login page looks great. Let's test   functionality. Great, it works. Let's test mood \nselection. So, it's testing all of the features,   which I think is a really great thing that I don't \nsee a lot of these types of tools doing. And now   it's saying it finished with the first version. \nThe current feature has mock data with multi-user   authentication, daily mood tracking, trends, \nentries, login, and demo credentials for testing.   So, it's currently using mock data, but if we \nproceeded with backend development, it'll create   the database and actually make it a real app that \nothers can use. But just to start, why don't we   log in with the demo credentials. So, we're logged \nin. We can select our mood. We can save it. And we   can see it's adding the bar chart. And we have \nour recent history as well. Pretty impressive   that it was able to do that and actually did it \nreally quickly. I did pause the video so that you   don't have to wait during the build, but it did it \na lot quicker than I expected. It was maybe like 5   minutes to get to this point. So, I'm going to say \ngreat, let's continue now with back end and let's   have it go ahead and start building out the back \nend. Okay. So, I just created an account here. It   says welcome Seth because that's my username. And \nlet's see if we can save a mood, which we did. So,   we built an app with user authentication \nand a backend database. Essentially,   a full stack app. It did this in literally like 10 \nminutes, and I'm really impressed with the design.   And I can open it in a new tab, and I could test \nit in there. And then we also could save it to   GitHub and then deploy our app as well. So, all \nof that just within emergent. Really impressive.   The next thing that I want to do is show you how \nyou can take this web app and convert it to a   mobile app. So, I'm going to say, can we take the \nweb app you built and convert to a mobile app? And   it's almost finished with the mobile optimized \nversion. We can see it's even creating a guide   here. And we can click into it to see what it did \nand how to actually test it on real devices. And   that would be the next step of turning it into \na mobile app that you could upload and submit   to an app store. But pretty cool that the agent \nwas able to do all of this, go from idea to web   app to even setting it up so that we can submit \nit as a mobile app. And it's giving us next steps   of how to submit for Android and iOS and some of \nthe key features it made like haptic feedback and   touch optimize interactions. So pretty impressive \nthat it was able to build this crossplatform app,   web app, mobile app, all within emergent all with \nthe agents. So I hope that you enjoyed this video.   Click the link in the description to go to \nImmersion and build your own apps today.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do vídeo sobre a Emergent, ferramenta de construção de apps com IA que gera apps web e mobile com agentes integrados, cuidando de APIs, backend e publicação, em fluxo rápido de poucos minutos.",
            "resumo": "Neste vídeo, o criador apresenta a Emergent, uma plataforma de construção de apps com IA que permite criar aplicações móveis e web sem lidar com APIs ou aspectos técnicos complexos. O agente integrado orienta desde a escolha de dados (5 humores), visualização (gráfico de linhas/barra) e autenticação (multi-usuário com usuário/senha) até a geração de código, visualização, deploy e sincronização com GitHub. O apresentador testa o frontend, valida o login e verifica a funcionalidade de seleção de humor, tudo com dados simulados. A ferramenta entrega um app full-stack com autenticação, banco de dados mock e backend, com possibilidade de evoluir para dados reais. Também demonstra a transferência do app web para móvel, com guia de testes em dispositivos reais e passos para publicação nas lojas. Tudo isso em cerca de 10 minutos, com convite para explorar mais via link na descrição.",
            "assunto_principal": "Demonstração da Emergent, plataforma de construção de aplicativos com IA que gera aplicativos web e móveis com agentes integrados, incluindo back-end, autenticação, testes automatizados, exportação para GitHub e publicação em lojas.",
            "palavras_chave": [
              "emergente",
              "inteligência artificial",
              "construção de aplicativos",
              "aplicativos web e móveis",
              "agentes de inteligência artificial",
              "autenticação multiusuário",
              "banco de dados simulado",
              "teste automatizado",
              "GitHub",
              "implantação",
              "publicação na App Store",
              "conversão de web para mobile"
            ],
            "resumo_em_topicos": "Resumo em tópicos\n- Visão geral: a Emergent é uma plataforma de construção de aplicativos com IA que gerencia APIs e infraestrutura, permitindo desenvolver aplicativos web e móveis com agentes integrados.\n- Fluxo de build demonstrado: o agente faz perguntas, o usuário define opções como 5 humores, tipo de visualização (linha/bar), autenticação multi-usuário, etc.\n- Visualização e código: há visualização do código, pré-visualização, implantação e sincronização com o GitHub; o código pode ser usado em outros builders.\n- Testes: o agente testa o frontend, valida o login e as funcionalidades de humor, entregando a primeira versão com dados simulados.\n- Backend: criação de back-end e banco de dados simulados; pronto para evoluir para dados reais.\n- Web para dispositivos móveis: o aplicativo web pode ser convertido em app móvel, com guia de testes em dispositivos reais e passos para publicação nas lojas, incluindo recursos como hápticos e interações otimizadas.\n- Conclusão: demonstração rápida (aproximadamente 10 minutos) e convite para continuar explorando com os links na descrição.",
            "prompt_tokens": 1415,
            "completion_tokens": 3276,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 55.48054790496826,
          "language": "",
          "view_count": 1810,
          "has_transcript": false
        },
        {
          "id": "NXivRTlnq4E",
          "title": "Criador de aplicativos de IA GRATUITO do Google + Teste Nano Banana",
          "title_pt": "Texto: Criador de aplicativos de IA GRATUITO do Google + Teste Nano Banana",
          "url": "https://www.youtube.com/watch?v=NXivRTlnq4E",
          "published": "2025-09-09T01:15:46.243700",
          "published_relative": "há 12 dias",
          "duration": "06:17",
          "date_published": "2025-09-08T09:17:40-07:00",
          "transcript_available": true,
          "transcript": "In this video, we're going to test two new things \nat once. One is going to be the new build apps   with Gemini feature in the Google AI studio. So, \nyou just go to ai.dev and then you can build apps   very similar to like how you would build in \nlovable or bolt except the AI functionality is   built in by default. So, you don't have to connect \nan API or anything like that. You also don't even   need to pay. It's free to test out. And then once \nyou're ready, you can sync it with GitHub and   then continue building in any other tool that you \nwant, including cursor or something like that. So,   we're going to test out the build apps with \nGemini feature. And we're going to build an   app using Nano Banana, the new image generation \napp from Google and from Gemini. So, we're going   to test both of these together by building an AI \napp that uses Nano Banana. So, in my testing, I   have been very impressed with Nano Banana. I don't \nknow if it's quite up to the level of hype that   some people have been talking about on X, but I do \nthink it's really good and worth testing out. So,   what we're going to do is save build an AI image \ngeneration app using Nano Banana and we're going   to send it off. You do have some advanced settings \nhere. It's using 2.5 Pro to write the code,   which is a really good model. It's one of the best \nmodels out there. And then you can add files if   you want, but we're just going to do a very simple \nprompt and send this off. So, similar to what you   would see with an app like Lovable on the left \nside, we have our chat. We have the files that   it's creating. We can see the code. And then here \nwe have our preview section as well. So, here it   created an AI image editor. Edit your images with \ntext prompts using Gemini Mana Banana. And just   created this little widget here. Something else \nthat's just cool to think about is you could take   this, you could publish it with your own API key \nand host it wherever you want. And then you could   build these like little lead generation tools and \nit was done in 5 minutes. So pretty cool. And I   think Google's AI APIs are a little bit under the \nradar. I think they're really powerful and people   don't always think of them first. I think people \nthink of Open AI still, but they're really good.   Even anthropic, I think people think of a lot \ninstead of the Gemini APIs. So I'm going to go   ahead and drop in this image of the ocean. For \nsome reason, this original isn't working, but   let's see if the Gemini is. So I'm going to say \nadd dolphins jumping out of the water. So let's   generate the image. Okay. So there is an error and \nthen if we see on the left side there are errors   and we can auto fix. Cannot read the properties of \nundefined. All right. Pretty cool that it has that   built in. I always like when these AI builders \nmake it really easy in one click. Be aware that   there is an issue and then debug it on its own. \nLet me know in the comments below if you think   this is something you would use instead of using \nlovable or bolt. And keep in mind this is free   to use. So yeah, let me know. Curious what you \nthink so far. And if you've tried it yourself,   what your thoughts are. Okay, so I'm testing it \nout again. Still not showing up in the original,   but it does seem to be working. And now it's \ngenerating a new image. And cool, it worked.   We have dolphins in our image. That actually did \nwork really well. All right. What I want to do is   I'll just say the original image doesn't show \nup, but I think it's not necessary because it   shows on step one. So, let's see what it does with \nthat. I'm assuming I just delete that cuz I don't   think it's necessary since we have our image \nupload there. All right, cool. So, it says it   just fixed that. So, let's see. Let me pull up an \nimage again. Let me pull that in. Okay, cool. So,   that is showing again. I think it's a little \nredundant. It doesn't fully make sense. It's not   necessary, but it is there, which is cool. Okay, \nwe've built out an app with this AI app builder,   and we're using the new nano banana model. So, I \nwant to add on another feature. I want to be able   to use the AI model to make edits to the generated \nimage. I want it to be more like chatGPT where you   can have a response and keep going from there. So, \nlet's see what it does. I want to test one more   use case of the nano banana model which is making \nmarketing assets. So I'm saying take this image   we have that same image and make it an ad for a \nbeach vacation. Add a text that says tickets to   Florida 20% off on Southwest. So let's see how \nwell it does. Okay, it did do it. But again,   I think with all these image models, you really \nneed to give it like really descriptive prompts   to make it exactly what you want, which is like \na marketing ad essentially. Cuz this I guess it   worked. And I will say the fact that it added the \ntext is impressive that it did that correctly. But   that wouldn't be something that you'd actually \nwant to use in a marketing design. But maybe   if you go down this path and start really \ntweaking the prompt, I think that's where   maybe the opportunity is with this model is adding \non these system prompts to figure out how can I   create an image editor that really provides value \nto businesses in ways that can save them time or   generate assets that are actually something they \nwould want to do like a social media generator,   something like that. Let's try this one more \ntime. Let's say add a whale and generate an   image. And then it should have the ability \nfor me to edit that image on top. Okay. And   then if I click edit that image, it puts that \nnow into the upload image. And now that's the   original again. So I could say and add a bird \nflying above and generate an image. And now we   should just be able to iterate through and keep \ngoing back and forth with what's generated. And   then we edit it like this. The fact that this is \neven possible, I wouldn't have even considered a   year ago or even especially a couple years ago \nthat we could get this good of image quality,   especially being able to add text and have the \ntext work correctly. So, this is something ChatGPT   maybe about 6 months ago released a model that \nwas really powerful and was able to do this and   it looks Google has now caught up. So, let me add \none more thing. Let's say please add the text 20%   off the sale. So, let's just see just to show you \nthis text capabilities and how the model can take   text and put it inside the image. Yep. And there \nwe go. And it is all there. And it was not spelled   incorrectly or anything like that. Okay. So, I'm \ngoing to stop there. Again, let me know what you   think in the comments. I'd love to hear if this is \nsomething you want me to dig more into. Be sure to   subscribe to our YouTube channel to get more free \ncontent like this. and we'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Teste de ferramentas de IA: Build Apps com Gemini no Google AI Studio e Nano Banana para geração e edição de imagens, tudo gratuitamente, com fluxo de exportação para GitHub.",
            "resumo": "Neste vídeo, o criador testa duas novidades: o Build Apps com Gemini no Google AI Studio e o Nano Banana, modelo de geração de imagens. Ele mostra como usar ai.dev para criar apps com IA sem APIs e sem custo, com opção de sincronizar com GitHub depois. Em seguida, ele constrói um editor de imagens IA que usa Nano Banana, com configurações avançadas (2.5 Pro) e código gerado em tempo real. O vídeo cobre geração, edição por prompts, adição de texto nas imagens e iteração com o usuário, além de detectar e auto corrigir erros. Conclui destacando o potencial das APIs do Google e pedindo comentários e inscrição.",
            "assunto_principal": "Teste de ferramentas de IA: construção de apps com Gemini no Google AI Studio e Nano Banana para geração e edição de imagens, com fluxo gratuito e integração com o GitHub.",
            "palavras_chave": [
              "Estúdio de IA do Google",
              "Gemini",
              "Nano Banana",
              "Geração de imagens",
              "Edição de imagens",
              "IA sem APIs",
              "ai.dev",
              "GitHub",
              "Criação de aplicativos com IA",
              "Instruções",
              "Depuração automática"
            ],
            "resumo_em_topicos": "- Objetivo: testar Build Apps com Gemini no Google AI Studio e Nano Banana.\n- Fluxo de trabalho: usar ai.dev para criar apps com IA sem APIs, com opção de sincronizar com GitHub.\n- O que foi feito: construção de um editor de imagens com IA usando Nano Banana, código gerado, visualização e widget de pré-visualização.\n- Resultados e observações: geração de imagens com prompts, inclusão de texto nas imagens, edição iterativa, detecção de erros com auto-correção; possibilidades para negócios, como geradores de assets.\n- Conclusão: APIs do Google são potentes e pouco exploradas; convidando comentários e inscrições no canal.",
            "prompt_tokens": 1886,
            "completion_tokens": 3866,
            "model": "gpt-5-nano",
            "cost": 0.0067
          },
          "analysis_time": 68.07281613349915,
          "language": "",
          "view_count": 4541,
          "has_transcript": false
        },
        {
          "id": "aCH2C6ikPSE",
          "title": "Lovable vs Carrd: qual ferramenta cria a melhor landing page?",
          "title_pt": "Texto: Lovable vs Carrd: qual ferramenta cria a melhor página de destino?",
          "url": "https://www.youtube.com/watch?v=aCH2C6ikPSE",
          "published": "2025-09-07T01:15:46.243717",
          "published_relative": "há 2 semanas",
          "duration": "07:23",
          "date_published": "2025-09-05T05:16:03-07:00",
          "transcript_available": true,
          "transcript": "​ Today we're gonna put Lovable the AI app and \nwebsite builder and Carrd to the test to see   which one is best for you when it comes to \nbuilding a landing page. we have featured   both of these tools prominently on the channel \nand by the end of the video, you'll have a   good idea about which one is best to use when \nit comes to building a simple landing page. So let's get started with Lovable by giving \nit a prompt, and then we'll choose a starting   point for Carrd after that. So the prompt is a \nlanding page for a freelancer who wants to sell   consultations for the social media marketing \nconsultancy. So we'll send that prompt away. While that's happening, we will just start \nwith Carrds. So I have a Carrd pro account,   which is very reasonable. I'll link \nto the pricing in the description,   but we're gonna choose a starting point here, and the key to Carrd is starting with a template,   and then from there you can easily adapt the \ntemplate in order to make it perfect for you. You can choose from profile, landing \nform, portfolio, and sectioned. So we'll start with the landing page and we'll \njust go with this one 'cause I like the colors   and select this. Here you can see this is \na drag and drop builder that whenever you   click on any of the elements, you can \nthen edit these elements on the left, and we'll continue with this in a moment. \nWe're just gonna go back to Lovable and   see what it's come up with. Now this \ntook about five minutes to complete,   but you can see on your screen it, \nthat it has created this landing page. And I'm just gonna open a preview in a new \ntab so we can have a look at this properly. So it's created the title. You can just see here. \nAlso, it has buttons. If we click these buttons,   nothing is working right now. That's because \nyou need to do some extra integrations here,   and as we scroll down, we can see that it's added \nall of these different content areas as well. And it's given us a name of Sarah Chen. But all in all, you can see that this is a very \ntypical AI created landing page from Lovable,   and one thing that I think is quite important \nhere is that it's done a lot of the copy for   us. Now, if we wanted this to be tailored \ntowards us, we could have created a PRD. I'll leave a link in the description \nabout how to do that so that the prompt   is stronger and it's gonna create something \nmore personalized towards you and what you   do. But obviously these are placeholders with \nthese testimonials, but it gives you a good   idea about what you can include on here, \nand it's done a lot of the copy for you. And I think that is an underrated \naspect of some of the AI app builders. And to make edits to this, we can click \nthe edit button down here on the left   and then click the different \nelements and then simply just change the text like this. So \nif we wanna say viral machine,   we can do that too. and then another great feature \nof Lovable is that you can click the chat here,   and this is great for anything that you want to \nask Lovable without changing the code to it. So   here I know a lot of people get stuck when it \ncomes to trying to integrate forms into here,   how to connect it to a database if \nthat is needed, and how to deploy it. Because I think this is a sticking point when \nit comes to creating these landing pages,   in that a lot of it is done through \nthe AI agent rather than as we're   gonna see with Carrd. Through \na more traditional way of using   a no-code tool. So I'll send off this \nprompt and then I'll go back to Carrd. Just a very quick overview of Carrd, you \ncan click on any element and change both   the text here, but also the appearance \nof it too, so we can increase the title, we can change the font. And we can change the color of the font \ntoo. And then as we go back to the text,   we can enter our text in here and then click done. Now, I think \none of the benefits of using Carrd   is when you click on an element like button, you can. Open this up here and simply send people to a Calendly \nlink here or to wherever it may be. But you can also click the add \nelement button here and embed a form. And then when you've done that, you can change \nthe fields of the form. You can click change   the button text again, the appearance here, \nand I'm not a big fan of this appearance,   luckily we can easily change that. And you \ncan connect something like MailChimp Mail,   Aite Active Campaign, and other \nemail marketing software tools. Additionally, we can click on any \nelement and simply delete it. Click yes,   and then those contents are now gone. So, for example, we can click \nthis button, delete this button,   and then we've got our name and email here. Additionally, adding something like I. Click \nwidget. And then we have a Stripe checkout,   Gumroad and PayPal that we can use for \npayment. So if you have something like Gumroad,   you can click Gumroad and then simply add in your \nproduct details here and the button label here. And let's say we don't like \nthis template to begin with. Instead of asking AI to come up with a \nnew style and adding new colors and fonts, we can go back to the different templates \nand simply just choose one that we prefer. For example, this one is a bit more simple. We can \nadd our image in here. Again, delete the button and then add a gum road y button here. Now after asking Lovable how to integrate \nMailChimp with this book free consultation   button down here, it's telling me , \nthat there are three options. You can   use MailChimp's marketing API directly \nfrom the front end, and it's saying   that this is less secure. You can do a backend \nintegration via Supabase, which is recommended, and option three is to use MailChimp's embedded   form code and you can replace your \ncurrent button with MailChimp's form. I also asked it to replace those buttons with a   Gumroad Buy Now button in the hero \nsection, and it's given me, again,   the different integration options. So there's \na Gumroad overlay, which is recommended. And at the bottom it says, implement \nthe Gumroad integration plan,   which I'll click and I'll come \nback with the results of this. So what it's done is it has integrated that,   as you can see here with the buy button. \nAnd it's saying, replace your product   ID with your actual Gumroad product id. So \nthere are further steps that you need to do in order to completely implement this. I'm just \ngonna make one more change and say edit button,   trash, delete. And now you can see how \nLovable does have some traditional no code editing capabilities where you can delete the button and then \n, it does actually center this button too. And if we click edit to a section, we can also \ndelete this section too, if we wanna just get   rid of all of that. So I'll do that now. And \nas you can see, that has deleted that section. So going back to Carrd. In \norder to continue with this,   what I would do is use ChatGPT to come up with \nsome of the copy here, and then edit that copy and then to deploy or to publish \nthis. You can click this button,   enter the title, and you can have a \nsubdomain on Carrd, or you can buy   your own domain and follow the instructions \nin order to have this go live as a website. Whereas with Loveable, you need to integrate the   backend and the and then follow \nthe deploy instructions here. So, which one is best for you and which \none are you going to use? Personally,   I'm stuck in two minds here because I think it's a lot quicker to get \nthe results that you want from Lovable,   from simple prompts, especially if you start off \nwith a stronger prompt. Instead of just a simple   one here, if you create a PRD and I'll leave \na link on how to do that in the description,   then it can come up with something much \ncloser to what you want first time of asking. Whereas Carrd, it takes a little while \nto go through the different templates.   I find introducing buttons and having \ncontrol over the editing is a lot easier   on something like Carrd and also when it \ncomes to deploying, integrating Gumroad,   integrating MailChimp. So what \nare your thoughts on this? Let us know in the comments. And if you \nwant to learn more about Lovable or Carrd,   then check out the playlist in the \ndescription and on your screen now   so that you can go through all of our tutorials. And then go to saascourse.ai to get your \nfirst free lesson on how to build your own   products with ai. Thank you for watching \nand we'll speak to you soon. Bye for now.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Este vídeo compara Lovable e Carrd para criar uma landing page simples de consultoria, destacando rapidez com prompts e controle visual de cada ferramenta.",
            "resumo": "Neste vídeo, o apresentador compara Lovable e Carrd para criar uma landing page simples de consultoria em social media. Ele testa Lovable, gerando automaticamente o conteúdo e o layout a partir de um prompt para uma freelancer vender consultorias, destacando a copy pronta e as sugestões de integrações. Em seguida, explora Carrd, selecionando um template de landing page, editando textos, cores e botões, e conectando formulários e opções de pagamento. O vídeo ressalta que Lovable facilita a edição por meio de IA e chat para dúvidas, porém exige configurações de backend para deploy; já Carrd oferece controle visual direto, modulação de elementos, integração com MailChimp, Gumroad, Calendly, Stripe e publicação com domínio. A conclusão sugere que Lovable é mais rápido com prompts bem definidos (PRD), enquanto Carrd demanda tempo para personalizar templates.",
            "assunto_principal": "Avaliação comparativa entre Lovable (IA de criação com prompts) e Carrd (editor sem código) para criação de páginas de destino simples",
            "palavras_chave": [
              "amável",
              "Carrd",
              "página de destino",
              "inteligência artificial",
              "sem código",
              "instrução",
              "Documento de Requisitos do Produto",
              "integração",
              "formulário",
              "pagamento",
              "MailChimp",
              "Gumroad",
              "Calendly",
              "domínio"
            ],
            "resumo_em_topicos": "### Tópicos\n- Contexto: comparação entre Lovable e Carrd para landing pages simples.\n- Lovable: geração de landing page via prompt, copywriting automático, chat de ajuda, necessidade de backend para deploy e integrações, opções como Gumroad, MailChimp, Calendly.\n- Carrd: inicia com template, editor drag-and-drop, personalização de textos, cores e fontes, integração de formulários, opções de pagamento (Gumroad, Stripe), publicação com domínio.\n- Pontos fortes: Lovable rápido com prompts bem definidos; Carrd oferece controle visual e fluxo de integrações.\n- Considerações finais: escolha depende do objetivo; Lovable é mais rápido com PRD bem definido, Carrd requer tempo para personalizar mas oferece maior controle.",
            "prompt_tokens": 2099,
            "completion_tokens": 3158,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 57.14175200462341,
          "language": "",
          "view_count": 477,
          "has_transcript": false
        },
        {
          "id": "hDb14KTmbgk",
          "title": "Lovable vs Figma Make: Qual designer de IA se sai melhor?",
          "title_pt": "Lovable vs Figma Make: Qual designer de IA se sai melhor?",
          "url": "https://www.youtube.com/watch?v=hDb14KTmbgk",
          "published": "2025-09-07T01:15:46.243740",
          "published_relative": "há 2 semanas",
          "duration": "07:25",
          "date_published": "2025-09-03T06:23:13-07:00",
          "transcript_available": true,
          "transcript": "In this video, we're going to compare Figma Make \nwith Lovable. We're going to do three different   use cases, and at the end, I'll give you my final \ndecision on which tool I would use for different   use cases. So, the first use case I'm asking it \nto do is to design an onboarding experience. And   what's cool about this video is you're going to \nsee the real results that each tool is able to   build. And I'm going to quickly edit it so you can \nsee this in as short of a time as possible. So,   here on the left side, I have Figma Make. Figma \nmake is Figma's AI design tool. It's a little   separate from Figma, so it's not designing Figma \nfiles, but it's designing designs and things like   that using AI very similar to how Level would do. \nSo, here we have our first onboarding screen that   we created. And I like, let me just pull this out \nso we can see what it looks like. I like what it   did here. And it created these onboarding screens. \nAnd I can keep clicking through just to see what   it did. It came up with four or five screens here \nand then I can click sign up or sign in. So that's   just the onboarding screens that it created. I \ndidn't give it much of a prompt. I like to see   how these tools do. It's just not much of a prompt \nat all. And then here what it it says next steps   add user authentication integrate location \nservices or create a main app dashboard. Why   don't I said create a main app dashboard with \nride booking. And let's see how it does. And   then let's go back over to Lovable. And it looks \nlike Lovable finished its onboarding as well. So,   here we go. Welcome to Rid Share. Next, next. And \nget started. And then that's it. I feel like Figma   did a little bit of a better job at making it \nlook more like an app with basically some of these   mobile elements like this back button for example, \nwhereas Lovable I think did a more polished job   overall. Now, I think that the reason for this \nis Figma is trained a little bit more. Just the   AI is a little bit better at building. When I \nasked for kind of an onboarding app like Uber,   it knew that was a mobile app. whereas I think \nwith lovable it's more of building web apps. So   that's the difference there and I think why we see \nsome of those like mobile elements on the Figma   make. So let's just see what Figma is able to come \nup with this second prompt here. I'm just curious.   But I think that's something that's really helpful \nto know the difference here is Lovable is going   to design more of a web-based design off the bat \nas opposed to Figma which if you ask for an app   will design more of an app interface. One thing \nthat you should know is that Lovable is able to   add a back-end database and actually build a \nfully functional app. Whereas with uh Figma,   you are really just building designs. So just \nkeep that in mind. These are different tools,   but in this test, we're really focusing more \non the design aspect of each of these tools.   Okay. So we now have our version two, which it \nsays it completed the full homepage. So let's   go through onboarding. I wonder if I click skip \nif it'll get through. Then if I click sign up,   it'll just bring me to that homepage. Now, \nof course, doesn't have a real image here,   but it put that in as a mockup. So, really think \nof Figma make as a tool for mockups. And yeah,   we have the ability to built out this full mockup. \nYeah, overall I am really impressed here with the   mockup capability of Figma make here. The next \ntest that we're going to do is a shopping web   app mockup for selling cars. In this test, I want \nto do a web app mockup because in the last test,   we did an iOS or a mobile app mockup. And in that \ncase, I think that Figma did a better job. But in   this case, let's see how Lovable does when we give \nit a web app mockup. And again, in this video,   we're going to really be testing the web \ndesign functionality as opposed to Lovable,   which can go to the next step of adding a backend \ndatabase, things like that. Check out some of our   other videos on how to actually do that. But \nin this video, I want us to come away with a   decision on which is better for the design aspect. \nNow, Figma has built its reputation on design. So,   I'm expecting Figma to win this out, but I'll be \nreally curious to see what happens after this and   then after the last test that we do. So, both of \nthese designs are finished. First, let's take a   look at Figma make. So, it did a really good job, \nI think, at building out this marketplace mockup.   It even got images of cars. I'm wondering if it \ngot them from Unsplash or something cuz yeah,   it doesn't look like AI generated images bas. \nI could be wrong about that, but although it's   definitely not matching the car to the image, \nwhich I think makes sense for a mockup, but pretty   cool. Let's see if it has different pages. It \ndoesn't look like it. It just has this one page,   but it also has filtering, which seems to work. \nIt has different views as well, which is pretty   cool. And yeah, the filtering like actually \ndoes work. So, that all is pretty impressive.   So, let's jump over to Lovable. So, it looks like \nwhat Lovable did was create kind of this homepage,   which is nice because Figma make only created like \nthe search page essentially. So, it designed out   what a homepage could look like. Here we go. It \nalso has images of cars. I think the images that   Lovable did are definitely AI generated because \nthat is not a real car. But then if I go to sell,   it looks like there's no like full page of \ncars here for lovable. Whereas with make it   has like the whole search functionality for \nthe marketplace. So again, I'm going to give   the design edge here to Figma versus Lovable. Of \ncourse, Lovable again, I could take this and start   building out a real marketplace, adding a backend, \nwhich with Figma, I can't. But overall, I actually   do prefer the design mockup capabilities of \nFigma make. We're going to do one last test here,   which is a mockup of a pizza restaurant website. \nAnd again, we're going to do these headto-head,   and we'll see what the result is. All right, so \nboth designs are finished. Let's start with Figma   make. And we have a nice little header here. Just \na little issue here with the view menu button not   visible until I hover. But we have add to cart for \ndifferent items, view full menu, story. I actually   really like this for a restaurant website. It's \nvery simple. It has everything that you need.   And I like I think for a mockup, really good. \nI like it. So, here we are on lovable. So,   we have a kind of similar header section, similar \nadd to order, view menu, story, visit. Actually,   very similar with both of these. Let's go back \nto Figma. Yeah, really similar. One thing I'll   say is that like lovable sites seem to have this \nfeel that it was generated by lovable. The more   you build with lovable, you get get a sense of \nthat. The other thing is I see Lovable does use   AI generated images. I wish I had the ability \nto turn that on and off. I actually don't love   that. I like how Figma they must be getting these \nimages from Unsplash or something like that. See   if I copy image address. Yeah, I can see that it \nis coming from Unsplash. And I actually prefer   that when possible cuz I just think the images are \nbetter. Yeah. Okay, so we've done three examples,   an iOS app, a web app, and a website. I will say \nfor design, I prefer Figma. Now, if I wanted to   take these to a full website or a full app with \na backend, then I would go with lovable. So,   just keep that in mind. But for design, after the \nthree examples, I would choose Figma Make. I hope   that you enjoyed this video. Leave a comment \nbelow. Let me know what you think, which one   you think is better. Subscribe to our YouTube \nchannel to get more free content like this.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo compara Figma Make e Lovable em três cenários de design e conclui que, para o design de interfaces, Figma Make é superior, enquanto Lovable é mais adequado para levar o projeto a um app ou site com backend.",
            "resumo": "Neste vídeo, o apresentador compara Figma Make com Lovable em três casos de uso: onboarding, marketplace de carros e site de pizzaria. No onboarding, Figma Make cria telas móveis com alguns elementos de app, enquanto Lovable oferece uma versão mais polida voltada a web; o narrador sugere que Figma Make é mais forte em mockups de aplicativos, enquanto Lovable pode adicionar backend e gerar um app funcional. No teste de marketplace, Figma Make entrega uma página de marketplace com imagens de carros, filtros e diferentes visualizações, levando a vitória no design de interface; Lovable gera uma homepage de busca, mas não apresenta uma página completa de listagem. No site de pizzaria, ambos produzem layouts similares, mas Lovable tende a usar imagens geradas por IA, enquanto Figma Make utiliza imagens de fontes como Unsplash. A conclusão é que, para design, prefere-se Figma Make; para transformar o projeto em um site/aplicativo com backend, Lovable é mais apropriado.",
            "assunto_principal": "Comparação entre ferramentas de IA para design de interfaces: Figma Make vs Lovable, com foco em capacidades de design (mockups) versus potencial de backend.",
            "palavras_chave": [
              "Figma Make",
              "amável",
              "inteligência artificial de design",
              "maquetes",
              "integração",
              "plataforma de venda de carros",
              "aplicação web",
              "aplicativo móvel",
              "back-end",
              "imagens geradas por IA",
              "Unsplash"
            ],
            "resumo_em_topicos": "- Objetivo: comparar o desempenho de design entre Figma Make e Lovable em três cenários.\n- Abordagem: demonstração prática de onboarding, marketplace de carros e site de pizzaria, com foco no aspecto visual e de interações.\n- Caso 1 – Onboarding: Figma Make gera telas móveis com elementos de app; Lovable entrega onboarding mais polido, com tom voltado para a web; conclusão: melhor para app com mockups, Lovable para experiência pronta para web.\n- Caso 2 – Marketplace de carros: Figma Make produz marketplace com imagens de carros, filtros e várias visualizações; Lovable cria uma página inicial de busca, mas não uma página completa de listagem; a vantagem fica com o Figma Make no design de marketplace.\n- Caso 3 – Site de pizzaria: ambos geram layouts próximos; Lovable usa imagens geradas por IA; o Figma Make recorre a imagens do Unsplash, geralmente com aparência mais autêntica.\n- Conclusão: para o design de interfaces, escolha o Figma Make; para levar o projeto a um site/app com backend, Lovable é mais adequado; as diferenças de imagens e o foco entre mockups e produtos funcionais estão na origem das escolhas.",
            "prompt_tokens": 2159,
            "completion_tokens": 2965,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 60.73982000350952,
          "language": "",
          "view_count": 659,
          "has_transcript": false
        },
        {
          "id": "Xjjoc0PDm-M",
          "title": "Eu vi que codifiquei um aplicativo social real em minutos (irreal)",
          "title_pt": "Eu vi que codifiquei um aplicativo social real em minutos (irreal)",
          "url": "https://www.youtube.com/watch?v=Xjjoc0PDm-M",
          "published": "2025-09-07T01:15:46.243759",
          "published_relative": "há 2 semanas",
          "duration": "11:10",
          "date_published": "2025-09-01T07:06:56-07:00",
          "transcript_available": true,
          "transcript": "There are so many vibe coding tools out there that \nit can be hard to know which one to use. Replit is one of the best that I've come across and it's \ngreat for people regardless of their technical background. You don't need any coding experience \nto build an app with Replit. You're going to see how powerful Replet is and how quick it is to \nbuild something that people can actually use. And you're going to see how easy it is to turn \nyour ideas into reality. Thank you to Replit for sponsoring this video. So, click the link in \nthe description to start using Replit for free and build alongside me in this video. There's a \nlot to cover, so let's jump in. The prompt I'm using is make a web app that helps golfers find \nnew friends to play with. Create profiles with golf goals and preferences, match users based on \nlocation and skill level, and include a messaging system. Design it with vibrant colors and engaging \nsocial interface. And then under the app type, we're going to do a modern web app. And then I'm \ngoing to click the improve prompt button to make this prompt even better. Now, this is a pretty \ncomplicated app that we're going to build. And I think this is really going to show you the power \nof Replit and what's possible with Replit and how easily you can build apps with it. So, what's nice \nabout its improved prompt feature is it breaks it down into core features, visual reference, and a \nstyle guide. So, pretty cool. visual reference, Bumble BFF, and Strava's social feature. I gave a \ncolor, a style guide, design, inspiration, design guide, and then the core features, user profile, \nlocation, and skill-based matching, in-app messaging, and search and filter functionality to \nfind golfers in your area. So, let's go ahead and start the chat. So, this is what creates the chat \nin Replit, and it goes into this planning phase. So in the planning phase, Replit is going to \ngive you a list of the features that it wants to build. It's going to also create like a design \ninspiration. So it's going to code up a very basic front end for the beginning and then you get to \ndecide whether you want to stick with that plan or make any changes. Okay. So Replet has completed \nits plan. On the left side we have the initial features. So we have the initial version with user \nprofile, location based matching, skill filtering, in-app messaging, discovery, profile browsing \nwith swipe and match notification and connection requests. So quite a lot of features for that \ninitial version. I think that all sounds good. And then it has some like later features that it can \ndo later such as real-time chat, advanced matching algorithm, golf course integration, things like \nthat. I like the feature set. And then what I really like about Replet is on the right side we \nhave a visual preview. So it mocked up this entire front end of the website. And I'm wondering I \nthink it might even have generated this image and it might be generating images for the mockup. And \nI really like what it created here. It's really good like this indication of an app. It even built \nout like this mockup of what the app looks like. Conversations creating a golf profile. Why you \nshould do it. So, I really do actually like this preview. So, what you can do is keep chatting and \nreview the plan and tweak it. But I'm going to go ahead and approve it and start. So, at this point, \nwhat Replit is going to do is on the left side, the agent is going to start working and building \nout those initial features. And on the right side, the preview is going to update uh once we have \nthe next version to see. And just jumping in here on the left side, we can see all of the work \nthat's happening. It's creating the messages page, discover page, profile page, homepage. It's \nbuilding out components. It's building out a lot of things that are going to go into the app. \nSo, the first initial build usually takes the longest and then future features will be built out \na little bit more quickly. We can also see on the left side that it is creating an object storage \nbucket which I assume is for profile pictures and it's also setting up the database. So that's \nsomething with Replit. The database is integrated although it uses Neon as the database. It's not \ngoing to be like proprietary to Replit. You're not stuck in the Replit ecosystem if you want to \ntake your code and your database later on. But it's all going to be integrated and easily set up \nhere inside of Replit. And then here real quick, something that is also cool. Even though \nthere is an error, that's not ideal, but what Replit is able to do, the agent is able \nto debug automatically. And that's what makes the Replit agent so powerful. All right, let's see \nwhat the agent is telling us. It says it built out the social platform with the golf theme design, \nthe hero section showcasing the platform's value, discover page, profile creation, real-time \nmessaging, mobile responsive design. It says, \"How does the overall design and user experience \nfeel? Are the golf themed colors appealing? And does the app seem intuitive?\" So, I actually do \nreally like the design. The one question that I have is basically, do people need to log in? \nlike it looks like it has this create profile, but I don't know that I've ever I logged in \nyet. I'm gonna say the design looks good, but do we need user authentication so users \ncan log in before creating a profile and accessing features like messaging? So, it says \nwe're right. It needs to implement Replit off using the provided blueprint to add user login, \nregistration, and protected routes. So, this is another thing that's nice about Replit is off \nauthentication, meaning how users sign in and sign up is all connected into the Replet ecosystem. \nSo, they have that pre-built. So, you don't have to worry about setting that up yourself, which is \nreally nice. And just to quickly explain to you what's happening on the agent side, it's going \nthrough step by step all of the things that it needs to do. So it's creating database storage \nto replace the in-memory storage that's like the browserbased storage with proper database storage. \nThen it's replacing the entire storage class implementation properly. It is then updating the \nroutes to integrate with Replit off and protecting the user related API routes with a authentication \nmeaning that users should only be able to go to where they are supposed to be able to go based on \nthem being logged in. So now replet is telling us it has completed the authentication system. It has \ndatabase integration protected API routes landing page for new users which I see here which is great \nthat it knew to do that on its own. User profile dropdown and logout option and loading states \nduring authentication checks. Let's test this out. It's asking me how the authentication flow \nfeels. So, why don't we go and when you're testing authentication in Replit, it's good to open \nit in a new tab. And then I'm just going to go ahead and click get started. And I assume this is \ngoing to take me to basically a Replit login. So, I'm just going to click allow. And because I'm \nalready logged into Replit, it just had that allow. Otherwise, it would basically if I was in \nincognito or any other user, it would prompt you to either log in with like Google or other offs or \nyou could just use email and password to create an account. So here I'm logged in now and I can see \nwhat it looks like for a logged in user. Like it said it has the drop down for profile and log out. \nAnd then from here once you're logged in users can go ahead create a profile enter information about \nthemselves. Then once obviously more users are on the app. Right now it's just me so it's a little \nhard to test. I could ask replet probably to add fake users to see what it looks like. But here is \nwhere you would be able to discover. You can even enable your location which is pretty cool and then \nit'll use your location from your browser. We have messages to actually chat with people and then all \nthe basic functionality that we wanted is here in the app. So Replet successfully built out an app \nwith a logged out state. So for users who aren't logged in yet, there's a landing page and then \nwhen once you log in, there's the profile messages and discover pages all created. And it did this \nbasically in two prompts. So if we go back to Replit, basically we had our initial prompt, then \nwe had another prompt asking for authentication, and then here we are. That was basically it. \nReally impressive what Replit was able to do. So I'm going to say I like the design and the \nfeatures. And let's see what Replit responds with when you just give it that response. So \nthat's pretty cool. It has access to the logs. So it knows that I successfully logged in and the \nauthentication is working and it sees that I've been exploring the app. the discover feature is \nworking and you've uploaded a profile picture. I uploaded a picture before when I was testing that \nout, but I didn't record that in this video. So, the other thing that's cool is it sees that \nthere's API calls failing basically in the logs. I guess it saw when I was going around \nthe app certain things were failing. Now, it's fixing that. And then now it's basically just \nsummarizing where we are. Creating a checkpoint. These checkpoints in replet are also really \nhelpful because you can always roll back to this if we build out something in the future and \nit's not working. We can always go back. And now it's asking, is there any particular aspect of \nauthentication or overall app experience you'd like me to enhance further? So there's of course \nso much more that we could build into this app, but I want to stop now because I think that \nthis has given you a really good idea of what's possible with Replit and how powerful Replit is. \nWe started from just a prompt. We optimized that prompt. We built out an entire front end and back \nend with database and user authentication for a social app. And we did it in about 10 minutes. So \nyou can just imagine how much further we can get if we spent more time building this out and \nrefining it and tweaking it for our specific use case. The last thing I just want to cover \nquickly is Replit has deployment built in as well. So if we go to the more tools here and we go \nto deployment, all you have to do is click set up your deployment. It deploys it and then \nyou'll have a URL that anyone can access on the internet and it scales up really well because it's \nautoscale. So this is really great for production ready apps that really could be used even in \nenterprise level apps. The other thing to be aware of with Replit is they have a really cool security \nscanner. So, if you click that, it's going to scan for vulnerabilities. And this is something \nthat's a hot topic with Vibe Coding. But really, there's no reason that Vibe coding has to not \nbe secure. It's just a matter of running the appropriate checks and making sure that everything \nis set up properly, especially with the database and everything is done in the correct way. I hope \nthat you enjoyed this video. Leave a comment below to let me know what you think and if Replit is \nsomething that you could see yourself building with. and click the link in the description \nto go to Replit and start building for free.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Existem tantas ferramentas de codificação vibe por aí que pode ser difícil saber qual usar",
            "resumo": "Existem tantas ferramentas de codificação com vibe por aí que pode ser difícil saber qual usar. O Replit é uma das melhores que já encontrei e é ótimo para pessoas, independentemente de seu histórico técnico. Você não precisa de nenhuma experiência em codificação para construir um aplicativo com o Replit. Você vai ver o quão poderoso o Replet é e quão rápido é construir algo que as pessoas realmente possam usar. E você vai ver como é fácil transformar suas ideias em realidade. Obrigado ao Replit por patrocinar este vídeo. Então, clique no link na descrição para começar a usar o Replit gratuitamente e construir junto comigo neste vídeo. Há muito o que cobrir, então vamos começar. O prompt que estou usando é criar um aplicativo web que ajude golfistas a encontrar novos amigos para jogar com. Crie perfis com metas e preferências de golfe,",
            "assunto_principal": "Eu vi que codifiquei um aplicativo social real em minutos (irreal)",
            "palavras_chave": [
              "ao longo",
              "na verdade",
              "ao lado de",
              "fundo",
              "baseado",
              "construir",
              "botão",
              "clicar",
              "codificação",
              "cores",
              "capa",
              "criar"
            ],
            "resumo_em_topicos": "- através de\n- na verdade\n- ao lado de\n- fundo\n- baseado\n- construir\n- botão\n- clicar",
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "model": "gpt-5-nano",
            "cost": 0.0
          },
          "analysis_time": 63.65454840660095,
          "language": "",
          "view_count": 515,
          "has_transcript": false
        }
      ],
      "status": "success"
    }
  ]
}
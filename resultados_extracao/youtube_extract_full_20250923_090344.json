{
  "executed_at": "2025-09-23T09:03:44.230722",
  "mode": "full",
  "total_channels": 107,
  "total_videos": 64,
  "params": {
    "days": 1,
    "max_videos": 30,
    "mode": "full",
    "no_llm": false,
    "asr_provider": "faster-whisper",
    "format": "md",
    "translate_results": "pt-br",
    "resumo_max_palavras": 150,
    "llm_model": "gpt-5-nano",
    "ui_extras": {
      "selected_groups": [
        "Ideias e Negócios com IA",
        "Notícias e Novidades em IA",
        "Tendências em IA",
        "Informações Big Techs IA",
        "Ferramentas de IA",
        "Pesquisas em IA",
        "Influenciadores IA",
        "Crítica/Opinião sobre IA",
        "Ética/Regulamentação/Segurança IA"
      ],
      "selected_channel_labels": [],
      "manual_entries": "",
      "translate_titles": true
    }
  },
  "channels": [
    {
      "channel_id": "@AIAnytime",
      "name": "@AIAnytime",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@AIDailyBrief",
      "name": "@AIDailyBrief",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "-OpFBC8SlzY",
          "title": "Como a Apple poderia obter sua vingança com a IA",
          "title_pt": "Como a Apple poderia obter sua vingança com a IA",
          "url": "https://www.youtube.com/watch?v=-OpFBC8SlzY",
          "published": "2025-09-23T00:03:46.728220",
          "published_relative": "há 12 horas",
          "duration": "13:09",
          "date_published": "2025-09-22T16:53:31-07:00",
          "transcript_available": true,
          "transcript": "Today we are talking about the right form factor for AI wearables and where Apple could get its AI revenge. Welcome back to the AI daily brief. Every few months we get renewed chatter about AI native devices, AI wearables. Sometimes it's because of new product launches. Other times it's because of rumors. But it's this fascinating discourse where people are debating what a category will look like that frankly isn't even really a category yet. It is just something that some companies are betting on. Today, we're going to look at the latest news, a bunch of which has come in the last week or so, get a sense of the state of play, and talk about why after all of their flops, failures, and frankly just unimpressiveness in AI, Apple could secretly be sitting on the AI device Trojan horse. Let's start with the latest news from over the weekend, though. The short of it is the latest burst of reporting around the much bali hood and anticipated OpenAI device that represents a collaboration between Sam Alman and Johnny IV. Now, it's been pretty clear that OpenAI and Altman are trying to capture some of the magic of the iMac, iPod, and iPhone era Apple team. Obviously, the hiring of the designer of many of those products, Johnny IV, is integral to that. But the information also reports that the company has been hiring Apple engineers and contracting with iPhone manufacturing partners over recent months. The information writes that Lux Share, which is a major assembler of both iPhones and AirPods in China, has a contract to assemble at least one of OpenAI's devices. And sources say that OpenAI has also approached Gore, which assembles AirPods, HomePods, and Apple watches. Sources say that the first release target is late next year or early 2027. And the reporting also included some confirmations and updates on the form factor the device would take. The information writes, \"One of the products OpenAI has talked to suppliers about making resembles a smart speaker without a display. Another source said that the company has also considered building glasses, a digital voice recorder, and a wearable pin.\" Now, the first part, the idea of it resembling a smart speaker without a display, seems in line with rumors from earlier this year that the device would be something like a pocket-siz puck. Back in May, the Wall Street Journal reported that the idea was to have a third core device a person would put on a desk after a laptop and an iPhone. They wrote that the product would be capable of being fully aware of a user's surroundings in life and would be unobtrusive. On the flip side, the reporting that OpenAI has considered a wearable pin is very much not in line with previous comments where Johnny IV has been quite negative about previous devices like the rabbit and the humane pin, saying, quote, \"There has been an absence of new ways of thinking expressed in products.\" Sam Alman also dashed the rumors that the first device would be smart glasses. Perhaps recognizing that Meta has a big lead in that area. But all of this does line up with the reporting that they were considering not just a single device, but a family of devices. It may simply be that they're at the stage where they're just considering their options and understanding if then sort of implications of if they were to develop a particular type of device, what the constraints would be. Overall, in 2025, OpenAI has now recorded more than two dozen employees from Apple who previously worked on consumer hardware. That's up from about 10 last year and none in 2023. It's not all that surprising that they're able to be successful with this poaching. The information writes, \"Some longtime Apple employees working on the company's hardware products have become bored with the incremental changes in the type of products they're working on and frustrated with the bureaucracy at Apple. It hasn't helped that employees have seen their income suffer due to Apple's lackluster stock over the past year.\" Unsurprisingly, they also write, \"Iive's involvement with OpenAI too has enhanced the company's credibility in the eyes of its recruits from Apple.\" So the takeaways for those keeping track at home. One, open AAI recruitment of Apple hardware folks is increasing. Planning for the supply chain for this device or devices is happening. From a timeline perspective, we're looking at somewhere between 12 and 18 months, call it, and the form factor remains up in the air. Now, presumably, one of the reasons that we're hearing more about OpenAI's device right now is the buzz around Meta's next generation of smart glasses that were announced last week. So far, the tech press has seemed to have fairly universally positive experiences. The glasses now feature a tiny built-in screen that's invisible to the outside world. And Meta also seems to have figured out how to do gesture controls with a haptic wristband. Lanceoff of Techraar commented that the new version of the Ray-B bands feel like they succeeded in every way that Google Glasses failed. They look less conspicuous, they're more comfortable to wear, and they have a much more significant battery life. The device is also not months and months out. They will, according to Mark Zuckerberg, be available within a few weeks. And at a price point of $799, they're expensive, but nowhere near the, for example, $35,000 for the Apple Vision Pro. The fact that these Ray-B bands are succeeding in the ways that Google Glass failed is obviously very intentional. It's quite clear that Zuckerberg is making his big bet over the form factor for AI devices. At last week's announcement, he said, \"Glasses are the ideal form factor for personal super intelligence because they let you stay present in the moment while getting access to all of these AI capabilities to make you smarter, help you communicate better, improve your memory, improve your senses.\" And this is the sort of grandiose language that the people behind these devices are using. Sam Alman has made similar proclamations about his device. During the swirling news cycle following their announcement back in May, he said, \"Just the way we think of our current computers were designed for a world without AI. And now we're in a different world and what you want out of hardware and software is changing quite rapidly. And if Altman's device really is some version of this little puck that you either keep in your pocket or wear as a necklace or something else, there is an interesting difference in the bet about what the future of AI devices is built for. Alman from the little we know appears to be betting on a vision of ambient AI. In other words, a series of devices all talking to each other and maintaining context that can create the feeling of an omnipresent AI assistant. Zuckerberg's bet, meanwhile, is still very much rooted in the idea of a device acting as a portal to use AI. The glasses can serve as a comfortable way to access your AI, but they're still fundamentally a device that you turn on and use and control rather than an AI enhancement to your surroundings. So far, the ambient AI vision has been a little stuck on go. One of the more prominent devices to get previewed in recent months is a product called Friend. The device is a pendant offering that had some similar features to earlier AI wearables. It records conversations, can help user keep track of their day and keep a diary of events, and provide observations throughout or once the day is done. A series of fairly dismal reviews were published earlier this month, epitomized by the wired headline, I hate my AI friend. Now, what was interesting about this is that whereas with previous generations of AI wearables, the big complaint was that the devices fundamentally didn't work and really didn't do anything, this time around. The complaints were around one, how people reacted to the pin and the general hostility that they found, and two, the fact that they simply didn't like its personality. In fact, engineer Ali Bell commented at the time, \"Extraordinary leap forward that we can critique a wearable's personality and not just its usable hardware.\" Still, there are some early positive reviews of the friend as well. Robert Scobble writes, \"Now that I have used a few of the always listening devices like Avi Shiffman's friend, it makes me want a display in a camera so I can show the AI things, a display so it can show me things, but they are cool. They just leave me wanting a lot more, like a virtual being on my screen.\" Now, addressing this multimodal capability is obviously a clear goal for Meta. For example, during last week's event, Mark Zuckerberg said, \"Glasses are the only form factor where you can let AI see what you see, hear what you hear, talk to you throughout the day, and very soon generate whatever AI you need right in your vision in real time.\" The question is, if the use cases that people are looking for involve explicitly deciding to call up and use the AI rather than it being on all the time, is the perfect AI device already sitting in every pocket in the world? Right now, a huge percentage of people access AI using their smartphone, and it's not necessarily all that inconvenient. Now, some of the knocks on a smartphone are that they don't offer enough bandwidth. In other words, typing and reading responses is too slow, although presumably that could be solved with better voice mode. For Zuckerberg and Altman, another issue with the phone, though, is a matter of screen use and the way that it potentially disconnects people. A big philosophy that both of those two seem to share these days is about getting people to look up from their phone and connect with others around them. Certainly. So far, it looks like Google's big AI device bet is the smartphone. The recent release of the Pixel 10 was all about AI, even though some of the AI features weren't labeled as such. The chipset for the phone was specifically chosen to give better AI performance at the cost of a better CPU. And while this might not be the generation to do it, you get the sense that Google wants the smartphone to become an AI enhanced experience in every way. What's more, now that people have gotten their hands on the iPhone 17, it seems like Apple is making a similar bet. Apple lacks the advanced software models that Google has, but the hardware is no joke. Match.com developer Adrien Grundlin posted a video of what he's been tinkering with, writing, \"Here's Apple's foundation model running on iPhone 17 Pro. It's just so fast. Apple was not joking. The A19 Pro chip is really good for running LLMs on device.\" And yet, if one was looking at the recent Apple event for their real Trojan horse for AI devices, I think that it was not in fact the iPhone, but instead another device that got a new version announced. Maybe the most shared part of the entire presentation was the announcement of real-time translation via the AirPods 3. Basically, the idea is that the AirPods 3 will listen to the language that's being spoken around you, translate it live into your ear, and if you have your iPhone, translate what your response is back into the language that someone can read. At no point in this announcement did they talk about the AI or Apple intelligence that was used to do this translation. They just focused on the use case. That got a lot of people thinking that maybe when it comes to applied AI, the AirPods 3 are actually where it's at. Signal tweeted, \"It should be super clear to everyone that AirPods are the ultimate AI Trojan horse. Always on, socially acceptable, and frictionless. Everyone's carrying a microphone, speaker, and computer adjacency in their ears right now. The AI hardware race is not really about big headsets, glasses, or humanoid robots now. It's about what you can put between someone's nervous system in the cloud without them noticing. That's AirPods. This is the ultimate ambient cognition opportunity, and it's apples to lose.\" Scobble agrees, writing, \"Yeah, the ultimate always on wearable. Much better than any other I've seen, and I have a bunch.\" The others require you to put something around your neck, signaling to others, you are different. Most people don't like that. Headphones have been normalized in society for years. So, who is making the right bet here? Well, first of all, I tend to think that our question about form factor might actually be slightly orthogonal to the question we should be actually asking, which is about use cases. In other words, the problem so far with the dedicated AI wearable devices hasn't just been that they are obnoxious and cause you social ostriization. It's that the things that they enable aren't valuable enough to justify all of that. In other words, people might deal with the staire and stigma of the friend pendant if it did something more for them than just try to summarize their day and talk to them like a robot friend. One of my, I guess, slightly contrarian takes, although this may be a generational thing, is that I think that the reports of people being disconnected in social experiences by having to look at their phone, are wildly overstated. Every time an entrepreneur says something like that, it feels to me like they're trying to sell a different vision for interaction because they have a device that better fits that vision of interaction. This is not to say that the mobile phone hasn't caused serious societal disruption. I think we are living through the fallout of the first generation of that in a profound and painful way. But I don't think that the primary issue is that when we're together in person, it's awful and burdensome to have to take out a thing to snap a photo. I see people complain all the time about folks at concerts or other live events just viewing everything through their screen. But maybe for those people, the value of the experience when they get to look back on it through the video they captured at the event is more rich and powerful for them than if they had just been quote unquote present without their phone the whole time. The point is, I think that a lot of the early stages of AI device exploration are inevitably going to be solutions in search of problems. That doesn't mean that companies shouldn't do it. I don't think we know yet what type of interactions are going to become normal in the future. The only way we're going to find out is by people trying things and some of them unexpectedly working. Still, in the near term, I think that it is far more likely that AI enabled experiences come to the devices we are already using and which are already socially acceptable versus them showing up and getting normalized on an entirely new type of device. Broadly speaking, on the dividing line between ambient always on AI versus AI you have to switch on when you want. I tend to think that for some meaningful period of time, we're going to be in a mode where most people want to switch on the AI when they want to switch on the AI. To the extent that there are ambient AI use cases that become really valuable, I'm very much in the camp that earbuds and the form factors that we already use are likely to be a better starting point than something new. When push comes to shove, everything comes back to utility in some way, shape, or form. A thing's got to be super useful or it's got to be super fun. Otherwise, what are we doing here? And so until devices solve for that, I think the pile of good try but try again is just going to get bigger. Let me know what you think in the comments. For now, that is going to do it for today's AI daily brief. Appreciate you listening as always and until next time, be safe and take care of each other. Peace.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise sobre como a OpenAI, possivelmente em parceria com a Apple, estaria explorando formatos de wearables de IA (falando desde alto-falantes até óculos) e disputando o futuro da IA ambienta versus uma IA que funciona como portal de acesso.",
            "resumo": "O vídeo discute o futuro dos dispositivos vestíveis com IA e se a Apple pode estar envolvida em uma revolução por meio de dispositivos da OpenAI. Há relatos de recrutamento de engenheiros da Apple e de parcerias com fabricantes de iPhone para viabilizar um ou mais aparelhos, com lançamento previsto em 12 a 18 meses. Possíveis formatos incluem um alto-falante inteligente sem tela, óculos digitais e um alfinete vestível. Enquanto a Meta aposta em óculos com tela integrada e sensores, a OpenAI parece explorar uma visão de IA ambiental, em que vários dispositivos mantêm contexto entre si. O histórico de Friends e críticas a dispositivos vestíveis com personalidade também é mencionado como desafio. Em resumo, a OpenAI está avaliando uma família de dispositivos com cronograma próximo, buscando diferenciar-se pelo fator de forma e pela integração ambiental da IA.",
            "assunto_principal": "Avaliação de futuros wearables de IA, com foco na OpenAI e possíveis ligações com a Apple, incluindo formatos, cadeia de suprimentos, cronograma e desafios de adoção.",
            "palavras_chave": [
              "OpenAI",
              "Apple",
              "dispositivos vestíveis com IA",
              "IA ambiental",
              "fatores de forma",
              "óculos inteligentes",
              "pino vestível",
              "alto-falante sem tela",
              "Recrutamento da Apple",
              "Lux Share",
              "Gore",
              "Johnny Ive",
              "Ray-Ban",
              "Meta",
              "Amigo",
              "Linha do tempo de 12 a 18 meses"
            ],
            "resumo_em_topicos": "- Contexto: debate sobre o formato ideal para dispositivos de IA vestíveis e a possibilidade de a Apple se envolver.\n- Avanços recentes: OpenAI recruta engenheiros da Apple e negocia com fabricantes como Lux Share e Gore para viabilizar dispositivos, com lançamento entre o fim de 2024 e o início de 2027.\n- Formatos em estudo: alto-falante inteligente sem tela, óculos digitais e até um pin vestível; a ideia de um “puck” portátil foi mencionada como possível conceito.\n- Abordagens de IA: ambiência (IA ambiental, com dispositivos interconectados mantendo contexto) versus dispositivo-portal (óculos) que a pessoa usa ativamente.\n- Cenário de mercado: Meta avança com Ray-Ban e o carro-chefe de óculos; Apple Vision Pro é referência de custo elevado.\n- Desafios: recepção pública a wearables do tipo pin e críticas à personalidade/eficiência dos dispositivos.\n- Conclusão: a OpenAI considera uma família de dispositivos com perspectiva de 12–18 meses, o que sugere uma corrida pela liderança no formato de IA vestível.",
            "prompt_tokens": 1758,
            "completion_tokens": 2448,
            "model": "gpt-5-nano",
            "cost": 0.0046
          },
          "analysis_time": 89.13743877410889,
          "language": "",
          "view_count": 2878,
          "has_transcript": false
        },
        {
          "id": "DPFNiLW_yqg",
          "title": "The Truth About the AI Bubble",
          "title_pt": "A verdade sobre a bolha da IA",
          "url": "https://www.youtube.com/watch?v=DPFNiLW_yqg",
          "published": "2025-09-22T12:03:46.728296",
          "published_relative": "há 1 dia",
          "duration": "29:29",
          "date_published": "2025-09-21T05:20:06-07:00",
          "transcript_available": true,
          "transcript": "Today we are looking at the best analysis that I have yet found on whether AI is in a boom or a bubble. So what's your guess about what it's going to say? All right friends, today we are talking about the big question at least from a macro perspective. Is AI a bubble? This of course is a question that has been lurking for some time. One could go back to last summer, the summer of 2024 to see some of the first places where this conversation broke into the mainstream. We had the Goldman Sachs report, Gen AI, too much spend, too little benefit, Seoia's AI's $600 billion question, which was very comfortable calling it an AI bubble. Of course, subsequent to that, we've had hundreds of billions of dollars of market cap added, tens of billions in new revenue realized, hundreds of millions of new users. Basically, to the extent that it was a bubble, then it has done nothing but gotten bigger. Or maybe that bubble talk was premature and was about something else. For my money, at least part of the bubble conversation has always been connected to the uncomfortable weight that this market and economy has put on Gen AI. Chad Gibbt launched at almost the exact same time that Jerome Powell started the fastest rate hiking cycle in history. And for most of that hiking period, it was AI enthusiasm versus the world when it came to Wall Street performance. In the wake of the initial disappointment around GBT5, there was an interview with Sam Alman where he was widely interpreted as having said that there was a bubble even though he couched his language. a lot more than the headline suggested. And really, it's just a question that's never fully gone away. Now, functionally, does this matter to those of us who are just using these tools or figuring out how they are going to impact our businesses? The short answer is no. If you have used these tools for your work or your personal life, especially if you are here listening to this show, you will have undoubtedly come to the conclusion that they are immensely powerful and are likely to reshape much of what you do. Ethan Malik recently tweeted, \"A third of American adults use AI many times a day to almost constantly and another third several times a week. I can't usefully add much to discussions of valuation bubbles, but if bubble means a disappointing technology that is overhyped and not useful, that doesn't match the data.\" And so for our purposes, let's clear out that side of the bubble conversation. I've spent enough time on this show recently talking about the shift in sentiment around GBT5, around why capabilities actually are continuing to increase, about how many different areas beyond just core chat interface AI has still to explore and how fast those areas are evolving. Things not only like Nano Banana's image generation, but also world models. Let's instead then talk about the other part of the bubble question, which is specifically about markets. And for that, we're going to turn to Azimar, the creator of Exponential View, which is both podcast and Substack. I've known Azim for more than a decade, since back in our social entrepreneurship days when that whole movement was first starting. And he's always been a really interesting and comprehensive and dispassionate thinker when it comes to the future of technology. An optimist, but never a hu wanting to look at things in full terms. And so, when I saw that he had written a long form piece called Is AI a bubble? I knew for sure that this was going to be this week's longread Sunday/bigthink episode. As has been our style lately, we're going to do a combination of reading excerpts plus discussing, but in this case, I am going to try to get through the majority of the argument because I think part of what makes it powerful is its comprehensiveness. Azim writes, \"A month ago, I set out to answer a deceptively simple question. Is AI a bubble? Since 2024, people have been asking me this as I've spoken at events around the world. Even as Wall Street bankers largely see this as an investment boom, more people are asking the question in meeting rooms and conference halls in Europe and the US. The best way to understand a question like this is to create a framework, one that you can update as new evidence emerges. This essay is that framework. Five gauges to weigh Gai against history's bubbles. Azim starts historically. Bubbles, he writes, are among the oldest stories of capitalism. They're parables of excess belief in collapse. But bubbles are not just financial phenomenon. They are cultural artifacts. They return again and again as morality tales about greed and folly. Tulip mania, often misremembered as a frenzy of bankrupt weavers and drowning merchants, was less disastrous than legend suggests. It was confined to wealthy merchants and left the Dutch economy largely unscathed. But the myth has endured, and that is the point. Bubbles become stories we tell ourselves about the dangers of optimism. Some bubbles are financial. The South Sea frenzy of the 1720s, the roaring stock market of the 1920s, Japan's real estate boom of the 1980s, and the housing crash of 2008. Some are technological. In the 1840s, railways were hailed as the veins of a new industrial body, and they were. But a body needs only so many veins, and tracks were soon laid in places commerce could not sustain. Telecoms in the 1990s promised a wired utopia, only for 70 million miles of excess fiber to lie dark underground. The.com boom gave us a vision of a new economy, much of which did eventually materialize, but not before valuations evaporated in 2000. The funny thing is there doesn't seem to be an academic consensus on what an investment bubble is. Nobel laurate in economics Eugene Famma has gone so far as to say that they don't exist. Azim's goal with this piece is to go beyond the I know a bubble when I see it kind of idea. He suggests that the two key pieces are when stock markets become overvalued and collapse and then secondly whether the quantity of productive capital such as the money going into capex or VC also collapses. To get specific, he writes, \"We see a bubble as being a 50% draw down from the peak equity value that is sustained for at least 5 years. In the case of the US housing bubble and the dot, that trough was roughly 5 years long. Full recovery to pre-bubble peaks took 10 years for US housing and 15 for the dot. Alongside, we would expect a substantial decline in the rate of productive capital deployed once again 50% from peak. Ultimately, he says, a bubble means a phase marked by a rapid escalation in prices and investment where valuations drift materially away from the underlying prospects and realistic earnings power of the assets involved. Bubbles thrive on abundant capital and seductive narratives, and they tend to end in a sharp and sustained reversal that wipes out much of the paper wealth created on the way up. A boom, by contrast, can look very similar in its early stages with rising valuations and accelerating investment. But the crucial distinction is that in a boom, fundamentals eventually catch up. the underlying cash flows, productivity gains, or genuine demand growth rise to meet the optimism. Booms can still overshoot, but they consolidate into durable industries and lasting economic value. Now, I will say and a little editor's note here, this is kind of becoming the clever person's interpretation or analysis of what's happening now and is almost kind of what Sam Alman was saying. The clever feel-good at dinner parties take is well yeah of course the investment guys are getting a little overexuberant and maybe spending on things that they shouldn't and a lot of the things that they're investing in now aren't going to be useful in the future but the underlying technology is real and it will be world changing just on a longer time scale than we think. Now there is nothing wrong with this point of view. It's a very reasonable nuance point of view. I just basically have an allergy to this type of clever analysis that again mostly serves to make people feel nuanced and sophisticated in conversation with their peers. End editor's note. Back to Azim. He writes, \"Between the boom and the bubble lies a gray zone, periods of exuberance when it is genuinely hard to tell whether capital is building the foundation of a new economy or merely inflating prices that will not be sustained.\" And that of course gets us to the question of is AI a bubble? So what are the gauges that he is applying to actually look at this? There are five. Gauge one, economic strain. Is investment now large enough to bend the economy? Gauge two, industry strain. Are industry revenues commensurate with deployed capex? Gauge three, revenue growth. Is revenue rising or broadening fast enough to catch up? Gage four, valuation heat. How hot are valuations compared to history? Are stocks excessively overpriced? And gauge five, funding quality. What kind of money is funding this? Is it strong balance sheets or fragile flighty capital? What is he does with the rest of the essay is to look at each of these five areas and put them on a green yellow red kind of scale where ultimately he argues that two reds equals trouble when it comes to bubble analysis. The first gauge is economic strain. Azim writes the investment underway is vast with Morgan Stanley expecting 3 trillion in AI infrastructure spend by 2029 but it has not yet reached the runway extremes of history's great blowouts. But as Aim points out, it's not just the sheer magnitude that is the question. The other big factor is what he calls dependence. He points out that in the US, a third of GDP growth right now can be traced to data center construction. You might remember this chart I shared last month that showed that the pace of data center construction was about to overtake the pace of general office construction. Now, when it comes to the economy's overall dependence on this particular area, Azim writes, \"It's not inherently bad, but it may be dangerous if the momentum falters. An economy leaning this heavily on one sector for growth can find the ground falling away faster than expected. And by the way, I think that this is actually why the bubble narrative is so everpresent and part of why people can't just be excited about what's happening. There is actually an interesting argument that people are so concerned about their analysis that this is a bubble that they're not recognizing that AI is one of very few technology changes that actually has the chance to create jobs in the short term even as it's going through the phases of creative destruction. Creative destruction is of course the famous idea from Joseph Shimter that new technologies while inevitably creating new things wreak a path of destruction in terms of old processes and old jobs and old roles and old industries even that get replaced and competed away. In the process of creative destruction we usually see the destruction before the creative. One of the reasons that there's anxiety around AI and agent related job loss is that it's much easier to see the onetoone replacement effects for certain highly capable agents on jobs that exist today than it is to imagine 5 years out what new industries are going to be created by the new capabilities that these technologies represent. This is sort of the normal pattern of new technology shifts. However, with all of this capex spend, with data center construction, there are big sectors of the economy, things like construction that are going to be forced to hire new people, upskill them in new ways, in ways that could be value accreative in the short term. But again, people are so concerned that it's overexuberant and it's all going to go away that they're not really letting themselves get excited about those short-term gains. Anyway, coming back to Azim, he writes, \"The surge of capex poured into the physical infrastructure that AI demands is an act of optimism. This is what capex is. Money spent today in the belief that it will become a funnel of revenue tomorrow. If it's well placed today, it will eventually lead to productivity gains and economic expansions. AI data centers are not just factories for a single product. They are infrastructure.\" Microsoft, OpenAI, and the US government all see it this way. They see compute as a foundational utility of the 21st century, no less critical than highways, railways, power grids, or telecom networks were in earlier eras. To build such infrastructure inevitably requires historic sums, on a par with the railway or electricity buildouts of the past. Azim points out that in sheer terms, AI data centers are likely to be among the largest infrastructure buildouts in modern history. However, he writes, useful though infrastructure is, especially when private capital gets involved, things can get divorced from reality. the financing structure matters as much as the technology itself. He then points out the difference between the way that railways were funded versus electricity and road systems. Railways were largely private and had a number of different investment bubbles. Whereas, as he puts it, electricity and road systems benefited from greater public investment and coordination and were less prone to speculative excess. A boom becomes dangerous when the resources at demand start to bend the whole economy around it. Wages get sucked into one sector, supply chains reorient to serve it, and capital markets grow dependent on it. The snapback is vicious when expectations break. Consequently, he suggests that a good way to gauge the economic strain is to look at investment as a share of GDP. He calls this a crude but telling ratio, showing how heavily the economy leans on one technological bet. By this measure of past bubbles, the railway bubbles were the heaviest. In the US, railway spending peaked at about 4% of GDP in 1872, which was just before the first crash in that area. On the other end of the spectrum, the telecom boom of the late 1990s topped out at around 1% of GDP. Azim writes, \"The AI buildout sits in the middle zone. Around 370 billion is expected to flow into data centers globally in 2025 with perhaps 70% earmarked for the US or roughly 0.9% of American GDP. Goldman Sachs projects spending will climb by another 17% in 2026. My own forecasts are in line with this view. annual capex of 800 billion by 2030, perhaps 60% of the US, which would bring the American share to 1.6% of 2025 GDP. So for his economic strain gauge, he places the green segment as a technology representing up to 1% of GDP, the yellow as up to 2% of GDP and the red as above 2%. Generative AI today at 0.9% is still in the green, although it could be heading into the yellow soon. The biggest caveat with the economic strain analysis here is that the depreciation of AI capex could be much faster than the comparative depreciation of railway track or telecom fiber. GPUs, he writes, by contrast agent dog years. Their useful life for frontier applications such as model training is perhaps 3 years after which they are relegated to lower inensity tasks. Roughly a third of hyperscaler capex is going into such short-lived assets. They remain in theory monetizable in years five and six. The rest goes into shells, power, and cooling that lasts two or three decades. Adjusting for asset life makes the AI buildout look even more demanding. Unlike railroads or fiber, the system must earn its keep in a handful of years, not generations. Interestingly, he says, while the negative implications of that are clear, there is also an optimistic case. He writes, shorter depreciation cycles may impose financial discipline on incoming investors. During the railway mania, decades long asset lives masked the weakness of many business models. companies could stagger on for years before insolveny. In AI, the flaws may surface quickly, forcing either rapid adaptation or rapid failure. Ultimately, he concludes, the strain is noticeable, but not yet unbearable. Venture funding in the AI application layer, while noisy, remains modest compared to the telecom mania of the 1990s. That suggests that there may be running room before the cycle overheats. Next up, we have gauge 2 industry strain. Every boom, he writes, needs to prove that the money poured into new equipment is starting to earn its keep. In any growth stage, it is unlikely that revenues will cover investment, but they should be non zero. This gauge looks at the ratio of capex to revenues. Now, there have been a number of different estimates of how to look at genai revenues. Some of the most common that you see, especially when people are trying to say that there's a bubble, is just adding up the revenue of OpenAI, Anthropic, and a handful of other startups, usually pointing to a number that comes to between 15 and 18 billion, and saying something to the effect of how could that possibly justify the hundreds of billions being spent on infrastructure. Azim's estimates are over 60 billion this year. And even that, he says, could underount the value. He writes, \"Meta, for example, has suggested that the technology has increased conversions on its platform by about 3 to 5%. Indirect effects like this may help explain why some analysts such as Morgan Stanley peged 2025 revenues far higher at 153 billion.\" And yet, it's undeniable that capex intensity is also increasing. He writes, \"In 2021, before ChatBT, hyperscalers invested about 44% of their operating cash flow in capex. By 2024, that had risen to 68% and in 2028, it will be higher still. But these firms can absorb this shift by replatforming with structurally higher capital intensity driving growth and efficiency gains. This dynamic has been in place for a decade already. Between 2015 and 2018, he writes, Microsoft Azure's capex represented between 70 and 90% of revenues. It was an investment in the future. He continues, this makes for an interesting comparison to earlier boom cycles. The railroads are particularly pertinent. The railroads direct revenue contribution was tiny compared to the value the railroads created in the US economy. Railway bubbles were always tethered to the reality of cash flow. The bonds issued to finance new track and rolling stock had to be serviced out of passenger fairs and freight revenues. Whenever capex outpaced earnings, the strain showed. The manas of 1873, 1883, and 1887 all followed the same pattern. A sharp decline in the ratio of annual revenues to capital spending and in some cases outright revenue contraction. At the height of the US railroad expansion in 1872, capex was around two times revenues. In the late 1990s telecom bubble, capex amounted to just under four times revenues. By contrast, today's genai boom runs on roughly 60 billion in revenues against about 370 billion in global data center capex. A capex torevenue ratio of six times the most stretched of the three. On the industry train gauge, then railways sat healthily in the green. Genai was in the yellow, but Gen AI is in the yellow, nearing red. Still, he says it's not quite a warning sign, not least because Gen AI has people clamoring for access to AI data centers. One report suggests that enterprise customers are committing to capacity before data centers are even built. What is driving that is usage and with that comes astonishing revenue growth. So, of these indicators, jumping ahead a little bit, this is the one that is the closest to red. When push comes to shove, Azim does not argue that any of the gauges are yet in the red when it comes to AI. For my money, I think that Azim and his team are underounting revenue. I think that part of why there is such incredible demand is those second order effects like the ones he talked about at Meta and my guess is that Morgan Stanley's estimate is much closer to the reality which would push this number down even farther. Still, all of this is prelude to gauge three revenue growth. He writes, \"The problem in the railroad and telecom booms was not sector strain per se, but that revenues ran out of momentum. Investment expects a return. After the railway bubble burst in 1873, revenue declined by 3% year-over-year. Telecoms did slightly better, declining 0.5%. Before the crashes, revenue growth was hardly explosive. Railways in 1873 expanded 22%, enough to double in 3 years. Telecom in the late 1990s managed only 16%, a doubling time of just over 4 years. By contrast, Genai revenues are still accelerating. By our estimates, Genai revenues will grow about twofold this year. And this is likely a conservative forecast. City estimates that modelmakers revenue will grow 483% in 2025. Open AI forecasts annualized growth of about 73% to 2030. While analysts like Morgan Stanley estimate this market could be as large as 1 trillion by 2028, equivalent to compound growth of 122% a year over the period. This puts Generative AI in his estimation very squarely in the green when it comes to revenue growth. given that basically every estimate has at the very minimum genai doubling every year. Azim continues, \"In my conversations with large companies, I get the strong sense that they can't get enough of this technology right now and this likely supports the strong growth rates. IBM CEO survey shows that Genai is already expanding IT budgets with 62% of respondents indicating that they will increase their AI investments in 2025. If you listened to Friday's show, you will have heard me talk about KPMG's latest pulse survey, where the anticipated investment among their 130 survey companies with a billion dollars in revenue each was 130 million over the next 12 months, which was up from 112 earlier in the year and 88 in Q4 of last year. Ultimately, he points out that we are still at the quote foothills of enterprise use. For now, firms can barely secure enough tokens to meet their needs. He also notes that the consumer side tells a parallel story. US consumers, he writes, already spend around 1.4 4 trillion a year online. This could plausibly double to 3 trillion by 2030 if it grows at 15 to 17% a year. And it has grown at more than 14% a year since 2013. Against this backdrop, a Genai app sector rising from today's 10 billion to 500 billion within 5 years looks less far-fetched. Exponential growth rates of 300 to 500% are already visible in mid-size startups and the large model providers, suggesting that even a small reallocation of consumer digital spending could drive revenues into the hundreds of billions. Taken together, he says, \"These signals point to an industry still in strong ascent, unlike the relatively meager revenue growth that preceded the railway and telecom busts. If Genai revenues were to grow at even half the pace of last year, then on my conservative forecast, they would reach 100 billion by 2026, covering about 25% of that year's capex.\" Gauge 4 is called valuation heat, and as he puts it, is all about the mood of the market. He writes, \"This is often where bubbles reveal themselves most clearly. How exuberantly investors are pricing the sector regardless of fundamentals, and this is almost a default part of new technology cycles.\" He writes, \"As Carlotta Perez has argued for decades, financial markets tend to overshoot in the early installation phase of each technological revolution, pouring in capital far beyond what near-term revenues justify. The frenzy looks irrational in the moment, but it is the mechanism by which society lays down the new infrastructure. The challenge is whether the frenzy can evolve into the deployment phase when the infrastructure becomes universal and delivers real productivity gains. Now obviously the story that we all know about this one is the dot bubble. Companies raising tens or hundreds of millions of dollars on absolutely no revenue and no business model to speak of ultimately led to the bubble popping and a long slow rebuild where so many of the ideas that were initially present actually came to fruition backed by real revenue and real growth. Azim importantly makes the point what's going on in Genai does not compare to this. The key measure here is the price earnings ratio or PE a shorthand for how many years of current profits an investor is effectively paying for. A high PE means companies are betting on rapid future growth but too high for too long investors might be buying into a fantasy. This was the case in the dot era. At the peak the NASDAQ traded at a PE of about 72. One detailed study estimated that internet stocks alone carried an implied PE of 605. In other words, investors were willing to pay for more than six centuries of current earnings. The issue wasn't that the demand disappeared. Amazon's revenues grew from 2.76 billion in 2000 to 3.12 billion in 2001, but that no company could grow fast enough to justify those sky-high expectations. In other words, he writes the fundamentals improved, but expectations collapsed. Today, he says the picture is much calmer. The NASDAQ PE is about 32, half of the dot era. The broader tech market is higher than the longr run average, but nowhere near dot territory. Ultimately, he puts this category in the green as well. Prices, he says, haven't yet broken free of gravity in the way that valuations did. A couple things to note here. You will sometimes see people point to the incredibly high valuations that startups are getting in the venture realm as evidence of bubble. I think there are a couple things that make that not all that concerning when you look at it in this overall context. The first and most obvious one is that venture dollars ultimately are a tiny tiny portion of the financial markets. In 2024, US venture investment deals were worth $215.4 billion. Last week, after Oracle announced its projections for the coming years, the company added $244 billion to its market cap, about 30 billion more than all of VC in 2024. The point is that VC is just ultimately relatively small and has an outsiz impact on our imagination as compared to what it does in our markets. Second, its impact is even lessened because VC is meant explicitly to take risky bets. Venture capitalists are wellprepared, as are LPs, for the idea that most of their investments will fail. That's just built into the industry. And finally, while valuations are high and moving quickly, the rate of revenue growth among many of these companies is unlike anything we've ever seen in startups before. One may quibble about how durable that revenue is. There is a huge amount of, for example, what some have called curiosity revenue where enterprises and consumers try interesting new products but then don't stick around that maybe are warping some of those growth numbers. But still taken as a whole, companies are making more and faster in this technology shift than just about any we've ever seen before. All of which finally brings us to gauge 5, funding quality. Funding quality, as writes, is not a standard metric, but a composite judgment. It asks who the money is coming from, how it is structured, and whether the capital is willing to wait years for returns or rather chase quarterly pops. Low-quality capital in short is short-termist, undisiplined, and debt laden. It rushes and flees quickly. High-quality capital is more patient, better underwritten, and able to withstand volatility. Every bubble has its signature weakness, invariably rooted in how it was financed. Railways were fueled by speculative retail investors with little capital behind them. By the early 1870s, funded debt averaged 46% of total assets among American railroads. When overbuilding met a credit squeeze, financing evaporated. Do firms a century later were a little sturdier. Venture capital was a boutique business in 1995 with only 5.3 billion deployed. By 2001, more than 237 billion had been poured into startups, often by new and inexperienced managers. The frenzy spilled into public markets. IPO volume between 1999 and 2000 ran six times above historical averages. companies went public with little revenue. One other aside note on the manager thing, by the way, not only do you not have new and inexperienced managers running around venture capital right now, you actually have the exact opposite. Alps have been starved of liquidity for so long that the entire industry has been forced to start to use secondaries as a mechanism to get some liquidity. And many, many funds in the wake, especially of rising interest rates in the poster era, have shuttered their doors and not been able to raise again. meaning the crop of people that are around now are a lot more battleh hardened even relative to venture capital terms. Anyways, back to Azim, he continues, telecoms in the late 1990s leaned on mountains of cheap debt. US and European carriers doubled and quadrupled their leverage in just a few years. Deutsche Telecom and France Telecom together added 78 billion in net debt between 1998 and 2001. When revenues failed to keep pace, defaults rippled through the sector. In each case, the capital that fueled the boom proved ephemeral, but the degree of fragility differed. Railways and telecoms were most exposed to credit crunches with debt ratios ballooning. Doss were hostage to market mood with equity values evaporating. On this front, today's AI boom looks sturdier. Microsoft, Amazon, Alphabet, Meta, and Nvidia are minting extraordinary cash flows, easily enough to bankroll their own buildout for now. But investment needs are racing ahead. Morgan Stanley reckons total global data center capex will hit 2.9 trillion between 2025 and 2028. Hyperscalers can cover perhaps half of that from internal cash. The rest must come from private credit, securitized finance, and new operators. Governments have also pledged 1.6 trillion in sovereign AI investments, and Gulf Capital is seeking new opportunities. Here is where the risk creeps in. Morgan Stanley itself points to a $ 1.5 trillion gap that will need to be plugged by debt markets and assetbacked securities. The sums are enormous. 800 billion from private credit, 150 billion in data center ABS, and hundreds of billions more in OEM loans and vendor financing. That 150 billion alone would triple the size of the data center securitized markets almost overnight. And not every borrower looks like Microsoft. So the point for him is that right now, as much as you could say companies are spending too much on capex, they're spending their own money on capex. They're not going into debt or finding weird novel instruments to do so. The question is how long that can persist. As a sums up, the foundations are stronger than in past bubbles, but the superructure is starting to resemble the old pattern. Esoteric debt structures, concentrated counterparties, and hardware that may not hold value are reappearing. If Genai revenues grow 10fold, creditors will be fine. If not, they may discover that a warehouse full of obsolete GPUs is a different thing to secure. So where does that net out? Simply put, we are in boom territory, not bubble. Of aim's five gauges, four of them, economic strain, revenue growth, valuation heat, and funding quality are all in the green right now. The closest to red is industry strain, which is again a measure of capex investment divided by revenue, where he is purposely going with a relatively modest or conservative revenue number. The inescapable conclusion is AI is not a bubble. But of course, that doesn't mean that it won't become one. The pressure points that Azim considers worth watching include more and more of the economy relying on AI. Basically, if investment climbs towards 2% of GDP, a sustained fall in enterprise or consumer spending, especially if it's followed by a shrinking order backlog for companies like Nvidia, valuations jumping from where they are at a PE ratio of 32 right now to up to 50 or 60. And lastly, if a greater and greater portion of capex starts to be covered off of the balance sheet, he concludes, my current heruristic is that if two of the five gauges head into the red, you're in bubble territory. Time to sell up, buy the VIX, and take some deep breaths. Genai isn't there yet. Racing fast, the engine is whining but not overheating. How long would it take for two gauges to get into the red? I've toyed around with combinations and most scary scenarios take a couple of years to play out. And not all scenarios are scary. That said, so many macro factors from a recession in the US to rising inflation, a challenging interest rate environment, and domestic or international politics could dampen spirits. While we might not be solidly in bubble land, it would be hubristic to assume the AI investment cycle is immune to those exuberant dynamics. And this, I think, is a great take. One does not need to shout bubble left and right just because things are moving fast, in some cases faster than we've ever seen. Things moving fast does not a bubble make on its own. At the same time, we don't need to be polyianish about the risks. Companies are betting hundreds of billions of dollars on a future which none of us can know exactly how it's going to play out. There are many, many ways for that story to play out in the future that leads to bubble dynamics. Neither do we need the clever but ultimately fake nuance of well sure we're in a bubble now but that doesn't mean that there won't be value later. What the data suggests at least if you agree with the interpretation which of course is totally reasonable for one not to is that at this moment we are firmly not in bubble territory and thanks to this framework we have a much better system for tracking to see how things are changing over time. Big ups to Azim at exponential view for this piece and for now that's going to do it for today's AI daily brief. Appreciate you listening or watching as always and until next time, peace.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Hoje estamos olhando para a melhor análise que já encontrei até o momento sobre se a IA está em um boom ou em uma bolha.",
            "resumo": "Hoje estamos olhando para a melhor análise que encontrei até agora sobre se a IA está em um boom ou em uma bolha. Então qual é o seu palpite sobre o que ele vai dizer? Certo, amigos, hoje estamos falando sobre a grande questão, pelo menos de uma perspectiva macro. A IA é uma bolha? Essa, é claro, é uma pergunta que tem rondado há algum tempo. Pode voltar ao último verão, o verão de 2024, para ver alguns dos primeiros lugares onde essa conversa chegou ao grande público. Tivemos o relatório do Goldman Sachs, IA Generativa, gasto demais, pouco benefício, a pergunta de 600 bilhões de dólares da IA da Seoia, o que era muito confortável chamá-la de bolha de IA. Claro, desde então, tivemos centenas de bilhões de dólares em valor de mercado adicionados, dezenas de bilhões em nova receita realizada, centenas de milhões de novos usuários. Basicamente,",
            "assunto_principal": "A Verdade sobre a Bolha da IA",
            "palavras_chave": [
              "sobre",
              "adicionado",
              "sempre",
              "análise",
              "basicamente",
              "benefício",
              "maior",
              "bilhão",
              "bilhões",
              "sem dinheiro",
              "bolha",
              "chamada"
            ],
            "resumo_em_topicos": "sobre\nadicionado\nsempre\nanálise\nbasicamente\nbenefício\nmaior\nbilhão",
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "model": "gpt-5-nano",
            "cost": 0.0
          },
          "analysis_time": 78.2487781047821,
          "language": "",
          "view_count": 5643,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@AIJasonZ",
      "name": "@AIJasonZ",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@AINowInstitute",
      "name": "@AINowInstitute",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@AIinsighthub001",
      "name": "@AIinsighthub001",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Aitrepreneur",
      "name": "@Aitrepreneur",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@AmazonScience",
      "name": "@AmazonScience",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Analyticsvidhya",
      "name": "@Analyticsvidhya",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Apple",
      "name": "@Apple",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Argonalyst",
      "name": "@Argonalyst",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@AssemblyAI",
      "name": "@AssemblyAI",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@CenterforHumaneTechnology",
      "name": "@CenterforHumaneTechnology",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ColdFusion",
      "name": "@ColdFusion",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ColeMedin",
      "name": "@ColeMedin",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Computerphile",
      "name": "@Computerphile",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DanGalletta",
      "name": "@DanGalletta",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DataCouncil",
      "name": "@DataCouncil",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DavidOndrej",
      "name": "@DavidOndrej",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Deeplearningai",
      "name": "@Deeplearningai",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DevelopersDigest",
      "name": "@DevelopersDigest",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Feliperaitano",
      "name": "@Feliperaitano",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@GregIsenberg",
      "name": "@GregIsenberg",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "BRUELrChH7k",
          "title": "Making $100K/month with iOS apps (BREAKDOWN)",
          "title_pt": "Ganhando US$ 100 mil por mês com apps iOS (DECOMPOSIÇÃO)",
          "url": "https://www.youtube.com/watch?v=BRUELrChH7k",
          "published": "2025-09-22T18:07:02.102169",
          "published_relative": "há 18 horas",
          "duration": "32:50",
          "date_published": "2025-09-22T11:00:21-07:00",
          "transcript_available": true,
          "transcript": "I'm going to show you how to build a 100K MR mobile app. There are people today that are building this type of scale mobile apps, millions of dollars a year of revenue, that have very little experience, but know how to create products that are niche enough, that resonate with people, and that hit the right marketing channels. Now, I'm not promising by the end of this that you'll be able to hit 100K MR. No, of course not. But what I am promising you is that by the end of this, you'll have the frameworks necessary, the thinking necessary, the sauce necessary for you to start something that could hit 100k MR or more. [Music] Um, so my hope is that it gets your creative juices flowing and and that you end up shipping something that that is valuable and that starts generating revenue for you and creates happy customers. Now there are uh literally kids now creating mobile apps that are hitting this amount of scale. Um, and it, you know, I think it's they've just have a good understanding of the lay of the land. They understand creators really well. They understand what makes viral apps really well. They understand what makes viral social formats. So, if they can do it, so could you. I'm going to give the whole playbook here. Um, I have done consumer mobile in the past. I've started and sold uh venturebacked consumer mobile apps. I was an adviser to Reddit, adviser to Tik Tok. So, I'm not just a Joe Schmo. and I, you know, have been in the trenches and I want to share this sauce with you. It is no fun keeping the sauce to myself. It's like, you know, eating spaghetti. It's no fun to eat spaghetti alone. You know, you want to invite your family. You want to invite your neighbors. You want to invite your friends. So, you are my family. You're my neighbors, my friends here today. All that I ask is you like and comment on this so I know to keep sharing this sauce with you. Um, and also it'll spread to more people. So, you know, I think the world is is a is a better place when we have products that people love to use every single day. So, let's get into it. If you want to build a 100K or mobile app, you want to pick a daily habit to serve. Important word here, habit. The habit is because of the frequency of it. You know, habits is something that you do frequent. You're going to want to find a narrow wedge use case. Um, so you don't want to create something. You don't want to pick this huge huge competitive um space. You want to pick something that's narrow and that wedges into something. And I will say having AI a part of that is important because that's going to AI obviously is very interesting to consumers right now. They want to use consumer AI products. You're going to want to prototype this in a relatively short amount of time. You can use something like Lovable or Bolt. You can use something um I think they integrate with Expo to create the mobile app. Uh you can use something like ROR and you can use something like Vibe Code app. And then you're just going to want to do distribution tests. So you're going to want to focus on one channel with three formats per week. So the mistake a lot of people make is they're trying five different channels, 10 different formats. No, I think you know the people that really crush it uh here are are focusing on one channel. Think Instagram or Tik Tok. Uh and then just uh different formats. When I mean by formats, I mean, you know, are you doing stories, you know, like I don't mean like an Instagram story, like a story where you're doing these, let me tell you about the story of how, you know, I lost 65 pounds or are you doing uh like meme style stuff, different types of meme formats, um, and content formats that, you know, hopefully resonate. And there I can do a whole video on how to find formats, uh, in if you know, in the future. Um once you find something that uh starts to take off from a format perspective, you're going to want to onboard, you know, 100 true true users. If you can't get a 100, it's 12, 18, 25, then you start monetizing them. Uh the you know what you see is people either do X dollars per month or week or an annual uh basis. Uh and then you do this retention loop and referrals. So once you have a group of people, you want to incentivize them to invite their friends and then you start scaling via ads, ASO, app store optimization, and affiliates. Typically, I'm seeing anywhere between 15% and 40% affiliate cuts um for these consumer mobile apps. And then you get to 100KMR. It looks so simple, doesn't it? But it is more complicated than that. And in this episode today, we're going to go deeper in each of these different categories. Um, and I hope to just give you a little bit more confidence around some of this stuff. Yes, I know that, you know, people are going to say in the comment section, you make it look so easy. You make it look so easy. Uh, I'm not trying to make it look easy. I'm just trying to distill it as much as possible uh for you. So, I talked about the key word being a habit. Um, and I want to I want to just double click into that. a habit, you know, let's just say we're talking about in the wellness space, the habit might be something like a sleep tracking nuance, you know, in money, it might be micro saving challenges. In learning, it might be 10-minute space drills. In fitness, it might be form feedback bursts. And it even might be even more niche than that, you know, and it probably is. It probably is like these are this is niche and it's not niche enough in my opinion. Uh the important thing is like if you want to build something in wellness let's say and you want to build something in sleep you want to look for an evidence of paid demand that's you know a lot of people come up with ideas for mobile apps uh consumer mobile apps and they have a lot of demand but people are not willing to pay for it. So that is a that's like one of the biggest mistakes people make. Don't make that mistake. You you want to look at uh search volume uh within communities. Uh you want to look for competitor gaps. You want to look at high frequency, daily use case, not weekly. You know, if you're seeing weekly use cases or monthly use cases, kill it. One of the reasons why Cal AI works is the people in that, you know, in that what is Cal AI? You take a picture and it tells you how many calories it is. Um, people are doing that every single day. In fact, they're doing it multiple times a day. So, they're thinking it it's valuable to them. they're willing to pay for it and they're selling the outcome of look fit, look good and people will pay for that. So, um there's a few ways that you can find demand. Uh one is you can go to Reddit um and you can actually just go into different subreddits. Um what I like to do is I like to uh just sort by uh the top or the best. Um, and then you can actually, you know, sort. Let's do top and maybe this year I'm in the SAS subreddit. Um, and then you can just see like what people are talking about. Um, and just and it gives you validation to what you what it is you're building. So, you know, if it's if it's health, you're building something wellness, like what are the 10 different subreddits that you need to that you should be looking into? How can you sort by top and best uh by the year, by the week, by the month, and then just write notes around what people are saying, how they're talking, and that'll help you validate it. One of my favorite features on idea browser is this market insights bit. So, it basically uses AI to scrape Facebook groups and Reddits, all the stuff that I was doing manually, basically going to, you know, subreddits and trying to figure out what are the different pain points, uh what are some pe what what are some products that people are asking for? what are the different habits that these people have? But I just auto I built this to automate the whole thing. So for example, you know, I'm in this, you know, I can see the fractional executive marketplace in management OS and I can see what are the different pain points and solutions and underserved segments and just literally go in and see how often are people, you know, saying it's really hard to find uh fractional executives and I can and literally get quotes from people how people are, you know, you can see like current workarounds people are using LinkedIn and Upwork and Top tool. It's like I never even heard of Toptool. And then willingness to pay signals. Someone said burn thousands of dollars. Several users mentioned 2 to 10,000 engagement gone, you know, gone arry. So I just love playing with this, going through this, seeing what the different solutions that people are asking for. It's crazy that people are literally on Facebook groups and subreddits being like, \"Hey, someone go and like, I would I would pay for this. I would pay for this.\" They're asking for it. It also goes into these underserved segments and much much more. Um, I just think that there's a treasure trove of data in Facebook groups and subreddits. And yeah, that's what one of that's why I built Idea Browser. Idea Browser is a paid is there's a free component and there's a paid product. what I showed you today was uh the paid paid product. Uh and then Tik Tok, you know, it's free to use Tik Tok and you can just, you know, if you're building something in sleep tracking, what you can do is uh just go onto Tik Tok um search for um sleep tracking. And you know, I'm just going to do that right now. Sleep tracking. And then uh once you search for it, you'll see in the top right there's three dots. Click the three dots and you click filters and then you sort by the most amount of likes. Um and then you can just watch videos of people in your space to give you to give you a sense of like is there demand for this habit. So step one is basically finding this habit. Uh usually it's related to a trend. Um but find a habit you you know could use some of these tools to go ahead and do that. Once you've uh figured that out, you figured out what you want to build, um you know, this is sort of how I think about, you know, the the the experience of the app. So, you create the app, the user basically discovers the app in the app store. There's a listing view in the app store. It's really important to have or you know just a really clean you know name and and and app store previews that you know get people to um want to download it right so the conversion rate on the app store is really important you know for example like I think the name Vibe Code app is a really good name for a vibe coding app for mobile apps um so you know one of the reasons why this is now you know top 10 I think developer app is you know the name is is really good. So think about how you can optimize the name and the the previews include a video in there so people are going to download it they're going to open it and then you basically have maximum 60 seconds in onboarding and it's important to create value first. When you look at some of the, you know, some of these apps, um, that, you know, have a lot of, uh, virality to them, they basically have, you know, just a 60, you know, a very short value first mentality for developing that. Um, and then you're going to create, uh, an account. um they'll have a starter plan for success and then you create like a daily check-in and then you can create some sort of streak or nudge and progress within the uh within the framework of the app. So to to just summarize what what we figured out here is, you know, you you figure out a habit, you figure out a a a micro niche in that habit, you validate that by things like Reddit, Idea Browser, Tik Tok, um you optimize the app store previews, um you optimize the name, create a really good brand, um and uh you know, you're off to the races. you, you know, you include things like leaderboards and streaks and progress because you want people to feel like they're, you know, making progress on whatever habit they are. Uh, there is. And by the way, there's so much like people people, you know, see these examples of like Calai and all these apps and they're like, it's over. There's too much competition. There is so many different habits that and micro habits that there's opportunity for. So, keep going. What I've seen in terms of pricing is there's usually a free trial between 7 to 14 days. I'm actually seeing seven days to be uh a little more effective. Um and then what I've noticed is people are charging, you know, seven to I, you know, I put $15 here, but re realistically all the way up to $40 a month for different core experiences. You can do something where you know you you have a payw wall after the first habit win. So like you get them to you know basically participate in the habit they win and then it's like okay now you understand the value of this product go and pay for it or you can do something like a $49 a year annual anchor an add-on for a pro pack where it's like $5 a month or $10 a month. This is for your like power users. You don't have to worry about this for your minimal viable product. This is like post 100K a month, but something to consider also like do you want to create like a group or team plan, you know, for example, Calai for your company and stuff like that. That's a way to get a lot of seats really quickly. But again, that's post 100K a month. Um, this is the way to think about uh pricing. So, you know, this is this is just helpful for me to think about um and might be helpful for you this this graph around. Okay. was just around um h how to think about getting a stranger onboarded and how to get them become an advocate for your company. So they download the app, they're onboarded, you want to get that first success within 24 hours. And I can't tell you how important that is. If you can get success like that win within the first hour, 30 minutes, two hours, that is actually so much it's an order of magnitude better than 22 hours, 18 hours, you know, 40 hours cuz it just you might not be able to win them back. So, you get them for the first win. So important. Your your MVP is you're just focusing on the first win of the habit and then you try to get them to engage back into the app. Think about like three sessions in seven days building that routine, right? So you want to go from first win to building the routine. Um what ends up happening is uh you people are going to go into different camps. So you're going to go in some people are going to go into the camp of uh they're not really using the app. They're idle. Um so you want to basically trigger a nudge or a benefit. So, you know, I see that you're not taking a photo of, you know, your h you know, your h your food today. You know, how can I how can how can you get the user to actually do that? And you want to position that as value for the the user. The the mistake a lot of uh app builders make is they think about themselves. They're just pushing the content. They're like, I need you to be active because I know if you're active, you're going to be using this product more. You're going to be spending more money. But that's a mistake. What you want to do is just position it as, okay, how how can let me let me put my my feet in the shoes of of this customer. How, you know, what can I what can I send them that's going to produce value that's going to get you to the win. So triggers and nudges are very important. Um, even if they're 3 days idle, you want to you want to trigger and uh nudge them. Um, and then you want to for the people who do streaks, these are people that are going to be your active power power users. And then you're going to want to basically get those people and prompt those people to share and refer the product because those people are going to be your advocates. They're using it every single day. So you're going to basically segment those people and then send them notifications um and communication uh on social and stuff like that that says like hey like you know if you share it you're going to get XYZ. So in this section I'm going to talk about how to actually get customers. This isn't the only way to get customers, but how I'm seeing a lot of these apps get customers. Um, it's basically a mix of organic, owned, and paid. So, on organic, what they're doing is they're have, you know, these Tik Tok pages. Sometimes it's multiple Tik Tok pages. Um, and they're also using IG with many chat integration. So, I'm sure you've seen it. It's basically like they'll do a a reel and they'll say comment xyz for more and then many chat will automatically DM people. Um they're doing things like uh SEO GEO they're using platforms like X. I think even Roy from Cleuly the founder of Cluey was saying how how important X is in terms of getting customers. Um they use that to send them to get them on a wait list of some sort. you know, could be a newsletter, could be just a weight list that's owned and operated. Um, and you know, they also use things like paid, so you know, ASA, which is a, you know, Apple's, um, search program. Uh, so the paid search when you're actually searching on the app store. Um, they're using Facebook and IG creatives and they're creating, you know, tens if not hundreds of them. And they're using a clipping. I actually think that clipping 97% of it is like complete waste of money. Um but some of them are seeing success around clipping. I should have mentioned what is clipping. Clipping is basically when uh you take long form, you put it into short form, and then there are these a agencies that you can pay that will say like for every million views you get, I you know, if you pay me $5 CPM, um you know, I'll I'll go, you know, would you pay me $5 CPM? If I get you a million views, absolutely. Because then you're looking at it, you're like, a million views. If I convert 1% of those to my app, then I'm going to crush it. But the problem is a lot of those views just aren't converting from what I've seen. So would love to hear what people are are seeing in terms of clipping in the comment section. But um hard to f hard to find this that working. I'm sure it does work in some cases, but for the most part it hasn't been working. Um or I haven't seen it work. Then uh in terms of owned, you also have the inapp share prompts. That's going to be a huge lever for you. Um, and then you can do things like referral where it's like three for one month pro. So that's just a way to get your customers to have more customers. So um I I do think that you can get from like 30 day zero to 30 days to app revenue. So you can do something like for the first few days you define your wedge then you define your you know wireframes and prototype then you create your core loop which is hard right that's around it's hard but you know at this point hopefully you can you understand the habit you've think you've used things like Reddit Tik Tok and idea browser to validate some of uh some of it um then you do you know the telemetry the payw wall you do some onboarding and the ASO then you do some channel tests and and then you work on retention. Like you could come up with an idea and build an app in 30 days and get to some revenue. Uh you can screenshot this. Um but I do believe it's totally possible. Let's talk about the metrics that um that you should care about if you're trying to get to 100K MR. So retention churn streaks percentage is kind of an underrated one. You want to get that as high as possible. D7 and D30 meaning day seven and day 30 retention. Um the revenue obviously the uh ARPU arpoo average revenue per user the trial to the paid percentage you know that's going to be a huge one and the annual mix percentage um the acquisition the cost per install you know your organic installs your ASAct you know all of that stuff is going to be really important these are all levers like you're basically a scientist and you're playing with all these levers in the referral camp you have invites per users and the K factor K factor basically means the virality of uh you know for every one person that comes into the app how many of them how many are they inviting. So if you have a K factor above one that's what you're you want to get because you know that means every person is bringing another person in the activation camp what's going to be really important to you is your day zero to D1 success percentage your sign up completion and your time to first win. Um, I included this over here because a lot of people don't know how to think about new features and what to put on the backlog of feature development. So, the way I think about it is when you're coming up with an idea. So, let's say you've okay, you've built your MVP, you've got your core loop, um, but you, you know, it isn't exactly working. Some of these, you know, the retention isn't as high as you want or the streak percentage isn't as high as you want. So you're you're going to at this point you're going to come up with a bunch of ideas for how to fix that. But it's important to use this impact times confidence uh over effort and put it into a score. Uh you know I call it the ice score. Um you know not all feature ideas are created equal. So you have to you know you uh if you're working with a team you and your team have to come up with your best guess at what the impact's going to be if you create this what your confidence is that and how much uh effort is it going to take to go build that and based on that you can prioritize what you are going to ship this week and then try to aim to ship three things per week if not kill defer that other stuff right just like put it in the backlog don't think about it focus on your one two or three things this week. If if I'm building a 100K uh MR mobile app, one of my northstars is going to be weekly active paying users. And the way to think about that is you're going to have your acquisition volume, right? How many people are coming in at the top of the funnel and you know, how are you going to be able to, you know, get more of acquisition? Well, you just, you know, play with your how much you're spending on on app store keywords, paid ASA creatives. That's your IG and creator budget. Um, and then your organic, right? Um, the activation rate, so your onboarding speed, the paid conversion, the pricing, and the timing, and the weekly retention, which is streaks and notifications. So I think that you know just thinking about the northstar as your weekly active paying users wapu and then thinking about playing with the levers of acquisition activation rate pay conversion and weekly retention is how you're going to start thinking about it if you know anyone can go and create a mobile app that gets you know a few hundred MR but the ones that get to 100k MR really understand these levers quite well. the the monthly MR, you know, because they're software businesses and there's not much cost, your gross margin is going to be 80 to 90% before Apple takes their cut. Um, so I think, you know, you don't want to spend a lot of money on paid first. In fact, I would spend nothing really on paid in the beginning. I would be working just on organic um doing my organic stuff trying to get uh you know maybe some affiliate but you know mostly organic um and then once you've figured out okay what's my LTV lifetime value um then you can start playing with paid and then you should think about paid as a paidback within less than 3 months um you know the LTV how do you calculate LTVs is a common question it's your ARP RPU, um, your RPO, average revenue per user, times month retained, and then you should think about trying to get an LTV over CAC of above three. The best apps, the best consumer mobile apps have an LTV over CAC above three. Um, and that's what I'm seeing in these 100K plus MR uh, consumer mobile apps is they just they're spending a lot of money because, you know, it's they're they're just getting paid back so quickly. So, uh this is the framework for how you could create a consumer mobile app um and how how some of the best people are thinking about it um that what I've observed. And um without further ado, I'm going to actually give you four ideas that I think could fit in this framework around the habits um and that are sorely needed. Um so, and this is just to get your creative juices flowing. This is really to get I know you're going to listen to this and you might be like I don't really like this one but it actually got me thinking about something else. So the dog allergy scanner. So for owners of dogs with food sensitivities. So there's millions of dogs out there. Percentage of them have food sensitivities. People really care about their dogs obviously. Snap a photo of ingredient labels at the store. AI flags unsafe food for your dog specific allergies. So what is the core loop? The core loop is you scan save unsaved feedback save to favorites. You can monetize with a $5 a month premium. So you can do multiple pets, you know, vet Q&A, custom diet plans, things like that. And then how do you grow this thing? Well, you do it via vet partnerships and pet tik tok. Um, so really simple one. I think there's a lot of analogies here to like cali and uh there's a guy who has an app. I think it's called I think his name. Yeah, Bobby the Bobby approved app and he he has like a YouTube channel and he just says you know is this a healthy is this a healthy Bobby approved organic no seed oils thing and people there's millions of people that scan in grocery stores um to see if it's you know healthy. Well, this is just sort of a similar idea but for allergies. Um, and you know there's the saying for a business, are you a vitamin or are you a painkiller? A vitamin business you don't really want to be in. A vitamin business means like you don't really need it, but a painkiller you really need. Um, and this is something that would fit into the painkiller because obviously people don't want to feed uh stuff that is going to make their dogs lives uh worse worse than you know or just not not fun, right? So um we don't want to hurt our dogs. Um the second one is um second idea is something that actually triggered uh affects me. So I know this well this is why I I in included this one. So I get migraines and I would pay for something like this. So it's called a migraine weather guard. So for migraine sufferers who track triggers which I do track my triggers things like red wine, things like um uh some red meats um and stuff like that. It uses hyperlocal weather, barometric pressure shifts to warn users hours before onsets, daily check-in log log symptoms, builds personal trigger models, monetize via $7 a month subscription, affiliate with migraine products like cooling caps and supplements, and then you can do niche distribution through Reddit migraine groups, neur neurology clinics, uh, and migraine Tik Tok. So, another simple idea. Um, you know, uses AI to basically figure this stuff out. Um, that's the wedge. Um, people would pay for it. It's a painkiller. And that's the hook. Uh, you're starting to get it. I also like that it does the affiliate stuff. So, that helps you get your LTV a little a little bit up. This one, uh, number three, uh, the silent study timer. So, for students in competitive exam prep, like things like the MCAT, the CFA, the BAR, and there's hundreds of thousands of the of them. Um, you create something for for them that's a study timer. So, it's not a generic Pomodoro app. There's there's hundreds of those apps, but you simulate like a vi a library vibe with a shared silent study rooms where avatars show up who's active. You can do gamified streaks, leaderboard for hours studied, accountability groups. You can monetize via $29 a year um premium study rooms with advanced analytics that tells you, you know, how locked in you are. And you remember we talked about names for um for apps, why certain apps are just crushing it. Calai, uh we talked about the vibe code app. Well, if something like this was called like locked in, I think it would do really well. Um and then the growth would be via YouTube study with me channels and discord servers. Another kind of idea I would have for this is a lot of people uh in uh listen to lowfi studying music. So they create you can create like a YouTube channel, put lowfi music, make that music with AI, get people onto onto it and then basically send them to this app. That's is this is an idea that will work. This idea will work. Uh, so you're gonna go, you create the organic uh via via these YouTube channels and then you send them to this app. I don't know why people aren't doing this. Uh, and you can also pay some of these other, you know, low-fi channels to promote some of your stuff with a with a a link in bio. How much would it cost? Right? So, this is a this is a good one. The one downside to this idea I will say is students are less likely to pay than for example 37year-old migraine people suffering from migraines who who have kids uh who just you know want to make sure they're not going to get it. But um I do think this is a cool idea. And the last the last idea is a plant watering AI coach. So um we've all dealt with plants that we buy and they die and it sucks. So, for urban apartment dwellers, Los Angeles, New York, Miami, uh, snap a photo and and anyone really. Um, snap a photo, but that's who you would target, I think. Um, high disposable income, that sort of thing. Snap a photo of a plant. The app identifies the species, builds watering and sunlight schedule. You can send push reminders align with weather, skip watering if humid today, monetize via $3 a month premium, and then you do the affiliate thing, links to soils, pots, fertilizer, and then you growth via Instagram plant influencers and Etsy plant sellers. So, I think I put this as the end. It's probably my least favorite idea cuz there this is actually quite competitive. Um, there are apps that are doing the something similar that are making millions of dollars a year, but I do think that, you know, I've used some of them. They're not the best apps and I still think that there's, you know, opportunity even if there is competition to have your own take on it with the right name, with the right brand, and with the right go to market strategy. So, this has been uh episode on just building consumer mobile apps. Um, you know, I think that for a while you couldn't build a consumer mobile app that got to this amount of scale and without raising tons of venture capital and and then taking it years of time. But I do think that now, right now, as of recording this, um there's just a remarkable opportunity because people on the consumer side want to try AI apps. Um and unlocks all these new behaviors like, oh, take a photo to do this and AI analyzes it. Um and then you have all these creators that would could distribute your product and just, you know, I just think that's a it's a remarkable time to build. And I think that people think that um it's getting saturated with consumer mobile apps, but um I don't think that's the case. That's my hot take. I think there's going to be so so many examples of, you know, there's going to be like a hundred, you know, mini versions of Cali or more um that are successful. And my hope is that someone listening got a little bit of creative juices that helped them be like, you know what, I am going to start an app. I am gonna start an app and uh that's all I can ask for. So um if you enjoyed this, please let me know. I hope it got the creative juices flowing. Have a creative day, friends, and I'll see you next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Guia para construir aplicativos móveis com potencial para 100 mil dólares em receita recorrente mensal, usando hábitos diários, validação de demanda e distribuição estratégica.",
            "resumo": "Neste vídeo, Greg Isenberg apresenta um playbook para chegar a 100K MR com apps móveis. Ele enfatiza a importância de escolher um hábito diário, um nicho estreito e uma proposta que ressoe com os usuários. O conteúdo destaca a necessidade de validar a demanda paga antes de desenvolver, observando sinais como volume de busca, lacunas da concorrência e comunidades online (Reddit, subreddits). Propõe prototipagem rápida com ferramentas como Lovable, Bolt, Expo e Ruby on Rails, além de testar uma única estratégia de distribuição com três formatos por semana (ex.: Instagram/TikTok, Stories e formatos virais). Depois de obter 100 usuários reais, o caminho é monetização, retenção e indicação. A escala envolve anúncios, ASO e afiliados (15–40%), sempre complementada por uma mentalidade e pelos frameworks necessários.",
            "assunto_principal": "Estratégias para desenvolver aplicativos móveis com potencial de receita recorrente de 100 mil por mês, incluindo validação de demanda, foco em hábitos diários, prototipagem rápida e canais de distribuição.",
            "palavras_chave": [
              "aplicativos móveis",
              "receita recorrente",
              "100 mil MR",
              "hábito diário",
              "nicho específico",
              "validação da demanda",
              "teste de mercado",
              "prototipagem rápida",
              "ferramentas de prototipagem",
              "distribuição",
              "formatos de conteúdo",
              "afiliados",
              "Otimização da loja de aplicativos",
              "retenção"
            ],
            "resumo_em_topicos": "- Premissa: o vídeo oferece um roteiro para alcançar 100 mil MR com apps móveis, com ressalvas sobre a complexidade do caminho.\n- Estratégia central: focar em um hábito diário, em um nicho estreito e validar a demanda paga antes de investir no desenvolvimento.\n- Validação de demanda: usar sinais como volume de busca, lacunas de concorrentes e insights de comunidades (Reddit, subreddits).\n- Prototipagem: prototipar rápido com ferramentas como Lovable, Bolt, Expo e Ruby on Rails; incorporar IA como diferencial.\n- Distribuição: testar uma única via de distribuição com três formatos por semana (ex.: Instagram/TikTok, stories, formatos virais).\n- Onboarding e monetização: conquistar 100 usuários reais, depois monetizar, manter retenção e incentivar indicações.\n- Escala: crescer via anúncios, ASO, afiliados (comissões entre 15% e 40%) e expansão orgânica.\n- Observação final: o caminho exige frameworks e mentalidade, não é simples, mas o vídeo visa fornecer as bases para que mais pessoas consigam chegar ao patamar desejado.",
            "prompt_tokens": 1955,
            "completion_tokens": 4039,
            "model": "gpt-5-nano",
            "cost": 0.007
          },
          "analysis_time": 100.43792414665222,
          "language": "",
          "view_count": 13625,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@GuilhermeReisDinastIA",
      "status": "error",
      "message": "Falha ao acessar https://www.youtube.com/@GuilhermeReisDinastIA/about",
      "videos": []
    },
    {
      "channel_id": "@HuggingFace",
      "name": "@HuggingFace",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@IAExpertAcademy",
      "name": "@IAExpertAcademy",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Incomestreamsurfers",
      "name": "@Incomestreamsurfers",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "vGAbJS5bqgk",
          "title": "Claude Code Opus 4.1 ESTÁ DE VOLTA (FINALMENTE)",
          "title_pt": "Texto: Claude Code Opus 4.1 ESTÁ DE VOLTA (FINALMENTE)",
          "url": "https://www.youtube.com/watch?v=vGAbJS5bqgk",
          "published": "2025-09-23T11:09:23.598235",
          "published_relative": "há 1 hora",
          "duration": "08:11",
          "date_published": "2025-09-23T03:58:42-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where I'm going to be talking about Clawude Code and how in my opinion it seems like it's genuinely back. Now, this is Quotely. This is a project that I've been working on for the about the last 3 weeks and I was having some real problems with Claude Code while they were buggy. So, I moved over to Codeex and it worked for a little bit and then I started having problems with Codeex as well. Now, one of the biggest problems with Codeex, in my opinion, is it's not as good at running things itself, running Docker, getting everything running, etc., etc., whereas Claw Code just seems to be much better for that system. So, let me just show you what I created yesterday, and I'll just explain to you guys why I genuinely think Claw Code is back. So, let me just log in here so I can finally log in, which by the way, Claude Code fixed for me. And then yesterday, what I was working on was this right here, which is the instant policy comparison. So what I can do is I can upload a declaration image for a insurance declaration and then I can process it and I can press process here and what it'll do is it will use AI to actually read this uh policy document and extract all of the information. Now this was created with claude code yesterday through quite a long process I have to say it did take a little bit of time but Claude Code did manage to absolutely smash this in the end. Now you can see it did take a long time. Took a few hours of coding to be frank and it took, you know, I was I was just playing video games at the same time and I was just kind of letting it run. I was playing Runescape with my with my best friend. And eventually after I added the Playright MCP, it started to really get an idea of what was going on. Playright MCP absolutely vital if you're using Claude code because look, it just kept saying it's correct, it's correct, it's correct, it's correct. That's like look use the player IMCP it's logged in it's not there and then you can see here I can see the dashboard is loading but the declaration upload document is not showing the back end is also connection refused errors let me check the back end is still running and then verify the front of the code so eventually it got everything running and it just kept running through fixes I wasn't even giving it any feedback I just said it's still not working or you know fix it fix it fix it and then eventually we got to the point where we could process this document with AI. So you can see Jane Doe city um 2008 Ford Explorer which if you look at the document here you can see 2008 Ford Explorer and then you can press get multiple quotes right and then you can do this and you can see the turbo rator payload becomes um the information from the document I uploaded and I can press run quote here and and it will send the the users's uploaded information from the image to our insurance quotator and it will actually find quotes right so if I scroll down here you can see carrier one total 1,200 term 1,200 monthly 200 quoted so that's equity insurance company and then progressive insurance comes back at exactly the same price so this entire process I built with claude Claude code, but it wasn't me telling Claude code what to do, right? You can just literally see I'm not telling it. I just kept saying I'm getting load failed or this kept happening, etc., etc. And it didn't just make things up, right? It genuinely coded a fix to the issue. You can see it's not hard coding things. It's genuinely fixing things. So right now while I'm making this video I also have um Claude code running with Grove Fixes and I just gave it a load of bug reports that users had given me and I put them into clawed code and you can just see that it's just running now. So yeah, this thing where it makes genuine fixes to problems like you can see here. This is just not something that you know two weeks ago was actually happening. Now let me show you another thing that they've added. This is actually a pretty cool update from Claude. You can write ultrathink now and you can see it changes the color and everything. So you know that it's genuinely making a change. You can see thinking on max, right? So I put it on ultra think mode. So once you've got it on ultraink mode, what it does is, and this is another theory that I did have about a week ago when I said codeex was significantly better. It's also because we're not using thinking mode on claw code. Like I rarely use thinking mode. So you can say think and it goes blue. What is it? Think a lot. Uh no ultra think is like the the big one. And then I'm not sure what the the medium one is. But it's pretty cool that they made it so it actually changes the um the the tokens, right? I do actually really like that. Not the tokens, the color. So now you can actually see if you're telling it to ultra think you can see ultra think thinking on. So it's less like ultra think meme and actually genuinely ultra thinking. So I wanted to talk about this guys because I think two weeks ago I wouldn't have been able to fix this entire script whereas now with claw code I was able to. So yeah, guys, honestly, um I know that I've been talking a lot about Claude Code recently and saying that Codeex is better, but it seems like Codeex has degenerated and Claude Code is kind of bad. So, I did talk about this the other day in a video. This one here, Postmortm and three recent issues. It seems like this might have actually had more of an effect than I said it would have in the video that I made. It genuinely seems like this has had a good effect and it does seem like Claude Code might actually be back, which is massive because like it's been pretty frustrating to just have to move away from Lord Code because I really really did like Lord Code. But I'm going to be I'm going to be genuine. I'm going to be honest with you guys right here, right now. I think it might be back. Okay, probably not to the point that it was at the very beginning, but I did renew my $200 max subscription yesterday and um we are using the Max plan again. We are using Opus and I didn't regret it yesterday. It really really fixed quite a large complicated issue. added a new feature to quote lead which like I said is a project I've been working on for a little bit of time now and I'm genuinely impressed with the results. Okay, I'm not just bullshitting you. I'm not just going to write Claude Code is insane in the title or anything like that. I'm being genuine. I want people to know that in my opinion Claude code is feeling like it's back now. I'm I've been using Ultraink. Um I've been using MTPs. You can see I've just got the playright MTP here, but um in this conversation for example, I have uh playright uptach and superbase. This combination of things allows me to basically do anything on Grove. And yeah, if I needed Superbase here as well, I would probably add it. But yeah, this is this is my workflow. I actually stopped using codeex. I noticed well, first of all, they rate limited me finally after using it for 3 weeks. And then second of all, it did actually seem like something's happened and it and it's degenerated a little bit and it's not as good as it was. So maybe their servers are uh are having issues. We don't know. But seems like this is always the case. Fighting over who is the best when people think you're the best, make you make yourself worse to save money and hope no one notices. And then your competitor comes along and makes themselves the best. And then today, I would guess Anthropic is going to release a new model. I think they're famous for releasing on Tuesdays if I'm not mistaken. So, I'm genuinely expecting a new Anthropic model today. And I'm hoping it's going to be absolutely crazy. But yeah, honestly, Opus 4.1 is doing a great job. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. I'll see you very, very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo afirma que Claude Code Opus 4.1 parece ter voltado a funcionar de forma estável, apresentando Quotely para ler apólices de seguro com IA e gerar cotações, em comparação favorável com Codeex, com novidades como ultrathink e uso do plano Max.",
            "resumo": "O autor relata dificuldades iniciais com Claude Code e com Codeex, sugerindo que Claude Code é superior para rodar ambientes como Docker. Ele demonstra Quotely, um projeto que lê automaticamente uma apólice de seguro a partir de uma imagem, extrai dados com IA e gera cotações. O processo envolveu várias tentativas, ajustes com Playwright MCP e o uso de ultrathink para sinalizar progresso. O narrador observa que Claude Code corrige falhas de forma genuína, enquanto Codeex mostrou degradação recente. Também menciona Grove Fixes, MTPs e Superbase como partes do fluxo de trabalho. Conclui que Claude Code parece ter recuperado o fôlego, renovou a assinatura Max do Opus 4.1 e aguarda novas melhorias, mantendo a esperança de que continue estável.",
            "assunto_principal": "Retorno e avaliação do Claude Code Opus 4.1, comparação com Codeex, demonstração de automação de leitura de apólices de seguro e geração de cotações, com novidades como ultrathink.",
            "palavras_chave": [
              "Claude Code",
              "Opus 4.1",
              "Codeex",
              "ultra think",
              "Playwright MCP",
              "Grove Fixes",
              "cotações de seguros",
              "Processamento de Documentos",
              "Inteligência Artificial",
              "Automação",
              "Superbase",
              "Plano Max"
            ],
            "resumo_em_topicos": "- Contexto: o vídeo discute dificuldades com Claude Code e Codeex e a percepção de que Claude Code voltou a melhorar.\n- Demonstração principal: apresentação do Quotely, um projeto que lê apólices a partir de imagens, extrai dados com IA e gera cotações automaticamente.\n- Detalhes técnicos: uso de Playwright MCP, ultrathink para indicar progresso e ajustes contínuos até o processamento bem-sucedido.\n- Comparação de desempenho: Codeex mostra degradação recente; Claude Code é visto como opção mais estável para certas operações.\n- Fluxo de trabalho: integração com Grove Fixes, MTPs e Superbase no processo de automação.\n- Conclusão: renovação do plano Max do Claude Code Opus 4.1 e expectativa de melhorias futuras, com tom honesto sobre a recuperação de desempenho.",
            "prompt_tokens": 1909,
            "completion_tokens": 2704,
            "model": "gpt-5-nano",
            "cost": 0.005
          },
          "analysis_time": 71.5924870967865,
          "language": "",
          "view_count": 253,
          "has_transcript": false
        },
        {
          "id": "Dk7ZRUwsJdk",
          "title": "QWEN CONTINUA A SER COZINHADO: Qwen3-Coder-Plus acaba de ser lançado",
          "title_pt": "QWEN continua a ser cozinhado: Qwen3-Coder-Plus acaba de ser lançado",
          "url": "https://www.youtube.com/watch?v=Dk7ZRUwsJdk",
          "published": "2025-09-22T19:09:23.598315",
          "published_relative": "há 17 horas",
          "duration": "08:14",
          "date_published": "2025-09-22T11:45:35-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where we're going to be talking about Quen 3 Koda Plus. Now, I wouldn't normally talk about a model like this. However, I've been recently pretty impressed with Quen 3 and just how well it's actually working and how well it works, etc., etc. So, I'm going to be testing out in this video. I've already got the benchmark, the normal bog standard benchmark running um here, uh which is the benchmark that I always do. It's this one here. It's the prompt to generate a service website. But at the same time what I want to test is I want to test the same prompt inside um the CLI right because you can see here this is Quinn3 coder plus which is the new model. So let's just do the same thing. So MKD coder plus cdcoder plus then we'll write quen and then we'll put the same prompt here. There we go. So now it's doing both things at the same time. It's running two. Right. So, we have one where it's created the next the next my app using kilo code. And then we're going to do the other one now. Now, I need to put this on um where it doesn't ask constantly for permission to do things. So, let's just see how to do that. Auto approve. Auto approve enabled. Just everything. Um, right. Yeah. Okay. I just want everything. Can I just put a star here? maybe and save. Done. And save. Okay, there we go. Done. So, that should put everything on auto approved. So far, this is pretty quick, I have to say. Surprisingly quick. Um, let's see if I can do the same thing here where I skip permissions. Accepting edits. Okay, so they've copied Claude code. So, okay, so we got both running here, I hope. Okay, this one is struggling obviously, but let's see if it can work through the the struggle. Yeah, looks like that did it. Looks like it installed it properly. This is flying. I have to say this is absolutely flying so far. Yes, always allow. Come on. So, yeah, Quen Coder. I've been really impressed with uh Quen Code Max was the model that I used. Very, very impressive stuff, but it wasn't available in Quen Coder. So now that we can use the latest model inside Quen Coder, I'm very very curious to see just how effective this new Quen system actually is. So I'll let these run guys and I'll give you my thoughts on them in just a second. Couple of things to note. This is a brand new model 5 days ago, 17th of September. Quen 3DOD Plus. It's Alibaba's proprietary version of the open source Quinn 3 coder 480 A3 uh A350B or 35B. It is powerful coding agent uh model specializing in autonomous programming via tool calling environment uh interaction combining coding proficiency with versile general purpose abilities. So what that basically means is it should actually perform even better inside Claude CLI and I can tell you h sorry not claude CLI uh Quinn CLI and I can tell you right now that is a very good um data page like normally they're much shorter so I can already tell that this is actually an extremely good model um and it's just so fast as well it's actually kind of crazy. I'll let these run guys. We'll go through them once it's done. We'll see how many mistakes, how many errors there are, etc., etc. Okay, so the CLI one is completed. Uh kilo code one is still running. Uh my old school Runescape Iron Man is still splashing. So everything is fine there. Uh let's just see if this is any good basically. So uh this is in Koda Plus. I need to go to COD plus. There we go. And then I need to open that inside Visual Studio Code. So we got a new window here. File, open folder code plus. Okay. And then we go terminal, new terminal. We do cd my next app npm rundev, which should work first time. There we go. And let's see. Okay, some color problems. Pretty basic layout, but I mean it's done the job for sure. Looks like everything is generated properly. Yeah. Okay. Not bad. Not a bad attempt at all to be honest with you. For quite a cheap model, this is pretty good. Um I would say this would be good as like the coding model and then using something else as like the planning model. Let's see. Yeah, I mean the code here is pretty perfect to be frank. Oh, there we go. Pagon, which is page not found. So, there are some um 404 issues on here, which is a bad sign. But yeah, I mean, overall, this is a pretty damn good attempt by um by Quen again, right? Comparing this to this says 2023. That's interesting. Compared comparing this to most other um I know this isn't free or open source, but like based off a free or open source model. Like, we haven't heard anything from Llama, for example, in [ __ ] ages, by the way. Can I just say never heard any never heard anything back from llama and meta and stuff but Quen have been cooking and yeah this is pretty damn cool. So this is using my Quen subscription just so you know guys. Um I'm not actually sure. Oh Quen max preview. So there's another one here. Interesting. The most powerful language model in the Quen series. I'll have to be testing that out as well in a moment. I think I did test that before but it's not available in the Quinn CLI. So, that's what kind of what I was waiting for. I just wanted to see if I'm paying for this cuz I'm I'm really not sure if I'm paying for this or not. Um, okay. So, Quen 3 Max preview, which I didn't see on Open Routter, as far as I know. Let's have a look. No, it's not. So, Quen 3 Max is here, but Quen 3 Max preview isn't. Yeah, this is the one I tested before on September the 5th. I remember. I wonder if they're the same model. Quen's next model is going to be very, very interesting, guys. I have to say, I don't think I'm paying for this. I'm pretty sure I'm not paying for this. So, this is a free almost as good as [ __ ] um Claude model, which is completely crazy when you think about it. Okay, let's see how Kilo Code is getting on. Uh looks like it's still got a bit of work to go. I'd be curious to see if there's any like a big difference. This cost 175 on API cost, which is pretty reasonable. I'm just curious if there's going to be a big difference between these two or not. Okay, so I haven't really got time to wait for this to fully finish, but this is what um Kilo Code built. It does have a few errors, but uh obviously it's not really a fair comparison because I'm not I'm not letting it fully run. But I mean, I would say this looks a little bit different um to the other one, which is good. It looks a little bit better, but it is still pretty basic just like the other one. Uh, it's automatically in Italian, which uh, like I said, I haven't fully Hang on. There we go. Okay, so the English one didn't even work there. Oh, that's because of that. Let's see if I put weddings here. Yeah, it works. Um, so yeah, overall this is pretty good for a medium level, not free, but based off a free and open source model. Like traditionally, they've been absolutely crap. This is Alibaba's um, proprietary version of Quen. Quen is open source and free. They took Quen and they built this and it's a very lowcost model that can do pretty good code to be honest with you. So if that's what you're looking for, this is definitely worth your time. I think in my opinion the next Quen model um Quen Max once Quen Max is available inside Quen CLI, I genuinely believe it's going to be a competitor for uh Claude Code. Um but yeah, you may call me crazy, but that's my opinion. Thanks so much for watching, guys. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo avalia o Quen 3 Coder Plus no Quen CLI, comparando desempenho, automação de permissões e qualidade de código com outras abordagens, discutindo custos e o potencial do Quen Max frente à Claude.",
            "resumo": "Neste vídeo, o apresentador avalia o Quen 3 Coder Plus e o testa no Quen CLI, comparando com a versão baseada em código, utilizando um benchmark comum que gera um site de serviço. Ele executa prompts em paralelo, ativa auto-aprovação para evitar confirmações constantes e observa que o Quen 3 Coder Plus é extremamente rápido. O código gerado é importado para Visual Studio Code e testado localmente, com resultados eficazes para um modelo de baixo custo, embora haja alguns problemas como uma página 404 e questões de cores. O narrador comenta que a versão proprietária da Alibaba do Quen, baseada no Quen 3 Coder, é rápida e competitiva frente à Claude, sugerindo que o Quen Max pode se tornar um concorrente relevante assim que estiver disponível no Quen CLI. O vídeo também discute custos de API (aproximadamente 175) e a possibilidade de estar ou não pagando pela assinatura, além de observar que Claude ainda não respondeu. Conclui que o Quen é promissor e que o futuro do Quen Max no CLI é empolgante.",
            "assunto_principal": "Avaliação do Quen 3 Coder Plus e condições de uso/competitividade no Quen CLI, com comparação a Claude e considerações sobre custo, velocidade e qualidade de código.",
            "palavras_chave": [
              "Quen 3 Coder Plus",
              "Quen Interface de Linha de Comando",
              "teste de desempenho",
              "aprovação automática",
              "geração de código",
              "versão proprietária do Alibaba",
              "Claude",
              "Quen Max",
              "custo de API",
              "erro 404",
              "Visual Studio Code",
              "Next.js",
              "assistente de codificação"
            ],
            "resumo_em_topicos": "### Contexto\n- Avaliação do Quen 3 Coder Plus e comparação com o Quen disponível no CLI.\n### Objetivo\n- Medir desempenho, velocidade e qualidade de código; testar automação de permissões.\n### Metodologia\n- Benchmark padrão gerando site de serviço; execução paralela no CLI e na interface; auto-aprovação ativada.\n### Resultados principais\n- CLI rápido; código gerado de boa qualidade para um modelo de baixo custo; alguns problemas como 404 e questões de cores.\n### Observações técnicas\n- Modelo da Alibaba é uma versão proprietária do Quen; custo de API≈175; comparação com Claude; discussão sobre pagamento/assinatura.\n### Conclusões e perspectivas\n- Quen Max pode competir com Claude Code; expectativa de disponibilidade no Quen CLI; Quen continua promissor como alternativa de baixo custo.",
            "prompt_tokens": 1939,
            "completion_tokens": 3393,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 80.82956218719482,
          "language": "",
          "view_count": 1795,
          "has_transcript": false
        },
        {
          "id": "mg7W1cF5Lxs",
          "title": "Este novo modelo Stealth NÃO é o Soneto 4.5 (A Verdade)",
          "title_pt": "Este novo modelo Stealth não é o Soneto 4.5 (A Verdade)",
          "url": "https://www.youtube.com/watch?v=mg7W1cF5Lxs",
          "published": "2025-09-22T13:09:23.598336",
          "published_relative": "há 23 horas",
          "duration": "12:07",
          "date_published": "2025-09-22T05:41:56-07:00",
          "transcript_available": true,
          "transcript": "Okay guys, welcome to this video. I was right. Okay, I'm just going to say right now I was right. There is a new stealth model and oh look, it has 200,000 context window. H I wonder what this could be. I think this is Claude 4.5 Sonnet Opus. Don't know, don't care. Might be HiQ 4.1. They might be being sneaky. Actually, I'm going to call it right now. This might actually be HiQ 4.1 because it's apparently very very fast. I'm going to be testing out this model. I don't know if I'm going to use Klein or Kilo. Not really sure yet. I don't really know how these companies even get in touch with uh Okay, so apparently it's not on Kilo code. So, it's on Klein. Um let's try uh Supernova here. Yeah, I I'm convinced this is I'm absolutely convinced this is going to be 4.1. So, supports image, supports browser use, supports prompt caching. Oh, look. It supports browser use. Guess guess what the only other models that normally out of the box support browser use are. By the way, it's it's Sonet or Clawude models, just so you know. Okay, so I am going to test this out. But unlike other people who are claiming this is almost definitely Sonet um 4.5 or whatever, I'm actually going to make a prediction and say that in my opinion this is um this is actually HighQ 4.1 or something. So they're gearing they're gearing for slightly less hype than people are expecting. So this is the prompt that I normally use. I'm going to try and see if it can scaffold itself an app though. So I'm just going to dump this prompt in. Let's just quickly open folder here. We'll just create a new folder. So new folder. This is um new model. So, I'll just open this folder fresh so that it can at least, you know, be in its own folder. So, client code supernova. Give it the prompt and we'll see how this goes. Now, apparently this is super quick, which is actually what makes me suspect that it's not Claude Sonnet. It's actually HiQ, but this doesn't seem actually as quick as I was expecting. Okay, so it it it create. Okay. Yeah, that's that's a good start. So, this is on my school community, by the way, guys. If you're curious about joining the school community and you're just getting started with AI coding, definitely check out the school community. It'll be one of the links in the description. Let's just quickly check this out. So, what is this model called? Code. Oops. Code Supernova. Free stealth model now available in client. So, this is 3 days ago. I didn't even notice this. That's crazy. Supernova is clawed 4.5 or G code 2. So, people aren't sure. The dumbest model I've ever used. Yeah, for sure. This is HighQ. It's actually made by Xia. Probably Rock Code 2. Okay, so apparently it's not going to be Sonic. I'm just going to I'm definitely going to be testing this, but yeah, people aren't sure about it at all. Oh, hello. Yeah. Okay, so I have a feeling this might not be um a decent model. People are people are claiming of course that it's Claude 4.5, but I'm actually not sure that it is now. Uh is this is Grock code 2. It's free and really what free and really good. It says 100% clawed 4.5. It self-reports as anthropic doesn't really matter. It has purple gradients which is genuinely yeah interesting. I reckon it's highQ 4.5 guys. I'm not going to lie. People are not People are saying it's not incredible which in my opinion it means that it's highQ good price. I'm just reading comments just trying to find out what it is here guys. This is the absolute classic. I love this in the AI community. It's trash. makes no so much mistakes and don't care for everything. It tries to create dobbat files. What the [ __ ] And then someone just says that shows how bad you are in prompting. This is all you ever see when someone says, \"Oh, uh, this model is not very good.\" Well, your prompting is not good enough. I love that in the AI community. >> Oh man, the AI community makes me laugh. There are some complete crazy people in the AI community. I'm not going to lie. It might not be Sonic 4.5, but it's model from Cloud. Come on, bro. It's Claude. Blog tells us blog code tells us enthropic. Guys, just say no. Right. Asking an AI model what [ __ ] model it is is so stupid. I'm sorry if you do that, but yeah, take take what you want from what I just said, but it doesn't work. Okay, a model will tell you it's chat GBT 3.5 for God's sake. Come on. Like, that is not a good way to do things. Please. Maybe Amazon Nova. Oh, yeah. True. possible. There is no Sonic 4.1. Yes, there is. Don't think it's claw 4.5 because Claw 4 is performing better for me. It's always it's also somewhat ambitious. Writes code modifies files even when I tell it just answer my question about my code base. But yeah, I mean that is a Claude. That is something Claude does do as well. So what I'm actually trying to do right now guys is I'm trying to give you a kind of understanding of how I work out what a model is, right? And how good a model is. So a lot of people are saying it's really bad, right? It's very bad. Haha. and it's got 200,000 context window, but it and it's very very fast. Right? So, in my opinion, what I'm taking from that is that it's highQ 4.5, right? Or highQ 4 or highQ 4.1. This is something that a lot of companies do. They build up hype about a new model. Everyone gets excited. Buzz buzz buzz buzz. Is this club 4.5? And all the Twitter mentions go up and you know, what have you. And then bang, they hit you with the Yeah, it was it was Haiku 4. guys enjoy highQ4. This happens all the time, just so you know. So, this is absolutely not new. So, 200,000 context window multimodal support built for a coding. But if you actually you can do a little test guys if you don't believe me that this is a claude model. I'll show you another way to check. So, if we go on client here and we go on any recent model. So, claude code fast one. So you can you can tell it's not Grock because Grock doesn't and never has and I don't know when it ever will support images and uh browser use more importantly images are probably supported by most. So even GBT5, right? It doesn't support all of them, but all anthropic models have 200,000 and they support all of the things online, right? So look, supports all 200,000 tokens. Supports all 200,000 tokens. In my opinion, this is HighQ 4, HighQ 4.1, and it's just going to be their cheap improvement on um the HighQ family, which I can tell you right now, nobody [ __ ] about. It is what it is. Uh if it's super fast though, that is pretty interesting. Oh my god, what is it doing? I have never seen anything like that before. Okay, interesting. It's very fast. Okay, but I'm not going to cope here. I'm not going to be like, \"Oh, it's actually really good, guys. My god, this this is insane.\" Right? My titles and thumbnails are different to my actual videos. It's just the way it is, guys. If you can't get over me writing insane in the title because it gets more clicks, I'm I'm sorry, right? I'm sorry that I I do that, but I don't really have a choice because if I don't put insane, it rarely gets like even 2,000 views. So, like I'm literally forced to write the word insane. But like I just hope that people can understand that, you know, there's a difference between someone who does title, thumbnail, and then actual clickbait or whatever in the video and title, thumbnail, clickbait, and then like actually tries to give value and tries to give something in the video, right? And I'm also not AI generated and I never will be. I'm I'm not going down that route because at that point it's not my channel. It's just I'm just an AI, right? So probably not going to go down that route anytime soon. Let's have a look here. Okay, so nothing works. Beautiful. Beautiful. I like it. I like it. Um, so far terrible experience. This is not This is not going to This This isn't anything new. It's nothing crazy. Um, yeah, not not too impressed by this. It's fast. I'll give you that. But I don't really care about fast models. I care about good models. I think this is Haiku. Claude Haiku. That's my guess. Um, and they're doing it to build up the hype like they always do. So, everyone refreshes their Claude code subscriptions because oh my god, Sonet 4.5 Opus is insane. But yeah, I'm going to use a different title. I'm not going to I'm not going to clickbait with um if it if it says Sonic 4.5 in the title, I'm asking a question. I'm not making a statement. Okay. But I don't think this is Sonic 4.5. I really I'm ing on the side of um HiQ 4.1 would be my guess. I'm surprised though if it is Haiku 4.1 that they haven't increased the context window. I don't know what it is with Anthropic. I don't know if they have a major problem with context windows. I'm not really sure what the issue is over there at Anthropic. Um but they don't seem to ever be able to break through the 200,000 context window unless you pay them five grand a month, which is not happening for most people. So yeah, very interesting stuff, but just another cheap [ __ ] model that nobody really asked for and nobody needs. Is this their opensource model? Is this a competitor to GPT O? It is called Supernova, which makes you think of game changer. Yeah, that would make sense. I don't think Claude has an open source model, right? Claw opensource model. They don't have any, right? Yeah. Okay. So, actually, I'm going to change my prediction here. I think this is Claude's answer to GBT O. The reason being is there's no way they're still stuck on 200k. Oh, okay. It's not terrible. Uh, yeah, it's pretty basic though, guys. I'm not going to I'm not going to [ __ ] [ __ ] I'm not going to beat around the bush here. It's pretty basic. Let's be honest. It's not It's not fantastic. None of the pages work. And it says it's completely done. I am going to change my prediction. My prediction here is this is okay. I'm going to say two things. This is either IQ4 or 4.1 or this is Claude's answer to GPT OS, which is their open-source model that they'll be releasing to compete with GPT OS. I think I'll leave the video there, guys. this definitely isn't worth your time unless this is an open source model in which case I mean it did a pretty decent job for an open source model if it's open source. We'll find out in the future what it is whether it's open source or not. This SVG is very strange but it actually interestingly again this SVG here is pretty much exactly the same as the one that um Claude made recently for me. Oh, was it Chad GPT? It might have actually been Chad GPT. This result here kind of looks a bit more chat GPT to be honest. So maybe it's like GPT OS the next one. What open GPT OS. Um what what uh context does this have? If this says 200K, I'm going to say this is like an improvement on GP. Okay. 131,000. Um I'm not exactly sure what this is. This is either an open source model from Anthropic or it's um HiQ4.1 or HiQ4. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very, very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise de uma suposta nova 'modelo stealth' com 200 mil tokens de contexto, discutindo se é Claude 4.5 Sonnet Opus, HiQ 4.1/4.5 ou outra, testando recursos como imagem, navegador e cache de prompts, e explorando o hype em torno desses lançamentos.",
            "resumo": "Neste vídeo, o apresentador afirma ter previsões corretas sobre um suposto novo modelo stealth com 200 mil tokens de contexto. Ele discute várias hipóteses de identidade — Claude 4.5 Sonnet Opus, HiQ 4.1/4.5 e outras — e descreve a experiência de teste com prompts, código do cliente e criação de pastas para scaffolding de apps. O vídeo aponta que o modelo oferece suporte a imagens, navegador e cache de prompts, sinais comuns em modelos Claude ou Anthropic, mas questiona a origem real, sugerindo que pode ser HiQ ou uma variação barata de uma linha existente. O apresentador critica o hype na comunidade de IA, explica como verifica características (padrões de suporte a recursos, 200 mil tokens) e observa que, apesar da velocidade, sem resultados consistentes não vale o investimento. Também menciona a comunidade escolar e a presença de opiniões conflitantes nos comentários.",
            "assunto_principal": "Discussão sobre a identidade e as capacidades de um suposto modelo stealth com 200 mil tokens de contexto, comparando Claude 4.5 Sonnet Opus, HiQ 4.1/4.5 e outras possibilidades, com testes práticos e análise do hype no ecossistema de IA.",
            "palavras_chave": [
              "modelo furtivo",
              "200 mil tokens de contexto",
              "Claude 4.5 Sonnet Opus",
              "HiQ 4.1/4.5",
              "Grock code 2",
              "Supernova",
              "Klein",
              "Kilo",
              "suporte a imagens",
              "navegador",
              "cache de prompts",
              "teste de código",
              "hype da IA",
              "comunidade de IA"
            ],
            "resumo_em_topicos": "### Contexto\n- Apresentador discute uma suposta nova versão stealth com 200 mil tokens e o hype ao redor.\n- Explora identidades possíveis: Claude 4.5 Sonnet Opus, HiQ 4.1/4.5, entre outras.\n\n### Recursos observados\n- Confirma suporte a imagens, navegador e cache de prompts; observa padrões comuns de Claude/Anthropic.\n- Analisa velocidade como indício de identidade, porém permanece cético.\n\n### Abordagem e testes\n- Utiliza prompts e estruturas de apoio para apps para entender o funcionamento.\n- Testa com código do lado do cliente e organização de pastas; compara com plataformas como Klein, Kilo e Supernova.\n\n### Opiniões e conclusão\n- Destaca o hype exagerado na comunidade de IA e a dificuldade de confirmar identidade apenas por sinais.\n- Conclui que, apesar da velocidade, o valor e a praticidade ainda não estão claros e não fica impressionado.",
            "prompt_tokens": 2115,
            "completion_tokens": 3129,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 94.22941708564758,
          "language": "",
          "view_count": 1730,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@IshanSharma7390",
      "name": "@IshanSharma7390",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@JeffSu",
      "name": "@JeffSu",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@JulianGoldieSEO",
      "name": "@JulianGoldieSEO",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "jfCbMWk_xCg",
          "title": "A NOVA batalha de IA entre Codex e Claude Code é INSANA! 🤯 (Quem REALMENTE vence?)",
          "title_pt": "A NOVA batalha de IA entre Codex e Claude Code é INSANA! 🤯 (Quem REALMENTE vence?)",
          "url": "https://www.youtube.com/watch?v=jfCbMWk_xCg",
          "published": "2025-09-23T10:13:56.274449",
          "published_relative": "há 2 horas",
          "duration": "07:45",
          "date_published": "2025-09-23T03:01:19-07:00",
          "transcript_available": true,
          "transcript": "Today I'm going to blow your mind with the truth about Codeex versus Clawed Code. Everyone thinks one is clearly better than the other, but I just spent weeks testing both tools on real projects. The results shocked me. We're diving into the battle between codeex and clawed code. Here's what everyone gets wrong. They think one tool is just better than the other. But after testing both tools on real projects, the truth is way more complex. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency Goldie Agency. Whilst he's helping clients get more leads and customers, I'm here to help you get the latest AI updates. I'm going to show you exactly when to use each tool because picking the wrong one could waste you weeks of work. Let me start with something that will surprise you. Codeex is better at raw coding power, but Claude Code destroys it when it comes to workflows and external tools. Let me show you what happened when I tested both tools on the same WordPress project. I gave both tools the exact same instructions. Build a WordPress directory that can do a curl request to find therapists in California. Codeex built something that looked amazing. Clean design, solid code structure. But it completely ignored my instructions. It didn't build the curl request feature I asked for. Claude code built the entire website with all the functionality I requested. The curl request worked perfectly. Everything was there. This tells you something crucial. Codeex focuses on making things look good. Claude code focuses on following your exact instructions and building workflows. But when I tested them on a different project, everything flipped. I had this complex UI project that Claude Code struggled with for weeks. I threw it at Codeex and something magical happened. It fixed everything Claude Code couldn't figure out instantly. Not only did it fix the problems, but it created this incredibly beautiful UI that looks like something you'd pay thousands for. The animations were smooth, the colors were perfect, and the entire backend worked. It even created tests and swagger documentation. This looked like a million-doll app. Meanwhile, Claude Code was still struggling with basic parts of the same project. But here's where it gets interesting. I took a custom workflow project using claw.md files. Something that Sonic 4 handles perfectly in clawed code. When I gave it to codeex, it was complete trash. Couldn't handle the workflow at all. So, what does this tell us? These tools have completely different strengths. Let me break down exactly when to use each tool. For UI and UX work, use Codeex. Trust me, don't use clawed code for UI work. Codeex creates interfaces that look professional and modern for back-end development. Codeex wins again. It writes cleaner code and handles complex logic better. But here's where Claude code shines. Shell commands, you need Claude Code. MCPS, Claude Code, custom workflows with external tools. Claude Code is your only choice. Codeex just can't handle this stuff. It gets confused and breaks down. Now, let's talk pricing. I pay $20 a month for Chat GPT and never hit limits. Claude Code, $200 a month and you'll run out quickly. That's 10 times more expensive. So, here's my strategy. Don't pick one tool. Use both. Get the $20 Claude code plan. Get the $20 Chat GPT plan. Skip the $200 plans. Then split your work. Use Claude Code for database updates, MCPS, Stripe integrations, APIs and shell commands. Use codeex for UIUX and complete projects. This saves you money and gets better results. Here are specific scenarios where each tool wins. Building ASA app. Start with codeex for front end. Use clawed code for payment processing and API integrations. Marketing websites, codecs all the way. The designs are just better. Data analysis with external databases. Clawed code handles the connections you need. Mobile app interfaces. Codeex creates cleaner designs. Workflow automation. Clawed code is the only option that works reliably. Learning curve matters too. Codeex is straightforward. You describe what you want. It builds it. Claude code has more complexity but can do more integrations. My advice, start with codeex for your first projects. Get comfortable with AI coding, then add clawed code when you need advanced integrations. If you're new to coding, the answer depends on your goals. Want to create beautiful websites? Start with codecs. Want to build complex systems that connect services? Start with clawed code. But honestly, you need both skills. The most successful developers use multiple AI tools. Here's a prediction. Within a year, these tools will start merging capabilities. But right now they have distinct strengths. Developers who understand these differences and use the right tool will build better projects faster and cheaper. Developers who force one tool to do everything will struggle. So which tool wins? Neither and both. Codeex wins for UIUX and standalone apps. Claude code wins for workflows, integrations, and system automation. The real winners are developers who use both strategically. Now let me share something that most people don't know about these tools. The way they handle errors is completely different. When Codeex hits a problem, it usually gives you clean error messages and suggests fixes that actually work. It's like having a senior developer looking over your shoulder. But clawed code, when something breaks in a workflow, it can be a nightmare to debug. The error messages aren't always clear, and because it's dealing with so many external connections, figuring out what went wrong can take hours. This is another reason why I recommend starting simpler projects with codecs. You'll learn faster because you won't get stuck debugging complex integration issues. Save those headaches for when you really need Claude Code's workflow powers. Here's something else that might surprise you about these tools. The speed difference is huge. Codeex generates code fast, like really fast. You ask for something and boom, it's done. The whole process feels smooth and instant. Clawed Code is slower, but for a good reason. It's thinking through more complex logic. It's considering how everything connects together. When you're building workflows that touch five different services, that extra thinking time is worth it. But when you just want to build a landing page quickly, that delay gets annoying. And here's a pro tip nobody talks about. The way you write prompts for each tool should be different. With Codeex, you can be direct and simple. Tell it exactly what you want the final result to look like. Focus on the visual and functional outcomes. With Clawude Code, you need to be more detailed about the process. Explain the steps. describe how things should connect. Think of it like giving instructions to two different types of workers. One is great at creative tasks. The other is great at following complex procedures. I expect Anthropic to release a new model very soon. They usually do it on Fridays. If they don't, people will start moving to codeex in large numbers, but until then, this two tool strategy is your best bet. Julian Goldie reads every comment. So, make sure you comment below with your experience using these tools. And if you want to take your AI skills to the next level, check out my AI profitboardroom@school.com/iprofitlab 7462/about. It's the best place to scale your business, get more customers, and save hundreds with AI automation. But if you're just getting started, welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get access to over 1,000 free N8 workflows, see how one member made over $10,000 with Chat GPT, and get a full blueprint to generate thousands of leads free with AI. You'll also get access to our free AI community, free AI course, and proven AI case studies. The link is in the description. Start testing both tools on your projects and let me know how it goes. Thanks for watching and I'll see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo compara Codeex e Claude Code, mostrando que cada ferramenta tem forças distintas e que a estratégia ideal é usar ambas conforme a tarefa, com Codeex para UI/UX e Claude Code para workflows, integrações e automação.",
            "resumo": "O apresentador analisa Codeex e Claude Code, afirmando que não existe um vencedor único. Em testes com projetos reais, Codeex domina a geração rápida de código e o UI/UX, enquanto Claude Code se destaca em workflows, integrações e automação. Em um projeto WordPress, Codeex falhou ao implementar uma curl request, enquanto Claude Code entregou tudo. Em outro projeto de UI complexo, Codeex criou uma UI impressionante enquanto Claude Code teve dificuldades. Fluxos com claw.md mostraram que Codeex pode falhar, enquanto Claude Code lida bem com fluxos externos. A recomendação é usar os dois: Codeex para front-end e UI/UX; Claude Code para bancos de dados, APIs e automação. Preços: Codeex mais acessível; Claude Code caro. A previsão é que os dois se complementem cada vez mais e que desenvolvedores que dominem ambos ganhem agilidade e custo-benefício.",
            "assunto_principal": "Comparação entre Codeex e Claude Code: forças, fraquezas e estratégia de uso",
            "palavras_chave": [
              "Inteligência artificial para desenvolvimento",
              "Codeex",
              "Claude Code",
              "Interface do usuário / Experiência do usuário",
              "fluxos de trabalho",
              "integrações",
              "comandos de shell",
              "MCPS",
              "APIs",
              "WordPress",
              "preços",
              "estratégia de uso",
              "erros e depuração",
              "instruções",
              "modelos futuros"
            ],
            "resumo_em_topicos": "- Título do vídeo: comparação entre Codeex e Claude Code e suas implicações para desenvolvedores.\n- Conclusão central: não há vencedor único; use as duas ferramentas de forma estratégica.\n- Codeex: destaque para UI/UX, código limpo e velocidade na geração de código.\n- Claude Code: destaque para fluxos de trabalho, integrações com ferramentas externas, comandos de shell, MCPS e automação de APIs.\n- Exemplos práticos: projeto WordPress mostrou que Codeex pode falhar em instruções específicas (curl), enquanto Claude Code entregou a funcionalidade completa.\n- Projeto UI complexo: Codeex entregou UI impressionante; Claude Code enfrentou dificuldades.\n- Fluxos com claw.md: Codeex teve desempenho ruim; Claude Code lida melhor com fluxos de trabalho externos.\n- Estratégia prática: utilize Codeex para frontend/UI e projetos independentes; utilize Claude Code para bancos de dados, APIs e automação; divida as tarefas.\n- Prompts: Codeex responde a instruções diretas; Claude Code requer descrição de processos e conectividade.\n- Custos: Codeex ~US$ 20/mês; Claude Code ~US$ 200/mês; recomendação de planos básicos.\n- Perspectiva futura: é provável que as ferramentas se futuramente converjam; quem dominar as duas terá vantagem.",
            "prompt_tokens": 1783,
            "completion_tokens": 3122,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 71.47198009490967,
          "language": "",
          "view_count": 420,
          "has_transcript": false
        },
        {
          "id": "VOfocF3BmdE",
          "title": "A NOVA atualização do Google Firebase Studio é INCRÍVEL (GRÁTIS!) 🤯",
          "title_pt": "Texto: A NOVA atualização do Google Firebase Studio é INCRÍVEL (GRÁTIS!) 🤯",
          "url": "https://www.youtube.com/watch?v=VOfocF3BmdE",
          "published": "2025-09-23T07:13:56.274509",
          "published_relative": "há 5 horas",
          "duration": "09:12",
          "date_published": "2025-09-23T00:00:34-07:00",
          "transcript_available": true,
          "transcript": "New Google Firebase Studio update is insane and it's free. Today I'm going to show you Google's new Firebase Studio update that just dropped and this thing is nuts. They added AI templates that build your apps for you. They added smart files that teach the AI how to code better. You can now upload 100 megabyte projects in seconds. And the AI can add databases and user login with just one sentence. Plus, I'll show you exactly how to use it to build real apps that make money. and stick around because I'll reveal the one feature that changes everything for solo developers. Look, I've been building apps and websites for over a decade. I've seen tools come and go. But what Google just did with Firebase Studio, this is different. This could replace entire development teams, and most people have no clue this even exists yet. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency, Goldie Agency. Whilst he's helping clients get more leads and customers, I'm here to help you get the latest AI updates. So, what exactly is Firebase Studio? It used to be called Project IDX. Now, it's Firebase Studio. And it's basically a full development environment that lives in your browser. You don't need to install anything. You don't need a fancy computer. You just open a browser tab and start building front end, back end, mobile apps, whatever you want. But here's where it gets crazy. They just added AI that doesn't just help you code. It actually understands your entire project. It knows what frameworks you're using. It knows your coding style and it can make changes across multiple files at once. And the best part is completely free while it's in preview. Google is basically giving away enterprise level development tools for nothing. If you want to take this further and learn how to scale your business with AI automation, join my AI profit boardroom. It's the best place to learn how to use AI to get more customers and save hundreds of hours. The link is in the description. Julian Goldie reads every comment. So, make sure you comment below and tell me what app you want to build after watching this. Let me show you what they just added because these updates are absolutely insane. First, they added AI optimized templates. These aren't just basic starter projects. These are complete applications that are preconfigured to work with Google's Gemini AI. When you start a new project, you can pick from React, Angular, Flutter, Next.js templates. But here's the crazy part. These templates come with something called agent mode turned on by default. What's agent mode? It means the AI doesn't just answer your questions. It actually takes action. You can tell it add user authentication to this app and it will modify your code, add the right libraries, set up the database, everything. But wait, it gets better. Each template comes with something called an aerials.md file. This is basically a set of instructions that tells the AI exactly how to code for your project. It knows your preferred coding style. It knows what libraries to use. It knows how to handle errors. So, when the AI makes changes, they're not random changes. They're changes that fit perfectly with your existing code. And here's the wild part. You know how adding backend functionality usually takes days or weeks. Database setup, API endpoints, authentication systems. With the new Firebase Studio, you can add all that with natural language prompts. You literally type add user login and a database to store user posts and the AI will add firebase off set up fire store database create the login components connect everything together. I'm not talking about giving you code to copy. I'm talking about it actually building the entire backend infrastructure for you. They also added enhanced prompts. You know how sometimes you have an app idea but you don't know how to explain it to the AI. This feature helps you refine your ideas into detailed project specifications. And you can now upload projects up to 100 megabytes. You can take an existing codebase, upload it to Firebase Studio, and the AI will understand the entire project structure. Let me show you exactly how this works with a real example. I'm going to build a simple task management app using one of these new AI optimized templates. Watch how fast this is. First, I go to Firebase Studio and select the React template. It automatically sets up the project with all the AI features enabled. Now, I'm going to use a simple prompt. Turn this into a task management app where users can create, edit, and delete tasks. Add user authentication so each user sees only their tasks. Watch what happens. The AI is now modifying multiple files. It's adding authentication components. It's setting up the database schema. It's creating task components. It's adding routing. Look at this. In less than 2 minutes, we have a fully functional task management app with user login, with a database, with a clean interface. This would normally take a developer several days to build from scratch. Now, you might be wondering, is this actually good or is it just hype? Here's my honest take. If you're a complete beginner who's never coded before, this is incredible. You can build real applications without learning syntax or complex configurations. If you're a solo developer or small team, this is a gamecher. You can prototype ideas in minutes instead of weeks. If you're building internal tools for your business, this is perfect. customer dashboards, inventory systems, reporting tools, you can build them yourself instead of hiring expensive developers. But here's who shouldn't use this yet. If you're building missionritical applications that handle millions of users, you probably want more control over your infrastructure. Let me be completely honest about the downsides because there are some. First, it's in preview. That means features can change. Your projects might break if Google updates something. Second, the AI generated code isn't perfect. It's really good, but you still need to review what it creates. Third, while the development environment is free, Firebase services aren't. If your app gets popular, you'll pay for database reads, file storage, hosting. The free tiers are generous, but they have limits, and you're locked into Google's ecosystem. If you want to move to AWS later, that's going to be complicated. Let's talk about what free actually means here. The Firebase Studio environment itself is free while it's in preview. You can create projects, use the AI features, deploy simple apps, all without paying anything. But Firebase backend services have their own pricing. For authentication, you get unlimited users. For the database, you get 50,000 reads and 20,000 writes per day free. For hosting, you get 10 GB of bandwidth per month. For most small projects, you'll never hit those limits. But if you build something that gets traction, you'll need to pay. My advice, build your minimum viable product on the free tier. Test your idea, get users, then worry about scaling costs later. Let me share some techniques that most people miss. First, customize the aerials.md file for your specific needs. If you prefer certain libraries, add them to the rules. The better your aerials.md file, the better code the AI will generate. Second, start with enhanced prompts for complex projects. Let the AI help you think through your architecture first. Third, use agent mode for big changes and ask mode for specific questions. Agent mode is powerful, but it can make unexpected changes. And finally, test your app early and often. The AI can build features fast, but bugs can compound quickly if you don't catch them. Here's what most people don't realize. This isn't just a cool development tool. This is the beginning of a massive shift in how software gets built. Right now, building an app requires technical expertise, time, and often a team. With tools like this, any entrepreneur with a good idea can build and test their concept. We're going to see an explosion of new applications. And here's the scary part for traditional developers. A lot of basic development work is about to become automated. But if you're a developer who solves complex problems, who understands business needs, you're going to become more valuable than ever. So, should you use Firebase Studio? If you're an entrepreneur with app ideas, absolutely. Even if you've never coded before, you can build functional prototypes. If you're a small business owner who needs internal tools, this could save you thousands in development costs. If you're learning to code, this is incredible for understanding how full applications work. But don't expect it to replace deep technical knowledge. The AI is a powerful assistant, not a replacement for thinking. Look, I've been in this industry long enough to know when something is genuinely game-changing. And this Firebase Studio update is the real deal. But here's what I want you to do right now. Don't just watch this video and forget about it. actually go try Firebase Studio. Pick one simple app idea, maybe a personal blog, maybe a simple toou app, maybe a small business website, and build it using these new AI features. And when you build something cool, make sure you comment below and show me what you created. I read every single comment. Want to make more money with AI? Welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get 1,000 plus free N8N workflows, 200 plus chat GPT prompts, how one member made 10,000 plus with chat GPT, and a full blueprint to generate thousands of leads free with AI. What you'll also get is a free AI community, free AI course, and proven AI case studies. Link in the comments and description. But most importantly, go build something. The best way to understand these tools is to use them. What app are you going to build first? Let me know in the comments below.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise da nova atualização do Google Firebase Studio com IA integrada, modelos otimizados e capacidade de criar aplicativos rapidamente, inclusive com backend automático, em modo gratuito durante a pré-visualização.",
            "resumo": "O apresentador analisa a nova atualização do Google Firebase Studio (antigo Project IDX), agora no navegador, com IA integrada que entende o projeto e pode agir em múltiplos arquivos. São templates otimizados com modo agente, que permite adicionar autenticação, banco de dados e outras funcionalidades apenas com prompts em linguagem natural. Também há um arquivo aerials.md que orienta a IA com o estilo de código desejado. Usuários podem fazer upload de projetos de até 100 MB. O vídeo demonstra, com um exemplo prático, como criar rapidamente uma aplicação de tarefas com autenticação em menos de 2 minutos. O autor destaca benefícios para iniciantes, freelancers e pequenas equipes, além de ressalvas sobre pré-visualização, qualidade do código gerado e custos do backend. Ele oferece dicas estratégicas para usar IA com segurança e escalabilidade, e discute o impacto no futuro do desenvolvimento.",
            "assunto_principal": "Nova atualização do Google Firebase Studio com IA integrada, templates otimizados e desenvolvimento rápido de apps.",
            "palavras_chave": [
              "Estúdio Firebase",
              "Inteligência Artificial",
              "modelos de IA",
              "modo agente",
              "aéreas.md",
              "envio de 100 MB",
              "autenticação",
              "Firestore",
              "desenvolvimento no navegador",
              "pré-visualização",
              "custos do Firebase",
              "prototipagem rápida"
            ],
            "resumo_em_topicos": "- O Firebase Studio (ex-PIDX) funciona no navegador, sem instalação.\n- IA com modelos otimizados e modo agente que executa ações.\n- Arquivo aerials.md para orientar a IA no estilo de código desejado.\n- Possibilidade de adicionar autenticação, banco de dados e backend via prompts.\n- Envio de projetos até 100 MB; demonstração prática com aplicativo de tarefas em menos de 2 minutos.\n- Vantagens para iniciantes, freelancers e equipes pequenas; ressalvas para aplicativos críticos.\n- Desvantagens: ainda em pré-visualização, o código gerado pode exigir revisão, custos do backend.\n- Dicas: personalizar aerials.md, usar prompts avançados, combinar o modo agente com o modo de perguntar e testar cedo.\n- Potencial de transformar a forma como o software é construído.",
            "prompt_tokens": 1753,
            "completion_tokens": 3493,
            "model": "gpt-5-nano",
            "cost": 0.0061
          },
          "analysis_time": 90.85938906669617,
          "language": "",
          "view_count": 2818,
          "has_transcript": false
        },
        {
          "id": "2nGsmi1Zzz0",
          "title": "Supernova: O NOVO programador de IA GRATUITO é INSANO!",
          "title_pt": "Supernova: o novo programador de IA gratuito é insano!",
          "url": "https://www.youtube.com/watch?v=2nGsmi1Zzz0",
          "published": "2025-09-23T03:13:56.274517",
          "published_relative": "há 9 horas",
          "duration": "08:39",
          "date_published": "2025-09-22T20:00:03-07:00",
          "transcript_available": true,
          "transcript": "Supernova new free AI coder is insane. Today I'm going to show you a brand new AI coder that just dropped. It's completely free and it's beating some of the biggest names out there. This thing can see images, write code, and build entire apps in seconds. I tested it on four tough coding challenges and the results will blow your mind. Plus, I found proof this mystery model might be from one of the biggest AI companies. So, here's what happened. A new stealth model just launched across multiple coding platforms. It's called Code Supernova, and nobody knows who made it, but I did some digging and found some wild evidence about who's really behind this thing. This isn't just another AI model. This is a multimodal reasoning model that can handle images and has a massive 200,000 token context window. That's huge. Most models cap out way lower than that. And here's the crazy part. It's completely unlimited on platforms like Hilo Code. No throttling, no caps, just pure speed and power. But wait, there's more. This model has three different reasoning levels: low, medium, and high. So, you can dial up the thinking power based on what you need. That's something only the most advanced models have. The focus here is on visual understanding. This thing can look at screenshots, diagrams, mockups, and turn them into working code. Imagine showing it a hand-drawn sketch and getting a full website back. Now, here's where it gets interesting. I ran some tests to figure out what this mystery model really is. And the evidence I found points to one specific company. When I looked at the request logs, I found something called numbum sources used in the output. This is exclusive to one company's API, Grock. That means this code supernova model is likely a bigger, better version of Grock's coding model. Think about it. Grock has been quiet on the coding front. Then suddenly this anonymous beast model drops with all their signature features. It's not a coincidence. So, I put this thing through four realworld tests. The kind of challenges that separate good models from great ones. Test number one was building a movie tracker app. The results were mixed but promising. The app looked amazing. Great design, clean interface, all the features you'd want. But there were some issues. The movie container overflowed from its div. Not great for user experience. Worse, it loaded every single movie without any limit. That's a memory killer and API spammer. You can't ship something like that to real users. When I compared it to Claude code, Claude won on usability. Claude's UI might not be as pretty, but it works perfectly on the first try. That matters more than looks. Test number two was a calculator with a specific UI framework. This is where things got rough. The model completely failed at aligning elements properly. The calculator looked broken and unusable. That's a hard fail on this test. But test number three brought some redemption. I asked it to edit an FPS game and add a step counter plus a life bar that changes when players jump. This generation was awesome. The model crushed it with game development. Previous Grock models were decent at this, but Supernova is much better. The UI could be slightly improved, but it worked perfectly in one shot. That's impressive for game logic and mechanics. However, test 4 revealed a major weakness. Long complex tasks. I asked it to edit a large code base and add an SVG generation modal. This is where supernova completely broke down. The model started glitching hard. It kept saying, \"Let me check over and over. Eventually, kilo code itself detected the glitching and stopped the generation.\" I've seen this exact behavior with gro code fast before. Long generations make it unstable and unreliable. That's a serious problem for real world use. So, where does this leave us? Supernova is good, but not great. Yeah, for simple to medium tasks, is fast and capable. The multimodal features are genuinely useful. Being able to show its screenshots and get working code is powerful, but the reliability issues hold it back. When it works, it's impressive. When it doesn't, it fails hard. I'd still recommend other models like Claude for serious work. They're more stable and consistent. But Supernova is worth keeping an eye on. The speed alone makes it interesting for quick prototypes and experiments. And if the team behind it fixes the glitching issues, this could become a real contender. Here's what I think is really happening. This is Grock's play in the coding space. They've been behind on AI coding compared to OpenAI anthropic. This anonymous launch lets them test their technology without the pressure of a big announcement. The multimodal capability suggests they're building something bigger. Most coding happens with visual references now. Screenshots, designs, mockups. An AI that can see and understand these is the future, right? But let's talk about what this means for you. If you're just starting with AI coding, this is a great free option to experiment with. The unlimited usage on platforms like Kilo Code means you can test without worrying about hitting limits. For professionals, it's worth trying, but keep your main tools ready. The glitching issues make it unreliable for important projects. The visual features are where this shines though. If you work with designs, mockups, or need to debug visual issues, Supernova could save you tons of time. You can use it through Kilo Code, Rukan, or Open Code. Just install the platform you prefer and look for the Supernova model option. Kilo Code is probably the easiest to start with. Just install it, select Supernova from the model list, and you're ready to go. Now, here's something crazy I noticed during testing. The speed difference is insane. While other models take 30 to 60 seconds to generate complex code, Supernova does it in 10 to 15 seconds. That's a game changer for productivity. But speed isn't everything. I've seen fast models that produce garbage code. What matters is the quality combined with speed. And that's where Supernova gets interesting. The visual understanding feature is what sets it apart, though. I showed it a messy screenshot of a broken website layout. Within seconds, it identified the CSS issues and provided exact fixes. That's the kind of capability that saves developers hours of debugging time. This anonymous launch strategy is becoming the new normal in AI companies. Drop models without fanfare, let users discover them, and gather real feedback before official announcements. It's smart because it avoids the hype cycle and focuses on actual performance. But here's what's really wild about this whole situation. The timing of Supernova's release isn't random. We're seeing a massive shift in how AI companies compete. Instead of big flashy launches with demos that don't work in real life, they're going stealth. Think about it. When was the last time a major AI announcement actually delivered on its promises right away? Usually, there's months of waiting, bugs, and disappointment. This stealth approach flips that completely. And this is another angle nobody's talking about. The name supernova itself is interesting. A supernova is when a star explodes and becomes incredibly bright before it dies. Is this Grock's way of saying their old coding models are dead and this is the explosion into something new? The unlimited access on multiple platforms also tells us something. This isn't a limited beta test. Someone invested serious money to make this available everywhere at once. That's not cheap. It signals they're confident in the technology and ready to scale fast. What's your take on these stealth launches? Are they better than the traditional hype cycle? Here's my honest assessment. After extensive testing, Supernova is a solid addition to the AI coding landscape. Not groundbreaking, but definitely useful. The mystery around its origins creates interesting speculation. My money is on it being a Grock model based on the technical evidence. The speed and visual capabilities are its strongest points. The reliability issues are its biggest weakness. For free access and unlimited usage, it's worth trying. Just don't expect perfection yet. The AI coding space is evolving incredibly fast. Models that seem amazing today will be obsolete in months. Stay flexible, keep testing new options, and always have multiple tools in your toolkit. That's why I test everything and share the real results with you. Not the marketing hype, but the actual performance. Julian Goldie reads every comment, so make sure you comment below about your experience with AI coding tools. My AI profit boardroom. The best place to scale your business, get more customers, and save hundreds with AI automation. Want to make more money with AI? Welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools, and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, 1,000 plus free nan workflows, 200 plus chat GPT prompts, and a full blueprint to generate thousands of leads free with AI. What you'll also get free AI community, free AI course, proven AI case studies. That's where you'll find the real strategies for turning AI tools like Supernova into actual business results. Thanks for watching and I'll see you in the next one where we dive even deeper into the latest AI developments that are changing",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o Code Supernova, um novo codificador de IA gratuito e multimodal, possivelmente ligado à Grock, com geração rápida baseada em imagens, mas com confiabilidade variável em testes práticos.",
            "resumo": "O vídeo apresenta o Code Supernova, um codificador de IA gratuito e multimodal capaz de interpretar imagens e gerar código rapidamente, com contexto de até 200.000 tokens e três níveis de raciocínio. O foco é trabalhar com referências visuais (capturas de tela, mockups, diagramas) para criar código. Em quatro testes práticos, o desempenho variou: (1) aplicativo de rastreamento de filmes com interface bonita, porém memória livre e sem limites; Claude Code teve melhor usabilidade; (2) calculadora com interface desalinhada; (3) edição de um jogo FPS com contador de passos e barra de vida funcionou muito bem; (4) edição de uma grande base de código gerou falhas. Conclusão: útil para tarefas simples e médias e prototipagem rápida, porém instável para projetos críticos. O lançamento furtivo alimenta especulações sobre a origem, possivelmente Grock, e sugere cautela para usos profissionais.",
            "assunto_principal": "Lançamento sigiloso do codificador de IA Code Supernova, com capacidades multimodais, uso gratuito e desempenho misto, possivelmente ligado à Grock.",
            "palavras_chave": [
              "Supernova de Código",
              "Programador de IA",
              "multimodal",
              "contexto de 200.000 tokens",
              "sem limitação de taxa",
              "Grock",
              "testes de codificação",
              "Kilo Code",
              "Rukan",
              "Código Aberto",
              "falhas",
              "velocidade de geração",
              "visuais de código",
              "lançamento furtivo"
            ],
            "resumo_em_topicos": "--- Introdução\n- Apresentação do Code Supernova e a premissa de ser gratuito e multimodal\n- Suposta origem ligada à Grock e estratégia de lançamento sigiloso\n\n---Características Principais\n- Capacidade multimodal: interpretar imagens e diagramas para gerar código\n- Contexto de até 200.000 tokens\n- Três níveis de raciocínio (baixo, médio, alto)\n- Uso sem limitação de taxa em plataformas como Kilo Code\n- Foco em entendimento visual para acelerar prototipagem\n\n--- Testes Realizados\n- Teste 1: aplicativo de rastreamento de filmes; UI bonita, porém estouro de memória; Claude Code venceu em usabilidade\n- Teste 2: calculadora; desalinhamento de elementos\n- Teste 3: edição de jogo FPS com contador de passos e barra de vida; resultado muito bom\n- Teste 4: edição de grande base de código; falhas e geração longa\n\n--- Desempenho e Conclusões\n- Velocidade de geração: significativamente mais rápida que concorrentes\n- Qualidade vs confiabilidade: útil para tarefas simples/médias; instável para projetos críticos\n- Recomendações: usar para prototipagem rápida; considerar Claude para trabalhos sérios\n- Limitações visuais identificadas como grande entrave\n\n--- Implicações de Mercado e Futuro\n- Lançamento sigiloso como nova norma entre IA; foco em desempenho real, não no hype\n- Indícios de investimento e escalabilidade (acesso ilimitado em várias plataformas)\n- Possibilidade de evoluções futuras caso as falhas sejam corrigidas\n\n--- Recomendações ao Usuário\n- Para iniciantes: opção gratuita e rápida para experimentar\n- Para profissionais: reduza o risco mantendo ferramentas estáveis à mão\n- Acompanhar atualizações da equipe por trás do Code Supernova",
            "prompt_tokens": 1762,
            "completion_tokens": 3314,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 96.99340176582336,
          "language": "",
          "view_count": 4063,
          "has_transcript": false
        },
        {
          "id": "NVzDyHrxKq4",
          "title": "A NOVA atualização de imagem Flash do Gemini 2.5 é INCRÍVEL!",
          "title_pt": "A nova atualização de imagem Flash do Gemini 2.5 é incrível!",
          "url": "https://www.youtube.com/watch?v=NVzDyHrxKq4",
          "published": "2025-09-23T00:13:56.274524",
          "published_relative": "há 12 horas",
          "duration": "10:12",
          "date_published": "2025-09-22T17:00:35-07:00",
          "transcript_available": true,
          "transcript": "Today, I'm going to show you Google's new AI that just broke the internet. This thing can edit your photos better than a pro designigner in seconds. 10 million people joined Gemini in one week because of this. I'm about to blow your mind with what this can do. Get ready because this changes everything. So, what is this nano banana thing? It's Google's new AI that can edit images like magic. But not just edit, it can create. It can transform. It can do things that used to take hours in Photoshop in just seconds with simple words. Here's what blew my mind. This AI brought 10 million new users to Gemini in just one week. 10 million. That's more than most apps get in a year. Why? Because this thing is revolutionary. Let me show you what makes this so special. First, it can understand multiple images at once. You can give it two photos and tell it to merge them. Want to put yourself in a photo with your pet? Done. Want to change the background of your room to see how new wallpaper looks? Easy. Want to place yourself anywhere in the world? No problem. But here's where it gets crazy. Most AI image tools make you look weird or fake. You know what I mean? That uncanny valley thing where something looks off. Nano Banana doesn't do that. It keeps you looking like you're right. Your face stays your face. Your features stay your features. It just changes what you want changed. The character consistency is mind-blowing. You can take the same person or pet and put them in different scenes, different clothes, different poses, different lighting, and they still look exactly like themselves. This is huge for content creators. Think about this. You could create an entire photo series with the same character without doing multiple photo shoots. You could test different product photos without hiring models. You could create marketing images without expensive equipment. Here's another crazy feature. It can do precise local edits with just words. Want to blur the background? Just ask. Want to remove a stain from your shirt? Tell it. Want to remove someone completely from a photo? Say the words. Want to change someone's pose? Easy. Want to add color to a black and white photo? Done. This isn't just basic editing. This is professional level stuff and you don't need to know Photoshop. You don't need design skills. You just need to know how to talk. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency Goldie Agency. Whilst he's helping clients get more leads and customers, I'm here to help you get the latest AI updates. Let me tell you why this matters for your business. Content is everything now. Social media marketing ads. Everyone needs images. Good images. But good images cost money and time. Lots of both. With Nano Banana, you can create professional images in seconds. Need product photos? Make them. Need social media content? Create it. Need marketing images? Generate them. All with simple text prompts. But here's something most people don't know. This tool can maintain consistency across multiple edits. You can have conversations with it. You can say, \"Make this change, then that change, then another change.\" And it remembers everything. It keeps track of all your edits. This is where it gets really powerful for business. You can iterate on images in real time, test different versions, try different styles, all without starting over each time. The multi-image fusion capability is insane. You can combine photos in ways that look completely natural. Want to put your product in different environments? Combine photos? Want to show your service in different locations? Merge images. Want to create before and after shots? Blend pictures. Here's what Adobe said about it. They tested it and found notable strengths in maintaining cross-edit coherence. That means when you make multiple changes, everything still looks natural together. That's huge. Most AI tools break down when you ask for complex edits. They start looking fake or weird. Nano Banana stays consistent. It preserves fine details. It keeps the overall scene looking real. For content creators, this is a gamecher. You can create entire visual stories with one character. You can build brand consistency across all your images. You can test concepts without expensive photooots. But let's talk about speed. This thing is fast. Google built it on their flash architecture. That means results in seconds, not minutes. You type your prompt, hit enter, and boom, done. Compare that to hiring a designer. First, you explain what you want, they create a draft, you give feedback, they make changes back and forth for days. With Nano Banana, you get results instantly. The natural language processing is incredible. You don't need to learn special commands or technical terms. You just talk to it like a person. Remove the person in the back. Make the sky more blue. Add flowers to the garden. It understands. Here's something cool. It's integrated right into Gemini. You don't need a separate app. You don't need new accounts. If you use Gemini, you already have access. Just start uploading images and giving prompts. The quality is professional grade. We're not talking about basic filters or simple effects. This creates images that look like they came from a professional studio. The lighting is natural. The shadows make sense. The details are crisp. For businesses, this opens up so many possibilities. Product cataloges with consistent lighting and backgrounds. Social media content that matches your brand perfectly. Marketing materials that look expensive but cost almost nothing to create. The style transfer capabilities are amazing. You can take any image and change its artistic style while keeping the content the same. Want your photo to look like a painting? Done. Want it to look like a sketch? Easy. want it in a specific art style, no problem. But here's what really makes this special. It's not just about creating new images. It's about improving existing ones. Got old family photos that are faded, restore them. Got photos with bad lighting, fix them. Got images with unwanted objects, remove them. The precision is incredible. When you ask it to remove something, it doesn't just delete it. It intelligently fills in what should be there. remove a person from a beach photo and it adds sand and waves that match perfectly. The pose alteration feature is mind-blowing. You can change how someone is standing or sitting in a photo. The AI understands human anatomy and creates natural looking poses. It's like having a professional photographer and model available any time. Color correction happens instantly. Black and white photos become full color with historically accurate tones. Faded photos become vibrant again. Poorly lit photos become bright and clear. For social media managers, this is incredible. You can create consistent visual content across all platforms. Same style, same quality, same brand feel. But with unlimited variations and creativity, the background replacement is seamless. Unlike cheap green screen effects, this looks natural. The lighting adjusts. The shadows match. The perspective stays correct. It's like your subject was always in that location. With Nano Banana, you can create entire catalogs from basic product shots. Different backgrounds, different lighting, different presentations, all looking professional and consistent. The facial consistency is incredible. If you're creating content with people, they stay looking like themselves across all variations. No more weird AI faces that look almost human, but not quite. This solves one of the biggest problems in AI image generation, the uncanny valley effect. When faces look almost real, but something feels off. Nano Banana doesn't have this problem. Faces look natural and human for personal use. Imagine the possibilities. Family photos with perfect lighting. Vacation photos with ideal weather. Group photos where everyone looks their best. All possible with simple text commands. The speed makes iteration possible. Don't like the first result? Ask for changes immediately. Try different approaches. Experiment freely. There's no cost for trying again. The integration with Google's ecosystem is powerful. Create images in Gemini. Use them in Google Docs, share them through Google Drive, everything works together seamlessly. Here's what makes this different from other AI image tools. Most focus on creating new images from scratch. Nano Banana excels at editing and transforming existing images. That's often more useful for real work. The quality consistency across different types of edits is remarkable. Whether you're doing simple color correction or complex scene composition, the quality stays high. No drop off in different use cases. For content creators building personal brands, this maintains visual consistency. Your face, your style, your brand elements stay consistent across all content. But with unlimited creative variations, the cost savings for businesses are massive. Professional photo editing costs hundreds per image. Photo shoots cost thousands. With Nano Banana, you get professional results for almost nothing. The time savings are equally important. What used to take days now takes minutes. What required specialized skills now needs just simple instructions. What costs thousands now costs almost nothing. This democratizes professional image creation. Small businesses can compete with big brands visually. Individual creators can produce studio quality content. The accessibility is incredible. No technical skills needed. No expensive software. Just natural language and immediate results. This isn't just a tool. It's a creative partner. It understands what you want and helps you achieve it. It maintains consistency. It enables experimentation. The future of visual content creation is here. Google has created something that changes how we think about images and creativity. Remember, 10 million people join Gemini in one week because of this feature. That's real demand for real capability that solves real problems. The best part, you can start using it right now. It's built into Gemini. No waiting lists. Just start uploading images and giving prompts. This is the future of image editing and the future is available today. Julian Goldie reads every comment. So, make sure you comment below and let me know what you think about Nano Banana and how you plan to use it. If you want to scale your business and save hundreds with AI automation like this, check out my AI profit boardroom. It's the best place to get more customers and learn the latest AI strategies. And if you want to make more money with AI right now, welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get 1,000 plus free nan workflows, discover 200 plus chat GPT prompts, see how one member made 10,000 plus with chat GPT, and get a full blueprint to generate thousands of leads free with AI. Plus, you get a free AI community, free AI course, and proven AI case studies. Click the link in the description to join now.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "A apresentação destaca o Nano Banana, IA de imagem integrada ao Gemini 2.5, que edita, cria e restaura imagens com prompts simples, mantendo a identidade e entregando resultados em segundos.",
            "resumo": "O apresentador mostra o Nano Banana, IA de imagem da Google integrada ao Gemini 2.5, capaz de editar e criar imagens rapidamente com apenas comandos em linguagem natural. Entre os recursos estão fusão de várias imagens, inserção de pessoas em contextos variados, mudança de fundos, remoção de objetos, mudança de pose, colorização de fotos em preto e branco, restauração de fotos antigas e estilo artístico. O sistema preserva a identidade e os detalhes, evitando a sensação de estranheza quando as edições ficam muito naturais, e permite edição local precisa sem Photoshop. É possível iterar, testar variações e manter consistência de iluminação e estilo em toda a coleção, além de aplicar em catálogos, conteúdos de redes sociais e materiais de marketing. A integração é direta no Gemini, sem apps adicionais, com rapidez de resultados e foco em negócios.",
            "assunto_principal": "Nova IA de edição de imagens integrada ao Gemini 2.5 (Nano Banana) que edita, cria e transforma imagens, mantendo a consistência facial e a qualidade de estúdio.",
            "palavras_chave": [
              "Nano Banana",
              "Gemini 2.5",
              "edição de imagens com IA",
              "consistência facial",
              "vale inquietante",
              "edições por prompts",
              "fusão de imagens",
              "remoção de objetos",
              "alteração de pose",
              "colorização",
              "restauração de fotos",
              "marketing visual",
              "catálogos de produtos"
            ],
            "resumo_em_topicos": "- Nano Banana é a nova IA de edição de imagens integrada ao Gemini 2.5, capaz de editar, criar e transformar imagens com prompts em linguagem natural.\n- Suporta fusão de múltiplas imagens, mantendo a consistência facial e evitando o vale da estranheza.\n- Edições locais precisas com comandos simples: desfocar fundos, remover objetos, mudar a pose, colorir etc.\n- Integração direta no Gemini, sem apps adicionais e sem habilidades avançadas.\n- Permite iterar rapidamente, testar variações e manter estilo e iluminação consistentes.\n- Ideal para criadores, comércio eletrônico e marketing, com catálogos e imagens de marca confiáveis.\n- Recursos de restauração, transferência de estilo e melhoria de fotos antigas, com resultados de nível de estúdio.",
            "prompt_tokens": 1732,
            "completion_tokens": 4208,
            "model": "gpt-5-nano",
            "cost": 0.0072
          },
          "analysis_time": 69.1710033416748,
          "language": "",
          "view_count": 2342,
          "has_transcript": false
        },
        {
          "id": "cHKQrQv_jSo",
          "title": "Os NOVOS agentes de IA do Replit são INSANOS!",
          "title_pt": "Os novos agentes de IA do Replit são insanos!",
          "url": "https://www.youtube.com/watch?v=cHKQrQv_jSo",
          "published": "2025-09-22T16:13:56.274531",
          "published_relative": "há 20 horas",
          "duration": "09:37",
          "date_published": "2025-09-22T08:45:03-07:00",
          "transcript_available": true,
          "transcript": "New Replet AI agents are insane. Today I'm going to show you something that just dropped and it's absolutely nuts. Replet just released agent 3 and I tested it for hours. This thing builds automations that used to take days in just minutes. I made bots that check my calendar, send emails, and connect to Slack without writing a single line of code. This is going to change everything for business owners. Let me show you exactly what happened when I tested this thing. I opened up Replet and found this new agents and automation section. and I've been testing it for days and I've got multiple projects running right now. Now, fair warning, it's still in beta, so there are some bugs. I'll show you later. But what this thing can do is crazy. The first thing you see is this event trigger screen. This is how you send messages to your agent. You get three options: Slack, Telegram, and timebased triggers that run at specific times. Here's the cool part. The Replit agent sets up everything for you automatically. No more spending hours figuring out API connections and web hook configurations. Building automations used to be a nightmare. You'd spend days just getting the basics working. But this streamlined approach is gamechanging. Even compared to agents I built with Claude Code, this experience is way smoother. It's like having a tech team build your automations for you. For my first test, I picked the Telegram trigger and created an AI bot that could send emails through Replet's email service and check my calendar. Building this complete agent took about 28 messages back and forth. That's it. 28 messages and I had a working automation that would normally take me days to build. Here's what you need to get started. You need to add your OpenAI key. That's the only requirement. After I entered that, I had to set up uh the Outlook integration. The integration process opens up uh an O aut window for authentication. I saved some screenshots of this process and it's super simple. You just click connect and authenticate. Once the Outlook integration was done, the agent built everything automatically. When setup finishes, you get this agent playground where you can test everything before you deploy it. This is where it gets good. During testing, I asked the agent to check my calendar gaps. It ran all its tools and showed me my availability perfectly. But here's a limitation I found. The playground doesn't have persistent memory. Memory only works when you deploy to Slack or Telegram. When I asked about my previous message in the playground, it couldn't remember our earlier conversation. Now, since this is for testing, they really should add agent memory here, too. I ran into issues later that could have been caught in testing, but since it's beta, this will probably get fixed soon. After testing, you can publish your chatbot to Telegram. The publishing process is different for Telegram and Slack. For Telegram, you have to create a new connection every time. With Slack, you connect once and you're done. In Telegram, you need to create a new bot for each deployment, get its API key, and paste it in. In Telegram, I opened the bot Father app like it told me to. I created a new bot, gave it a name and username, and got the API token. I called mine Mailbot. Once I pasted the token back into Replet, it published automatically. That was the entire setup process. Seriously, that's it. Now, here's where it gets interesting. I started testing by asking it to schedule a meeting. It asked for all the details I needed to provide, followed by the time zone. Then it asked if I wanted to send invitations. Since the meeting was with my script writers, I gave it one of my other email addresses. The bot confirmed it sent the invitation. I checked my email and there it was. An email from the Replet mail service with the meeting notification. But then I noticed something weird. Looking back at my original prompt, I had only asked for calendar availability checking. I never included the ability to schedule appointments. When I asked if it had scheduled the appointment, it said it couldn't do that capability. This led me back to Replet to ask about the Outlook integration. The agent told me that scheduling wasn't possible because I hadn't included it in my initial prompt. But here's the crazy part. This wasn't Repl's limitation. The agent identified the missing feature and added it automatically during our conversation. Agent 3 introduced longer autonomous run times as a new feature. I tested this with apps 2. The difference is way more noticeable in app development than agent building since it still asks for confirmation at various points. They also mentioned app testing capabilities for agents to test their own applications, but the agent still made errors like incorrect formatting messages. This shows the agent wasn't fully tested before deployment. I also tried making other integrations and projects. Replay offered a musical vibe agent that promised to return Spotify songs based on described vibes. I thought it would integrate with my personal playlist, but when I asked about functionality, it just searches the Spotify database without accessing personal data. This was disappointing since it doesn't offer unique capabilities, but I think this could be modified. Regarding Replit's app development features, I created a liquid glass design website with a phone demo. I asked for an iPhone mockup, but the layout looked cluttered. The liquid glass design itself was excellent, but the overall result wasn't remarkable. I also tested a solar system explorer which looked impressive. I wanted to develop a dashboard for selling agent files. It automatically asked me for Stripe integration for payment processing. The testing feature they advertise was actually good. App testing is now automated as you can see in the interface. While this currently only applies to apps rather than agents, seeing complete website testing happen automatically is impressive. Let me show you something else I discovered. The agent building process is way more intuitive than anything I've used before. When you're setting up integrations, it walks you through each step. No more guessing what API endpoints to use or how to format requests. It handles all the technical stuff in the background. But here's what really impressed me. The error handling is smart. When something goes wrong, instead of just throwing an error message, it tries to fix the problem automatically. I had a few instances where the agent caught mistakes in my setup and corrected them without me even knowing. The conversation flow is natural, too. You're not filling out forms or clicking through endless menus. You just talk to it like you would talk to a developer on your team. Tell it what you want and it figures out how to make it happen. Now, let's talk about the business applications. This isn't just a cool tech demo. This is something you can use to actually automate parts of your business. Right now, think about all the repetitive tasks you do every day. checking calendars, sending follow-up emails, updating project status, pulling reports from different tools. All of that can be automated with these agents. This democratizes automation in a way we've never seen before. Small businesses can now build the same kind of automated workflows that used to require enterprise budgets and technical teams. That's a gamecher. My overall impression of the agents and automations feature is highly positive. Despite being in beta, the potential is substantial. Many users will find value in building custom automations with Replet. Once the Slack connection issues are resolved, I'll integrate these agents into my daily workflow. The user experience is smooth, the setup process is simple, and the results actually work. That's more than I can say for a lot of automation tools I've tried. Most of them promise easy setup, but then you spend hours figuring out why nothing works. With Replet Agent 3, I was building working automations in minutes, not hours. And that's with beta software. I can only imagine how good this will be when they iron out the bugs and add more integrations. If you're running any kind of business, you need to pay attention to this. The companies that adopt AI automation early are going to have a massive advantage over those that don't. While your competitors are still doing everything manually, you'll have agents handling the routine tasks so you can focus on strategy and growth. This isn't just about saving time, though that's huge. It's about scaling your operations without scaling your headcount. It's about providing better customer service without hiring more support staff. It's about never missing important tasks because you forgot or got busy. The future of business is automated and tools like Replet Agent 3 are making that future accessible to everyone, not just the big tech companies with unlimited budgets. Every business owner who's willing to learn and adapt. So, here's what I recommend. Sign up for Replit and start experimenting with Agent 3. It's free to get started and the learning curve is minimal. Pick one repetitive task in your business and see if you can automate it with an agent. Start small, learn the system, and gradually build more complex automations. By the time this comes out of beta, you'll already have a head start on your competition. The AI automation revolution is happening right now. The question isn't whether it will affect your business. The question is whether you'll be leading the charge or scrambling to catch up. All right, that's everything I discovered testing Replet Agent 3. This technology is moving fast and the possibilities are endless. And if you want to stay ahead of the curve and scale your business with AI automation, you need to join my AI profit boardroom at 8462/about. It's the best place to scale your business, get more customers, and save hundreds with AI automation. And if you want to make more money with AI, welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get 1,000 plus free N8N workflows, 200 plus Chat GPT prompts, see how one member made 10,000 plus with Chat GPT, and get a full blueprint to generate thousands of leads free with AI. What you'll also get is a free AI community, free AI course, and proven AI case studies. Make sure to comment below with what you want to see next.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do lançamento do agente 3 da Replit, que facilita a criação de automações com pouca ou nenhuma codificação e promete transformar fluxos de trabalho empresariais.",
            "resumo": "Hoje eu testei o novo agente 3 da Replit, que cria automações em minutos que antes levavam dias. Ele permite bots que checam minha agenda, enviam e-mails e conectam ao Slack sem escrever código. A plataforma oferece gatilhos por Slack, Telegram e horários, e o agente monta tudo automaticamente, sem complicações de APIs e webhooks. O processo começa com a chave do OpenAI e a integração do Outlook; depois surge o 'agent playground' para testar antes de publicar. Observações: a memória persistente não funciona no playground — só quando implantado no Slack ou Telegram. A publicação difere entre Telegram (cria um bot novo a cada implantação) e Slack (conecta uma vez). Testes mostraram agendamento, envio de convites e correção automática de erros pelo próprio agente. O beta ainda tem bugs, mas o potencial para democratizar automação empresarial é grande.",
            "assunto_principal": "Lançamento e avaliação do agente 3 da Replit para automação de tarefas e integrações",
            "palavras_chave": [
              "Replit",
              "agentes de inteligência artificial",
              "automação",
              "integração",
              "Telegram",
              "Slack",
              "Outlook",
              "OpenAI",
              "robô",
              "ambiente de testes",
              "beta",
              "memória",
              "publicação",
              "automatização empresarial"
            ],
            "resumo_em_topicos": "- Lançamento do agente 3 da Replit e seu potencial de automatizar tarefas rapidamente\n- Gatilhos disponíveis: Slack, Telegram e gatilhos baseados em horários\n- Configuração automática: chave de API da OpenAI e integração com o Outlook, seguida de um playground para testes\n- Memória: memória persistente disponível apenas quando implantado no Slack ou Telegram; o playground não guarda contexto\n- Publicação: o Telegram requer criação de novo bot por implantação; o Slack permite conexão única\n- Testes práticos: agendamento, envio de convites e correção automática de erros pelo próprio agente\n- Beta ainda com bugs, porém com grande potencial para democratizar a automação\n- Exemplos explorados: automação de agenda, envio de e-mails, integrações diversas e feedback sobre limitações\n- Impacto nos negócios: transformação de fluxos repetitivos e redução da dependência de equipes técnicas",
            "prompt_tokens": 1719,
            "completion_tokens": 2216,
            "model": "gpt-5-nano",
            "cost": 0.0042
          },
          "analysis_time": 54.545766830444336,
          "language": "",
          "view_count": 1438,
          "has_transcript": false
        },
        {
          "id": "MfwNgApXQbM",
          "title": "O NOVO agente de IA do OpCode é INSANO!",
          "title_pt": "O novo agente de IA do OpCode é insano!",
          "url": "https://www.youtube.com/watch?v=MfwNgApXQbM",
          "published": "2025-09-22T12:13:56.274538",
          "published_relative": "há 1 dia",
          "duration": "10:36",
          "date_published": "2025-09-22T05:00:43-07:00",
          "transcript_available": true,
          "transcript": "Today I'm going to show you something that will blow your mind. There's a new tool called Opode that just changed everything about Claude Code. It fixes all the problems Claude Code has been having. Rate limits, short memory, and all those annoying issues are basically gone now. This thing is so good. It's like having a whole team of AI agents working for you. Let me tell you what's been happening. Claw code used to be amazing. Then it got worse, way worse. The rate limits started hitting hard. The context got shorter. It kept forgetting what you were working on. It was like watching your favorite tool slowly break down. But here's where it gets crazy. Someone just built something that fixes everything is called op code. And it's not just a small fix. This thing completely changes how you use cloud code. Think about this. What if you could have multiple AI agents working on your projects at the same time? What if they never forgot what they were doing? What if you could track exactly how much you're spending and never get surprised by huge bills? That's exactly what OPC code does. But there's more. Way more. Uh, this tool lets you create custom agents, not just one, multiple agents, each one specialized for different tasks. You want a debugging agent? Done. You want one for writing docs? Easy. You want one that only works on refactoring code? You got it. Here's the part that made my jaw drop. These agents can run in the background while you're working on something else. They're fixing bugs, writing code, updating documentation, all at the same time. But wait, there's something even better. Remember how Claude code would forget everything when you started a new session? That's gone. Up code saves everything. Your conversations, your code, your progress, everything stays connected. The interface is built with Tari. It's fast. It's clean. It looks better than anything else out there. You get a dashboard that shows you everything. How much you're spending, how many tokens you're using, which projects are costing you the most money. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency Goldie Agency. whilst he's helping clients get more leads and customers. I'm here to help you get the latest AI updates. Let me walk you through how this actually works. First, you need Claude code installed. If you don't have it, it's simple. You need node.js version 18 or higher. Then you run one command and you're done. For op code, you need a few more things. Rust, burn, and git. If you've been using AI tools, you probably already have these. If not, they install in minutes. Getting op code running is stupid simple. You clone the repository. You run a few commands, then boom, you have this beautiful desktop app that makes Claude code 10 times better. Here's where it gets interesting. You open the app and you see all your projects. You can work on multiple projects at once. Each one has its own sessions. Each session remembers everything. But the real magic happens with the agents. You create an agent by giving it instructions. Tell it what kind of work you want it to do. Give it rules to follow. Set up the environment it should work in. Then you deploy that agent to any project. It starts working immediately while you're doing other things. I created a debugging agent. Every time there's an error in my code, this agent jumps in. It finds the problem. It suggests fixes. Sometimes it even fixes the problem automatically. I have another agent for documentation. It reads my code and writes explanations. It updates comments. It creates readme files all without me asking. The usage dashboard is incredible. You can see exactly where your money is going. last 30 days, last week, today, every project broken down, every agent tracked separately. You know what the best part is? The diff visualization. When an agent makes changes to your code, you see exactly what changed. Side by side comparison. You can accept the changes or reject them. One click. This solves the biggest problem with clawed code. Context limits. When clawed code hits its limit, it forgets everything. With OP code, you have multiple threads. Each agent works independently. The main session stays clean. It's like having a team of developers who never get tired, never forget instructions, never make the same mistake twice. But here's what really convinced me this tool is special. Session persistence. Your conversations don't disappear. Your code history stays intact. You can go back to any project from weeks ago and pick up exactly where you left off. The configuration options are insane. You can set permissions for each agent, control what files they can access, set environment variables, configure hooks and commands. Want to run an agent only on weekends? Done. Want to limit an agent to specific folders? Easy. Want to get notifications when an agent finishes a task? Set it up in two clicks. I tested this with a real project, a spreadsheet chat app I built before. I opened it in Upcode, created a new session, started working with multiple agents at once. One agent was refactoring old code. Another was adding new features. A third was writing tests. All happening at the same time, all coordinated perfectly. The model selection is flexible too. You can choose Claude Foropus or Claude for Sonnet. You can set the thinking mode. Auto mode lets Claude decide or you can pick basic thinking, deeper analysis, extensive reasoning, or maximum computation. Here's something most people don't realize. Op code doesn't magically fix Claude's model limits. The context length is still the same. The rate caps are still there. But op code works around these limits so smartly that they become invisible. How? Session management. Instead of one long conversation that hits the limit, you have multiple shorter conversations. Each agent has its own context. The main session coordinates everything. It's like having a project manager who never forgets anything, who can talk to multiple team members at once, who keeps track of every detail without getting confused. The installation process is where most people get stuck, but it's actually simple if you follow the right steps. First, make sure you have NodeJS installed, version 18 or higher. You can check by running node version in your terminal. If you don't have it, download it from the official node.js website. Install it. Then install clawed code using mpm install. One command. That's it. For op code, you need the system requirements met. Any modern computer works fine. You need at least 4 GB of RAM. About 2 GB of storage space. Windows, Mac or Linux will work. The required tools are Rust, Burn, and Git. If you've been doing any development work, you probably have these. If not, each one installs in minutes. Once you have everything, open your command prompt. Clone the opcode repository using the get clone command. Navigate to the directory. Install the dependencies with bun. Build the application. Launch it. The whole process takes maybe 10 minutes less if you already have the prerequisites. When you first open up code, you select a project to work with. Any existing project works or create a new one. The interface is intuitive. Everything is where you'd expect it to be. The session management is where op code shines. You can have multiple sessions running at once. Each one independent, each one persistent. Switch between them instantly. The agent creation process is brilliant. You start with a template or build from scratch. Give your agent a name. Write the system prompt. This tells the agent what its job is. Set the configuration. What model should it use? What files can it access? What commands can it run? How should it handle errors? Deploy the agent to a project. It starts working immediately. You can see its progress in real time. Every action logged, every change tracked. The usage dashboard gives you complete visibility. Total tokens used, cost per project, cost per agent, breakdown by time period. You know exactly where your money goes. This transparency is huge. With regular clawed code, you never know how much you're spending until the bill comes. With OPC code, you see everything in real time. The diff visualization changes everything. When an agent modifies your code, you see the before and after, side by side, colorcoded, additions in green, deletions in red. You can review every change before accepting it. One click to approve, one click to reject. You stay in complete control. But here's the real power. The checkpoints op code automatically saves your progress at key moments. Before major changes, after successful builds, when you close a session, you can roll back to any checkpoint instantly. Made a mistake, go back, want to try a different approach, roll back, and branch from there. This eliminates the fear of experimenting. You can try crazy ideas, knowing you can always go back. This makes you more creative, more willing to push boundaries. The background agents are game changers. Set up an agent to run tests every time code changes. Another to update documentation automatically. Another to check for security issues. These agents work 24/7. They never sleep, never take breaks, never forget to run that important check you always forget about. The productivity gain is massive. Tasks that used to take hours now happen automatically. Code quality improves because nothing slips through the cracks. The settings configuration gives you fine grained control. Environment variables for each agent. Permission levels, file access restrictions, command whitelists. You can sandbox agents completely. Give them access only to specific folders only let them run certain commands. Only allow them to modify certain file types. This security model means you can run powerful agents without worrying about them causing damage. They can only do what you explicitly allow. The proxy support is clever, too. If you're behind a corporate firewall, op code can route through your existing proxy. No special configuration needed. It just works. But here's what I love most. The learning curve is almost zero. If you can use clawed code, you can use op code. The interface is familiar. The concepts are the same. But everything works better. You don't need to change how you work. You don't need to learn new commands. You just install opcode and immediately get all the benefits. The community around opcode is growing fast. People are sharing agent configurations, best practices, creative use cases. The ecosystem is exploding with possibilities. Someone created an agent that automatically writes unit tests. Another that generates API documentation from code comments. Another that optimizes database queries. The possibilities are endless because agents are programmable. You're not limited to what the tool provides out of the box. You can create agents for any repetitive task. Want to scale your business and save hundreds with AI automation? Check out my AI profit boardroom at school.com AI profofit lab 7462 about it's the best place to learn how to use AI to grow your business and get more customers. And if you want to make more money with AI, welcome to the free AI money lab with Julian Goldie. Inside you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents. Get 1,000 plus free nan workflows, 200 plus chat GPT prompts, see how one member made 10,000 plus with chat GPT, and get a full blueprint to generate thousands of leads free with AI. You'll also get free AI community access, a free AI course, and proven AI case studies. The future of development is here. Opcode is leading the way. Don't get left behind.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o OpCode, uma ferramenta que transforma Claude Code ao permitir múltiplos agentes persistentes, gestão de custos e sessões contínuas, superando limites de contexto.",
            "resumo": "Neste vídeo, o apresentador apresenta o OpCode, uma ferramenta que revolucionou o Claude Code, resolvendo limites de contexto, limites de taxa e memória de curto prazo. O sistema permite criar múltiplos agentes personalizados que trabalham em paralelo em diferentes tarefas (depuração, documentação, refatoração), rodando em segundo plano sem que o usuário precise interromper o fluxo. Cada sessão mantém progresso e histórico, mantendo tudo conectado entre tarefas. O painel de uso mostra gastos, tokens e custos por projeto, com uma visualização de diff para aceitar ou rejeitar mudanças. Mesmo com os limites do modelo, o OpCode contorna-os por meio de gestão de sessões e contextos independentes. O vídeo detalha requisitos, instalação (Node 18+, Rust, Burn, Git), passos de clone, compilação e lançamento, além de exemplos práticos em um projeto real.",
            "assunto_principal": "Ferramenta de IA para desenvolvimento com múltiplos agentes persistentes que amplia Claude Code, contorna limites de contexto, oferece gestão de custos, visualização de dif e sessão contínua.",
            "palavras_chave": [
              "Código de operação",
              "Claude Code",
              "agentes múltiplos",
              "persistência de sessão",
              "gestão de custos",
              "painel",
              "visualização de diferenças",
              "depuração",
              "documentação automática",
              "integração com projetos",
              "instalação"
            ],
            "resumo_em_topicos": "- O que é o OpCode e como ele melhora Claude Code\n- Agentes personalizados e paralelos para diferentes tarefas (depuração, documentação, refatoração)\n- Execução em segundo plano sem interromper o fluxo de trabalho\n- Persistência de sessões e histórico conectado entre tarefas\n- Painel de uso: custos, tokens e gastos por projeto\n- Visualização de diff: aceitar ou rejeitar mudanças com um clique\n- Gerenciamento de contexto com múltiplas sessões independentes\n- Configuração de agentes: permissões, arquivos acessíveis, variáveis de ambiente, hooks\n- Instalação e requisitos: Node.js 18+, Rust, Burn, Git; passos de clonagem, compilação e implantação\n- Demonstração prática com um projeto real e uso simultâneo de vários agentes\n- Limites do modelo mantidos, mas contornados pela gestão de sessões e contextos",
            "prompt_tokens": 1793,
            "completion_tokens": 2601,
            "model": "gpt-5-nano",
            "cost": 0.0048
          },
          "analysis_time": 69.92902398109436,
          "language": "",
          "view_count": 5296,
          "has_transcript": false
        },
        {
          "id": "mH-VIAtv2r8",
          "title": "Claude 4.5? O NOVO modelo Stealth é INSANO!",
          "title_pt": "Claude 4.5? O NOVO modelo Stealth é INSANO!",
          "url": "https://www.youtube.com/watch?v=mH-VIAtv2r8",
          "published": "2025-09-22T12:13:56.274547",
          "published_relative": "há 1 dia",
          "duration": "10:23",
          "date_published": "2025-09-22T02:53:09-07:00",
          "transcript_available": true,
          "transcript": "Claude 4.5 new stealth model is insane. Today I'm going to show you a brand new stealth AI model that just dropped out of nowhere and it's absolutely crushing everything. This thing codes faster than anything I've ever seen. It builds entire VS Code clones in one shot. And the crazy part, you can use it completely free right now. But here's the kicker. Nobody knows who made it and it might disappear any day. So here's what happened. A mysterious new AI model called Code Supernova just appeared. And when I say appeared, I mean it literally showed up on multiple coding platforms with zero announcement, no press release, no fanfare, nothing. This model is different. Really different. It's got a massive 200,000 context window. That's huge. It can process images. It can code. And it's fast. Like scary fast. Now, here's where it gets interesting. As some people think this might be the new Gro 4 coder. Others are saying it could be Claude 4.5. The system prompts look similar to Anthropic style, but nobody knows for sure. What I do know is this thing works and it works well. Let me show you what happened when I tested it. I gave it one simple prompt. Create a VS Code clone. That's it. One prompt. And in seconds, it built a fully functional code editor that actually works. Not a mockup, not a demo, a real working app. Think about that for a second. A complete VS Code clone from one prompt. That would take a human developer weeks, maybe months. This thing did it instantly. But that's just the beginning. The real power comes from its multimodal capabilities. You can feed it images, wireframes, screenshots, whatever you want, and it understands them perfectly. I tested this with a plant website wireframe. Just a simple sketch, black and white, basic layout. I showed it to Code Supernova and asked it to build a website. What came back blew my mind. It didn't just copy the wireframe. It improved it, added animations, kept the structure, added product cards, even tried to match the fonts. The AI actually failed at the fonts, but everything else was spot-on. The website had jungle plants, outdoor plants, different categories, all clickable, all animated, all functional from a simple wireframe sketch. Now, here's the crazy part about accessing this model. You don't need to sign up anywhere. You don't need to pay anything. You just go to certain coding platforms and it's there ready to use. when Surf has it, Kilo Code has it, Cursor has it, multiple platforms are offering it completely free. But here's the thing, this might not last long. These stealth models usually disappear as quickly as they appear. So if you want to test this, you need to move fast. Let me walk you through how to access it. If you're using VS Code with one of these extensions, go to settings, look for model provider, select your platform, then look for Code Supernova in the model list. Select it. That's it. You're now using one of the most powerful coding models ever created. But let's talk about what makes this special. The speed is insane. Most AI models take time to think, to process, to generate code. This thing is instant. You type your prompt and boom, code appears. The reasoning is built in. It doesn't just write code. It explains what it's doing. It creates plans. It reviews details. It thinks through problems step by step. And the multimodal part changes everything. You can show it screenshots of apps you want to clone, wireframes of websites you want to build, design mockups you want to code. It sees them, understands them, and builds them. I tested this with different types of projects, simple ones, complex ones, front end, back end, everything in between. For a crypto trading dashboard, it built the entire interface, portfolio section, trading controls, AI assistant, all the features you'd expect. The quality wasn't perfect, but for a first pass, it was impressive. I had it generate SVG graphics, a butterfly, a gaming controller. The butterfly looked amazing. Perfect symmetry, clean lines, professional quality. The controller was okay, but not great. Still better than most AI models, though. When I asked it to animate the controller, things got weird. The joysticks moved correctly, but the buttons were floating around. Clearly not perfect. But the fact that it could even attempt complex animations is remarkable. Here's what I think is happening. This isn't just one model. There are multiple stealth models appearing right now. Code supernova is one, but I've seen others on the webdev arena. There's a model called Rainar. Different names, similar capabilities, also mysterious, also powerful, also possibly connected to major AI companies. Some people think these are test versions, beta releases, companies like Anthropic and others testing their latest models in the wild before official launches. Think about it. If you're developing the next generation of AI models, you want real world testing. You want to see how people actually use them. You want feedback, but you don't want the pressure of an official launch. So, you release them quietly on smaller platforms with cryptic names. Let people discover them organically, see how they perform, fix the bugs, then launch officially later. That's probably what's happening here. Code Supernova might be Claude 4.5 in disguise, or it might be something else entirely. We don't know. And that's part of what makes this exciting. But here's what I do know. These models are good. Really good. better than anything we had access to just a few months ago. The context windows are massive. 200K tokens means you can feed these models entire code bases, complete documentation, huge data sets. They can understand and work with information that would overwhelm older models. The speed is gamechanging. When AI can generate code instantly, the entire development process changes. You stop thinking about coding as typing. You start thinking about it as conversation. The multimodal capabilities open up new possibilities. You can design visually and have AI translate those designs into working code immediately. No more back and forth between designers and developers. But there are downsides. The quality isn't always perfect. These models can generate code that looks right but doesn't work correctly. They can miss important details. They can make assumptions that aren't accurate. Tool calling seems to be a weak point. When these models need to interact with external APIs or services, they sometimes struggle. The connections aren't always reliable and the outputs can look artificial. That crypto dashboard I mentioned, it look like an AI generated it. Clean but generic, functional but not inspired. Good for prototyping but not ready for production. Still, for rapid prototyping, these models are incredible. You can test ideas in minutes instead of hours. You can explore concepts without committing huge amounts of time and resources. The question is, how long will this last? Stealth models are temporary by nature. They appear, people discover them, they generate buzz, then they disappear. Sometimes they come back as official releases. Sometimes they vanish forever. You never know which will happen. My advice, if you're interested in AI assisted coding, test these models now while they're free, while they're available, while you can access them without restrictions. Build something, experiment, push the boundaries, see what's possible. Because this technology is moving fast and opportunities like this don't last long. The future of coding is changing. These stealth models give us a preview of what's coming. Instant code generation, multimodal understanding, massive context windows, lightning fast responses. In a year or two, this might be normal. Every developer might have access to AI assistance this powerful. But right now, it feels like magic. Code Supernova and models like it represent a shift. We're moving from AI that helps with coding to AI that can actually code. The difference is huge. Instead of suggesting improvements or fixing bugs, these models can architect entire applications. They can make design decisions. They can implement complex features. They can solve problems end to end. That changes everything for individual developers, for development teams, for entire companies. If you can describe what you want, AI can build it. The bottleneck isn't technical skills anymore. It's imagination. It's creativity. It's knowing what problems to solve. This democratizes software development in ways we've never seen before. People with great ideas but limited coding skills can build real applications. Designers can implement their visions directly. Entrepreneurs can prototype rapidly. But it also raises questions. What happens to traditional programming jobs? How do we ensure AI generated code is secure? How do we maintain quality standards when anyone can generate software instantly? I don't have answers to these questions. Nobody does. We're all figuring this out together. But what I do know is that ignoring these changes isn't an option. The developers who adapt to AI assistance will thrive. The ones who resist will struggle. It's not about replacing human creativity. It's about amplifying it. Code Supernova might disappear tomorrow or it might stick around. Either way, it's shown us what's possible. And what's possible is remarkable. So, here's my challenge for you. Go test these models. Build something you've always wanted to create but thought was too complex. See how far you can push the boundaries. Don't worry about perfection. Don't worry about production quality. Just experiment, learn, discover what's possible when AI can code as fast as you can think. The tools are there. The access is free. The only limit is your imagination. But remember, this window might close quickly. Stealth models are temporary. Free access is rare. Take advantage while you can. Whether code supernova is clawed 4.5 or something else entirely doesn't really matter. What matters is that it works. It's powerful and it's available now. The age of AI assisted development isn't coming. It's here. These stealth models prove it. The question isn't whether this technology will change everything. The question is how quickly you'll adapt to it. And that's entirely up to you. Now, if you want to take your business to the next level with AI, I've got something special for you. My AI profit boardroom is the best place to scale your business, get more customers, and save hundreds with AI automation. We've got a community of entrepreneurs just like you using AI to grow their businesses faster than ever before. But before you go anywhere, you need to check out the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get access to 1,000 plus free N8N workflows, 200 plus chat GPT prompts, and get a full blueprint to generate thousands of leads free with AI. Plus, you get a free AI community, free AI course, and proven AI case studies. The link is in the description below. Julian Goldie reads every comment, so make sure you drop your thoughts below. Have you tried Code Supernova? What did you build with it? Let us know in the comments. And if you got value from this video, smash that like button and subscribe for more AI updates. We're tracking all the latest developments, so you don't have to. See you in the next one.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise de um suposto modelo stealth de IA para codificação, Code Supernova (possível Claude 4.5), com velocidade incrível, visão multimodal e acesso gratuito, mas com origem incerta e risco de desaparecer rapidamente.",
            "resumo": "Neste vídeo, o apresentador analisa um modelo stealth de IA para codificação, possivelmente Code Supernova ou Claude 4.5, que surgiu sem anúncio em várias plataformas e é usado gratuitamente. O modelo oferece janela de contexto de 200k tokens, capacidade de processar imagens e gerar código instantaneamente. Em uma demonstração, ele pediu para criar um clone do VS Code e o resultado foi uma aplicação funcional em segundos. O recurso multimodal permite alimentar wireframes e imagens, que são entendidos e transformados em código com melhorias visuais. O apresentador testou com um wireframe de site de plantas e o modelo criou um site com categorias, animações e interatividade, embora com falhas de fontes. O acesso é gratuito através de plataformas como Surf, Kilo Code e Cursor, sem cadastro. Modelos stealth são temporários; o vídeo comenta vantagens, limitações e o impacto futuro da codificação assistida por IA.",
            "assunto_principal": "Modelos stealth de IA para codificação, exemplificados pelo Code Supernova (ou Claude 4.5), com destaque para velocidade, contexto ampliado e capacidades multimodais, além de acesso gratuito e riscos.",
            "palavras_chave": [
              "Por favor",
              "forneça a lista de termos para traduzir."
            ],
            "resumo_em_topicos": "",
            "prompt_tokens": 1783,
            "completion_tokens": 3532,
            "model": "gpt-5-nano",
            "cost": 0.0062
          },
          "analysis_time": 52.83598518371582,
          "language": "",
          "view_count": 3751,
          "has_transcript": false
        },
        {
          "id": "SLs9SsPFprQ",
          "title": "A NOVA atualização do Modo IA do Google é INSANA (GRÁTIS!)",
          "title_pt": "A nova atualização do Modo IA do Google é insana (grátis!)",
          "url": "https://www.youtube.com/watch?v=SLs9SsPFprQ",
          "published": "2025-09-22T12:13:56.274554",
          "published_relative": "há 1 dia",
          "duration": "09:25",
          "date_published": "2025-09-21T21:00:37-07:00",
          "transcript_available": true,
          "transcript": "Google just dropped something crazy and it's totally free. I'm talking about their new AI mode update that's going to change how you search forever. Okay, today I'm going to show you features that feel like magic. You can upload pictures and PDFs and get instant answers. You can point your phone at anything and get live explanations. There's even a planning tool that builds custom guides for you. This is bigger than Chat GPT and it's already rolling out to millions of users. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency Goldie Agency. Whilst he's helping clients get more leads and customers, I'm here to help you get the latest AI updates. Julian Goldie reads every comment, so make sure you comment below. I've been testing AI tools for years, but what Google just released with AI mode is next level, and here's what blows my mind. It's completely free. While everyone's paying monthly fees for chat GPT, Google is giving you something that might be even better. Think of it like this. Chat GPT gives you answers, but it's stuck with old information. Google AI mode is different. It's powered by Gemini AI, but uses live web data, real-time information, fresh results every time you ask a question. It doesn't just give you text answers. It handles complex questions with multiple parts and gives you follow-up suggestions. First up, image and PDF upload. You can drag any picture or PDF into AI mode on your computer. The AI reads the entire file and answers detailed questions about it. You have a 50page research paper, upload it. Ask specific questions, get instant answers that reference the exact content. You have a screenshot of code, upload it. Ask how to fix bugs. The AI tells you exactly what to do. But it gets better. They added Canvas. It's a planning workspace that stays with you across sessions. Ask AI mode to create a study plan or business strategy. Instead of just text, it opens Canvas and builds an interactive guide. You can edit it, add to it, come back later. It's like having a personal assistant that remembers everything. Now, here's the feature that made my jaw drop. Search live with real-time video. Point your phone camera at anything. A math problem, science experiment, broken appliance. IM mode sees what you see and explains it live on your screen. Google integrated AI mode directly into Chrome's address bar, the Omnibox. You don't even need to go to google.com anymore. Type complex questions right in your browser's address bar. Hit the AI mode button, get instant AI answers with follow-ups, all without leaving your current page. And there's a new feature called Ask Google about this page. Select any content on the web page you're viewing. AI mode analyzes it and gives you an AI overview in a sidebar with follow-up questions and answers without ever leaving the page. You're reading an article about investing. Select a paragraph about dividend stocks. IM mode instantly explains it in simple terms and suggests related questions. When you search for products, AI mode now shows real-time prices, images, reviews, and inventory levels, all in one place. You're not clicking through 10 different websites to compare prices anymore. AI mode does it all and presents everything in clean cards. Same with local businesses. Search for restaurants and you get ratings, hours, maps, and all the info you need without clicking anywhere. This is going to kill comparison websites. Why visit 10 sites when AI mode gives you everything instantly? Google launched this as a labs experiment in March 2025. It was invite only at first. In May 2025, they opened it to all US users over 18 who opt into search labs. No wait list, no fees, completely free. By summer 2025, they expanded to over 180 countries. In September, they added five new languages. If you're in the US, you can use this right now. Just go to Google Search Labs and opt in. Takes two seconds. Students can upload lecture PDFs or photos of notes. Ask detailed questions about the content. With Canvas, they create study schedules that adapt as they learn. With Search Live, they point their camera at textbooks for instant explanations. I tested this with a calculus textbook, pointed my phone at a complex equation. Our IM mode broke it down step by step, explained each part, and suggested practice problems. Tech creators can ask, compare Python frameworks for web development, and get detailed summaries with links to the best resources. Upload code snippets and get explanations or debugging help. For power users, travel and project planning becomes effortless. AI mode highlights local businesses with live information, best coffee shops near you with ratings and hours, real-time stock and pricing for products. If you create content or do a SEO, pay attention because this changes everything. Early reports show AI mode can reduce organic clicks on simpleformational queries. People get answers directly from the AI summary instead of clicking through to websites. But here's the opportunity. To get featured in AI mode answers, your content needs to be highly authoritative and well structured. The old SEO rules about expertise and trustworthiness are more important than ever. Focus on clear formatting. Use bullet lists, tables, and headers so the AI can easily pass and site your information. For local businesses, make sure your Google business profiles are complete. AI mode pulls directly from these listings. For video creators, include transcripts, timestamps, and schema markup. The AI needs to understand your content to recommend it. Chat GPT is great for conversations and creative tasks, but its knowledge is static unless you're using browsing plugins, and you pay for the good version. Google AI mode uses live web data from Google's massive search index. It's built into search and Chrome, and it's completely free. Perplexity and Bing Chat are similar tools that search with AI, but Google's advantage is integration. AI mode works everywhere you search. In Google, in Chrome, on your phone. Like all AI, Google AI mode can still make mistakes or hallucinate information. Always double check important facts against reliable sources. Source transparency isn't perfect yet. AI mode summaries don't always clearly site every source. Google is working on this, but treat AI answers as a starting point, not the final word. Privacy is a consideration. AI mode uses your search history, location, and other context to personalize answers. Be cautious about sharing sensitive information. If you upload files or images, Google may use that data to improve their AI systems. Google processes over 8 billion searches per day. If even a small percentage become AI mode interactions, we're talking millions of people getting AI powered answers daily. This isn't just another AI tool. This is Google integrating advanced AI into how billions of people find information. For businesses, you need to think about how your content will be discovered and presented by AI. The old rules of SEO are evolving rapidly. For individuals, you have access to incredibly powerful AI capabilities without paying monthly fees or learning new platforms. Go to google.com and look for the search labs icon. It looks like a beaker. Click it and opt into AI mode. Start with simple questions to get familiar. Then try uploading a PDF or image to see the multimodal capabilities. Test Canvas by asking AI mode to create a plan for something you're working on, a workout routine, study guide, or project timeline. If you have the Google app, look for the AI mode tab and try search live. Point your camera at text, objects, or anything you want explained. In Chrome, watch for the AI mode button in your address bar. Use it to ask questions without leaving your current page. Google AI mode represents a fundamental shift in how we interact with information. It's not just a better search engine. It's an AI assistant that understands context, processes multiple media types, and provides real-time answers to complex questions. And it's free. While other companies charge monthly fees for similar capabilities, Google is making advanced AI accessible to anyone with an internet connection. If you create content, you need to adapt your strategy for an AIdriven world. If you're a business owner, you need to understand how customers will discover your products and services. The AI revolution isn't coming. It's here and Google just made it available to billions of people for free. If you want to take your business to the next level with AI automation, you need to check out my AI profit boardroom at school.com/iprofitlab7462. It's the best place to scale your business, get more customers, and save hundreds of hours with AI automation. You'll connect with other entrepreneurs who are already using AI to grow their businesses and get access to the strategies that are working right now. And if you want to start making money with AI today, welcome to the free AI money lab with Julian Goldie. Inside you'll get 50 plus free AI tools and 200 plus chat GPT SEO prompts. You'll learn how to make money with AI agents, get access to 1,000 plus free NAT workflows, and discover 200 plus Chat GPT prompts that actually work. One member already made over $10,000 with Chat GPT using these exact strategies. Plus, you'll get a full blueprint to generate thousands of leads free with AI. What you'll also get is access to a free AI community, a free AI course, and proven AI case studies from real businesses. The future of business is AI and the businesses that adapt first will have the biggest advantage.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Resumo em uma frase: o Google lançou, gratuitamente, o Modo IA com multimodalidade, dados em tempo real e integração total, prometendo transformar buscas, planejamento e SEO.",
            "resumo": "Resumo: O vídeo descreve o Modo IA do Google, uma atualização gratuita alimentada pelo Gemini IA que utiliza dados em tempo real. Recursos incluem upload de imagens e PDFs com respostas baseadas no conteúdo, Canvas como espaço de planejamento persistente, busca ao vivo com vídeo ao apontar a câmera, IA integrada na Omnibox para perguntas sem sair da página, e a função 'Pergunte ao Google sobre esta página'. Também há resultados de produtos e negócios com preços, avaliações e estoque em tempo real. A disponibilização começou como laboratório em 2025, com expansão global para usuários opt-in. O vídeo destaca implicações para SEO: conteúdo autoritativo e bem estruturado, transcrições e marcação de esquema, presença no Google Meu Negócio. Alerta sobre privacidade, confiabilidade de fontes e o fato de perguntas simples poderem reduzir cliques em resultados orgânicos.",
            "assunto_principal": "Nova atualização do modo IA do Google (modo IA) e impactos em buscas, conteúdo e SEO",
            "palavras_chave": [
              "modo IA do Google",
              "Gemini IA",
              "multimodalidade",
              "envio de imagens e PDFs",
              "Canvas",
              "busca ao vivo com vídeo",
              "Omnibox",
              "Pergunte ao Google sobre esta página",
              "resultados em tempo real",
              "SEO e conteúdo autoritativo",
              "transcrições e marcação de esquema",
              "Google Meu Negócio",
              "privacidade",
              "alucinações",
              "integração com o Chrome",
              "laboratórios experimentais"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Contexto: anúncio do Modo de IA gratuito do Google, integrado ao ecossistema de busca e Chrome.\n- Principais recursos: upload de imagens/PDFs, Canvas, busca ao vivo com vídeo, Omnibox, e a função 'Pergunte ao Google sobre esta página'.\n- Funcionalidade multimodal: leitura de conteúdos, explicações em tempo real e informações atualizadas.\n- Experiência do usuário: integração sem sair da página, respostas com perguntas de acompanhamento, visualização em cards.\n- Implicações para SEO e criadores: necessidade de conteúdo autoritativo, formatação clara, transcrições e marcação de schema; possível redução de cliques em buscas simples.\n- Privacidade e confiabilidade: uso de dados de navegação, dados enviados para melhoria, possibilidade de falhas/alucinações; importância de checagem de fatos.\n- Disponibilidade: lançado em laboratório, expansão global para usuários com opção de adesão e suporte a vários idiomas; instruções para experimentar.",
            "prompt_tokens": 1743,
            "completion_tokens": 3127,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 84.55645418167114,
          "language": "",
          "view_count": 5796,
          "has_transcript": false
        },
        {
          "id": "JC36UkVRz2Q",
          "title": "A NOVA atualização do Google NotebookLM é INCRÍVEL (GRÁTIS!)",
          "title_pt": "A nova atualização do Google NotebookLM é incrível (grátis!)",
          "url": "https://www.youtube.com/watch?v=JC36UkVRz2Q",
          "published": "2025-09-22T12:13:56.274568",
          "published_relative": "há 1 dia",
          "duration": "10:40",
          "date_published": "2025-09-21T18:00:28-07:00",
          "transcript_available": true,
          "transcript": "Today I'm going to show you Google's newest notebook LM update that just dropped. This thing is absolutely nuts. We're talking custom reports in any style you want. We're talking 80 plus languages. We're talking about turning your research into blog posts with one click. And the best part is completely free. This is going to change how you create content forever. Hey, if we haven't met already, I'm the digital avatar of Julian Goldie, CEO of SEO agency Goldie Agency. Whilst he's helping clients get more leads and customers, I'm here to help you get the latest AI updates. Let me tell you what just happened. Google took Notebook LM and basically turned it into a content creation machine. You can now make reports that sound exactly how you want them to sound. You can write in Korean, Spanish, French, whatever language you need. And get this, it even suggests what type of report you should make based on what you upload. So, stick around because I'm about to show you exactly how this works, how you can use it to make money, and why this might be the biggest AI update of the year. Google just rolled out five massive updates to Notebook LM. Each one is a gamecher for content creators, first custom reports. You can now tell NotebookM exactly how to write. Want it formal for business clients? Done. Want it casual for your YouTube audience? Easy. Want specific headings and structure? No problem. This is like having a writing assistant that adapts to any style you need. Second, 80 plus languages. Upload research in English, get a report in Japanese, upload Spanish docs, get German reports. Think about this. You can now create content for global audiences without knowing their languages. The possibilities are endless. Third, smart suggestions. Upload scientific papers. It suggests a white paper. Upload news articles. It suggests an explainer. The AI actually analyzes your content and figures out what format works best. It's like having an editor who knows exactly what you're trying to create. Fourth, custom prompts. You can edit the exact prompts Notebook LM uses. Want it to write like a specific author? Want certain elements included every time? You control that. Now, this is huge for branding consistency. Fifth, blog post template, upload research, and get a blog post back complete with headlines, structure, and flow. Almost ready to publish. But wait, there's more. They also added flashcards, quizzes, and expanded audio overviews. Your research doesn't just become articles anymore. Become study materials, training content, and multimedia resources. Here's how custom reports work and why it's absolutely crazy for content creators. Upload your sources like normal PDFs, documents, web links, research papers, whatever you've got. Then, instead of getting just a basic summary, you click create report and then custom. Now, the magic happens. You choose your structure. Want sections with specific headings? Done. Want bullet points for easy reading? Easy. Want a narrative flow that tells a story? No problem. Pick your style. Academic for research papers. Conversational for blog posts. Sales focused for marketing copy. Technical for industry reports. Simple for general audiences. Whatever matches your brand or target audience. Set the tone. Friendly for social media content. Formal for business documents. Persuasive for sales pages. Neutral for news articles. The same research can sound completely different based on who you're writing for. Choose length and output format. Short and punchy for social posts, long and detailed for comprehensive guides, blog post format, white paper structure, briefing docs, whatever you need. Here's what this means for creators. Upload research about AI tools. Set tone to match your YouTube channel style. Choose blog post format. Boom. You get a first draft that sounds like you wrote it. Same research, but now it matches your voice and brand. You still need to fact check and add your unique insights, but imagine cutting your research and writing time in half while maintaining your brand voice. That's what we're talking about here. This language feature is absolutely insane for anyone wanting to expand globally. We're talking over 80 languages now. But here's the key part. This isn't just translation. The AI actually adapts the tone and style for each language and culture. A casual blog post in English becomes a casual blog post in Spanish. Not just word for word translation. The cultural context changes. The expressions change, the flow changes to match how people actually communicate in that language. Think about the business opportunities here. Research a trending topic once in English. Generate reports in Spanish for Latin American markets. Create French content for European audiences. Make Japanese versions for Asian markets. You just multiplied your content output by however many languages you want to target. But here's where it gets even crazier. You can upload sources in one language and get reports in completely different languages. Upload a bunch of Japanese research papers about AI. Get an English blog post back. Upload German business documents. Get a Spanish marketing brief. The AI reads and understands content regardless of the source language. For global teams, this eliminates language barriers in content creation. For creators who want international reach, this opens up massive no revenue streams. And remember, this is all completely free. No subscription fees, no per language charges, nothing. The smart suggestions feature is where Notebook LM starts feeling like it actually understands what you're trying to accomplish. Here's how it works. Upload scientific papers and research studies. And Notebook LM automatically suggests creating a white paper. Upload news articles and press releases. It suggests making an explainer article. Upload business documents and financial reports. It might suggest a briefing dock or executive summary. The AI is analyzing your content type, complexity, level, and subject matter. Then it recommends the best format for that specific information. It's like having a publishing expert who instantly knows what format will work best for your content. Pro tip for creators. Want deep technical content that establishes authority. Upload academic PDFs and research studies. Want general audience content that gets shares and engagement. Upload news articles, blogs, and popular press about the topic. The AI matches the complexity and style to your source material. Now, custom prompts take this to the next level. Instead of just picking from preset options, you can write detailed instructions. Something like, \"Write a 900word blog post in a conversational tone that sounds like you're talking to a friend. Include three key takeaways at the end with specific action steps. Add two clear calls to action that don't sound salesy.\" Or you could write, \"Create a technical white paper for industry professionals. Use formal language, but keep it readable. Include data citations in parenthesis. Structure it with executive summary, problem statement, methodology, key findings, and actionable conclusions. You have complete control over voice, structure, length, tone, and formatting. This means you can train Notebook LM to write exactly how you write or how your brand sounds across all content. The new blog post template is solid for getting started, but with custom prompts, you can create templates that are perfectly customized for your specific audience and brand voice. Now, let's talk about making money with this because these features open up serious revenue opportunities. Content creators, here's your new workflow. Research a trending topic thoroughly. Upload all your sources to notebook. Generate a custom blog post that matches your brand voice. Edit it. Add your personal insights and experiences. Publish. You just cut your content creation time in half while maintaining quality. But it gets better. Generate the same content in multiple languages for international audiences. Create flashcards for your community as bonus materials. Generate audio overviews for podcast episodes or YouTube audio content. One research session becomes multiple revenue streams. Students and researchers upload your literature review sources. Generate a white paper outline and structure. Use that as your starting point for papers and dissertations. Create flashcards from the same sources for exam prep. Turn study materials into multiple formats. Marketing teams and agencies. This is huge for client work. Collect content research from multiple sources. Generate briefs in different languages for international campaigns. Create blog posts for different audience segments using different tones and styles. Generate executive summaries for client presentations, course creators, and educators. Turn your expertise into products faster. Upload your knowledge base and research. Generate course outlines, lesson plans, study guides, and quiz questions. Create multilingual versions for global markets. The key is always adding your unique voice, experiences, and insights on top of what the AI generates. People pay for your perspective and expertise, not just AI output. Be real about limitations. AI can make stuff up. Always verify facts before publishing. Citations might not link properly, so add your own. Be careful with sensitive documents. Some users wanted more advanced features like diagrams. Community feedback is mixed. Here's how to use it step by step. Upload sources. Click reports, then new custom report. Customize settings for structure, tone, style, length, language. Hit generate, review, edit, fact check, add your voice, export, news. Treat this as first draft, not finished product. Here's how to monetize this. Faster content creation means more output, more blog posts, more content, more traffic, more money. International expansion with multiple languages. Offer content services at scale. Create educational products faster. Repurpose one research session into multiple formats. Always add your voice and expertise. People pay for insights, not AI output. This update shows where AI content creation is heading. The barrier between research and content is disappearing. Creators who adapt quickly get massive advantage. Those who rely only on AI without adding value will struggle. This is massive. Custom reports, 80 plus languages, smart suggestions, custom prompts, all free. If you create content or run a business, try this today. Remember the limitations. Fact check everything. Add your voice. Site sources. Use it as powerful first draft tool. Want to take your business to the next level with AI? Check out my AI profit boardroom at https www.school.com.ai profitlab 7462 about it's the best place to scale your business, get more customers, and save hundreds with AI automation. And if you want to make more money with AI, welcome to the free AI money lab with Julian Goldie. Inside, you'll get 50 plus free AI tools and 200 plus Chat GPT SEO prompts. You'll learn how to make money with AI agents, get a thousand plus free workflows, and see how one member made $10,000 plus with Chat GPT. Plus, you get a full blueprint to generate thousands of leads free with AI. You'll also get access to our free AI community, free AI course, and proven AI case studies. The link is in the description below. Go check out Notebook LM right now and let me know in the comments what you think.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Atualização do Google Notebook LM transforma a ferramenta em uma máquina de criação de conteúdo, com relatórios personalizados, suporte a mais de 80 idiomas e geração de posts a partir de pesquisas, tudo gratuitamente.",
            "resumo": "Neste vídeo, o apresentador analisa as cinco grandes atualizações do Google Notebook LM: relatórios personalizados, suporte a mais de 80 idiomas, sugestões inteligentes, instruções de entrada personalizáveis e modelos de postagens para blogs. É possível enviar fontes (PDFs, documentos, links, pesquisas) e receber relatórios no tom, estilo e formato desejados (acadêmico, casual, empresarial, técnico) com comprimentos variados. As sugestões automáticas identificam o formato mais adequado (white papers, explicativo, briefing, etc.). Ainda há recursos como flashcards, questionários e resumos em áudio. O vídeo destaca que tudo é gratuito, ressalta o potencial de alcance global, adaptação cultural e economia de tempo na criação de conteúdo, mantendo a voz da marca e exigindo apenas verificação de fatos pelo criador.",
            "assunto_principal": "Atualizações do Google Notebook LM para criação de conteúdo: relatórios personalizados, 80+ idiomas, sugestões inteligentes, prompts personalizáveis e modelos de blog.",
            "palavras_chave": [
              "Google Notebook Modelo de Linguagem",
              "relatórios personalizados",
              "80 idiomas",
              "multilinguismo",
              "sugestões inteligentes",
              "prompts personalizáveis",
              "modelos de blog",
              "criação de conteúdo",
              "gestão de marca",
              "expansão global",
              "conteúdo gratuito"
            ],
            "resumo_em_topicos": "- Novidades principais: cinco recursos-chave: relatórios customizados, suporte a mais de 80 idiomas, sugestões inteligentes, prompts customizáveis e template de blog.\n- Como funciona: faça upload de fontes (PDFs, documentos, links ou pesquisas) e escolha tom, estrutura e formato; gere um rascunho alinhado à marca.\n- Benefícios para criadores: redução de tempo, voz consistente e alcance global sem barreiras linguísticas.\n- Globalização de conteúdo: adaptação de tom e estilo por idioma; não é apenas tradução, mas conteúdo culturalmente adequado.\n- Fluxo de monetização/uso: pesquisa de temas, geração de posts sob a marca, edição e publicação rápidas.\n- Outros recursos: flashcards, quizzes e resumos de áudio.\n- Observações importantes: ferramenta gratuita; exige verificação de fatos e inserção de insights do criador.",
            "prompt_tokens": 1681,
            "completion_tokens": 3242,
            "model": "gpt-5-nano",
            "cost": 0.0057
          },
          "analysis_time": 78.11337089538574,
          "language": "",
          "view_count": 8524,
          "has_transcript": false
        },
        {
          "id": "sSQRQJZ9jeY",
          "title": "NOVA IA do Sim DESTRÓI N8N? (GRÁTIS!) 🤯",
          "title_pt": "NOVA IA DO SIM DESTRÓI N8N? (GRÁTIS!) 🤯",
          "url": "https://www.youtube.com/watch?v=sSQRQJZ9jeY",
          "published": "2025-09-22T12:13:56.274575",
          "published_relative": "há 1 dia",
          "duration": "14:50",
          "date_published": "2025-09-21T14:30:09-07:00",
          "transcript_available": true,
          "transcript": "New AI destroys N8N and it is completely free. Today I'm going to show you an AI automation platform that just dropped and it's about to change everything. I'm talking about Sim AI, a brand new workflow builder that uses actual AI agents to create your automations for you. This thing is so smart. It literally builds workflows by talking to you like a human. I tested the Copilot feature and the results are going to blow your mind. Plus, I'll show you exactly how I built three different money-making workflows using just plain English commands. So, here's what happened. I was scrolling through my feeds yesterday and I see this new platform called SIM AI that just launched. The tagline says AI that builds workflows for you. And I'm thinking, yeah, right, another overhyped automation tool. But then I actually tested it and my jaw literally hit the floor. This isn't just another Zapia clone or N8N competitor. Yes, it has the traditional drag and drop interface like other platforms. But here's what makes it special. The AI Copilot feature that lets you build complex workflows just by talking to it in plain English. Instead of spending hours learning where every button is and how to connect APIs, you literally just tell the AI what you want and it builds the entire workflow for you. I'm talking complete automations with API calls, data transformations, conditional logic, everything. Let me show you exactly what I tested. I opened up Simai and used the copilot feature to say, \"Build a workflow that scans Gmail for client requests, sends the content into a Slack channel, and automatically creates a task in ClickUp.\" That's it. No technical setup, no API documentation, just plain English. And here's the crazy part. The AI copilot actually understood what I wanted and started building the workflow in real time. It pulled in Gmail integration, set up the Slack posting, connected ClickUp, and even added smart filtering so it only triggers on emails with client request in the subject line. The whole thing took maybe 3 minutes to build. 3 minutes. And when I looked at the output, it was perfect. The workflow automatically reads my Gmail, finds emails with the right subject line, extracts all the important details like sender, message, content, and urgency level, then formats everything nicely before posting to Slack. But here's what really impressed me about the output. The Slack message it creates isn't just a dump of the email content. The AI structured it with clear sections. Client name at the top, request summary, full message content, and even suggested priority level based on keywords in the email. Then it automatically creates the ClickUp task with the client name as the task title. Includes all the email details in the description, assigns it to the right team member based on the request type, and sets the due date intelligently. If it's marked urgent, it gets a shorter deadline. If it's a standard request, it gets normal timing. The level of detail in these outputs is incredible. Most automation platforms just move data from point A to point B. This AI actually thinks about how to structure and present that data in the most useful way. I decided to test something more complex. Next, I told the co-pilot to create a YouTube content workflow that takes a video link, extracts a transcript, summarizes it into a blog post, and then generates three LinkedIn posts with hashtags. Instead of just building basic connections, the AI created something sophisticated. When you input a YouTube URL, it doesn't just grab a raw transcript. The output includes a clean formatted transcript with timestamps, speaker identification if there are multiple people, and automatic removal of filler words and stutters. Then for the blog post generation, the output isn't just a summary. The AI creates a full blog post with an attention-grabbing headline, introduction paragraph that hooks the reader, main content sections with subheadings, key takeaways and bullet points, and even a call to action at the end. But wait, it gets even better with the LinkedIn posts. Instead of three generic posts, the AI generates three completely different styles. The first one is educational and focuses on the main learning points. The second is more personal and tells a story about the insights. The third is engaging and ask questions to drive comments and engagement. Each LinkedIn post comes with relevant hashtags that aren't just random. The AI analyzes the content topic and suggests hashtags that actually get engagement in that niche. It even includes a mix of popular hashtags and more specific ones to maximize reach. The formatting is perfect, too. Each post is optimized for LinkedIn's algorithm with the right length, proper spacing, and strategic emoji placement. You literally just copy and paste these outputs, and they're ready to publish. Now, here's where it gets really interesting. I wanted to test the limits of what this co-pilot feature could handle. So, I asked it to build a complex workflow for monitoring competitor content and generating content briefs for my team. The AI didn't just create a simple web scraper. The output system it built is incredible. When it finds new competitor content, it doesn't just notify you. It creates a detailed analysis report that includes the content topic, target keywords, estimated traffic potential, content length and format, key points covered, and gaps we could exploit. But here's what blew me away about the content brief output. The AI generates complete content briefs that include suggested headlines, target keyword clusters, content outline with specific sections to cover, competitor analysis showing what they missed, recommended content length, and even suggested internal links for SEO. These aren't basic templates either. Each brief is customized based on the specific competitor content and our existing content strategy. The AI actually analyzes what we've already published and suggests angles that complement our existing content while targeting the same keywords more effectively. The output gets saved directly to our Google Drive in organized folders by topic and competitor. The file names are automatically formatted with dates and keyword targets, so everything stays organized. No manual sorting or filing required. I also test the invoice processing workflow that I mentioned earlier. The output from this automation is exactly what every business owner dreams of. When an invoice comes in via email, the AI doesn't just extract basic data. The output includes complete invoice details, vendor name, invoice number, amount, due date, line items with descriptions and costs, tax amounts, and payment terms. But it goes further than that. The AI also categorizes expenses automatically, flags any unusual amounts or vendors, and checks against our approved vendor list. Then it creates a formatted summary that gets sent to our accounting team with everything they need. Invoice image, extracted data in a clean table format, expense categorization, approval recommendations, and even suggested payment scheduling based on cash flow optimization. The ClickUp task it creates includes all this information plus links to the original invoice, due date reminders, and automatic assignment to the right person based on expense category, rent goes to facilities, software to IT, marketing expenses to the marketing team. What makes CMAI special isn't just that it can build these workflows quickly, is that the outputs are actually useful without any additional formatting or processing. Most automation platforms give you raw data that you still need to clean up and format. With SIM AI's copilot feature, the outputs come pre-formatted, properly structured, and ready to use immediately. The AI understands business context, not just technical data transfer. I'm putting together a complete training inside the AI money lab showing exactly how to leverage platforms like Simai to build multiple income streams. We're covering everything from content automation to lead generation systems to custom service workflows. Link in the comments and description to join over 20,000 members who are already scaling their businesses with AI automation. Let me show you another workflow output that really impressed me. I asked the co-pilot to build a lead generation system that monitors social media for people asking questions related to SEO services. The output report it generates for each potential lead is incredible. It includes the person's social media profile, their specific question or painoint, their business details if available, contact information, social media engagement levels, and even a suggested outreach approach based on their communication style. But here's the really smart part. The AI doesn't just find people asking generic business questions. The output filtering is so sophisticated that it only flags people who show genuine buying intent. Someone complaining about their website, traffic gets flagged. Someone just asking casual questions doesn't. The outreach suggestions in the output are customized for each person. For technical people, it suggests leading with data and case studies. For busy executives, it recommends short results focused messages. For small business owners, it suggests emphasizing ROI and cost effectiveness. Each lead report also includes a suggested follow-up sequence with specific messaging for day 1, day three, and day seven if they don't respond. The AI analyzes their social media activity to suggest the best times to reach out and which platforms they're most active on. This level of detailed actionable output is what makes AI copilot features so powerful. You're not just getting automation, you're getting intelligent business assistance that thinks through the entire process. Now, I know what some of you are thinking. This sounds too good to be true. there's got to be a catch. So, I really pushed the platform to see where the outputs might fall short. I asked it to build a complex e-commerce workflow involving inventory management, customer segmentation, and personalized email campaigns. The output reports it generates are enterprise level quality for inventory management. The output includes real-time stock levels, reorder point alerts, supplier lead time tracking, seasonal demand predictions, and automated purchase order generation. When stock gets low, it doesn't just send an alert. It creates a detailed report with recommended order quantities based on sales velocity and seasonal trends. The customer segmentation outputs are equally impressive. Instead of basic demographic groups, the AI creates behavioral segments based on purchase history, browsing patterns, email engagement, and lifetime value predictions. Each segment gets detailed profiles with recommended marketing approaches and product suggestions. For email campaigns, the output isn't just generic templates. The AI generates personalized email content for each customer segment with subject lines optimized for their engagement patterns, product recommendations based on their purchase history and send time optimization for maximum open rates. If you're building any kind of business that relies on repetitive processes, these AI generated outputs are going to save you months of manual work and thousands of dollars in specialist costs. content creation, lead generation, customer support, data processing, marketing automation, everything becomes intelligent and actionized automatically. The beauty of the copilot approach is that you don't need any technical knowledge. You just describe what you want in plain English and get professional-grade outputs that would normally require specialized software and expert knowledge to create. The reality is that AI automation with intelligent outputs is going to separate the businesses that thrive from the ones that get left behind. Companies that embrace these tools early are going to have massive competitive advantages. Better data, faster insights, more personalized customer experiences, everything. But you have to act fast. Simai is free right now during their launch phase, but that's not going to last forever. Once they prove the value and start scaling, pricing is definitely coming. Get in now while you can test everything for free and build out your automation systems. I'm also seeing huge opportunities for people who can master these AI co-pilot platforms. Businesses everywhere need these intelligent automation systems but don't know how to describe their requirements to AI effectively. If you can learn to work with AI co-pilots to generate useful business outputs, you're looking at a massive service business opportunity, the workflow outputs I showed you for content creation alone could be sold as a service for thousands of dollars per month. Think about it. Instead of spending months learning traditional automation platforms, you can master AI assisted workflow building in weeks. Then you can offer automation services to businesses at premium prices because you're delivering enterprise level outputs in a fraction of the time. The automation revolution is happening right now. And most people have no idea how sophisticated these outputs are becoming. We're not just talking about moving data between apps. We're talking about AI that generates business intelligence, marketing insights, and operational recommendations automatically. This changes everything about how businesses operate. Marketing automation, customer service, sales processes, content creation, data analysis. Every single business function can now generate intelligent, actionable outputs just by describing what you want to and AI. Julian Goldie reads every comment. So, make sure you comment below and let me know which workflow outputs impressed you most. Are you more interested in content generation, lead analysis, or business intelligence automation? But here's what really sets this apart from traditional automation platforms. Most tools just move data between applications. SIM AI's C-pilot feature actually thinks about your business processes and creates intelligent outputs that help you make better decisions. The error handling in these workflows is also impressive. Instead of just failing when something goes wrong, the AI creates fallback processes, sends detailed error reports with suggested fixes, and even learns from failures to prevent similar issues in the future. The scalability is incredible, too. As your business grows, these workflows adapt automatically. The AI adjusts processing capacity, optimizes performance, and suggests improvements based on usage patterns and business growth. The lead generation workflow I showed you could be packaged as a service for real estate agents, insurance brokers, consultants, or any business that needs qualified prospects. You could charge monthly retainers for providing qualified leads with detailed intelligence reports. The customer service automation could be sold to e-commerce businesses, SAS companies, or service providers who want to improve their support operations while reducing costs. The ROI on these implementations is so clear that businesses will pay premium prices for proper setup. Also, if you want a free SEO strategy session to see how we can help scale your business with these AI automation strategies, there's a link in the comments and description to book directly with our team. For my AI profit boardroom members, this is exactly the kind of cuttingedge automation we focus on. We're not just using these tools. We're building entire business models around the intelligent outputs they generate. Currently have over 1,000 members and the results speak for themselves. The AI automation revolution is here and the outputs are incredible. The question isn't whether these tools are going to change business forever. The question is whether you're going to be generating intelligent business insights automatically or still doing everything manually. Get started with SIM AI today while it's still free. Start building workflows that generate actionable business intelligence and thank me",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Nova IA chamada SIM AI promete transformar a automação de fluxos de trabalho ao construir automações completas apenas com comandos em inglês, entregando saídas bem estruturadas prontas para uso.",
            "resumo": "Este vídeo apresenta o SIM AI, uma nova plataforma de automação que usa IA para construir fluxos de trabalho inteiros apenas com comandos em inglês simples. O apresentador testa o Copilot, que monta automações completas com chamadas a APIs, transformações de dados e lógica condicional em tempo real, sem necessidade de configurar documentação de API. Ele demonstra um fluxo: ler Gmail, filtrar solicitações de clientes pelo assunto, postar no Slack e criar uma tarefa no ClickUp, com formatação e priorização automáticas. Em seguida, o Copilot gera saídas bem estruturadas: mensagens no Slack com seções claras, criação de tarefas com detalhes e datas, e atribuição automática. Outros testes mostram um fluxo de conteúdo de YouTube (transcrição, resumo, blog) e três posts no LinkedIn com hashtags, além de fluxos para Briefs de conteúdo de concorrentes e processamento de faturas. O resultado é que as saídas vêm prontas para uso, sem edição adicional.",
            "assunto_principal": "Plataforma de automação com IA (SIM AI) que cria fluxos de trabalho inteiros a partir de comandos em inglês, com Copilot, integrações diversas e saídas prontas para uso.",
            "palavras_chave": [
              "SIM IA",
              "Copiloto de IA",
              "automação de fluxos de trabalho",
              "integração de aplicativos",
              "Gmail",
              "Slack",
              "ClickUp",
              "YouTube",
              "transcrição",
              "resumo",
              "blog",
              "LinkedIn",
              "etiquetas",
              "brief de conteúdo",
              "briefs",
              "concorrentes",
              "monitoramento de conteúdo",
              "faturas",
              "processamento de faturas",
              "Google Drive",
              "saídas pré-formatadas",
              "otimização de processos"
            ],
            "resumo_em_topicos": "### Visão geral\n- O SIM AI é uma plataforma de automação que usa IA para criar fluxos de trabalho inteiros apenas com comandos em inglês.\n- O Copilot permite construir automações complexas com integrações com Gmail, Slack e ClickUp, sem codificação.\n\n### Casos de uso apresentados\n- Fluxo Gmail → Slack → ClickUp com filtragem por assunto e saída bem estruturada.\n- Conteúdo de YouTube: transcrição com carimbos de tempo, resumo, blog completo e três posts no LinkedIn com hashtags relevantes.\n- Geração de briefs de conteúdo de concorrentes, monitoramento de conteúdo e salvamento no Google Drive.\n- Processamento de faturas: dados completos, categorização, recomendações de pagamento e criação de tarefas no ClickUp.\n\n### Saídas e impacto\n- Saídas pré-formatadas, prontas para uso, sem necessidade de edição adicional.\n- Economia de tempo e simplificação de automação para negócios.",
            "prompt_tokens": 1683,
            "completion_tokens": 6049,
            "model": "gpt-5-nano",
            "cost": 0.0099
          },
          "analysis_time": 110.510094165802,
          "language": "",
          "view_count": 5369,
          "has_transcript": false
        },
        {
          "id": "hnTeVBHbcow",
          "title": "As NOVAS atualizações de IA do Google Gemini são INSANAS!",
          "title_pt": "As novas atualizações de IA do Google Gemini são insanas!",
          "url": "https://www.youtube.com/watch?v=hnTeVBHbcow",
          "published": "2025-09-22T12:13:56.274582",
          "published_relative": "há 1 dia",
          "duration": "08:25",
          "date_published": "2025-09-21T10:00:54-07:00",
          "transcript_available": true,
          "transcript": "New Google Gemini AI updates are insane. Google AI just posted on X saying they had a busy week. They just dropped five gamechanging updates. We're talking about Olympic level AI performance, sharable custom assistance, free video generation with sound on YouTube, AI built right into your browser for US users, and autonomous payment systems. Update one, Gemini 2.5 Deepthink goes Olympic. Gemini 2.5 Deepthink just achieved gold medal level performance at the 2025 ICPC World Finals. This is literally the Olympics of programming where the smartest computer science students compete. Gemini solved 10 out of 12 incredibly complex programming problems in just 5 hours. But here's the crazy part. It solved problem C in under 30 minutes, which literally no human team could solve. Not one of the 139 university teams from around the world cracked this problem, but Gemini figured it out and you now have access to an AI that can solve problems. And this isn't just about coding. When an AI can think at this level, it can tackle complex problems in any field. Update two, you can now share your Gemini app gems with anyone just like sharing a Google Drive file. You can set permissions, share with specific emails, or create sharable links. is a complete enterprise level sharing system. Before this, custom gems were locked to your account. Now you can create custom AI assistance and distribute them to your entire team. Update 3, V3 fast transforms YouTube. At Google's made on YouTube event, they announced V3 Fast coming to YouTube shorts for completely free. You can create short video clips with sound effects and speech using just a single text prompt. This is the first time AI generated videos include high quality sound. But it gets crazier. You can now animate people in your photos. Take a still photo and bring it to life with AI animation. Edit with AI transforms your camera roll into a first draft video. Analyzing footage and pairing it with music and effects. Soon creators can turn spoken words into music with speech to song. Take any quote from a video and use Google's LIA 2 model to remix it into a catchy song for shorts. You could type a description of the perfect promotional video and have it generated with sound. Take product photos and animate them. Turn customer testimonials into jingles. All free on YouTube shorts. Julian Goldie reads every comment. So, make sure you comment below and let me know which of these updates excites you the most. Before we dive deeper, I want to tell you about something that's going to help you take advantage of all these new AI capabilities. I've created the AI profit boardroom, which is the best place to scale your business, get more customers, and save hundreds of hours with AI automation. We currently have over 1,000 members who are already implementing these exact strategies. Update 4, Gemini in Chrome for everyone. Gemini is now rolling out to all Chrome users in the US for free. Before this, you needed a paid subscription. Now, it's built right into Chrome for everyone using Mac and Windows. You can highlight any text on any web page and instantly get analysis or explanations. Reading competitor websites, get immediate strategic insights, reviewing industry reports, get summaries without reading everything. The real power is contextual awareness. Gemini understands what web page you're on, what you're reading, what task you're completing. It works across multiple tabs to provide insights relevant to your current project. Update 5. AI agents can now handle payments. Google announced the agent payments protocol AP2. This allows AI agents to handle payments and complete transactions autonomously. Over 60 major companies back this including Mastercard, PayPal, American Express, and Coinbase. You could have an AI agent that finds the best deals and actually completes purchases. The AI compares options and executes transactions without human intervention. The system uses cryptographically signed digital contracts called mandates. An intent mandate captures your request. A cart mandate provides final approval. For complex scenarios, you can set detailed mandates that let AI auto purchase when conditions are met. Imagine an AI managing all your software subscriptions, finding better deals automatically, or handling office supplies, purchasing before you run out, or managing vendor relationships and contract renewals. When you combine Olympic level thinking with sharable assistance, video creation with sound, browser integration, and autonomous payments, you get something exponentially more powerful. Your AI can think through complex problems, create video content with sound, share solutions with your team, and handle financial transactions. This automation level has never existed before. In the middle of our journey here, I want to mention that we have a complete SOP and process for implementing all of these AI tools inside the AI money lab. You'll find the link in the comments and description along with over 100 different use cases that show you exactly how to profit from these capabilities. If you're in e-commerce, use Deep Think to optimize supply chains, create gems for product research, generate video ads with sound, and automate vendor payments. If you're in professional services, handle complex client analysis. Create sharable methodology gems. Produce educational videos with sound and automate billing. If you're in content creation, use Olympic level thinking for strategy, sharable gems for brand voice, professional video generation, and automated tool payments. There's always a window where early adopters gain massive advantages. The businesses that master these tools will operate at a level that seems magical compared to traditional companies, but this window won't stay open forever. Your competitors will eventually figure this out. The question is whether you'll be leading the transformation or catching up. Here's what most people don't understand about this Google announcement. Previous AI updates gave us better chat bots or smarter assistance. These five updates create an entirely new category of business automation. For the first time ever, you have AI that can think at superhuman levels, work collaboratively across teams, create professional multimedia content, integrate seamlessly into your existing workflow, and handle real money transactions. This isn't just about productivity anymore. This is about fundamentally changing how businesses operate. Think about it. 6 months ago, if you wanted professional video content, you needed cameras, editing software, maybe a whole production team. Now, you can create Hollywood quality videos with sound using just text. If you wanted expert level problem solving, you needed to hire specialists or consultants. Now you have AI that outperforms Olympic level programmers. The speed of this transformation is unprecedented. We're not talking about gradual improvements over years. These capabilities went from impossible to available in a single week. That's the kind of technological leap that creates new industries and destroys old ones. Get access to deep think and test it on complex challenges. Create custom gems for your business and share them with your team. Experiment with V3 fast on YouTube shorts. Use Gemini and Chrome if you're in the US. Prepare for AP2 payment automation. The AI Profit Boardroom is specifically designed to help you implement these cutting edge strategies. We have over 1,000 members scaling their businesses with AI automation. If you want to book a free SEO strategy session to discuss how these updates can transform your business, you'll find that link in the comments and description. And remember, we have a complete SOP inside the AI money lab. You'll get over 100 use cases, video tutorials, and access to 19,000 members. You'll see how we provide 100 different tutorials as freebies daily. The reason we have 19,000 members is because people want to learn from others successfully implementing these strategies. These Google Gemini updates represent the future of business, Olympic level thinking, sharable assistance, video creation with sound, browser integration, and autonomous payments. Companies that master these tools will dominate. Those that ignore them will become irrelevant. Comment below and let me know which update you're most excited to implement. Julian reads every comment and we love hearing your AI success stories. The future is here. These tools are available now. Your only question should be how quickly you can start using them to transform your business. Thanks for watching and I'll see you in the next video where we'll dive deeper into implementation strategies for these revolutionary AI updates.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise das cinco novas atualizações do Google Gemini, que prometem transformar automação de negócios com desempenho de elite, compartilhamento de gems, geração de vídeos com som, integração no navegador e pagamentos autônomos.",
            "resumo": "Resumo do vídeo: o vídeo analisa as cinco atualizações do Google Gemini, destacando o impacto na automação de negócios. Gemini 2.5 Deepthink apresenta desempenho olímpico ao resolver 10 de 12 problemas nas Finais do ICPC, incluindo o problema C em menos de 30 minutos, provando pensamento de nível super-humano. Em seguida, atualização de compartilhamento: gemas de IA criadas podem ser compartilhadas com permissões, como o Google Drive, para equipes inteiras. Terceira atualização traz o V3 Fast Transform para o YouTube, permitindo clipes com som, animação de pessoas e transformação do rolo da câmera em vídeo com áudio, com fala para canção. Quarta atualização traz o Gemini no Chrome para todos nos EUA, com análises contextuais entre abas. Quinta atualização, pagamentos autônomos via AP2, com grandes empresas apoiando. A IA pode comparar ofertas e concluir compras. O vídeo termina com convite para experiência prática, SOP da AI Money Lab e casos de uso para setores.",
            "assunto_principal": "Transformação de negócios com as novas atualizações do Google Gemini: Deepthink olímpico, compartilhamento de gems, geração de vídeo com som, integração no navegador e AP2 para pagamentos autônomos.",
            "palavras_chave": [
              "Google Gemini",
              "Gemini Deepthink 2.5",
              "Desempenho olímpico",
              "YouTube Shorts",
              "V3 Fast transforms",
              "Geração de vídeo com som",
              "Animação com IA",
              "Chrome com Gemini",
              "Pagamentos AP2",
              "IA para negócios",
              "Gemas compartilháveis",
              "AI Money Lab"
            ],
            "resumo_em_topicos": "Resumo em tópicos\n- Atualização 1: Gemini 2.5 Deepthink atinge desempenho olímpico no ICPC, resolvendo 10 de 12 problemas; o problema C em menos de 30 minutos.\n- Atualização 2: Compartilhamento de gems de IA entre equipes com permissões, semelhante ao Drive.\n- Atualização 3: V3 Transformações rápidas no YouTube Shorts: clipes com som, animação de pessoas, edição por IA, fala-para-música.\n- Atualização 4: Gemini disponível no Chrome para todos nos EUA, com análise contextual entre abas.\n- Atualização 5: AP2 permite pagamentos autônomos por IA; grandes empresas apoiam; compra automática e contratos.\n- Impacto: cria uma nova categoria de automação de negócios, com aplicações em e-commerce, serviços profissionais e criação de conteúdo.\n- Convite: link para SOP e AI Money Lab, com chamada para participação e casos de uso.",
            "prompt_tokens": 1674,
            "completion_tokens": 6523,
            "model": "gpt-5-nano",
            "cost": 0.0106
          },
          "analysis_time": 116.72836780548096,
          "language": "",
          "view_count": 12493,
          "has_transcript": false
        },
        {
          "id": "0CpOluwidb0",
          "title": "NEW Magistral 1.2 AI Update is INSANE (FREE!)",
          "title_pt": "Nova atualização de IA Magistral 1.2 é INSANA (GRÁTIS!)",
          "url": "https://www.youtube.com/watch?v=0CpOluwidb0",
          "published": "2025-09-22T12:13:56.274588",
          "published_relative": "há 1 dia",
          "duration": "13:05",
          "date_published": "2025-09-21T05:59:51-07:00",
          "transcript_available": true,
          "transcript": "New Magestral AI models are insane and it's free. Today, I'm going to show you Mistral's newest AI models that just dropped and they're completely free. These things are beating expensive models left and right. They have new vision capabilities and crazy good reasoning. And the best part, you can start using them right now without paying a single penny. This is going to change everything for your business. So, what just happened in the AI world that has everyone talking? Mistrol just released new versions of their reasoning models called Magestro and they're absolutely insane. I'm talking about performance that rivals the best paid models, but you get the small version for free. Let me break this down for you because this is huge. We're looking at Magestral Small and Magistro medium. The small version is completely open source and free. The medium version is for enterprise, but you can try it in Lache. Both are reasoning models, which means they think through problems step by step before giving you answers. First, let's talk about what makes this so special. Magestro comes in two main versions. You have Magestro small, which is completely free and open source. Then you have Magestro medium, which is more powerful and available for enterprise use. Both are crushing the competition in reasoning tasks. Look at these benchmark numbers. On the AMA 24 math benchmark, Magestro Small scored 86.14. That's higher than many premium models. On AMA25, it hit 77.34. The medium version is even more impressive with 91.8. 82 on AE24 and 83.48 on ME25. But here's where it gets crazy. These aren't just good scores. These are incredible scores that put these models ahead of much more expensive alternatives. We're talking about free models competing with the best paid options. Now, you might be thinking, what does this mean for me? How can I actually use this to grow my business? That's exactly what I'm going to show you. The coding abilities of this model are off the charts. I tested it myself and it's writing code better than some developers I know. It can build websites, create automations, write scripts, whatever you need, this thing can do it. But wait, there's more. This model has what they call multilingual dexterity. That means it speaks multiple languages fluently. You can use it to translate content, write in different languages, reach global markets. This opens up so many opportunities. And here's the kicker. Mr. says their new models provide much faster reasoning through Lache. They claim significant speed improvements that make the thinking process faster and more efficient. That means quicker responses and better productivity for your business. Let me tell you about Lashhat real quick. This is Mistra's chat interface where you can access Magistro for free. No credit card needed. No subscription required. You just go there and start using it. I've been testing this for the past week and the results are mind-blowing. I used it to write email sequences that converted better than my previous ones. I had it create social media content that got more engagement. I even used it to optimize my website copy and saw an immediate boost in conversions. But here's what most people don't realize. The real power comes from knowing how to prompt this thing correctly. Most people are using AI wrong. They're not getting the full potential because they don't know the right techniques. So that's why inside my AI money lab, we have over 100 different use cases showing you exactly how to prompt AI models like Magestro, we have 20,000 plus members who are already using these techniques to scale their businesses. And every single day, I'm adding new tutorials to the school feed. You can get access to all of this training, plus the video notes, plus all the processes and SOPs we use. The link is in the comments and description below. Now, let's talk about what you can actually do with Magistro to make money. First, content creation. This model can write blog posts, social media content, email sequences, sales copy. Whatever type of content your business needs, Magistro can create it. Second, coding and automation. If you need websites built, apps created, or business processes automated, Magistro can write the code for you. You don't need to be a programmer. You just need to know how to ask the right questions. Third, customer service. You can use Magistral to handle customer inquiries, write support responses, create FAQ sections. It understands context better than most human representatives. Fourth, research and analysis. Need market research, competitor analysis, industry reports. Magistr can process massive amounts of information and give you actionable insights. Fifth, translation and localization. Want to expand your business globally? Magestrol can translate your content into multiple languages while maintaining the original meaning and tone. But here's the thing that really sets Magestro apart from other models. The speed. When I say it's 10 times faster, I'm not exaggerating. I timed it against other models and the difference is shocking. The speed improvements that Mistral claims are significant. According to their announcement, you can get responses much faster with their new flash answers feature in leap. This could be a real gamecher for productivity when you need quick reasoning and analysis. The performance benchmarks show these models are competing with top tier models while the small version being completely free. That combination of quality and accessibility is what makes this so exciting. Now imagine scaling this across your entire business. Every piece of content, every analysis, every complex problem, all handled by a reasoning model that can think through problems step by step. That's not just a productivity boost. That's a competitive advantage. But wait, it gets even better. The model is constantly learning and improving. Mist trial keeps updating it based on user feedback and new training data, so it's only going to get better over time. And unlike some other AI companies that keep changing their pricing or limiting access, Mistral has committed to keeping the basic access free. That means you can build your entire business workflow around this without worrying about sudden cost increases. Here's another huge advantage. The model understands context really well. You can have long conversations with it, refer back to previous parts of the chat, and it remembers everything. This makes it perfect for complex projects that require multiple steps. I used it to plan an entire marketing campaign last week. Started with the strategy, then moved to content creation, then to email sequences, then to social media posts. The model remembered the strategy throughout the entire conversation and kept everything consistent. This level of context awareness is usually only found in the most expensive models. Getting it for free is absolutely incredible. Now, let me show you exactly how to access this. Go to chat.mmistral.ai. That's where you'll find Lat Mistral's chat interface. You can sign up for free with just an email address. No credit card required. Once you're in, you'll see options for different models. Look for Magestro Small, which is completely free to use. You can also try Magestro medium if it's available for preview. For most tasks, Magestrol Small is incredibly powerful and more than enough. The interface is clean and simple, just like chat GPT. But in my opinion, it's actually better designed. Everything is intuitive and easy to use. But here's where most people mess up. They just start typing random questions without thinking about how to get the best results. That's like having a Ferrari, but driving it in first gear. The key is in the prompting. You need to be specific about what you want. You need to give context. You need to structure your request properly. For example, instead of saying, \"Write a blog post about AI,\" you should say, \"write a 1500word blog post about AI productivity tools for small business owners. Include specific examples, actionable tips, and a compelling introduction that hooks the reader.\" See the difference? All right. The second prompt gives the AI much more to work with. The result will be infinitely better. Another tip, use follow-up prompts to refine the output. Don't expect perfection on the first try. Ask for revisions. Request specific changes. Tell it to adjust the tone or style. Model is designed to work with you iteratively. I typically go through three to four rounds of refinement to get exactly what I want. And because Magistral is so fast, this entire process takes just a few minutes. A lot. Here's something else that's incredible about this model. It can handle multiple tasks simultaneously. You can ask it to write copy while also asking for SEO optimization suggestions. or you can have it create content while also doing competitive analysis. Most other models struggle with this kind of multitasking. They either get confused or produce lower quality results. Magistral handles it like a pro. This opens up entirely new workflows. Instead of using multiple tools or models for different tasks, you can do everything in one place. That's not just convenient. That's a massive timesaver. And time is money in business. Every minute you save on content creation, coding, research, or analysis is a minute you can spend on growing your business, acquiring customers, or developing new products. Speaking of growing your business, let me tell you about some of the advanced techniques we're using inside the AI profit boardroom. This is our exclusive community of entrepreneurs who are using AI to scale their businesses. We currently have 1,000 members who are sharing strategies, case studies, and results. These aren't just theories. These are real businesses getting real results with AI automation. One member just shared how he automated his entire email marketing sequence using Magistro. He's now getting 40% higher open rates and 25% more sales without doing any additional work. Another member used it to create a complete social media strategy for 6 months in advance. Content calendars, post copy, hashtag strategies, engagement tactics, everything automated. The results speak for themselves. Members are saving hundreds of hours per month while actually improving their results. That's the power of using AI correctly. But here's what really excites me about Magistr. It's not just about saving time or cutting costs. It's about unlocking new possibilities. Things that were impossible before are now easy. Want to create personalized content for thousands of customers? Magistr can do it. Want to analyze competitor strategies across multiple markets? No problem. Want to develop new product ideas based on market trends? He's got you covered. This level of capability was only available to big corporations with massive budgets. Now any entrepreneur can access it for free. That's democratization of AI at its finest. And this is just the beginning. As more businesses start using AI effectively, the competitive landscape is going to change dramatically. Companies that adapt will thrive. Those that don't will struggle to keep up. That's why I'm so passionate about teaching these strategies. I don't want you to be left behind. I want you to be ahead of the curve using these tools before your competitors even know they exist. The businesses that succeed in the next few years will be the ones that master AI integration. Not just using AI as a novelty, but building it into their core operations to create sustainable competitive advantages. Magistro gives you that opportunity right now for free. There's literally no barrier to entry except your willingness to learn and implement. Now, I know some of you might be thinking, \"This sounds too good to be true.\" What's the catch? I get it. In a world full of overhyped products and empty promises, healthy skepticism is smart. But here's the thing. There really isn't a catch. Mistra is a legitimate AI company backed by serious investors. They're not some fly by night operation. They're competing directly with OpenAI, Google Anthropic. Their business model is similar to others in the space. They offer free access to build a user base, then monetize through enterprise solutions and premium features. It's a proven strategy that benefits everyone. You get access to cutting edge AI for free. They get to refine their models based on real world usage. It's a win-win situation. The only catch is that you need to actually use it. The best AI model in the world won't help your business if it's just sitting there unused. You need to integrate it into your workflows, experiment with different applications, and continuously optimize your processes. That's where the AI Money Lab comes in. We don't just tell you about new AI tools. We show you exactly how to implement them in your business step by step use case by use case with real examples and templates you can copy. Julian Goldie reads every comment. So, make sure you comment below and let us know what you think about Magistro. Are you excited to try it? What's the first thing you want to use it for? inside the AI profit boardroom. It's the best place to scale your business, get more customers, and save hundreds of hours with AI automation. We currently have 1,000 members who are getting incredible results. You'll get access to live strategy sessions, implementation workshops, done for you templates, and a community of like-minded entrepreneurs who are all pushing the boundaries of what's possible with AI. If you're serious about using AI to transform your business, this is where you need to be. The link is in the comments and description below. Also, if you want personalized help with your specific situation, I'm offering free SEO strategy sessions where we'll analyze your business and show you exactly how to use AI to get more traffic, leads, and sales. The link to book your session is also in the comments and description. Thanks for watching, and I'll see you in the next update where I'll be covering the latest AI developments that can transform your business. Make sure to subscribe so you don't miss anything. And remember to check out the AI money lab and the AI profit boardroom.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Magestro Pequeno (gratuito) e Magestro Médio (empresa) da Mistral, com raciocínio passo a passo, desempenho competitivo, codificação e suporte multilíngue, tudo acessível gratuitamente via Lashhat.",
            "resumo": "Neste vídeo, o apresentador detalha as novas versões Magestro Small (gratuito/open source) e Magestro Medium (enterprise) dos modelos de IA da Mistral, com foco em raciocínio passo a passo. Ele apresenta benchmarks (AMA24/AMA25; AE24/ME25) que mostram Magestro superando muitos modelos pagos, destacando a velocidade de até 10x mais rápida e recursos para codificação, automação e suporte multilíngue. O acesso é via chat.mmistral.ai, sem necessidade de cartão de crédito, com Lashhat como interface de chat para uso gratuito; Magestro Small já atende à maioria das tarefas. O vídeo enfatiza a importância de prompts bem estruturados e menciona o AI Money Lab, que oferece 100 use cases, mais de 20 mil membros e tutoriais diários. Casos de uso incluem criação de conteúdo, desenvolvimento de código, automação, atendimento ao cliente, pesquisa e localização. Conclui que negócios podem escalar com essas ferramentas mantendo o acesso básico gratuito, com melhorias contínuas pela Mistral.",
            "assunto_principal": "Novas versões Magestro/Magistro da Mistral AI: gratuitas, de alto desempenho, com foco em raciocínio, codificação e uso empresarial.",
            "palavras_chave": [
              "Mistral",
              "Magestro Pequeno",
              "Magestro Médio",
              "Magistro",
              "Raciocínio",
              "Código Aberto",
              "Gratuito",
              "Referenciais AMA24",
              "Referenciais AMA25",
              "AE24",
              "ME25",
              "Lashhat",
              "chat.mistral.ai",
              "Instruções",
              "Codificação",
              "Automação",
              "Multilíngue",
              "Conteúdo",
              "Marketing",
              "AI Money Lab"
            ],
            "resumo_em_topicos": "## Visão geral\n- A Mistral lança Magestro Small (gratuito/código aberto) e Magestro Medium (enterprise), com foco em raciocínio passo a passo.\n- Apresenta Lashhat como interface para acesso gratuito.\n\n## Recursos e desempenho\n- Modelos de raciocínio que pensam passo a passo e competem com opções pagas.\n- Benchmarks citados: AMA24/AMA25, AE24/ME25 com números que destacam o desempenho superior.\n- Promessa de velocidade até 10x mais rápida e recurso de respostas rápidas (flash answers) em Leap.\n\n## Acesso e uso\n- Acesso via chat.mmistral.ai, sem cartão de crédito; Magestro Small suficiente para a maioria das tarefas.\n- Lashhat como interface de chat gratuita.\n\n## Casos de uso\n- Conteúdo (blog, redes, e-mails), codificação/automação, atendimento ao cliente, pesquisa/análise, tradução/localização.\n- Demonstrações de uso prático (planejamento de campanhas, melhoria de conversões).\n\n## Estratégia de prompts\n- Enfatiza a importância de prompts bem estruturados e fornecer contexto específico.\n- Menção ao AI Money Lab com 100 casos de uso e 20 mil membros para treinamento.\n\n## Treinamento e comunidade\n- AI Money Lab oferece tutoriais diários, notas e SOPs, com comunidade ativa para escalar negócios.\n\n## Considerações finais\n- Oportunidade de escalar negócios com custos gratuitos, atualizações contínuas pela Mistral e memória de contexto avançada, útil para projetos complexos.",
            "prompt_tokens": 1744,
            "completion_tokens": 4927,
            "model": "gpt-5-nano",
            "cost": 0.0083
          },
          "analysis_time": 114.71571707725525,
          "language": "",
          "view_count": 3328,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@KyserClark",
      "name": "@KyserClark",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "k_tJf1EuCf0",
          "title": "Por que reprovar em uma certificação não significa que você é um fracasso",
          "title_pt": "Por que reprovar em uma certificação não significa que você é um fracasso",
          "url": "https://www.youtube.com/watch?v=k_tJf1EuCf0",
          "published": "2025-09-22T12:32:12.903674",
          "published_relative": "há 1 dia",
          "duration": "09:08",
          "date_published": "2025-09-21T07:01:13-07:00",
          "transcript_available": true,
          "transcript": "Failure. Failure is something that's going to happen to you during your career. By the way, this is coming from an old newsletter that I wrote nine months ago. Okay? If you are not subscribed to my newsletter, go to kaiserclark.com/newsletter and you can get these insights well before I put them on a live stream. Well, before I put them in a YouTube video. And when I wrote that newsletter, I wrote it the day after I failed the OSWA. That's the offsec web assessor certification for the third time. So after I failed that certification for the third time and my mentality was this. Yeah, it sucks. It's awful. I mean I was I rate after failing that for the third time. I mean I I cannot I have never been that mad at something in my career ever before. I just thought I wasn't cut out to be a pentester because I'm over here doing pentesting for real worldwide applications, but I can't pass an OSWA certification. And I felt like a fraud. I felt like an impostor. It sucked. But then after I got through that initial stuff, I'm like, \"No, I'm not going to let this beat me.\" Cuz it can only beat you if you give up. Failure isn't even failure until you quit. If you quit, that's failure. The real success happens after you decide that you're going to push past the failure. And a good analogy that I always like to say is this. Tom Brady, greatest football player of all time. Love him or hate him, you gotta respect him. Seventime Super Bowl champion. That man has more Super Bowl rings than anybody. He's got the best stats for his position at the quarterback position. Considered the greatest of all time by many, if not all. And that man, even though he won seven Super Bowls, he lost three of them. So, seven wins in the Super Bowl, three losses in the Super Bowl. Furthermore, the guy played for like 21 seasons, maybe maybe a little more than that. I'm thinking 21. So, he was only in the Super Bowl for less than half the seasons he played in. Every year wasn't a success for him, but he came back year after year, and that's how he was able to have a very successful career. Same thing, Michael Jordan, he won six championships. I don't know how many years he played in the NBA, but he didn't win the NBA finals every year of his career. And for those of you who are gamers and not sports fans, you might understand this analogy. I used to be a huge gamer. I still am a gamer at heart, although I had to cut it back to really focus on my cyber security career. Imagine you're playing a video game and you just quit after you died one time. How many video games would you actually finish? Think about it. If you just quit after your first death, if you quit after your second, third, or fourth death, how many video games would you finish if you actually quit within the first five deaths? Not many. I I play a lot of video games. I die a lot, guys. It It's part of the process, part of the game. And cyber security is no different. When you go after certifications, you're going to fail. You're going to pass a lot if you really put in the time and effort and energy, but you're also going to come across failures. I have passed 18 certification exams, but I have also failed seven certification exams. And every failure sucks. But every time I failed, I tell myself, I'll get in next time. And that's the mentality you have to take when you fail. Let's say you're applying for a job. You're going to get rejected, guys. I have been rejected over 100 times when I was coming out of the military. A lot of people didn't think I had what it took to transition out of the military and be a successful pentester in the civilian world because it's a whole different world. Military world, civilian world, two different types of worlds, completely different. And I had a challenge. It was a huge hurdle to overcome. A lot of a lot of employers didn't believe in me. That was a huge hurdle. Got rejected over 100 times. Finally got a job that uh that I really enjoy. But if I would have just quit like, oh, you know what? Maybe pentester is not for me. Maybe I should just stay in the military. Maybe I should go into a sock analyst role. I thought about that. I I literally thought like, oh, I might have I might have to go into a sock analyst role. But I was like, no, screw that. I want to be a pentester and I'm going to be a pentester. I want to do whatever it takes to get there. And that's the mentality I took. I didn't want to be a sock analyst. I did not want to be a sock analyst. And then I would have applied as many times I needed to do as many interviews as I needed to re revised my resume as many times I needed to to land a full-time pet testing position. And that's the mentality you have to take. You're going to get rejected. You're going to fail your certifications. You're also going to run into other hurdles. Life happens, guys, right? You can be grinding out your certification studies or doing your labs and you could break your arm. What's going to pause your momentum? You could lose a loved one. You could your pet could die. My pet died on July 4th. my my old cat. It was It sucks. It sucks. And it stopped all my momentum. One of the saddest things I had to experience. You got to keep going, right? It's okay to grief. It's okay to like take a time out, but you can't let it stop your progress in the long run. That's going to happen to you during your journey. Hurdles, road bumps, flat tires, failure, it's all going to happen on your journey. What do you do after your failure? So, yes, like I said, you have to take that mentality and be like, I'll get it next time or we're going to get back on track no matter what. And you can't let it eat you up and you can't let it beat you down because if you do, it will. It absolutely will. And you can't fall in that trap. Also, understand this. If you fail, you're actually ahead of many, many, many, many other people because a lot of people don't even try. A lot of people don't even try. And those people are the real failures because they're not out there trying it. You you're trying it. If you fail, congratulations. You're ahead of 90% of people out there. I saw a quote one time saying that the best network engineers failed their CCNA on the first time. Now, I'm not a network engineer, but I did fail the CCNA the first time. I failed it by I think one and a half%. Like, it was very close. like I almost passed it and it was the first time I ever failed a certification exam. First time I failed any kind of exam um outside of high school. I failed plenty of exams in high school cuz I just didn't care about high school. But that's beside the point. Actually, that's a good thing to talk about. You know, people look at me like, \"Oh, he's got all these degree. He's got two degrees. He's got all these certifications. He must have been really good in school.\" Guys, I had a 2.0 GPA in school. I did not like school. I hated it. I did not pay attention. I was not a good student. I didn't read anything. I didn't read in school. Like they like, \"Hey, read this book.\" I'm like, \"I'm not reading that book.\" So, and I I'm an avid reader now. So, just because you wasn't into like being studious in your early years doesn't mean you can't be studious now. And I'm a prime example of that. So, yeah, I didn't pass the CCNA on my first try, guys. first exam, certification exam that I failed and it sucked and I passed it on my second try. But the reason why I passed it on my second try is because I went through an entirely different course and I read a whole different book to pass it. And going through the course material again made me understand networking so much more. And then going to my OSWA failures after I failed OSWA three times, I went and got the TCM security PWPA certification. I was like, there's got to be something I'm missing here. There's a technique that I don't understand. Let me do some other training from a different provider and see if I can make it click. And the funny thing is, I failed the PWPA the first time, too. And that made me feel like a big fraud, a huge one. but ended up passing OSWA shortly after the PWA failure and then I passed the PWPA like a day or two after I passed OSWA because the skills are like they go hand in hand. They're very similar certifications. So, it was uh a lot of overlap there. So, I was able to knock them out in a very short amount of time because I failed OSWA three times. I went back and got the TCM security PWPA, more training, fine fine-tune my skills, more practice, more reps, and that's what it takes to be successful in anything. And if you fail, honestly, it's just an indicator that you might not have done enough reps. That's really all it means. You probably just didn't do enough reps. You might understand a lot of it. You're just there. You're you might just need one more thing. And it's frustrating, but you have to understand that's part of the process. And that's what everybody who wants to succeed in this field has to go through in any field for that matter. And it's a necessary part of the journey. Everybody thinks the biggest wins are the trophy or the money or the house or the lifestyle. That's not the biggest win, bro. The biggest win is that time where you almost quit but didn't. [Music]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Falhar em certificações é comum; o segredo é não desistir, aprender com o erro e continuar tentando até alcançar o sucesso.",
            "resumo": "Este vídeo aborda como falhas em certificações não definem o valor profissional. O autor relembra a falha da OSWA pela terceira vez, destaca a sensação de fraude e mostra que a derrota só é real se houver desistência. Utiliza analogias com Tom Brady e Michael Jordan para enfatizar que o sucesso vem da consistência ao longo do tempo, não de vitórias em todas as tentativas. Compartilha experiências práticas: já passou em 18 certificações e falhou 7, buscando sempre adaptar métodos e explorar treinamentos de outros fornecedores. Relata também rejeições no mercado de trabalho e obstáculos pessoais, como a perda de um pet, mantendo o foco e a motivação. A mensagem final é que quem tenta tem vantagem sobre quem nem tenta, então persista e evolua.",
            "assunto_principal": "Resiliência e perseverança diante de falhas em certificações de cibersegurança",
            "palavras_chave": [
              "falhas em certificações",
              "perspectiva de carreira",
              "resiliência",
              "perseverança",
              "aprendizado com falhas",
              "OSWA",
              "certificações",
              "rejeições no mercado de trabalho",
              "evolução profissional",
              "motivação"
            ],
            "resumo_em_topicos": "- Falhar faz parte da carreira; não desistir é essencial.\n- A falha repetida na OSWA gerou sensação de fraude, mas não define o profissional.\n- Persistência vence: o sucesso é construção contínua ao longo do tempo, não vitória em todas as tentativas.\n- Analogia com atletas de elite (Tom Brady, Michael Jordan) para ilustrar a importância de jogar a longo prazo.\n- Em termos práticos, são 18 certificações aprovadas, 7 reprovadas, com ajustes de estudo e busca por novas abordagens (treinamentos de outros fornecedores).\n- Rejeições no mercado de trabalho e desafios pessoais, como a perda de um pet, são obstáculos que não devem parar o progresso.\n- Dicas: quando falhar, tente novamente; revise materiais e explore treinos de outros fornecedores (ex.: PWPA da TCM Security) para entender o que falta.\n- Mensagem final: persista, adapte-se e avance.",
            "prompt_tokens": 1981,
            "completion_tokens": 2975,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 67.77885293960571,
          "language": "",
          "view_count": 193,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@LatentSpacePod",
      "name": "@LatentSpacePod",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@LiamOttley",
      "name": "@LiamOttley",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "jhVg-Zbz0V8",
          "title": "3 AI Agent Use Cases Every Business Will Pay For ($100K Playbook)",
          "title_pt": "3 Casos de Uso de Agentes de IA pelos quais toda empresa pagará (Guia de US$100 mil)",
          "url": "https://www.youtube.com/watch?v=jhVg-Zbz0V8",
          "published": "2025-09-22T12:33:49.933995",
          "published_relative": "há 1 dia",
          "duration": "49:30",
          "date_published": "2025-09-22T01:39:47-07:00",
          "transcript_available": true,
          "transcript": "What if you could quit your job and build a $100,000 a year AI business by just focusing on three core offers? No guessing, no shiny object syndrome, just a proven blueprint of what to sell and who to sell it to. In this video, we're going to be breaking down the exact three agents he's selling, the painful business problems they solve, and how you can start building and selling them yourself. So, let's get started. Evan, mate, how's it going? I'm uh looking forward to jumping in and hearing about these three agents you've been uh you've been telling me so much about. Thank you for bringing me on. So Edin's been deep in the in the trenches of working on. I think it's an interesting uh topic to discuss really is the difference between these fully conversational agents that you build uh where it's sort of a system prompt and you're doing high level programming via prompting versus being a lot more granular and having much more control. And I think you guys are going to be very interested to hear about how uh using voice flow you can sort of combine these this the granularity of something like voice flow with the uh sort of free free form and sort of more uh agent style of of building building chatbots and and AI systems um into some of the most powerful and valuable things that businesses really really need right now. I think this is going to be a very refreshing angle to hear how um you can position these in like I suppose it's it's trying to sell a a website chatbot that does something very basic is of course going to be people trying to sell the tech. They're trying to sell the thing for so long and there wasn't necessarily a big business outcome while you might convert like a few% of your traffic to warm leads. Um but in this case everyone's found basically the agents that sit right on top of valuable business business problems and how to deliver on that across these three different categories. So keen to get into it, Matt. So these are just more than just you know chat box that you put on the website and I'm going to break it down why right so the first agent um is what I call CX agent. CX stands for customer experience agent. So it handles a lot of use cases where there are high volume conversations between the business and the customers themselves and it's trying really to smoothen that entire journey to really push the sales to a close in the end. Right? by ensuring that it's actually providing a lot of personalization by making sure that we actually care about the customers and making the brand's voice really consistent throughout these communications with the customers. Right? That's the first agent. And the second agent is the or I call it revenue recovery agent, but other people might call it differently. All it really does is it saves customers who disappear purchase. So if they're in the middle of a sales cycle, it will basically people who disappear or they just go to the business, it would try to save that. which basically catches up on customer who's you know about to leave but like hey this is the brother that don't leave yet and it's trying to bring back some of the leads that who have already left who have already ghost who went silent right who's kind of been dormant and you're trying to revive them essentially in a way and the last agent is the commerce agent and from the name itself it's quite specific to a use case right like for example retail and all it really does is helps customers find what they want and guide them through the entire purchase cycle and to process those pavements instant. So these are the three agents that I I found that has the most success to the market right now. And what sort of ticket size you think you've got on there? Uh the value of each. What sort of range are you selling these things for at the moment? I know there's a lot of variation in terms of scope, but what's the ranges people can expect to sell these kind of things for? So from experience, so a customer experience agent can have something I've circled them between something like 7,000 to 20,000 figures. And for revenue recovery agent, usually we market them around 10K. And for the commerce agent, again, it really depends on the scope. For simpler cases, we sold them for $5,000. For a slightly more complicated use cases, then we sold them for around like 20 to 30K essentially. So, Edwin's been kind enough to reveal his whole hand here and show us exactly uh how he's selling these things and why they're built on such painful business problems. So, um you guys strap in cuz you're going to be breaking down the even the tech stack that he's used to put these together as well. So, let's start with the customer experience agent, right? One thing I want to really clarify in the beginning is that this is not customer support because I've seen so many like tutorials or like creatives like talking about customer support, right? It's a big use case. But there's a difference. Customer support is being reactive. It's when things have gone wrong. When the customers want to, you know, they they need help with something or they just have something to complain or they want to troubleshoot something, right? Whereas customer experience agent is being proactive. is trying really hard to really keep the customers within the customer journey without them basically just leaving halfway through. It's actually that's the major like use case. If you literally imagine a business, let's say a pet grooming company, right? This is actually based on a real case study which I will dive a little bit more in details as well. But for now, just imagine there's a person called Sarah in that example and she has a dog called Bobby, right? And let's say she wants to arrange the dog for a dog grooming company. What Ruby does is basically they have a company that drive vans around the country and they try to basically try to clean and wash out the dog essentially and let's say she's a member of that company and she wants to book an appointment for Bobby right so she sent a text message through SMS to the company I want to book a another session for Bobby now the problem is they are quite a small team so they basically are member a team of five to six members and one of them is on the phone all day dealing with conversations s were basically 100 plus different members at the same time with basically the same questions. Now, we're all human, right? Like we work like 8 hours a day. There's only so many conversations you can have before you basically just you know what it's too much for me, right? And this is exactly what's happening with one of my clients which is a packing company. It's like okay I just it's way too much information like too way too many conversations to handle and a lot of the time they found that the response quality actually drop and they actually can just do something like oh just fill in this form right and there waiting time it's not great like the experience is just not great that was kind of the picture now imagine you have another agent that can basically personalize the conversations to a point now when Sarah test texted the company I want to book another session for Bobby it will say hi Sarah How's Bobby doing with his anxiety? Right? Because the assumption is that sometimes with some with some of the BS, they usually have some sort of anxiety issues or they have some sort of sensitive areas that basically needs to be a bit more careful with during cleaning. So, it will say that if there's an issue, right, it will say, \"Hey, how's doing with this anxiety?\" I can see from his last session really well. This is so interesting that you've gone like I mean the platforms don't really offer this stuff right now. Like I think HubSpot's been trying to do it saying that oh you can have full context of the past interactions with your customers but seeing this actually implemented on a small business scale is uh is is very very interesting about how you can have these kind of persistent persistent memory across different conversations um with the same customer. Yeah, exactly. And that's actually what customers want, right? Remember the business is a premium brand. So like you don't want to have a feeling of like just oh you're just another number, right? You're just number one out of like 100 customers, right? We want them to feel valued and that's where to make to make them feel valuable is by remembering little things like the anxiety or like oh would you like to book his usual food grooming for next Tuesday morning right that's being attentively saying hey my my my customers actually boo like his bad for for grooming every Tuesday it will remember that that's where the customer a good customer experience should have so maybe I can generalize that a little bit um into maybe like what kind of businesses with womb. Yeah. Basically small B2C's company like business to c consumers company that's kind of drowning in customer communications right usually again they usually have a small team that's handling a huge volume of conversations and they usually have their service businesses that have very very strict like brand voice requests. Again the reason why is because they want to be premium. That is why as an example for this pet company they have very strict language guide. As an example, we literally have like a 20 page like voice system which you can actually I have shown kind of examples of it in the guide but just to give it a snapshot of it. There are few keywords that the agent should be able to say for example instead of customer client you should say member instead of owner you should say pet like this level of detail is what is what really business is looking for to keep that premium feeling and keep that good customer experience. And the the problem is that chatbots are give us such a bad vibe of doing that. Like it give off such bad like vibe where it just keeps on saying like the same stuff over and over and over again. It's it feels really cheap. It feels really general. Right? So that's the challenge. How can we automate that experience? Right? That's the use voice for this. And maybe I can show a walk down a little bit how we kind of break down that um tech tech architecture. I think um you have some you have some data up there on uh on the CX use case. I think this is just a really really interesting thing. This is like the main takeaway um for this section guys is that uh improving the customer experience is one of the most like validated ways that AI is is providing an ROI or making a meaningful difference in the business. And I think this is a huge huge takeaway for you guys. We need to be using AI in areas that are natural to it and help you know you're not you're not forcing a fish to climb a tree kind of thing, right? And I think sometimes people try to get AI to do these crazy tasks that uh it's not really that well suited for and in this case the improved customer experience is showing in the data that this is where it's really providing a meaningful difference to businesses and it's like the fast response times it's more personalized messages it's better availability and these sort of external or like customerf facing systems um that takes takes it beyond just that customer support to being uh proactive I think is a really important thing for you guys to look at uh when you're coming to maybe niching down your agency or or or working with these kind of systems like you are Edin. So really really interesting to me that uh these I mean these are going to be everywhere in a few years right always so interesting for me to see as you guys will see in a little bit how Edwin's built these but when you notice that there's some major thing like this okay well in a few years every business is going to have this but right now a guy like Edwin is having to use voice flow and air table and and like cobble together all this stuff it shows that we're still so freaking early in this that there's not a centralized way of doing this by the way this I think this came out like maybe last week or last two weeks I can't remember exactly but this came came up very recently and I didn't obviously I didn't know about this beforehand but like a lot of the report by the way I recommend actually having a read on the report and yeah basically this basically confirms a lot of what I kind of experienced in the market right so as as you can see the top gen AI impacts across business area the second use case customer experience this is just behind productivity how crazy is that right far ahead of marketing which is what what you'd think yeah you'd think that would be like that's what everyone's trying to use it for Yeah. Yeah. But like actually there's like these three at the top. Yeah, for sure. Um maybe now I can break it down how we think about building this kind of system a little bit. This is the overall architecture. So we have the incoming message. Let's say hey just want to know where my dog's next appointment is. All these conversations are through SMS and we they use the client use over which is basically a Twilio variant and it passes through the message passes through to voice flow and voice flow acts as the braid. Now what I mean by that is two things. The first thing is persona. So basically giving the LM an identity. So you might know you might notice from prompting we always say something called identity prompting right? You are a uh customer experience agent right? But we take that a step further. We give them a name, a backstory, what it's trying to do, how many years of experience it has, right? And try to just be as specific as possible. Try to make it as almost like a character essentially. And yeah, implementing the brand voice within the persona. So that's that doc that you mentioned before, right? Yeah. Exactly. Exactly. Right. And we have the conversational flow. We have a flow for new member which are the new customers and we have the existing member which are the majority of the use cases. And most of the intents of the conversations usually have two things. It's like general questions or appointments, right? And the way that we can actually have that personalization is have all the customers and pub profile data saved in a database called Zeno. Now Zeno um is a database like to store all this like pub and customer data. And the way we do that is we retrieve that entire like information about the customers. their name, the email, this is the basic stuff, the address, but the more important stuff I guess is the dogs themselves like the when's their birthday. Like we literally have systems like if it's your birthday, say happy birthday to the dog, right? Yeah. To for example. So like and we have like the sensitive areas is like okay the sensitive areas I said before is like the face muscle. So we the agent should be able to take all of that information and draft a personalized response to the user. That's what we meant by personalization, right? That's awesome, man. Yeah. And um and for the questions because I know another thing is the customers have a lot of question answer pairs. So for example they have a set of predefined questions and they have a set of brand aligned answers that they want the agent to copy exactly as like a template essentially for the LM to generate a response. So the way that we do that is rather than like using a knowledge base right which if you know how rag works is like basically how to retrieve things semantically we actually wanted to retrieve this exact phrase like 100% of the time how we do that is we basically have each questions we give them a question ID right and based on the question ID like we semantically search for the question ID and then it search goes through the air table retrieve based on the question ID retrieve the questions and the answers and all relevant information like instructions etc. So it gets a little bit more complicated than that. But then the core idea is it pulls back all the information back to voice flow which basically has is this super brain that has all the information that he needs to generate response. I'm going to I'm going to call you on that on uh technicality here. Do you think it's necessary to have a retrieval system for a relatively small set of question answers there? Could you just stuff like the the tokens are cheap nowadays? There's a there's a huge amount of content you can fit in. So, where do you draw the line of like going to the rag system? Because there's a question of like is rag dead because of these massive models that are so cheap now. Um, is it is it a latency thing that you're trying to solve for? Like what is what is the difference here? I just think that there's a misconception that rag means factor search which is not true like maybe maybe our mind of the dummies needs to have that explained like what what do you mean? It's basically um it's rag retrieval retrieval augmented generation. Yeah, I guess it doesn't it doesn't have anything specific to a vector store, right? It's retrieval augmented. It's like context engineering is I think the buzz word they call it these days, right? Yeah, exactly. Like what what vector search like rack initially like basically to give you some context where the vector search comes from is when rag was becoming a thing a lot of basically a lot of the big vector stores company like pine cone um chor etc right they really try to push that product out and suddenly like everyone is like talking about vector it's like oh semantic search is the best thing right it's like these are things that are semantically similar to each other it means the retrieve accuracy is bad must be better but that's not necessarily the case what we're really trying to solve is like a search problem. It's like basically matching keywords, just searching for the on the user. Yeah, like cool the answer, right? So, yeah. So, rack is not necessarily just like back to search. And two, where do I draw the light? Well, because we're trying to build something like that's actually scalable, right? So, right now it has over I think 100 different questions. Okay. I was thinking you just had like a little 20 20 Q&A on on this though. That's obviously a lot of work for the client to do. So like I get if they've got a quick F FAQ on their site like how do you how have you found this when you're asking them hey we need now we need a 100 question and answer pairs from you um do they push back on that at all? Do you have an AI solution to it where they can just like upload their upload their knowledge what would have been the knowledge base and then you're converting that with a with a basic automation to convert it to like a com CSV file that you can imple import into here. You know what the good thing is I'm very lucky they already have that set up in a Google sheets. Okay. Okay. I guess that's for the existing support team, right? You can just probably find the existing support docs if they've got a support team, which you'd hope they do. Exactly. Because But what they literally do, they literally just go to the question. Okay. The guy basically the person who's texting the customers. Okay, this is the answer. Okay, I need to copy these answers. Okay, so you've just you've just automated their existing support process here, which is uh which is great. I think uh SMS is a channel. Um it's always it's always been an issue of what's the interface. It's like, how do you have these fully integrated end to end like customer experience things? Um, it's not like you're going to, hey, download our like dog grooming app. Like, you don't really want to force people to do that. Um, what you're going to send them to a website, then they're on the browser on their phone and they're going through this interaction. It needs to be either like through voice or it needs to be through SMS or WhatsApp. And those are really the best entry points people have. But then obviously SMS is sometimes like much more a US-based thing. WhatsApp's probably a bit more common for the rest of the world. Um, so it's it's interesting that you've I mean I think that these channels are are are essential if you can have these sort of fully contextualized conversations across these channels. It's it's really really powerful businesses and they're all going to have it soon. Yeah. And I think the key thing is we want the least again we're back to the customer journey like customer experience side right like the way that you want them to build them is like what's the least resistant path for the customers right as you said I don't want to go to the website I don't want to into another app like SMS just feels natural as well as WhatsApp right yeah I mean if you could just make phenomenal SMS experiences that are like this for businesses like you are on some built right over a gold mine yeah for sure um if you just want to show just that uh quick glance at that voice flow thing there. Um people can pause if they want. You guys have access to this board if you want to uh have a have a cruise around. Um but that's an example of what it looks like when you're setting these up on voice flow. Obviously a lot more uh logic based. Um but I assume there's there's aic parts within that. We can we can jump onto the next one to keep this moving. Another example for you guys is um another case that I have is for two way like basically this this link with the board will be in the description so you guys can actually see for yourself if you want essentially this is a more customcoded solutions like using Python um Bangraph and Pantic AI which is more customcoded frameworks and it's just another kind of a more advanced example of what you can actually push in terms of building these conversational systems and the second agent really want to talk about is the revenue I call it revenue recovery agent right like before I kind of jump into like all the techn technicalities. Let me just try to again I use Sarah again as another example and this is a very cool use case is because this company is quite unique in what it does. is an education consulting company and what they do is there are many students who want to study abroad in the UK right and they don't really have an idea of okay what schools do should I go to now the use case is when the students go to do these kind of consultations and also do the admission test that data being saved somewhere in the database but a lot of the times the CEO found that none of them actually got back to them like they took their stuff they took all the good stuff and then they just don't want to proceed like it's like oh I'm not too actually too serious about studying in the UK or like I've gone to another competitor who's cheaper whatever right whatever reason and they're just okay so what they're they're doing an admission test submitting it to them or they they're getting sent the resources and then they have to do it on their end like what would they why would they come back to is like at the end of that admission or consultation like hey let us know within let us know soon if you want to move forward is that kind of they just get left on that yeah so it's actually an inerson test that you have to do so like okay yeah so it's like an internal thing within the com within the education company where based on the schools of the test they can kind of see where the level they are at and they can recommend right schools for them to go to essentially gota and yeah a lot of the students take test and they never apply now one thing I need to kind of get out is like kind of the architecture right now is kind of not very systematic in the sense that there's a lot of students almost like 300 students to handle for each consultant which is a lot now 300 including students who hasn't got back to them like all the different cases right it's a lot and it's a nightmare And they don't simply they don't have the time to follow up and they don't have the organization to follow up on those students, right? And what we what we come ahead and said, hey, what if there is some sort of followup in terms of agents that can just automatically send them a WhatsApp message that can do some sort of follow up. For example, if they don't respond after 3 weeks, you can send them a WhatsApp message. Bases basically saying, \"Hey Sarah, from the taste test that you got, you got 90% maths and 67% English, right? Here's a full breakdown of your performance and the suggested improvements, right? This how we think that you can improve. Let me know if you have any questions, right? Something like that just to give some value like basically some sort of like um automations that based on these test results and then if they still don't respond, you basically have another follow-up sequence which is basically saying, \"Oh, hey Sarah, would we love to connect you with Tim, which is another student who has the same scores as you do, right?\" He double down in pro improving English with and ends up being in Harrow, which is a if you didn't know, he's a top UK. So, so this actually gives them incentive to reach back to us and like try to finish the customer journey. Again, you know how I'm dividing kind of these these all these three agents, but they're all linked together, which I'm going to talk a little bit in the end. Yeah. I mean, just just looking at that there as well, the um don't underestimate how like if someone sends you a message like that that sounds like they've taken the time to write it to you, in this case, you personalize it based off the test results and you maybe signed it like thanks from like Jane or something or like Tim at the bottom. And then you follow up with that one again, which again is very specific, like, hey, it looks like you had a weak thing when it comes to English. I can connect you with this. Like it's a pretty good offer, an interesting thing. And again, it sounds like it's coming from a real person. When you have messages like that, like there's a you can kind of play on human nature and what how we've been programmed after so many years is that ignoring people like that, we don't really like it. Like we feel like a bad person for ignoring someone who's taken the time. So there's a a like a reciprocity thing, especially when they've gone out of their way to connect you with something uh with someone like in that second message you have. Um, so I think when this sounds like the illusion of it being a real person and through a very personal channel like WhatsApp, I don't think many people are really going to be just flat out ignoring a very personalized and a message that comes from seemingly a human account. Um, so I'd say this is extremely effective um at at re-engaging these people. Yeah. And it's really getting the attention of the students as well, right? Or the parents in this case. It's actually a lot of the time actually parents because they're quite young relatively and the parents like really you know like the parents are really like serious about their scores right they want to know how to do right so that's another thing good for them it's like what we learn is that this is really effective for businesses with kind of a kind of a complex customer journey and they have a kind of a high drop off it during a customer journey and usually that can involve businesses with you know kind of sales processes that have kind of a lot of different steps um that can not just educational services right maybe some high ticket purchases that kind of needs them time to think about, right? And the the highest ticket items they are like the people are going to take more time to consider it and you need to send more follow-ups on them, right? And filling in those gaps in the sales process for sure. Yeah, those time gaps and sometimes you just have leads sitting in CRM. It happens to the guy like they're literally people like their data like leads in the database that just sitting there. No one has like all the following up with them. It's just such a wasted opportunity as well. and and they might have spent money on ads to get those leads. you know, it's like they literally sitting like $50 $100 in the hole per lead and it's just sitting there doing nothing or you like they've come off off ads and then like they've fallen through the cracks and they don't even have a system in the on the front end like in the near term if they fall through um what to do with them like like how you can solve with this and I think the biggest pro the bigger problem is for this for this specific case study is like not having a very organized way of managing those leads which is where CRM comes from we actually introduced into CRM So that's like that's actually like a bonus I guess. I would say like for this specific use case like around 70 to 75% actually drop off like after test as I mentioned and there was no lead tracking and everything. So that's why we're like okay can we do some sort of automation around follow-ups and the reactivation sequence so the students just don't just ghost you like right and that's where we kind of think about setting this solution combining high level which is a high level which is a common CRM and voice flow. So maybe I can break it down a little bit again what it looks like. So on a on a high level no pun intended um it basically there were different opportunities. So if you have used high level before that basically that's how you manage different stages of the leads. As an example there's there's a pipeline we set up which is called as test. Well what that means is people who have taken the test but they've just kind of just ghosted like you guys. for example more than two weeks they haven't you haven't heard back from them and there are different stages like for example they have they have no valid WhatsApp numbers to begin with or you've message them no replies finished interested et goes it goes on but basically what this does is you're basically organizing the leads very systematically right across different stages and the beautiful thing about high level is that you can actually set up automation workflows inside them so essentially we have the students who you know who their flags were you more than two weeks that we haven't contacted and because in high level you can actually save information like this right is for example with custom fields you can have very specific information about students the department like education course IGC GCSE is like a UK like course so there's all these different information but basically again the key to personalization is details and data the more specific data you can collect from the leads the more kind of ammo you can use like to craft this personalized message right because you have more data both so this is where the dynamic personalization comes from comes from the custom fields of the CRM again pushes through the voice flow as the brain and the brain will send the first DM through WhatsApp now there's two cases if they reply cool right they probably like they're still interested or they're not interested and if they're not interested they want to be out like it's a compet it's basically competitive server I'm not going to name them, but then regardless if the results are good or not, like they're interested or not interested, they're going to push back to high level and say the results. If there's no replies after 24 hours, there's still no replies. Then we then set up like we basically go through the follow-up sequence, sending a second, third personalized message again through the audio. So, it's sort of jumping back and forth between a high level triggering voice flow and then waiting like you've got a a trigger or yeah, I guess a 24-hour trigger back back on high level again to kick off another another like round of personalization and stuff. So, yeah, I think this orchestration is where it gets trickiest. uh especially um when you have I don't know maybe they've been talking back and if it's conversational it's asking questions back and forth when is that conversation considered dead or like stale and it needs like when when is like okay now that's technically a conversation done we need to like re-engage them with you know it gets gets quite tricky when you have uh say like Instagram DMs is a is an interesting one when you have like maybe appointment setting going on in in DMs and within that thread it can get quite messy about like when does the agent think that that's a stop um when does the follow-up message go out. Um so it's interesting to to know how you're how you're managing that with voice flow across sessions. Yeah. So basically um the good thing about voice flow is that they have something called like session IDs. Yeah. Yeah. Yeah. Exactly. So there's a dialog manager API which you can call through the specific session. So each phone number is the session ID. Gotcha. So that's how you can uniquely identify each user and once you start like you use a basically within the within the voice flow dialog management API once you initiate a conversation it stays within that session. You don't have to again you just have to kind of do the back and forth back and forth conversation. Now where does it happen? Right? That's a that's a really good question and usually there are like people usually there three types which are really serious like they just say oh sorry I haven't got back to you. That's that one thing right or one thing is like oh sorry I just it just you know my students are just not ready yet for the studying UK which is very common reason. Second reason is I've gone to like I've gone to someone else, right? And these are just like hard though. They're just like and then we will just end up wrap up the conversation be like no problem like let us know if we can like help you anything help you in the future, right? That's it. But there are sometimes conversations where like yeah I just need more time to think about it right now. There's two like situation where we do is that we actually flag it to one of the consultant if that's the case and we actually have the consult to call them because this is the moment where like you should like the human should be doing the work now like this is like it's now or never they're going to be gone like it's like a it's like a sales issue now. It's like can you create urgency and can you push them over the edge and that that human in the loop aspect for these systems. I know that's probably the two two issues. It's like how are you orchestrating it and making sure that like the the the sessions and threads are not kind of overlapping or there's issues with um like not being contextualized about what just happened and then it's like okay how do I handle the the human handoff when it needs to be done and that's always tricky because there's the back end right like I guess you're going in through the high level kind of conversation manager to be able to jump in this so if a human does need to jump in they're jumping in on high level yeah so within high level you can actually like have a custom view where you can assign which like human like for example you can assign bot which is voice flow in this case um but you can actually change the change the assenee to one of the consultants right and because we again from the custom fields you already know which assigne originally assigned because at the beginning of all consultation each student would have been assigned a consultant so it would just change back the assenee to the original consultant that was yeah sweet all right that's um that's the what revenue recovery agent Yep. That's okay. What's the What's the last one we got here? The last one is commerce agent. Sweet. Let's jump in. Okay. So, let's talk about commerce agent now. Actually, like commerce agent by definition is going to be kind of heavy retail heavy, right? And just from the report that we're getting from Google, it's actually like 50 getting like 51% like AI agent adoption rates, which is like crazy. It's like on top of financial services and media entertainment, which is kind of what you expect. Telecom. Yeah. and healthcare is actually not that high because you know with like compliance and stuff as well and you want manufacturing manufacturing and automotive is an interesting one. Yeah, that's that is another thing to to look out for actually now that you mentioned um in public. Yeah. But the the key thing is like retail CGP is got quite a high like adoption rate which which is not surprising I guess because the use case is there right and maybe I can break it down like kind of what I'm seeing from my angle. So again, if you imagine like we've got a restaurant chain which is like one of our clients, let's say they want to order from let's say McDonald's, right? They want to do some sort of like catering event, right? And if you know for catering like it's messy because like you got some sort of large budget, you got large amount of people that you need to manage and like within the catering menu like this is just a sample that I put together. It's like this is not the real thing of course but like you've got like all the different appetizers, you got like chicken, you got like all the different food types and it's messy because they come in different sizes as well for cater. So like you got like half trays, full trays, single wraps, like it's messy, right? And the problem is that when currently the person like call them up to try to do the catering order, it's like I have a budget of $500. I have 20 people I need to feed. I want some chicken salad. Two of them are vegans and I need to buy next Wednesday and then like I'm at this location. What should I do? And a lot of the people pick up the phone on the restaurant. They just make the food. Like they don't really like basically this is asking them to okay let me take the [ __ ] out. Let me actually do the maths in real time. Okay, $500 20 people like okay this is half a wrap feeds that many people and it cost that much. Like did they do the math? It's a nightmare basically and it's causing a lot of friction. And not to mention as well a lot of the people who pick up the phone at least in this specific restaurant chain their first language is not English. So it's or it already has a language barrier that's creating friction when people trying to do a catering order and catering order usually high like relatively higher ticket items within like the whole franchise right so this was a problem like this was a problem where like okay what can we do to eliminate that friction and that's where we have considered like basically developed an agent like because within the agent you can just give the same question and you will be able to recommend like let's say three three trays of wraps, two trays of rice, two trays of salad for this like kind of specific people, right? And here's the four closest restaurant to your location. Let me know which one you want to choose from, right? And within the force flow front, it looks a bit like this, right? Spoiler aling like the recommended package like the the wraps, like how many quantity, the price, right? and also the total price and the cost per person as well. So, okay. So, you've just you've just created a is this just a a literally a a fully contextualized prompt that has all the information about like what's on offer and the unit price for that or are you pulling in from a database somewhere for this stuff as well? So, a conversation really like it's again try to help customers to buy what they want and guide them through the purchase. Right? So, again it's the entire like transaction process and try to and that includes recommended products, right? We have two cases for use case for that. Whereas like for example there's like a you know uh basically a multi-location franchise right to recommend them the catering package. There's also like a retreat company trying to retreat like retreat packages essentially. So it's obviously completely different things but it's the core logic is more or less the same. It's still recommending these something. So when they've got like quite kind of custom orders that need to put together. I mean, you can do this for like my auntie has a framing business and I know this as like, hey, I have all these pictures that I need to have framed. Like, what do you think? It's like, oh, we could put you can either like put together a couple different packages and say in her case, you could use AI image generators off the back of it and like the the it kind of like you say kind of blends into that customer experience agent. when you're like really improving the customer experience, you're going to be instead of waiting for emails back and slow back and forth, you could create this great like commerce CX agent that's able to help them to identify like get proper packages pitched, they get real tight, like very quick responses on how much it's going to cost um as well. So yeah, there's huge use cases for those. Exactly. And actually one thing I want to add like I was going to mention a bit later but I actually want to add is that you can combine the right and and the use case would be loyalty. That's actually another thing that we I'm like we're currently having a discussion with client about like loyalty program loyalty program. So for example, if the right now there's no system that's kind of you know for a normal order at least no no one is tracking like okay this customer order this food that their favorite like food item is this um etc right that their order patterns like we're discussing internally like okay what if there's a use case where you can kind of map out like the ordering patterns what their favorite food is basically data about the customers and basically build an entire customer profile based on that essentially and yeah try to basically um recommend and package that way. That's another like for that's another thing that we're having. Yeah. Yeah. It's almost like driving sales with personalized offers. It all requires collecting that data um through I I've always said that I think these conversational uh channels um whether it's across Instagram Instagram DMs or whether it's WhatsApp like WhatsApp chat bots or whether it's um on the on your website. I think all of these are going to become when you're talking to what what you perceive as an AI chatbot on on a company's website, you're giving kind of raw unfiltered, you're not really thinking people are going to be digging into it too much, but um you start to get really good like intent signals, context on who they are, what they want. And that being like data data feeds into the business on one being able to aggregate it and see what the trends are and who the who their customers really are, but also on an individual level being able to like kind of weaponize that against them but and make much more personalized offers. And that's that's clearly the way things are going. So I think this is such a great thing for people getting into right now. Yeah, it's it's such a good use case and there's not a lot of traction right now on this. So maybe a good opportunity. So that's why I jump into it, right? So um yeah, maybe I can break down it will be now. Yeah, it'll be now. Um yeah, maybe I can break down kind of the text a little bit like this. Um so yeah, we no surprise we first look again and but this use case is basically an order capture conversation flow. So all the time we're just trying to collect information. Again, it's a it's more like a data capture exercise more than anything. So we have the budget for example, what can I get for $200, right? That's the one that's one thing. Customers information like I'm not going to go through this pretty basic, right? Name, email, and stuff like that. Yep. Anytime or the event, when is the catering event, the location because they need to know like because the franchise need to know which individual franchise should be like should be producing the food essentially. That's why I didn't even So the way that we do that is through an open cage um API. So what this does is you will capture the user address. Then you will call the open cage API. Now we already have in the back end all the possible franchise locations and their latitude and longitude. All we're doing here is basically kind of the closest um distance between um the users address which would translate to latl long and the individual locations lat. So you said this is just a a pure like coded function. Where where are you hosting? So you've got a program running somewhere. Are you like hosting this on your own own little server? Um what's what's the current like just Python script that's running in the background? Yeah, it's actually through superbase edge functions. Ah cool. Yeah. So um the client set up an account there. So we just built the functions on their end. And um it's basically fetching the four closest location, right? And then the users had the choice to like, okay, these are the four locations I think that's closest to you. Uh, which one do you want? And then they will be like, okay, maybe I like that one. And they have the freedom to to choose that one. Okay. And that's the location. Now the food recommendation is the kind of the hard spot. It's basically a a coded a complete like JavaScript coded solutions. Again, another superbase edge functions. So on a very very like high level, right? It's pretty much just saying okay I I basically collect all the data that I previously should have collected based on the budget the amount of people like the like basically is there any special dietary requirement etc and we actually within the code we have like basically a priorities into which we should prioritize like there's certain parameters that are optional right so like they might not always have dietary requirements right they maybe some most of the cases like okay I just want like I have a budget that's the amount of people go do the maths, right? And it then runs through the script and it just splits out like basically the um all the food options and the prices and basically just a recommendations like to the user. It's like this is totally like totally how much it's going to cost. Um this is the price and this is like what's the what's the food items look like. Now um this is again I think I said it already is basically another super base edge function essentially. So this is where the food recommendation comes in, right? And after after all that information, it's then being pushed to like a solo CRM which they're using, right? All the leads like are saved in there. Generally, they don't save leads on CRM because there's really no point if it's just like single orders for now. But like for these larger catering like orders, they're doing so. Now this this is still in development right now because they are still figuring out the kind of payment deposit collection kind of like this basically what we want to do the angle of this right now it's just saving everything in the CRM right the angle of this is to be able to essentially like for catering events you need to collect 50% of the right so it should be able to save this in the CRM and automatically triggers an automation that can send SMS with a dynamic payment link based on this order, right? And then you can set up follow-ups and you can, you know, once it's confirmed and it sends back and notifies people. Yeah, that's that's freaking awesome. I think being able to take handle this like end to end like the first touch like I I have like you'd know from the accelerator the solution sphere and how like on the ex like the outer layer you have these these these first people that like the interface between the business and the and the and the uh and the customers and that's where really where generative AI particularly these conversational agents can shine and you can handle everything from that very first uh touch all the way through to like the start of service delivery and ideally you can start to take that even further into service delivery and using conversational AI agents to walk them through that part, all the onboarding and things like that. So, yeah, this is this is awesome, man. I think everyone can take a take a lot away from this. So, I think to uh to wrap things up, I'll ask you some uh some more like sales questions for beginners who are looking to get into this, right? So, we've heard the whole you can't sell a chatbot for X because uh they don't they not don't seem valuable enough. What have have you shifted over to more of selling the selling the end result here and like the the 10 8 to 10% lift you saw in uh like revenue overall due to that reactivation. Um if you're recommending someone coming in wanting to sell these kinds of agents how are you getting your leads uh and how are you closing those? What what are you really positioning this as? And also the pricing because you're you're obviously getting these prices up very high. Um if we can just quickly run through those. So if anyone else basically as a beginner's guide if anyone wanted to get into selling these things you've obviously got the low code version and the more high like customcoded versions what's the what's the 0 to 10k for people looking to get in and sell these things. Yeah, I would say like begin you before you even sell anything, right? You need to actually like at least for me, I need to actually at least understand the tool enough that I know. It sounds they don't want to hear that when they don't they want the easy money. They want the shortcut, man. Like that's the wrong answer. But they keep it I mean I just had Mcklli on the other day and he's followed the same thing like the thing we teach in the accelerator which is like you if you have the time go through the fundamentals and learn the tool from the ground up. Pick one. He picked make.com got really good at it and built his whole business of agency off the back of it. You picked voice flow. I think there's a whole different discussion on the strategy around just picking one tool and getting good at it because as your story has shown if you guys have know won a uh a competition with uh voice flow and that helped them kind of get a bit of recognition and by picking there's a sneaky strat here I think by picking a a tool that's I mean obviously a huge one like Zappia is going to be a bit harder to get get noticed but there's tons and tons of different softwares in this sort of like early stage startup that have conversational AI or like automation capabilities And when the communities are so small around them, you can go in there, you can start making content on YouTube and you'll be the only guy or like one of a handful of people who specialize in that tool. You're going to get recognized by the by the team. You're going to be able to go in their Discord and their communities, get recognized, build up, but and suddenly you go up to being like an expert in this thing within a few months and as as in your case, they can start to send you leads. A lot of these companies when I talk to them, they're like, \"Yeah, we've got a ton of work. If you want to if you want us put us put you in touch with some of the people that are coming to us cuz they get not only small small businesses going to them and agencies, but also you get more like enterprise and bigger deals that float through across these companies plates and they just want to be able to hand those off to people to build their application or build their uh software into their company with. So, uh there's a lot there, but what would you give for the uh the uh the quick start guide here after you've learned the learned the tool of course?\" Yeah. After that then realistically you shouldn't be thinking about the solution. I know it sounds contradictory to what I just said like master two and not not think about solution. Yes. Because a lot of people when they're trying to sell AI or chatbots in general be like hey I've got this really cool chatbot that can capture all the leads. It can um has this functionality has voice like you you're attacking the wrong angle. Like they don't care like the businesses actually don't care about all the functions and the features of the chatbots, right? Then all they care about is does it actually solve the problem that they have. Do they even have a problem? And the thing is don't create problems, right? You just make them aware of a problem that one they might not be aware of, right? By just just in that case, you need to kind of explore with the business owner and two they're aware of. They're just not sure what the solution actually is, right? And that's where you come in and you try to actually understand their business, right? the entire like sales school when if you guys like go on the sales school shouldn't be talking about you shouldn't even mention AI at all realistic you should like you should be talking about okay what's what's your biggest problem right like why do you because for me right I'm getting most of the leads I get are from the content I make right it's through mostly through inbound leads right and a lot of the time they already have some sort of problem and I just talk to them 45 minutes about their problem like just be like okay and just go dig really deep into their problem be like okay what okay I'm uh for example I have way too many people like I don't have time to like answer the conversations right as an example right and you can be like okay well why is that and then they can just be like okay well it's maybe because like we only have like one or two people who are handling the conversations and you know um they don't and we don't have enough people it's not cost effective for us to yeah if you go why again then they'll say it's not cost effective right like and they will be like okay well then what's what's kind of the impact of problem right now like what's costing you like to actually approach me in the first place and they will be like well it's because I'm really want to scale or like I don't want like the customer like as basically what you said and then they was like okay and then you just dig deeper and be like okay and how is that costing you right now and then they'll be like well they they going to be have some sort of like numbers right or like they sometimes I should go from the employee perspective and be like a lot of the employees like they don't want to work late hours like they have a life believe it or not and they just don't want to be sitting on there on their phone like talking all day to the customer just on their phone on the same conversations every day it's boring to them as well right so and only when you actually uncover the true problem that they are actually having only then do you provide an outcome you don't say like AI you don't say Ja you just say I have a solution for you and it's going to do this like say the outcome like it's going to for example it's going to save you guys like six hours of communication time with customers right and then you break down the process. Here are the processes. Step one, step two, step three. Again, no technical language. They don't care. Like, step one, I'm just going to collect all the data from your site on the, you know, common FAQs. Step two, I'm going to collect a lot of the branding guidelines on your on your site. Step three, I'm going to go ahead and build a solution that can automate these kind of conversations based on what you just gave me. That's it. Like, keep it simple. Yeah, there we go. Make it sound make it sound so easy. It just I know I I I fall into the trap as well of like you know being overly complex and explain I but you're proud you're proud of the proud of the stuff you build right like oh this [ __ ] all the features of this is insane you know like bro I'm I'm like tracking all of your questions I'm integrating I've got a rag you want to you kind of want to nerd out but like that is that's why the the the nontechnical people tend to be pretty good like Josh my business partner who who basically runs runs morning side for us um takes all the the sales calls that we need over there he's never well until the other day he hadn't written a line of code in his life and he's just able to understand and dig into their business problems because he understands business and he knows enough about the tech to be able to communicate that and like okay these are the potential solutions communicate with the devs and so on but um mate that's been mega mega mega valuable um how can people get in touch with you and what can they uh reach out to you for yeah so um my LinkedIn's pretty open so it in general like if you just have something to say to me like I'm generally quite active on LinkedIn so if you just send me connection requests send me a DM I usually reply um unless it's you know but like generally I'll reply and then um if you're looking for more kind of more like you know educational materials or you just want to get educated on like conversation AI or just how AI can help business in general I do have a YouTube channel though it's not large channel or anything like just don't need to say that no you got a YouTube channel if I can own it you you're getting your leads from it like yeah go check out Ian's channel if you want more information like this where he's going to show you breakdown behind the scenes of how to build this stuff and then also we'll link your agency down there as well if people want to get in touch with you directly and uh and get some of the stuff built out for their business cuz it's obviously working for your clients and you're delivering great services. So, I really appreciate it, mate. And it's been freaking awesome to see your success over the past uh past six to 12 months and I'm excited for what's to come for you, man. No, for sure. Thank you very much for the time and bringing me on.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta três tipos de agentes de IA voltados a problemas de negócios (CX, recuperação de receita e comércio), mostrando como estruturá-los, precificá-los e vendê-los como soluções de alto valor.",
            "resumo": "Este vídeo apresenta três tipos de agentes de IA que resolvem problemas de negócios e costumam justificar tickets acima de US$5–30 mil. O CX agent (agente de experiência do cliente) lida com conversas de alto volume, personalização e coerência da voz da marca para conduzir o cliente até a venda, sendo proativo em vez de apenas oferecer suporte. O agente de recuperação de receita mira usuários que desaparecem ou ficam inertes na fila de compra, tentando reativá-los. O agente de comércio eletrônico ajuda clientes a encontrar produtos e a concluir a compra, guiando o processo de ponta a ponta. Os tickets médios variam conforme o escopo: CX ~ US$7k–US$20k, agente de recuperação de receita ~ US$10k, agente de comércio eletrônico ~ US$5k a US$30k. O vídeo também discute diferenças, casos reais e o uso de Voice Flow para combinar granularidade de fluxo com conversa livre, enfatizando soluções orientadas a negócios, não apenas chatbots.",
            "assunto_principal": "Três tipos de agentes de IA (CX, recuperação de receita e comércio) e como vendê-los como soluções de alto valor para negócios",
            "palavras_chave": [
              "Inteligência Artificial",
              "agentes de Inteligência Artificial",
              "Experiência do Cliente",
              "Experiência do Cliente",
              "recuperação de receita",
              "comércio",
              "vendas",
              "soluções de Inteligência Artificial",
              "Voice Flow",
              "chatbots",
              "ticket médio",
              "estudo de caso",
              "personalização",
              "proatividade",
              "gestão de marca"
            ],
            "resumo_em_topicos": "Resumo em tópicos (Markdown):\n- Contexto e objetivo: apresentar três agentes de IA voltados para problemas reais de negócio.\n- Agentes apresentados: agente de experiência do cliente (CX), agente de recuperação de receita e agente de comércio eletrônico (Commerce).\n- Agente de experiência do cliente (CX): objetivo proativo, alto volume, personalização, coerência da voz da marca; exemplo de aplicação em empresa de serviços para pets.\n- Agente de recuperação de receita: recuperação de leads/pedidos abandonados, reativação de clientes.\n- Agente de comércio eletrônico: auxílio na descoberta de produtos e conclusão de compra.\n- Faixas de preço: Experiência do Cliente (CX) US$7k–20k; Recuperação de Receita US$10k; Comércio eletrônico US$5k–US$30k (varia com o escopo).\n- Diferenciação: o CX não é suporte; foca na experiência do cliente/engajamento.\n- Técnicas/stack: uso do Voice Flow para combinar a granularidade de fluxo com a conversa livre.\n- Perspectiva de negócio: vender soluções que resolvem dores reais, não apenas chatbots.",
            "prompt_tokens": 1764,
            "completion_tokens": 3005,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 110.98415279388428,
          "language": "",
          "view_count": 15595,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@MITCSAIL",
      "name": "@MITCSAIL",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@MattVidPro",
      "status": "error",
      "message": "Falha ao acessar https://www.youtube.com/@MattVidPro/about",
      "videos": []
    },
    {
      "channel_id": "@MetaDevelopers",
      "name": "@MetaDevelopers",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "MVSsnTVEGhM",
          "title": "Start Designing with Meta Haptics Studio",
          "title_pt": "Comece a projetar com o Meta Haptics Studio",
          "url": "https://www.youtube.com/watch?v=MVSsnTVEGhM",
          "published": "2025-09-22T17:36:54.043848",
          "published_relative": "há 19 horas",
          "duration": "01:36",
          "date_published": "2025-09-22T09:42:27-07:00",
          "transcript_available": true,
          "transcript": "[Music] This stuff can get messy. One, two, and I might get zesty. We got shares and stops investing. Do my own thing. The best things to all want to judge, but they haven't met me. They want to image loaded. See how we keep it. See how we keep it heavy. One, two, sip and a be. I'm ready. Ready. See how we keep it steady steady. See how we keep it heavy on the floor. Ready? [Music] You don't [Music] want your key.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Vídeo de apresentação energética do Meta Haptics Studio, com trilha musical e falas motivacionais, que enfatiza preparação e experimentação para iniciar o design com a ferramenta, sem conteúdo técnico detalhado no trecho transcrito.",
            "resumo": "Este vídeo, publicado no canal MetaDevelopers, apresenta uma introdução energética ao Meta Haptics Studio, utilizando uma trilha musical de fundo e falas motivacionais que destacam independência, preparação e foco. O trecho transcrito não traz instruções técnicas ou demonstrações práticas, apenas sugere uma atmosfera de experimentação, ritmo e determinação para iniciar processos de design com a ferramenta. A narrativa incentiva a manter tudo pé pesado e firme, simbolizando uma abordagem estável para desenvolver experiências táteis com haptics. Em síntese, trata-se de uma peça de apresentação/teaser destinada a inspirar criadores a explorar o Meta Haptics Studio antes de mergulhar em conteúdos técnicos.",
            "assunto_principal": "Apresentação introdutória do Meta Haptics Studio, com foco em atmósfera, música e motivação, sem conteúdo técnico detalhado no trecho transcrito.",
            "palavras_chave": [
              "Estúdio Meta Haptics",
              "Meta Desenvolvedores",
              "design de hápticos",
              "apresentação",
              "trilha sonora",
              "motivação",
              "experimentação",
              "desenvolvedores",
              "introdução"
            ],
            "resumo_em_topicos": "- Contexto: vídeo de apresentação/teaser do Meta Haptics Studio no canal MetaDevelopers.\n- Conteúdo: trilha sonora, falas motivacionais e frases sobre estar pronto e manter a consistência; não há instruções técnicas no trecho disponível.\n- Tom e objetivo: enérgico, inspirador, voltado a incentivar designers a explorar a ferramenta.\n- Limitação: o trecho transcrito não oferece demonstrações técnicas; conteúdo futuro pode trazer detalhes.\n- Público-alvo: criadores e desenvolvedores interessados em haptics e design interativo.",
            "prompt_tokens": 263,
            "completion_tokens": 3139,
            "model": "gpt-5-nano",
            "cost": 0.0048
          },
          "analysis_time": 77.64735007286072,
          "language": "",
          "view_count": 1317,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@Microsoft",
      "name": "@Microsoft",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "GwF7tpr-5aE",
          "title": "Empowering Red Cross with digital tools to help save more lives",
          "title_pt": "Capacitando a Cruz Vermelha com ferramentas digitais para ajudar a salvar mais vidas",
          "url": "https://www.youtube.com/watch?v=GwF7tpr-5aE",
          "published": "2025-09-22T16:38:30.344786",
          "published_relative": "há 20 horas",
          "duration": "03:30",
          "date_published": "2025-09-22T08:59:57-07:00",
          "transcript_available": true,
          "transcript": "(peaceful music)\n(helicopter whirring) - Being a Red Crosser is like waking up in the middle of the\nnight, to go to a place where you have never been, to help somebody you have never met. That's the spirit of\nthe Red Cross volunteer. IFRC is a membership\norganization whose backbones are 16 million volunteers\nwho are always there before the crisis, during the\ncrisis, and after the crisis, at the community level. - In every corner of this\ncountry where there is a person who needs help, Costa Rican\nRed Cross is going to be there. - The Costa Rican Red Cross is the main ambulance service\nprovider in the country. When you call 911,\nwe're going to be there. - We have one emergency per minute. By year, is more than half\na million emergencies. People know where there is a Red Cross, there is hope. But we have many, many challenges. Costa Rican Red Cross\nneeds more digital tools to keep saving life and to do it better. - There's a huge disparity\nbetween the digital capacities of our National Red Cross\nand Red Crescent Societies. The IFRC Digital\nTransformation Impact Platform is there to support the\nleast digital mature and the least digital\nresourced National Red Cross and Red Crescent Societies. Essentially, Microsoft\nimmediately said, \"Yes, we want to be a partner\nwith you on that journey for the longer term.\" - The reach of the IFRC is amazing. 160 million people are\nserved every single year. This kind of digital technology\ncan help national societies reach and help people more\neffectively than ever. - The systems are out of date. We do have a lot of paper based processes. I mean, we're around 20\nyears behind technology. - We do it on paper because it's the only\noption we have right now, but we are still dreaming to have this system digitalized. - With the the support of IFRC and Microsoft, we're working on getting all that data together on a single database to make a decision based on data and to try to be faster to\nthe person that is in need. - Take the power of\nreal-time data, combine it with the cloud, support it all with AI. It helps organizations\nmarshal their resources, get to people more quickly\nand that can save lives. - Imagine we can help\n80 National Red Cross and Red Crescent Societies\nwhere there's floods, drought, violence and conflict\naffecting millions of people. - The partnership with\nMicrosoft for us is really about how do we reimagine the\nhumanitarian service delivery? How do we actually co-create\ntogether with the communities and our partners like Microsoft? - We strongly believe that\nwith better technology, better tools, we can save more life. And yes, of course, we cannot do it alone. We need help to keep helping people. (bright music)",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Vídeo mostra como a Cruz Vermelha da Costa Rica, com apoio da IFRC e da Microsoft, está digitalizando operações para salvar mais vidas por meio de dados em tempo real, nuvem e IA.",
            "resumo": "Este vídeo mostra como a Cruz Vermelha da Costa Rica, apoiada pela IFRC e pela Microsoft, está buscando transformar digitalmente suas operações para salvar mais vidas. A IFRC reúne 16 milhões de voluntários que atuam antes, durante e depois de crises, e a Costa Rica conta com a Cruz Vermelha como principal prestadora de ambulâncias, atendendo emergências a cada minuto. Enfrentam grandes desafios: sistemas desatualizados, processos em papel e um atraso de cerca de duas décadas em tecnologia. Com a Plataforma de Transformação Digital da IFRC, apoia-se as sociedades menos digitais; com a parceria da Microsoft, pretende-se consolidar dados em um único banco, usar dados em tempo real, nuvem e IA para alocar recursos rapidamente. A visão é apoiar até 80 sociedades nacionais em desastres e conflitos, reimaginando a entrega de serviços humanitários por meio da co-criação com comunidades. Juntos, podem salvar mais vidas.",
            "assunto_principal": "Transformação digital da operação da Cruz Vermelha da Costa Rica com apoio da IFRC e Microsoft para salvar mais vidas",
            "palavras_chave": [
              "Cruz Vermelha",
              "Federação Internacional das Sociedades da Cruz Vermelha e do Crescente Vermelho",
              "Microsoft",
              "transformação digital",
              "dados em tempo real",
              "inteligência artificial",
              "nuvem",
              "gestão de emergências",
              "serviços humanitários",
              "Costa Rica"
            ],
            "resumo_em_topicos": "- Contexto e atores: a IFRC reúne 16 milhões de voluntários; a Cruz Vermelha da Costa Rica é a principal prestadora de ambulâncias, com emergências ocorrendo a cada minuto.\n- Desafios atuais: sistemas desatualizados, processos em papel e atraso de cerca de 20 anos em tecnologia.\n- Solução e parceria: Plataforma de Transformação Digital da IFRC com apoio da Microsoft para transformação de longo prazo.\n- Objetivo de dados: consolidar informações em um único banco de dados para decisões baseadas em dados e resposta mais rápida.\n- Tecnologia em foco: dados em tempo real, nuvem e IA para alocar recursos e chegar aos necessitados com mais rapidez.\n- Impacto desejado: ampliar o alcance para até 80 sociedades nacionais em desastres e conflitos.\n- Abordagem: co-criação com comunidades e parceiros para reimaginar a entrega de serviços humanitários.\n- Mensagem central: tecnologia de qualidade pode salvar mais vidas, e a colaboração é essencial.",
            "prompt_tokens": 760,
            "completion_tokens": 5338,
            "model": "gpt-5-nano",
            "cost": 0.0084
          },
          "analysis_time": 81.24374008178711,
          "language": "",
          "view_count": 133,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@NVIDIA",
      "name": "@NVIDIA",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "mhIOr_vHl_Y",
          "title": "Como a IA se tornou 100.000 vezes mais eficiente em termos de energia — e está transformando a pe...",
          "title_pt": "Como a inteligência artificial se tornou 100.000 vezes mais eficiente em termos de energia — e está transformando a pe...",
          "url": "https://www.youtube.com/watch?v=mhIOr_vHl_Y",
          "published": "2025-09-23T10:39:59.593414",
          "published_relative": "há 2 horas",
          "duration": "01:51",
          "date_published": "2025-09-23T03:01:22-07:00",
          "transcript_available": true,
          "transcript": "We say accelerated computing is sustainable computing because it is inherently fundamentally more energy efficient and Nvidia has really pioneered this acceleration of compute power. We've improved the energy efficiency of the accelerated computing platform by 100,000 times over the past decade. And that type of energy efficiency improvement is really critical to us unlocking the next level of performance that allows us to build bigger and bigger models and do more and more with AI. The potential positive impacts of AI for sustainability are really huge. People are applying AI to long-term sustainability challenges. So things like climate modeling, climate tech, for carbon capture and storage, for battery chemistry to improve recyclability of materials. Put that in context of manufacturing across the world as well as transportation and buildings. The energy savings and the resource savings are really dramatic. There's so many examples. It's really easy to get excited about all the potential good, but it's totally valid to look at, okay, what's the footprint of AI as well? And it's true that the footprint of AI from an energy perspective is growing, but OpenAI estimates that it's only.34 W hours of energy that's used for a single CHAGPD query on average. And that equates to very, very small activities in your daily life like using your microwave for just 1.2 seconds or running a light bulb for just four minutes. So if you look at all the other things that we're using electricity for and generating emissions for, AI is a tiny fraction of a tiny fraction of of the overall pie. It's growing absolutely and it will continue to grow. But there's no other technology and no other energy consumer that is more likely to have a positive impact in the long term than AI. And in this period of rapid innovation, it's a democratizing tool that really unlocks potential for sustainability goals across sectors.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Computação acelerada é apresentada como mais sustentável, com ganhos de eficiência de 100.000x pela Nvidia, e a IA é vista como motor de impactos positivos para clima, indústria e mobilidade, ainda que sua pegada energética siga crescendo.",
            "resumo": "O vídeo apresenta a ideia de que a computação acelerada é intrinsecamente mais eficiente energeticamente, com a Nvidia afirmando ter aumentado a eficiência de energia da plataforma de computação acelerada em 100.000x na última década. Esse ganho é essencial para patamares maiores de desempenho, permitindo modelos maiores e avanços em IA. São discutidos impactos positivos da IA para a sustentabilidade, como modelagem climática, tecnologias de clima, captura e armazenamento de carbono, baterias e reciclagem de materiais, com aplicação em manufatura, transporte e edifícios. Mesmo com o crescimento da pegada da IA, é destacada a estimativa de 0,34 Wh por consulta do ChatGPT, ilustrando que a IA continua sendo uma fração pequena do consumo elétrico total, que deve crescer. A visão final é que nenhuma tecnologia supera a IA em impacto positivo a longo prazo e que ela é uma ferramenta democratizante para metas de sustentabilidade.",
            "assunto_principal": "Eficiência da computação acelerada e o papel da IA na sustentabilidade, com foco na Nvidia e na pegada energética da IA.",
            "palavras_chave": [
              "Inteligência Artificial",
              "computação acelerada",
              "eficiência energética",
              "NVIDIA",
              "sustentabilidade",
              "clima",
              "carbono",
              "baterias",
              "reciclagem",
              "manufatura",
              "transporte",
              "edifícios"
            ],
            "resumo_em_topicos": "- Premissa central: computação acelerada é sustentável por natureza; a Nvidia aponta ganhos de eficiência de 100.000x e destaca o papel da IA em avanços de desempenho.\n- Impactos positivos para sustentabilidade: modelagem climática, tecnologias de clima, captura/armazenamento de carbono, química de baterias e reciclagem de materiais, com aplicações em manufatura, transporte e edifícios.\n- A pegada de energia da IA está crescendo, mas é uma fração pequena do consumo total (estimativa de 0,34 Wh por consulta do ChatGPT).\n- Mesmo assim, a IA pode crescer e continua sendo a tecnologia com maior potencial de impacto positivo a longo prazo, além de atuar como ferramenta democratizante para metas de sustentabilidade.",
            "prompt_tokens": 525,
            "completion_tokens": 6622,
            "model": "gpt-5-nano",
            "cost": 0.0102
          },
          "analysis_time": 77.29128503799438,
          "language": "",
          "view_count": 891,
          "has_transcript": false
        },
        {
          "id": "7G0YSn2--EM",
          "title": "Legado de 50 anos da Sofinnova: acelerando a inovação em biotecnologia com a IA da NVIDIA",
          "title_pt": "Legado de 50 anos da Sofinnova: acelerando a inovação em biotecnologia com a IA da NVIDIA",
          "url": "https://www.youtube.com/watch?v=7G0YSn2--EM",
          "published": "2025-09-22T23:39:59.593468",
          "published_relative": "há 13 horas",
          "duration": "03:32",
          "date_published": "2025-09-22T16:03:14-07:00",
          "transcript_available": true,
          "transcript": "We're one of the oldest funds on the planet dedicated to the life sciences space. So we invest into biotechnologies, medical devices, industrial biotech, and digital medicine, which is the fund that I I run. And when you look at kind of our history, uh we've been around for over 50 years. So we have an incredible depth and breadth of connections, about 100 portfolio companies currently active. And we've also been active in investing into some of the largest companies today back in over 30 years ago. What's pretty awesome is the mission of Sophie Nova Partners is to advance the way that we are able to practice medicine as well as bringing our expertise into the industrial biotechnology field. What we have is an incredible amount of scientific knowledge and expertise as well as of course business depth and therefore access to to great companies as well across the planet. the more we actually started advancing and particularly the more we started connecting our portfolio companies with Nvidia the more they came back to us saying wow this is actually benefiting us because now we've been able to streamline our processes improve the power and the speed in particular of which we're able to do our analysis and therefore get to results way faster than we would have otherwise so for us as investors it means with the same amount of capital provided we get much bigger impact for the companies and for the companies it means their timelines are getting shortened drastically the NVIDIA VC Alliance program the way that it's been able to connect us with other VCs across the ecosystem and industry. Again, we're very much a life science focused venture fund. Traditionally, we're now of course bridging out and seeing that digital medicine. So, our fund strategy sits at the intersection between life sciences and technology. With this kind of an approach, of course, we tend to traditionally be much more on the life science side of things. By working with the VC Alliance program, we're also gaining much more exposure and connection with the tech side of things. So one, it creates an interesting dynamic for us as a fund to be able to see how is technology coming into the space and what therefore do we expect to see the big breakthroughs and advances in foundation models in biology, in health tech and these types of things, but also to be able to connect our portfolio companies with also the tech side of this space. It creates that kind of perfect dynamic for us here. Another aspect of the the partnership with Nvidia is also this incredible deal we're getting now with regards to Leptin, right? on the one hand is providing our portfolio companies with something that we as a VC we always like something that's exclusive. It helps us also sell our product to our future investments. You can come to us and work with us. We can give you something that's pretty impressive in terms of access to compute on the one hand and then secondly also an ability to tweak the requirements for that compute as and when needed. Because let's face it, a startup doesn't always know exactly what it's going to need when it's going to need it. Particularly in our space where you're building massive data assets, so biological data, it may take a while from the moment you get raw samples for example to be able to generate data then to analyze. If you're still paying for a certain compute requirement under all that time, that's a lot of cash and spend just kind of gone. With Lapin, with the personalization approach that you can have with Nvidia, that's what's so cool. So suddenly you can tweak that requirement and say okay we've got a mass amount of data instead of having to wait at a certain number of GPUs. We can actually scale that in very quickly and therefore get through the data processing and get to results much much faster. So for us of course one it's a certain level of advantage to be able to present in a competitive market and the second is of course it provides a way for our portfolio companies to get much faster to the value inflection points that then drive value in their companies going forwards.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Fator principal: a Sofinnova Partners, com 50 anos de atuação, explica como a parceria com a NVIDIA, o VC Alliance e Leptin aceleram a inovação biotecnológica, reduzindo prazos e ampliando o retorno.",
            "resumo": "Somos um dos fundos mais antigos dedicados às ciências da vida, com investimentos em biotecnologia, dispositivos médicos, biotecnologia industrial e medicina digital, mantendo cerca de 100 empresas ativas. Ao longo de mais de 50 anos, desenvolvemos profundo conhecimento científico e uma rede ampla, permitindo acesso a grandes companhias globais. Ao conectar nosso portfólio à NVIDIA, observamos um aumento de eficiência: análises mais rápidas, dados de maior qualidade e resultados em menos tempo, mantendo o mesmo capital e gerando maior impacto. O programa NVIDIA VC Alliance amplia nossa exposição ao ecossistema tecnológico e facilita a conexão com outros VCs. Além disso, a parceria envolve a solução Leptin, que oferece acesso exclusivo à capacidade de computação com ajustes de requisitos conforme a necessidade de dados biológicos em evolução, permitindo escalonamento rápido de GPUs e aceleração do caminho para marcos de valor para as startups.",
            "assunto_principal": "Parceria entre Sofinnova Partners e NVIDIA para acelerar a inovação em biotecnologia via IA, computação personalizada e o programa VC Alliance.",
            "palavras_chave": [
              "Sofinnova Partners",
              "biotecnologia",
              "ciências da vida",
              "dispositivos médicos",
              "biotecnologia industrial",
              "medicina digital",
              "portfólio",
              "Aliança de Capital de Risco",
              "NVIDIA",
              "leptina",
              "computação",
              "modelos fundacionais",
              "saúde",
              "inovação",
              "dados biológicos massivos"
            ],
            "resumo_em_topicos": "- Visão geral da Sofinnova Partners no ecossistema de ciências da vida.\n- Focos de atuação: biotecnologia, dispositivos médicos, biotecnologia industrial e medicina digital.\n- História de cerca de 50 anos e portfólio com aproximadamente 100 empresas ativas.\n- Benefícios da parceria com a NVIDIA: aceleração de análises, maior velocidade e maior impacto com o mesmo capital.\n- Programa NVIDIA VC Alliance: conexão com outros VCs e com o lado tecnológico.\n- Interseção entre ciências da vida e tecnologia e foco em modelos fundacionais na biologia e na saúde.\n- Destaque para Leptin: acesso exclusivo à computação com capacidade de ajuste de requisitos e escalabilidade.\n- Capacidade de startups escalarem grandes volumes de dados biológicos e atingirem marcos de valor mais rapidamente.\n- Perspectivas: maior sinergia entre tecnologia e biosciências para avanços na saúde.",
            "prompt_tokens": 957,
            "completion_tokens": 6184,
            "model": "gpt-5-nano",
            "cost": 0.0098
          },
          "analysis_time": 100.86307311058044,
          "language": "",
          "view_count": 1342,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@NVIDIADeveloper",
      "name": "@NVIDIADeveloper",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "Tjzuyh1Ra4Q",
          "title": "Desembalando o kit de desenvolvedor NVIDIA DRIVE AGX Thor",
          "title_pt": "Desembalando o kit de desenvolvimento NVIDIA DRIVE AGX Thor",
          "url": "https://www.youtube.com/watch?v=Tjzuyh1Ra4Q",
          "published": "2025-09-22T18:43:00.272870",
          "published_relative": "há 18 horas",
          "duration": "07:47",
          "date_published": "2025-09-22T11:34:47-07:00",
          "transcript_available": true,
          "transcript": "[Music] Hi there, I'm Tim Wong with Nvidia and what you see before me is the Drive AGX Thor developer kit. The Drive AGX Thor developer kit enables the development of safer, smarter autonomous vehicles and transportation solutions. It is part of NVIDIA's three computer solution for accelerating autonomous vehicles. NVIDIA DGX for AI training, NVIDIA Omniverse and Cosmos for simulation and synthetic data generation and Drive AGX Thor for deployment into vehicles. The developer kit is built on NVIDIA's Blackwell architecture, next generation ARM CPUs and the advanced NVIDIA drive OS7 software stack. It delivers 2,000 trillion flops of AI compute along with various IO for sensors and vehicle bus integration. Let's take a closer look at the drive AGX door developer kit and see what's included. First, you can see the paper insert with a QR code directing you to developer.invidia.com/drive/start. You get a bunch of USB cables to connect between your host PC and your development kit. This is the Mate X to Faulra splitter. supporting up to four cameras or displays. You get an HMTD 4-way splitter and a six-way splitter. This is the 1 GB Ethernet adapter. You can see the RJ45 port on one side and the HMTD port on the other as well as the USBC port to supply power. Now, let's take a look at the drive AX floor developer system unit. This is air cooled and air gets sucked in from this side and the exhaust air blows out of this side. Let's turn it around. The back side has all of the ports. This is where you have the main power switch and this is where you plug in AC power. The AC power cord is not provided and you can either provide one your own or purchase one separately. The first column is for cameras and displays with seven mate X quad connectors, all clearly numbered so you know which one supports what. There's a full-size display port for monitor out. The next column is for Ethernet connectivity via an HMTD 4-way or six-way connectors. It is important to note that the included Ethernet adapter can be only used with the HMTD sixway connector like this bottom one. At the bottom, we have two vehicle harness connectors. The vehicle harnesses were not included with this kit, skew 10, because this is meant for desktop or benchtop use. SK 12, which is meant for invehicle use, does include the two vehicle harnesses that connect here. There are four USBC ports at the bottom. The important ones to use and connect your host are the second for recovery mode and flashing and the fourth for debugging. Lastly, these are the PCIe ports. Let's set up our host PC. This one is running a fresh install of Ubuntu 24.04.3 LTS desktop. I've already installed the latest Nvidia driver for my GPU SSH as well as the latest Docker engine. Let's start by going to developer.envidia.com. Click on the person icon at the top right. Click on account in the do dropown. Click on my programs on the left. Click on the members area button. Click on the top link for Thor. and we're going to be spending the majority of our time going through the Drive OS 7.0.3 installation guide for Nvidia developer users. Here's the introduction showing that there are two ways to make everything work. Nvidia MV online and Nvidia developer users. We're going to focus today on Nvidia developer users. Let's quickly scroll through the requirements. Here are the hardware and software requirements. There are different variants of the drive AX Thor developer Thor kit. The one we are working on today is the D0 model with a drive AGX Thor X. This is where you can find the part number of your kit. Now we're looking at the configuring container registry access and again going to the NVIDIA developer user link. Let's open up a second browser tab for ngc.invidia.com. [Music] Because I show up as guest, I'm going to log in at the top right. Enter my email. Select Drive and then Drive OS SDK. Select private registry. Select containers on the left. Enter Thor in the search bar. Click on Nvidia Drive. Click on the tags tab. Copy and save the NVCR string at the top right for later use. The version build information at the end of the string will be very important. Click on setup. Click on generate API key. Select generate. Select personal key. Enter a key name. The duration for 12 months is fine. So we won't change that. And for permissions, select NVIDIA private registry. Select generate personal key. Copy the generated key and save it for later use. Now let's open a terminal window. Let's log in to the NGC container registry. The username is ooth token and the password is the API key you just created. You should see a login succeeded message. Then we'll go to install Nvidia drive OS. We need to build our pulland run command for the drive OS Docker container image. Replace the version build with what we saved earlier. Replace workspace with the directory of your choosing and then hit enter to start the pull. This will take a few minutes to complete. Once you see the agreement language and a root prompt, the Docker pull and setup is completed. You're now ready to develop code on your host PC, cross-co compile it for drive AGX Thor, and then transfer and run the code on Thor. After you connect two USB cables between your host PC and the developer system, namely the USBC ports U2 and the debug port, it's helpful to also open a terminal window on the host PC. Run the ls USB command to check that your developer system is connected correctly. You should see NVIDIA Corp Tegra Onplatform operator listed. You can also use minicom and connect to the developer kits MCU. The developer kit is already running OS 7.0.3, so there's no need to flash it. So, I'm going to skip over this section. You can see that there are a number of additional drive OS packages available on NGC. You can also go to GitHub and run the CUDA samples. There's a lot more information online. You can find it at developer.envidia.com/drive. nvidia.com/drive and then/s setup/start/d downloads or slashdocumentation depending on what you need to do. Let's take a closer look at the documentation resources. You can see that there are a number of useful documents like the product brief, the hardware quick start guide, the mechanical guide, sensors and ecosystem vendors as well as various software docs. Thank you for watching and please enjoy your new drive Ajax store developer kit.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o kit de desenvolvimento NVIDIA DRIVE AGX Thor, suas especificações, conteúdo, integração de hardware e software, e o fluxo de configuração para desenvolvimento e implantação de software em veículos autônomos.",
            "resumo": "Tim Wong apresenta o Drive AGX Thor developer kit, destinado ao desenvolvimento de veículos autônomos e parte da solução tríplice da NVIDIA (DGX para IA, Omniverse/Cosmos para simulação e Drive para implantação). O kit utiliza a arquitetura Blackwell, CPUs ARM de última geração e Drive OS 7, oferecendo cerca de 2.000 trilhões de flops de IA e diversas opções de E/S para sensores e integração com o barramento do veículo. O vídeo detalha o conteúdo da embalagem (cabos USB, splitter Mate X para câmeras/monitores, divisores HM TD 4/6 vias, adaptador Ethernet de 1 Gbps, portas USB-C e conectores de veículo), bem como a unidade de sistema refrigerada a ar. No software, descreve o fluxo de preparação do host (Ubuntu 24.04, driver NVIDIA, Docker), acesso ao NGC/NVCR, geração de chave de API, início de sessão e pull/run do Drive OS em contêiner, permitindo desenvolvimento e cross-compilação para Thor. Recursos de documentação também são mencionados.",
            "assunto_principal": "Kit de desenvolvedor NVIDIA DRIVE AGX Thor e fluxo de configuração para desenvolvimento de software de veículos autônomos",
            "palavras_chave": [
              "NVIDIA Drive AGX Thor",
              "Drive OS 7",
              "arquitetura Blackwell",
              "CPUs ARM",
              "veículos autônomos",
              "NGC / NVCR",
              "Docker",
              "compilação cruzada",
              "Ubuntu 24.04",
              "fluxo de instalação",
              "documentação NVIDIA"
            ],
            "resumo_em_topicos": "Texto: ## Visão geral\n- Apresenta o kit de desenvolvedor Drive AGX Thor, voltado ao desenvolvimento de veículos autônomos e à implantação em hardware embarcado.\n\n## Conteúdo e hardware\n- Descrição dos itens da embalagem (cabos USB, divisores Mate X, divisores HM TD, adaptador Ethernet, portas USB-C, conectores de veículo) e da unidade de sistema com resfriamento a ar.\n\n## Configuração de hardware\n- Distribuição de portas para câmeras/monitores, Ethernet, conectores de veículo (embora os harnesses não venham com SK 10, disponíveis em SK 12 para uso veicular).\n\n## Preparação de software\n- Requisitos: Ubuntu, driver NVIDIA, Docker; acesso ao NGC/NVCR; geração de API key para registro privado.\n\n## Fluxo de instalação\n- Login no registro privado, recuperação/armazenamento de NVCR string, pull do Drive OS em contêiner, preparação do ambiente para desenvolvimento e cross-compilação para Thor.\n\n## Recursos adicionais\n- Documentação disponível (product brief, hardware quick start, mechanical guide, sensores, software docs) e canais de suporte NVIDIA.",
            "prompt_tokens": 1510,
            "completion_tokens": 3372,
            "model": "gpt-5-nano",
            "cost": 0.0058
          },
          "analysis_time": 66.14346599578857,
          "language": "",
          "view_count": 949,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@NateBJones",
      "name": "@NateBJones",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "qVufzX_8bqE",
          "title": "Entrevistas com IA são uma porcaria: veja como usar IA para ser contratado (e contratar) em 2025",
          "title_pt": "Entrevistas com IA são uma porcaria: veja como usar IA para ser contratado (e contratar) em 2025",
          "url": "https://www.youtube.com/watch?v=qVufzX_8bqE",
          "published": "2025-09-22T13:44:10.998138",
          "published_relative": "há 23 horas",
          "duration": "18:11",
          "date_published": "2025-09-22T06:01:52-07:00",
          "transcript_available": true,
          "transcript": "If you are hiring or if you are interviewing, this is your interview guide. I'm making it for both because both sides are responsible for using AI better. And I want to talk about it because everybody's using AI and most of us are using it badly. That includes hiring folks and candidates. 83% of companies admit to screening with AI. I bet the others do anyway. 65% of candidates admit to applying with AI. I bet the others do anyway. Everyone sounds the same. Let's say you get past the application process. Now you have candidates using tools to interview. And you know what? Interviewers catch them. And candidates have a terrible experience because they're not even talking to humans anymore. I know a senior engineer who has over a decade of experience who recently got rejected because the AI interviewer talking to him talked over him wouldn't let him finish his sentence asked him confusing questions and it's not even clear it recorded it correctly and this is passing for efficiency. I'm seeing case studies here where companies are celebrating the efficiencies they get with AI hiring when people are all over Reddit and all over X talking about how terrible the experience is for candidates. This is not how you get your next champion if you are hiring. It doesn't work that way. We need an interview process that prioritizes human signal amidst the AI noise. And I want to give you specific strategies both if you're an applicant, which we'll do first, and also if you are hiring, which we'll do second. And I want to go into both because I think both sides have a responsibility to get better here. So number one, if you're an applicant, these are my top tips for how you interview better. Number one, fix your tool strategy. There are a lot of very expensive tools out there. Final Round AI runs over a hundred bucks a month. I think it's 148 or something. ridiculously expensive, but they're preying on the fact that you need a job. You don't have to use the most expensive tool. In fact, there are reports from the employer side of detecting final round AI interview responses because they sound so generic. Whereas, candidates are saying that a much cheaper alternative like Bay YZ AI is working better because the answers are fast and feel fluent and natural. The point is not to pick a cheating AI that helps you cheat undetectably. The point is to find something that you can partner with that helps you to structure your thinking. I actually think the most useful tool may be free. Google interview warm-up lets you practice and get better with AI answers. It helps you understand what you did right and what you did wrong. It helps you to go back and forth and spar in a way that's low stakes. You don't have to pay a lot to get help. Before we go further, I want to underline something like three or four times. The right tool will not get you the job. And the right tool will not get you the career. And the tool people are selling you lies if they say so. That is not what gets you a sustainable career. Figuring out how to showcase who you are, your passion, your genuine skills, your insights, that's what helps you win. And AI is only there to help you do that well. And the prompts that I'm writing for candidates in this piece are prompts that I am designing so that you can prepare better than anyone else prior to the interview with the help of AI. Let's get into your artifact strategy next. Almost no one has an artifact strategy. So tip number one, get an artifact strategy. What's an artifact? An artifact is a proof of work. It's it's a packet. It helps you to show your thinking around real problems. And by the way, that is going to help you prepare for interviews. As an example, you would want to look at a project you've done and not just do what so many people do, which is throw up a nice little website, put up a bar chart, say you made it go up and to the right. Instead, you want to build a proofof work packet that shows how you actually think, the constraints that you faced, the decisions you made, the trade-offs that you considered. Traditionally in product management, we've been doing this for a while because we were always told you have to show your thinking as a PM. I would now say looking at how people are actually interviewing, that is more and more the case for every role in tech. If you're in design, you're going to need to do this. If you're in engineering, you'll need to do this in your own way on the technical side. Even in roles like customer service and sales, you are increasingly going to be asked to show solid evidence of human judgment. Especially as you get into more senior roles, you want to be in a place where you can show that thinking clearly. And it doesn't necessarily mean that you just email this packet off and hope that that works well. I'm not saying that. It's in the interview. You have the option to pull it up if it's interesting and moves the conversation forward. It acts as an after interview additional packet of information if the interviewer is interested. And it helps you most of all to get prepared without sounding like a parrot. And so many of the issues with these AIs that assist you in interviews is that they make you sound like a parrot and you are so desperate to answer the question right, you don't realize you sound like everybody else. You should also include ugly artifacts, not just the pretty ones. I actually look when I get resumes, when I look at the websites people send me, I want to see is everything super polished or are you courageous enough to show things you've worked on, scratch notes, iteration history, failed experiments. The most compelling story I have ever seen on a personal website for a job was this lengthy single page post. And it showed a 5-year history in a role. And it went through meticulously what the person had done to add value at each stage in that role. And it had pictures and visuals and designed elements. And it read really fluently. And you could see how the person had negotiated setbacks and obstacles along the way to get the company to where it was. It was incredibly compelling. It showed iteration. It unquestionably proved authenticity. The last thing I want to call out is that the artifact strategy extends into how you interview. I I call it the star C method. If you've ever done STAR, you know it's situation task and then you go from there into the assignment and your response. And I'm adding constraints. And so star C is all about showing that you can work within constraints because AI answers classically are not very constraintheavy. And so what I recommend that you do is that you take your star situation and you want to make sure that you layer in the constraints that enabled you to make hard tradeoffs along the way because good constraints, if properly told in the STAR format so people can follow along, help you show good judgment. Good constraints help you show good judgment. And I think that that's increasingly important because if you're just giving a standard response and the interviewer has heard star before and all the AIs have heard star and you tell star, it feels very stale. You need something that helps you to add that human element. And if you remember star C, it can help. So situation, task, action, results, and make sure you layer in those constraints. That's the C. I want to go beyond just the toolkit and the artifacts and interview strategy for a minute with candidates. If you are using AI, please be transparent in 2025. It actually increases your authenticity. Let me give you an example of some talk tracks that would impress me. I use Claude for research. I went back to primary sources. I looked through what actually worked and what didn't work. The analysis that I'm putting in front of you is mine and I made sure that I can own it and stand behind it. Fantastic. Show the AI stack that you're using in the verification process you use. This is going to be true in technical roles and non-technical roles, too. Make sure you mention places where you disagreed with AI. May make sure you mention where you caught AI in hallucination. Make sure you mentioned what tools you wanted AI to use versus not. That conversation is important. And that actually is a nice segue brings me to the second part of this video where we're going to talk to hiring managers. Hiring managers, you need to evaluate better. And it starts with not penalizing people for exactly what I described. If your candidate talks about using AI, don't you dare penalize them. Especially if they're being transparent. That is the kind of culture you want to have in your company. You want AI champions who can talk about their successes with AI and also their failures with AI. Make sure that you don't penalize candidates who are showing that behavior. And so this brings me to the next piece. If you actually want candidates who work with AI, you need to stop running interview processes that are designed to have zero AI. So, I'm suggesting that you stop with your AI detection practices and start with AI assessment practices. Give candidates AI tools during interviews. Meta actually does with this with their engineers. They give them a llama install and they tell them to work with AI and assess their ability to do so. Evaluate how the candidate actually collaborates with AI. evaluate not just if they use it, but how they use it to add value, whether they just do what AI says or whether they're actually able to exercise some agency over the AI and direct it in ways that are useful to get the overall job done. Make sure that you also test how they handle really messy problems that require conflicting requirements, high thinking quality, and the ability to negotiate multiple constraints. Those are classical areas where AI breaks down. I just advised candidates who are interviewing to call out constraints with the star C method. I am suggesting to hiring managers that you fish for those constraints. Look for messy problems because the candidates will have to show they are good at what they're doing with their human brains to answer messier data problems. Don't just give a candidate a really clean data problem as a take-home exercise and expect to get useful value. In fact, take-home exercises are on the decline precisely because AI can get them done. What I'm advocating is that you give them exercises that are kind of a mess because you're testing their ability to use human judgment. And candidates, if you're still listening, I'm sorry, you're going to get some exercises that are a bit of a mess. But on the plus side, it gives you the chance to show your human skill sets. And that's what we're here to demonstrate. I want to give you also a framework as a hiring manager to assess candidates for AI fluency. It's one of the hottest topics in 2025. I'll probably do more on it soon, but as a quick rule of thumb, you want to be checking for three levels. One is AI literacy. I guess zero is no AI, but one is AI literacy where you are able to see that the candidate can choose between different tools intelligently. The candidate can verify outputs for hallucinations. The candidate has awareness of AI limitations. The candidate can tell you the difference between claude and chat GPT and why. Number two is AI integration, which can be technical or non-technical depending on the role. But you're looking for the candidate who can talk about their workflow design or how they would design workflows in your role with AI at the heart of those workflows, what tools they would select, why, how they would handle data. You want to check for error handling and have the candidate bring that up proactively. Talk about their evaluation and metrics philosophy. Talk about systematic collaboration. If you want someone who can actually help you be the 5% in the MIT study, that's someone who can help you with workflows. That infamous study with execs that said only 5% of projects deliver ROI. The key was good integration. Level two candidates on AI are going to be able to talk integration fluently. And yes, you want to be asking interview questions that test for that. You don't want to just ask your traditional role interview questions. Level three AI leadership. This is going to be for senior roles. You need someone who can do one and two. So they can do tool selection, output verification with their eyes closed. They can walk through workflow design, error handling, but they can do more. They can talk to you about strategic adoption. They can talk to you about AI governance. They can talk to you about team development with AI very fluently. They can architect systems that allow others to design workflows and ensure and be accountable for outputs against multiple workflows that are designed. These are the kinds of people that you're looking for in leadership roles where they understand the domain, but they also have a very high level understanding of AI that allows them to truly lead their team. Because these days, most people hiring for leadership roles need a leader coming into the space that doesn't need their handheld on AI. They need to be a champion for AI from day one and potentially be a champion in a room full of people where some of them are deep domain experts but may not be deeper on AI. And so every hire you make as a hiring manager needs to move the ball forward on your AI transformation strategy and that includes senior leadership roles. Expect your senior leaders to know how to develop their teams on AI from day one. Don't tolerate ramp time. Ask the questions you need to ask to ensure that they can do so. As an example of a good question, why don't you give them the actual stack you have? Not the ideal stack, the actual stack that you have. give them an example of the kinds of resistance you're seeing across your organization with AI and then say how would you solve this? How would you bring your team along? Let's say we needed the team to get to strong integration fluency within 2 months. What would you do? Why? Cuz you're then testing multiple things, right? You're testing domain expertise. You're testing their uh fluency with AI and how they would handle that. And you're also assessing leadership and change management. And you can break down that answer and see where they stumble, see where they're weak, see where they're strong. There's other questions, but you get the idea. When you are interviewing, and by the way, if you're still listening, this is like free intel for the candidates. There are red flags and green flags. And we've always had that, right? The AI red flags look a little different. And the AI green flags look a little different. And I want to spend some time for AI. A red flag looks like not just generic responses which I talked about at the top where you're overrelying on tools and like you're just reading the response which yes people can read body language they can read when you're like sliding your eyes to the side they can read the weird pauses people notice. Okay, candidates, if your candidate can't explain AI limitations, if your candidate can't go off script, if your candidate doesn't have the ability to break down a problem from a different angle on fairly short notice, that is a big red flag. It's also a great tell because AI tends to take some time to break down problems from different angles and is actually even the most cutting edge models are not super good at that right now. they tend to get stuck in the middle of a chat on a certain angle and anchor to that because of the context window. And so if you are suspecting that your candidate is just reading answers, if you shift the angle of the problem quickly, their AI may not catch up. It's a way to push them off script. On the other hand, in the AI world, we have new kinds of green flags. If your candidate volunteers, how they're catching AI errors, if your candidate volunteers to talk about how they do a systematic verification process for work they get done so that they take ownership and accountability for it and they're not just paring what AI says. If your candidate can quantify AI impact and talk both at the individual level and the team level and the organizational level about what AI can do for the business, what AI has done in their role, that's a huge green flag. If your if your candidate has a philosophy of the role that says this is how this role is evolving in the age of AI that they can explain coherently they can act as a peer champion for AI for their role. It's really compelling. So there's lots of green flags too. It's not just red flags here for both parties. Right? We're bringing this to a close here for candidates for hiring managers. I want to give you three principles to stick with that I think will help you. Three principles to unlock what feels like a stuck market right now. Number one, enhancement beats replacement. AI is there to make human judgment clearer, not to substitute for it. Candidates, that means if you're reading answers and not using your brains, you're losing. Hiring managers, that means if you're using AI to evaluate interview transcripts and you're not actually thinking about what the candidate is saying and taking the candidate seriously as a person, if you're just using AI to interview, you are also losing. You're also losing. You're contributing to the problem. Both sides win with transparency. That's number two. Candidates need to show better judgment when they admit to using AI. And managers must find better talent when they have to talk about how they actually use AI at work. So bring AI to the table. Don't hide it. Candidates don't hide it. Hiring managers don't pretend it's not there. Both sides need to talk about their AI strategy to actually move the ball forward. Third, last but not least, make sure that you know how to use your prompts well. I've included a bunch of I think nine s prompts that like dig deep on interview prep. But you need to have prompts that actually help you move the ball forward. If you're assessing résumés with prompts as an aid, not as a substitute, you need to have prompts that actually help you to do that. If you are preparing as a candidate, you need to have prompts that help you to research a JD and go way beyond the surface level in order to stand out as a candidate. I they have written prompts where you can get three or four pages of really strong interview prep material out of one job description because you're telling the AI very specifically what to look for that helps you to prepare. It's all about intent. It's not like my words are not magic. It's about telling the AI how to effectively assess what is in front of it, what is between the lines, and what you need as an interview prepper to get ready for a big conversation. Hiring is broken, kind of broken. I want it to get better. And I think the only way it can get better is if we admit that AI is at the table now. If we're transparent about it, and if we use AI to support human judgment rather than to replace it. Best of luck out there, and let me know how you're doing. Cheers.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo analisa o uso de IA em recrutamento e entrevistas, aponta falhas na experiência do candidato e apresenta estratégias para manter o toque humano e usar IA de forma responsável em 2025.",
            "resumo": "Este vídeo analisa o uso cada vez mais intenso de IA em recrutamento e entrevistas, destacando que, apesar das eficiências, muitos processos sacrificam a experiência humana. Cita casos de candidatos entrevistados por IA que interrompem, não deixam o candidato concluir, ou geram avaliações pouco confiáveis, e de empregadores que celebram a velocidade sem considerar o impacto. Propõe que candidatos e recrutadores assumam responsabilidade para usar IA de modo a preservar o sinal humano. Para candidatos, sugere: 1) ajustar a estratégia de ferramentas para opções acessíveis que ajudam a estruturar o pensamento sem soar como robô; 2) desenvolver uma estratégia de artefatos (provas de trabalho) que mostrem pensamento, restrições e decisões; 3) adaptar o formato STAR para STAR-C, enfatizando restrições e trade-offs; 4) ser transparente sobre o uso de IA, apresentando a pilha de ferramentas e fontes. Em resumo, IA deve ampliar autenticidade, não substituir mérito.",
            "assunto_principal": "Uso de IA em recrutamento e entrevistas, com foco no equilíbrio entre eficiência tecnológica e sinal humano.",
            "palavras_chave": [
              "inteligência artificial",
              "recrutamento",
              "entrevistas",
              "experiência do candidato",
              "sinal humano",
              "artefatos de trabalho",
              "STAR-C",
              "transparência",
              "autenticidade",
              "eficiência",
              "ferramentas de inteligência artificial",
              "candidatos",
              "recrutadores"
            ],
            "resumo_em_topicos": "- Contexto: IA está presente em recrutamento e entrevistas, prometendo eficiência, mas pode degradar a experiência humana.\n- Problemas atuais: entrevistas por IA que interrompem, respostas genéricas e registros pouco confiáveis; setores celebram velocidade sem avaliar impacto.\n- Estratégias para candidatos: \n  - ajustar a estratégia de ferramentas (opções acessíveis que ajudam a estruturar o pensamento, sem soar como robô);\n  - adotar artefatos (provas de trabalho) que mostrem pensamento, restrições e decisões;\n  - adaptar o STAR para STAR-C (inserir restrições e trade-offs) para demonstrar bom julgamento;\n  - transparência: compartilhar a pilha de IA e fontes utilizadas.\n- Estratégias para recrutadores: priorizar o sinal humano, exigir artefatos de qualidade, não depender apenas de IA, manter conversas humanas significativas.\n- Exemplos de ferramentas citadas: Final Round AI (caro), Bay YZ AI, Google Interview Warm-up.\n- Conclusão: IA deve ampliar autenticidade e evidência de competência, não substituir mérito.",
            "prompt_tokens": 1807,
            "completion_tokens": 3974,
            "model": "gpt-5-nano",
            "cost": 0.0069
          },
          "analysis_time": 68.66214203834534,
          "language": "",
          "view_count": 2708,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@NewMachina",
      "name": "@NewMachina",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "VVxl4nUepuk",
          "title": "O que é LLM RLHF?",
          "title_pt": "O que é LLM RLHF?",
          "url": "https://www.youtube.com/watch?v=VVxl4nUepuk",
          "published": "2025-09-22T12:45:22.834275",
          "published_relative": "há 1 dia",
          "duration": "06:18",
          "date_published": "2025-09-21T10:00:40-07:00",
          "transcript_available": true,
          "transcript": "Hello. How you doing? Have you heard the term RLHF and you're not quite sure you know exactly what this is? Well, if so, then watch along with me for the next few minutes and I will quickly get you up to speed. Okay, let's get started. So, what is RLHF or reinforcement learning with human feedback? Well, RLHF is a sophisticated machine learning approach that merges traditional reinforcement learning with human input. It aims to improve LM models by incorporating human judgment and preferences into the training loop, enhancing their alignment with human values. In simple terms, RLHF is a way to teach LM systems using both algorithms and human feedback to make them smarter and more aligned with what humans want. So, you may not know this, but it's possible you've participated in RLHF. When using tools like Chat GPT, you might have been asked to choose the best of two responses, which is a form of providing human feedback. This feedback is crucial as it helps train the RLHF reward model which in turn guides the LM to produce better outputs. In essence, by selecting preferred responses, you help the LLM learn what is more aligned with human expectations. So, what are the steps in training an LM with RLHF? Well, first you start with a pre-trained model to provide a solid baseline. This pre-trained model will have already learned a wide range of tasks and language patterns. This foundation allows the RLHF to focus on fine-tuning the model to align with specific human values and preferences. Essentially, starting with a pre-trained model saves time and resources by building on existing knowledge. Now, the next step is getting human feedback. So, how is human feedback collected? Human feedback is gathered by evaluating the LM's outputs, often through preference comparisons rather than direct rewards or penalties. This feedback is used to train a reward model which helps the LLM understand which responses are more desirable. In simple terms, the human feedback acts as a guide, helping the LLM learn what is right and what is wrong based on human standards. Next, we train a reward model using the original prompts and human feedback collected in the previous step. So, what is the role of the reward model and RLHF? A reward model interprets human feedback, translating it into a format the LM can understand to refine its responses. It ensures that the LM responses are aligned with human values by providing a structured way to evaluate outputs. Essentially, the reward model acts as a bridge between human feedback and the LLM, making sure the LLM learns the right lessons. Next, we fine-tune the pre and trade model. Just a quick note on terminology. The newly fine-tuned model you'll also see referred to as the policy model. So, how is the LM fine-tuned? While the LM is fine-tuned using techniques like proximal policy optimization, which helps refine its responses, the training process involves adjusting the model's parameters to better align with the desired outcomes. So after this, the next step is regularization. Regularization uses KL divergence, for example, to help maintain the balance between new learning and retaining previous knowledge. In simple terms, regularization ensures the LM doesn't lose what is already learned while it continues to improve. So the last step, we iterate over the entire process with more human feedback. Iteration involves continuously collecting new feedback to refine the LM's responses and improve its alignment with human values. Essentially, iteration is about keeping the LM up to date and aligned with what humans want through continuous learning. So, why is RLHF so important? Well, the reason is that it leads to more robust and reliable LM systems that are better aligned with human intentions, reducing the risk of unintended responses. By incorporating human feedback, LM models can better understand complex tasks and align their responses with human values and expectations. Okay, so let me know what you think of RLHF. Feel free to share your thoughts in the comments below. I want to hear what you think about this topic. Okay, thanks for watching this video along with all the other business playlist are listed in the YouTube description. I invite you to watch other videos on my channel. If you like the way I'm sharing this content, please consider subscribing. When you subscribe, this really helps my channel grow. One last thing, we all love technology and we're all excited about all the innovation with the cloud and machine learning, AI, but don't forget to carve out some time to live in the real world. Go outside, go swimming, go hiking, go climbing, go surfing, and get out and move your body. And if you do, let me know in the comments. I want to hear about this as well. And with that, have a great day. Thanks.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Explicação objetiva sobre RLHF (aprendizado por reforço com feedback humano), como funciona, etapas de treinamento e por que ajuda a alinhar modelos de linguagem com valores humanos.",
            "resumo": "RLHF é uma abordagem de aprendizado de máquina que combina aprendizado por reforço com feedback humano para alinhar modelos de linguagem aos valores humanos. O vídeo explica que, ao usar ferramentas como o ChatGPT, os usuários costumam escolher a melhor entre duas respostas, gerando o feedback que alimenta o modelo de recompensa. As etapas incluem iniciar com um modelo pré-treinado, coletar feedback humano via comparações de preferências, treinar um modelo de recompensa e usar esse modelo para ajustar o LM (conhecido também como modelo de política). O ajuste fino é feito com técnicas como PPO, seguido de regularização com divergência KL para manter o conhecimento anterior. O processo é iterativo, com mais feedback humano para melhorar continuamente. O resultado é maior robustez e alinhamento com intenções humanas.",
            "assunto_principal": "Aprendizado por reforço com feedback humano (RLHF) em modelos de linguagem",
            "palavras_chave": [
              "aprendizado por reforço a partir de feedback humano",
              "aprendizado por reforço",
              "feedback humano",
              "modelos de linguagem",
              "modelo de recompensa",
              "ajuste fino",
              "PPO",
              "otimização de política proximal",
              "regularização",
              "divergência de Kullback-Leibler",
              "alinhamento de valores humanos",
              "robustez"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- O que é RLHF\n- Coleta de feedback humano (comparações de preferências)\n- Papel do modelo de recompensa\n- Ajuste fino do LM (modelo de linguagem) com PPO\n- Regularização com divergência KL\n- Iteração contínua com mais feedback\n- Benefícios: maior robustez e alinhamento com as intenções humanas",
            "prompt_tokens": 1109,
            "completion_tokens": 4774,
            "model": "gpt-5-nano",
            "cost": 0.0077
          },
          "analysis_time": 67.8313798904419,
          "language": "",
          "view_count": 145,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@OlharDigital",
      "name": "@OlharDigital",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "32OoKx168fY",
          "title": "Trump deve aprovar acordo para venda do TikTok nos EUA",
          "title_pt": "Trump deve aprovar acordo para venda do TikTok nos EUA",
          "url": "https://www.youtube.com/watch?v=32OoKx168fY",
          "published": "2025-09-23T12:00:37.463372",
          "published_relative": "há 46 minutos",
          "duration": "04:37",
          "date_published": "2025-09-23T05:00:10-07:00",
          "transcript_available": true,
          "transcript": "O presidente dos Estados Unidos, Donald Trump, deve anunciar esta semana que o acordo para separar as operações do TikTok no país cumpre os requisitos da lei de 2024, que exige a venda dos ativos da plataforma. Segundo uma autoridade da Casa Branca revelou para Reuters, o negócio contará com investidores americanos. A Bitdense ficará com menos de 20% de participação. Todos os dados de usuários americanos serão armazenados em nuvem nos Estados Unidos, sob gestão da Oracle. A Casa Branca não terá assento no conselho, nem participação acionária na nova empresa. Vamos acompanhando os detalhes dessa história. Umas horas entramos em uma nova estação. Junto com ela chegou um evento astronômico relativamente raro. Vamos entender agora. [Música] A primavera no hemisfério sul começou nesta segunda-feira, precisamente às 3:19 da tarde. Com isso, experimentamos um fenômeno astronômico marcante, o equinócio, que ocorre quando o sol está diretamente sobre a linha do Equador. Por isso, os hemisférios recebem a mesma quantidade de luz e assim o dia e a noite tem praticamente a mesma duração em todos os lugares da Terra. É dessa particularidade que vem a palavra equócio, que no latim significa noite igual. O evento também marca o começo do outono no hemisfério norte e simboliza a transição natural entre as estações. Apesar de ocorrer todos os anos, podemos dizer que é um evento raro. Isso porque a Terra obedece tanto a um movimento de translação ao redor do Sol, quanto a um movimento no seu eixo de rotação. Com isso, a incidência de luz sobre os hemisférios será diferente em quase todos os dias do ano, exceto por essas duas datas. Além deste 22 de setembro, o equinócio de outono no Brasil foi no dia 19 de março. [Música] Começando o nosso giro pelos mais recentes lançamentos dos streamings com a HBO Max. Se você ainda não assistiu ao novo filme do Superman, essa é uma boa oportunidade. Vamos ver. [Música] Vamos. O superhomem, um dos heróis mais icônicos dos quadrinhos e do cinema, voltou às telonas em 2025 com uma nova versão dirigida por James Gun. O personagem que atravessou gerações como símbolo de força, esperança e justiça retorna para explorar de forma mais profunda a dualidade entre suas origens criptonianas e sua vida terrena, como Clark Kent. Dessa vez, ele é interpretado por David Corenswet. O filme reúne grandes figuras do universo do herói, como Lex Lutor, Louis Lane, Lanterna Verde e A Mulher Gavião, colocando Superman diante de novos desafios sem um mundo que questiona se seus ideais ainda têm lugar. James Gun, no entanto, trouxe uma camada adicional à narrativa. Em vez de ser uma espécie de personificação dos Estados Unidos, o Superman volta como um guardião universal. Essa abordagem mais crítica e política repercutiu bastante, já que o longa não apenas revisita o herói clássico, mas também o atualiza. Superman já está disponível nab Max. >> Vamos, me leva para casa. No domingo, teremos o final da temporada da minisérie brasileira Máscaras de Oxigênio não cairão automaticamente. Baseado em fatos reais, a história acompanha um grupo de comissários de bordo que, ao ver amigos e colegas adorecerem de Aides durante a década de 1980, sem acesso a tratamento, iniciou uma operação arriscada para trazer legalmente o medicamento AZ do exterior, mobilizando uma rede de solidariedade em meio à negligência do governo diante da crise. É burrice. >> O que a gente tá fazendo? Alguém tem que fazer. Posso ver as malas pequenas, por favor? [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo analisa a possível aprovação, pelos EUA, de um acordo para vender o TikTok, com investidores americanos e Oracle cuidando dos dados, seguido de explicações sobre o equinócio e destaques de lançamentos de streaming e da minissérie brasileira Máscaras de Oxigênio.",
            "resumo": "O vídeo inicia com a expectativa de que Trump anuncie que o acordo para separar as operações do TikTok nos EUA atende à lei de 2024, incluindo venda de ativos, participação de investidores americanos e Bitdense com menos de 20% de participação. Dados de usuários americanos ficarão armazenados em nuvem nos EUA, sob gestão da Oracle, e a Casa Branca não terá assento no conselho. Em seguida, explica brevemente o equinózio, o dia em que há equilíbrio entre dia e noite, decorrente dos movimentos da Terra. O conteúdo também traz novidades de streaming: o Superman de James Gunn, com David Corenswet, disponível na HBO Max, que reimagina o herói como guardião universal. Por fim, comenta a minissérie brasileira Máscaras de Oxigênio, baseada em fatos reais, sobre comissários de bordo que ajudam a levar AZ ao Brasil na década de 1980, em resposta à crise de saúde.",
            "assunto_principal": "Possível venda do TikTok nos EUA e implicações legais de 2024, com foco em participação acionária, armazenamento de dados e governança, seguido por segmentos sobre equinócio e cultura pop (streaming).",
            "palavras_chave": [],
            "resumo_em_topicos": "- Abertura com expectativa de anúncio de Trump sobre o acordo para vender o TikTok nos EUA, com condições: investidores americanos, Bitdense < 20%, dados de usuários armazenados em nuvem nos EUA com Oracle, Casa Branca sem assento no conselho.\n- Explicação do equinócio de primavera no hemisfério sul, significado de igualdade de dia e noite e a ideia de transição entre estações.\n- Destaques de streaming: novo Superman dirigido por James Gunn, estrelado por David Corenswet, disponível na HBO Max.\n- Encerramento com a minissérie brasileira Máscaras de Oxigênio, baseada em fatos reais, sobre comissários de bordo que ajudam a levar AZ ao Brasil na década de 1980, evidenciando a negligência governamental.",
            "prompt_tokens": 948,
            "completion_tokens": 3849,
            "model": "gpt-5-nano",
            "cost": 0.0062
          },
          "analysis_time": 82.66067099571228,
          "language": "",
          "view_count": 177,
          "has_transcript": false
        },
        {
          "id": "F-wBwa0wVio",
          "title": "Como será a primavera no Brasil? Confira a previsão do tempo",
          "title_pt": "Texto: Como será a primavera no Brasil? Confira a previsão do tempo",
          "url": "https://www.youtube.com/watch?v=F-wBwa0wVio",
          "published": "2025-09-23T02:46:37.463438",
          "published_relative": "há 10 horas",
          "duration": "03:55",
          "date_published": "2025-09-22T19:00:13-07:00",
          "transcript_available": true,
          "transcript": "Vamos ver agora como fica a previsão dos próximos dias. [Música] A nova estação começa com uma frente fria impulsionada por um ciclone extra tropical no Atlântico Sul. E o clima vai ficar instável em várias regiões do país com previsão de chuva, segundo a climatempo. No sul, os temporais devem dar uma trégua nesta terça-feira, mas o risco de ventania permanece para Santa Catarina e Paraná, superando a marca de 70 km/h. Além de rajadas de vento, raios e chuvas são esperados para o Sudeste e Centro-Oeste neste início de semana. Toda a região metropolitana de São Paulo, por exemplo, tem risco elevado para quedas de árvores, pontos de alaramento e cortes no sistema de energia elétrica. A frente fria também vai se estender por Mato Grosso do Sul e o centro sul de Goiás, enquanto as pancadas continuam em Mato Grosso. A previsão de chuva também para Brasília e Cuiabá, mas o calor ainda predomina no extremo norte sul matogrossense, em Goiás e no norte de Mato Grosso. Na região norte, a umidade gera risco de pancadas fortes e temporais isolados sobre o Amazonas, Acre, Rondônia e Roraima. Já no Nordeste, pancadas de chuva seguem ao longo do litoral do Maranhão e do Ceará, além da faixa leste entre a Bahia e o Rio Grande do Norte. No interior, a previsão é de calor intenso. Nesta terça-feira, São Paulo tem temperaturas entre 13 e 19º. Em Brasília, a mínima é de 17 e a máxima é de 29. Em Salvador, os termômetros vão de 25 a 33. Curitiba tem mínima de seis e máxima de 21º. Neste ano, segundo a Climatempo, a primavera será de chuva e calor um pouco acima do normal para algumas áreas do Sudeste e do Centroeste. [Música] Começando o nosso giro pelos mais recentes lançamentos dos streamings com a HBO Max. Se você ainda não assistiu ao novo filme do Superman, essa é uma boa oportunidade. Vamos ver. [Música] Crypto. Vamos. O superhomem, um dos heróis mais icônicos dos quadrinhos e do cinema, voltou às telonas em 2025 com uma nova versão dirigida por James Gun. O personagem que atravessou gerações como símbolo de força, esperança e justiça retorna para explorar de forma mais profunda a dualidade entre suas origens criptonianas e sua vida terrena, como Clark Kent. Dessa vez ele é interpretado por David Corenswewet. O filme reúne grandes figuras do universo do herói, como Lex Lutor, Louis Lane, Lanterna Verde e A Mulher Gavião, colocando Superman diante de novos desafios sem um mundo que questiona se seus ideais ainda têm lugar. James Gun, no entanto, trouxe uma camada adicional à narrativa. Em vez de ser uma espécie de personificação dos Estados Unidos, o Superman volta como um guardião universal. Essa abordagem mais crítica e política repercutiu bastante, já que o longa não apenas revisita o herói clássico, mas também o atualiza. Superman já está disponível nab Max. >> Vamos, me leva para casa. No domingo, teremos o final da temporada da minisérie brasileira Máscaras de Oxigênio não cairão automaticamente. Baseado em fatos reais, a história acompanha um grupo de comissários de bordo que, ao ver amigos e colegas adoecerem de Aides durante a década de 1980, sem acesso a tratamento, iniciou uma operação arriscada para trazer legalmente o medicamento AZ do exterior, mobilizando uma rede de solidariedade em meio à negligência do governo diante da crise. É burrice. >> O que a gente tá fazendo? Alguém tem que fazer. Posso ver as malas pequenas, por favor? [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "A previsão do tempo para os próximos dias é apresentada ao lado de novidades de streaming, incluindo o novo filme do Superman na HBO Max e a minissérie Máscaras de Oxigênio.",
            "resumo": "Este vídeo mescla previsão do tempo com notícias de streaming. Primeiro, descreve a frente fria impulsionada por ciclone extratropical, trazendo instabilidade, chuva e ventos fortes em várias regiões. O Sul pode ter trégua, mas Santa Catarina e Paraná permanecem com risco de ventos acima de 70 km/h; há pancadas, raios e quedas de energia em áreas do Sudeste e Centro-Oeste. A frente avança por MS e centro-sul de Goiás; Mato Grosso continua com pancadas, e Brasília e Cuiabá têm chuva prevista, com calor dominante no norte e centro-norte de MT e GO. No Norte, umidade pode provocar pancadas fortes; no Nordeste, chuva costeira. Temperaturas para terça-feira: SP 13-19°C; Brasília 17-29°C; Salvador 25-33°C; Curitiba 6-21°C. Em seguida, novidades HBO Max: o Superman de James Gunn com David Corenswet; e a minissérie brasileira Máscaras de Oxigênio, baseada em fatos reais.",
            "assunto_principal": "Previsão do tempo no Brasil com foco na chegada de frente fria e instabilidade, aliada a notícias de streaming (HBO Max).",
            "palavras_chave": [
              "previsão do tempo",
              "frente fria",
              "ciclone extratropical",
              "instabilidade climática",
              "ventos fortes",
              "chuvas",
              "queda de árvores",
              "temperaturas",
              "regiões do Brasil",
              "HBO Max",
              "Super-Homem",
              "James Gunn",
              "David Corenswet",
              "Máscaras de oxigênio"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Clima: frente fria associada a ciclone extratropical gera instabilidade, chuva e ventos fortes em várias regiões.\n- Regiões e riscos: Sul com possível trégua; SC e PR com ventos perigosos; Sudeste e Centro-Oeste com pancadas e raios; SP com risco de quedas de árvores; MS e Centro-Oeste com evolução da frente; Norte com umidade e pancadas fortes; Nordeste com chuva costeira.\n- Temperaturas: variação regional; SP 13-19°C; Brasília 17-29°C; Salvador 25-33°C; Curitiba 6-21°C.\n- Primavera: deve trazer mais chuva e calor acima do normal para partes do Sudeste e Centro-Oeste.\n- Entretenimento: HBO Max lança novo Superman dirigido por James Gunn, com David Corenswet; elenco com Lex Luthor, Lois Lane, Lanterna Verde, Mulher-Gavião. Disponível na Max.\n- Máscaras de Oxigênio: minissérie brasileira baseada em fatos reais sobre bombeiros de bordo e a crise de AIDS nos anos 1980, com crítica à negligência governamental.",
            "prompt_tokens": 951,
            "completion_tokens": 6003,
            "model": "gpt-5-nano",
            "cost": 0.0095
          },
          "analysis_time": 77.37816190719604,
          "language": "",
          "view_count": 3241,
          "has_transcript": false
        },
        {
          "id": "zBDL9wMH_ME",
          "title": "Ataque cibernético na Europa: fim de semana tem caos em aeroportos",
          "title_pt": "Ataque cibernético na Europa: fim de semana tem caos em aeroportos",
          "url": "https://www.youtube.com/watch?v=zBDL9wMH_ME",
          "published": "2025-09-23T01:46:37.463460",
          "published_relative": "há 11 horas",
          "duration": "02:55",
          "date_published": "2025-09-22T18:30:54-07:00",
          "transcript_available": true,
          "transcript": "Conforme reportado pelo olhar digital ao longo do fim de semana, um ataque cibernético na noite de sexta-feira afetou vários aeroportos pela Europa. Segundo a agência da União Europeia para Cyber Segurança, informou a BBC, um software malicioso foi usado para embaralhar sistemas de chequin automático. O ataque cibernético invadiu e interrompeu o funcionamento de um software da Collins Aerospace, empresa terceirizada que fornece sistemas para diferentes companhias aéreas de vários aeroportos. Com isso, companhias que usam o serviço para realizar o embarque dos passageiros foram afetadas. Houve transtornos, por exemplo, na Inglaterra, Irlanda, Bélgica e Alemanha. Os passageiros enfrentaram longas filas, cancelamentos e atrasos. A polícia investiga o caso, já imaginaram? E nas ofertas de hoje, olha só, a equipe do Olhar Digital encontrou um smartphone premium com descontão. Vamos ver. [Aplausos] Apesar de ser um smartphone de 2024, o Samsung Galaxy S24 Plus segue como um dos mais avançados dentro do portfólio da fabricante coreana, oferecendo recursos de inteligência artificial via Galaxy AI, além de câmeras de alta qualidade, bateria de longa duração e uma tela capaz de exibir imagens nítidas e vibrantes. Transforme sua televisão mais antiga em uma Smart TV com o Firestick. Basta conectar o aparelho na entrada HDMI e em poucos minutos você tem acesso a plataformas de streaming, música e até jogos. Portátil e leve, ele ainda cabe no bolso ou na mochila. Isso significa que você pode usá-lo em qualquer ambiente, na sala, no quarto ou até em viagens. Esse kit com cinco lâmpadas LED inteligentes da Neo Avant é uma opção prática para quem deseja modernizar a iluminação da casa e deixá-la mais interativa. Elas oferecem instalação simples, basta rosquear e conectá-las à rede Wi-Fi. Com suporte a comandos de voz de Alexa e Google Assistente, elas permitem ligar, desligar e ajustar configurações sem precisar do interruptor tradicional. A última oferta de hoje é um kit da Dell que reúne teclado e mouse sem fios em um conjunto prático e moderno para trabalhar ou estudar. E estamos falando de um ótimo custo benefício. Os links das ofertas, como você já sabe, estão no chat da nossa live. Aproveite. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Um ataque cibernético na noite de sexta-feira atingiu aeroportos europeus, interrompendo sistemas de checagem automática e causando atrasos e cancelamentos enquanto as autoridades investigam.",
            "resumo": "Segundo a cobertura do Olhar Digital, um ataque cibernético na noite de sexta-feira atingiu diversos aeroportos da Europa. A agência da União Europeia para Cyber Segurança, citando informações da BBC, apontou que um software malicioso foi usado para embaralhar sistemas de checagem automática. O ataque invadiu e interrompeu um software da Collins Aerospace, fornecedora terceirizada de sistemas para várias companhias aéreas. Como resultado, companhias que utilizam o serviço enfrentaram transtornos no embarque e nos procedimentos de check-in. Passageiros em países como Inglaterra, Irlanda, Bélgica e Alemanha enfrentaram longas filas, cancelamentos e atrasos. A polícia abriu investigação. O vídeo também inclui promoções de ofertas tecnológicas do canal Olhar Digital.",
            "assunto_principal": "Ataque cibernético a aeroportos europeus e interrupção dos sistemas de embarque",
            "palavras_chave": [
              "ataque cibernético",
              "aeroportos",
              "Europa",
              "sistemas de checagem automática",
              "Collins Aerospace",
              "check-in",
              "embarque",
              "filas",
              "cancelamentos",
              "atrasos",
              "investigação policial",
              "Agência da União Europeia para a cibersegurança"
            ],
            "resumo_em_topicos": "- Contexto: Ataque cibernético na noite de sexta-feira atingiu aeroportos europeus.\n- Impacto operacional: Sistemas de checagem automática foram embaralhados, prejudicando o embarque.\n- Envolvido: Software da Collins Aerospace invadido, fornecedora terceirizada para várias companhias.\n- Consequências para passageiros: Longas filas, cancelamentos e atrasos.\n- Localizações afetadas: Inglaterra, Irlanda, Bélgica e Alemanha.\n- Investigação: Polícia investiga o caso.\n- Contexto de ofertas: bloco de promoções de tecnologia apresentados pelo Olhar Digital.",
            "prompt_tokens": 640,
            "completion_tokens": 3112,
            "model": "gpt-5-nano",
            "cost": 0.005
          },
          "analysis_time": 80.21249294281006,
          "language": "",
          "view_count": 338,
          "has_transcript": false
        },
        {
          "id": "DOm5tdKbdvk",
          "title": "Equinócio de primavera: dia e noite têm a mesma duração nesta segunda (22)",
          "title_pt": "Equinócio da primavera: dia e noite têm a mesma duração nesta segunda-feira (22)",
          "url": "https://www.youtube.com/watch?v=DOm5tdKbdvk",
          "published": "2025-09-23T01:46:37.463475",
          "published_relative": "há 11 horas",
          "duration": "03:33",
          "date_published": "2025-09-22T18:00:20-07:00",
          "transcript_available": true,
          "transcript": "Algumas horas entramos em uma nova estação. Junto com ela chegou um evento astronômico relativamente raro. Vamos entender agora. [Música] A primavera no hemisfério sul começou nesta segunda-feira, precisamente às 3:19 da tarde. Com isso, experimentamos um fenômeno astronômico marcante, o equinócio, que ocorre quando o sol está diretamente sobre a linha do Equador. Por isso, os hemisférios recebem a mesma quantidade de luz e assim o dia e a noite tem praticamente a mesma duração em todos os lugares da Terra. É dessa particularidade que vem a palavra equócio, que no latim significa noite igual. O evento também marca o começo do outono no hemisfério norte e simboliza a transição natural entre as estações. Apesar de ocorrer todos os anos, podemos dizer que é um evento raro. Isso porque a Terra obedece tanto a um movimento de translação ao redor do Sol, quanto a um movimento no seu eixo de rotação. Com isso, a incidência de luz sobre os hemisférios será diferente em quase todos os dias do ano, exceto por essas duas datas. Além deste 22 de setembro, o equinócio de outono no Brasil foi no dia 19 de março. [Música] Vamos ver agora como fica a previsão dos próximos dias. [Música] A nova estação começa com uma frente fria impulsionada por um ciclone extra tropical no Atlântico Sul. E o clima vai ficar instável em várias regiões do país com previsão de chuva, segundo a climatempo. No sul, os temporais devem dar uma trégua nesta terça-feira, mas o risco de ventania permanece para Santa Catarina e Paraná, superando a marca de 70 km/h. Além de rajadas de vento, raios e chuvas são esperados para o Sudeste e Centro-Oeste neste início de semana. Toda a região metropolitana de São Paulo, por exemplo, tem risco elevado para quedas de árvores, pontos de alaramento e cortes no sistema de energia elétrica. A frente fria também vai se estender por Mato Grosso do Sul e o centro sul de Goiás, enquanto as pancadas continuam em Mato Grosso. A previsão de chuva também para Brasília e Cuiabá, mas o calor ainda predomina no extremo norte sul matogrossense, em Goiás e no norte de Mato Grosso. Na região norte, a umidade gera risco de pancadas fortes e temporais isolados sobre o Amazonas, Acre, Rondônia e Roraima. Já no Nordeste, pancadas de chuva seguem ao longo do litoral do Maranhão e do Ceará, além da faixa leste entre a Bahia e o Rio Grande do Norte. No interior, a previsão é de calor intenso. Nesta terça-feira, São Paulo tem temperaturas entre 13 e 19º. Em Brasília, a mínima é de 17 e a máxima é de 29. Em Salvador, os termômetros vão de 25 a 33. Curitiba tem mínima de seis e máxima de 21º. Neste ano, segundo acimatempo, a primavera será de chuva e calor um pouco acima do normal para algumas áreas do Sudeste e do Centroeste. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo explica o equinócio de primavera, quando o Sol fica sobre a linha do Equador, deixando dia e noite com duração quase igual, marcando a transição entre as estações e prevendo uma frente fria com instabilidade climática no Brasil.",
            "resumo": "O vídeo aborda o equinócio de primavera, ocorrido quando o Sol está diretamente sobre a linha do Equador, tornando o dia e a noite de duração quase igual e marcando o início da primavera no hemisfério sul (e do outono no norte). Explica que esse evento depende de movimentos da Terra e ocorre apenas em duas datas do ano. Em seguida, traz a previsão para os próximos dias: uma frente fria impulsionada por ciclone extratropical gerará tempo instável com chuva, ventos fortes, raios e risco de quedas de árvores e interrupção de energia em diversas regiões, incluindo São Paulo, Sul, Sudeste e Centro-Oeste; também aponta calor intenso no norte do país. A primavera é prevista, segundo a climatempo, como período de chuva e temperaturas acima da média em partes do Sudeste e Centro-Oeste.",
            "assunto_principal": "Equinócio da primavera e impactos climáticos no Brasil",
            "palavras_chave": [
              "equinócio",
              "primavera",
              "outono",
              "Sol sobre o Equador",
              "dia e noite iguais",
              "frente fria",
              "ciclone extratropical",
              "instabilidade climática",
              "chuva",
              "ventos fortes",
              "queda de árvores",
              "energia elétrica",
              "previsão climática"
            ],
            "resumo_em_topicos": "- O que é o equinócio e por que o dia e a noite têm durações próximas.\n- Data e significado: ocorre em 22 de setembro no hemisfério sul (início da primavera) e, no hemisfério norte, em 19 de março (início do outono).\n- Origem do termo e por que é considerado raro.\n- Previsão climática: frente fria associada a ciclone extratropical traz instabilidade, chuva, ventos fortes e raios.\n- Riscos regionais: quedas de árvores, alagamentos e interrupção de energia em diversas regiões, incluindo SP.\n- Perspectivas para a primavera: chuva e calor acima da média em partes do Sudeste e Centro-Oeste, segundo a Climatempo.",
            "prompt_tokens": 824,
            "completion_tokens": 5608,
            "model": "gpt-5-nano",
            "cost": 0.0088
          },
          "analysis_time": 81.08052921295166,
          "language": "",
          "view_count": 277,
          "has_transcript": false
        },
        {
          "id": "UgDOXj8r3Dg",
          "title": "Veja as mais belas imagens do eclipse parcial do Sol!",
          "title_pt": "Texto: Veja as mais belas imagens do eclipse parcial do Sol!",
          "url": "https://www.youtube.com/watch?v=UgDOXj8r3Dg",
          "published": "2025-09-23T00:46:37.463488",
          "published_relative": "há 12 horas",
          "duration": "03:31",
          "date_published": "2025-09-22T17:30:25-07:00",
          "transcript_available": true,
          "transcript": "E o fim de semana foi marcado por um eclipse parcial do sol. O Olhar Digital realizou uma transmissão especial ao vivo para você não perder nenhum detalhe desse espetáculo nos céus. Vamos ver agora como foi. Se você não conseguiu acompanhar o último eclipse do ano que aconteceu no domingo, não tem problema. Reunimos as principais imagens desse show astronômico. O fenômeno encerrou a temporada de quatro eclipses em 2025 e como sempre chamou a atenção de astrônomos e apaixonados por astronomia ao redor do mundo. Infelizmente o evento não poôde ser observado diretamente do Brasil. A melhor visibilidade ficou concentrada na Nova Zelândia, Austrália e algumas ilhas do Pacífico. No melhor dos casos, até 80% do disco solar chegou a ser encoberto pela lua. A transmissão do eclipse solar parcial pelo olhar digital foi feita diretamente de Dunedin, na Nova Zelândia, com imagens do time and date. A observação foi parcialmente prejudicada pela nebulosidade que encobriu o céu no início e durante o fenômeno. Algo muito especial é que o eclipse ocorreu junto com o nascer do sol na Nova Zelândia e a live do olhar digital teve até imagens de fora da Terra. Olha só esse registro do satélite Gois 18 da Administração Nacional Oceânica e Atmosférica. Dá para ver muito bem o momento em que um pedacinho do nosso planeta escurece e podemos ver ainda até como os astronautas enxergam um eclipse com esse registro da estação espacial internacional. >> E ali atrás a gente vê o sol e tá essas imagens são ao vivo, né, direto da estação espacial, transmissão da NASA, tá mostrando o sol durante o eclipse, tá? A gente não consegue ver detalhes do eclipse, mas a imagem de toda forma é fantástica, tá? >> Como explicou o astrônomo Marcelo Zurita durante a nossa transmissão, os eclipses vão muito além de um show nos céus. Eles são excelentes oportunidades para a ciência. >> A gente consegue fazer observação da coroa solar, né, da da que é a atmosfera do Sol, basicamente, dos campos magnéticos que vigoram ali na coroa solar. Eh, a gente consegue observar também, Capose, detalhes do relevo lunar, né? Apesar da gente ter sondas orbitando a lua já há algum tempo, a gente consegue observar esses detalhes também durante os eclipses totais da do Sol, né, naquele momento em que se forma o que a gente chama lá de anel de diamante, que apenas uma uma partezinha ali da da do relevo lunar permite a passagem da luz do sol em direção à Terra, tá? Então são coisas que dá para se fazer a partir do estudo de eclipses. Agora, com certeza, o eclipse total do Sol é o eclipse mais valorado, né, mais valioso paraa ciência, né, em função da quantidade de informações que ele trouxe e até hoje traz pra gente, né? Ча.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "A transmissão ao vivo da Olhar Digital cobriu o eclipse solar parcial de 2025 com imagens da Nova Zelândia, destacando registros científicos e a participação da ISS.",
            "resumo": "O fim de semana foi marcado por um eclipse parcial do Sol, com transmissão ao vivo da Olhar Digital de Dunedin, Nova Zelândia. A melhor visibilidade ocorreu na Nova Zelândia, Austrália e algumas ilhas do Pacífico, com até 80% do disco solar encoberto. Nebulosidade inicial prejudicou parte da observação, mas houve registros do GOES-18, da NASA e da Estação Espacial Internacional, incluindo imagens do nascer do sol na Nova Zelândia. O astrônomo Marcelo Zurita ressaltou que eclipses vão além de espetáculo: permitem observar a coroa solar, o campo magnético e detalhes do relevo lunar durante o anel de diamante, contribuindo com dados para a ciência. O evento encerra a temporada de quatro eclipses em 2025 e é considerado especialmente valioso para o estudo solar e lunar.",
            "assunto_principal": "Cobertura do eclipse solar parcial de 2025 pela Olhar Digital, com ênfase em imagens ao vivo e implicações científicas sobre a coroa solar, magnetismo e relevo lunar.",
            "palavras_chave": [
              "eclipse solar parcial",
              "transmissão ao vivo",
              "Olhar Digital",
              "Nova Zelândia",
              "Dunedin",
              "corona solar",
              "campo magnético solar",
              "anel de diamante",
              "relevo lunar",
              "GOES-18",
              "NASA",
              "Estação Espacial Internacional",
              "observação científica",
              "astronomia"
            ],
            "resumo_em_topicos": "### Visão geral\n- Fenômeno: eclipse solar parcial em 2025\n- Transmissão ao vivo pela Olhar Digital, de Dunedin, Nova Zelândia\n\n### Características da observação\n- Melhor visibilidade na Nova Zelândia, Austrália e algumas ilhas do Pacífico\n- Cobertura do disco: até 80%\n- Nebulosidade inicial dificultou o início e parte do fenômeno\n- Registros: GOES-18, NASA e ISS\n\n### Aspectos científicos destacados\n- Possibilita estudo da coroa solar e dos campos magnéticos\n- Observação de relevo lunar com o anel de diamante\n\n### Conclusão\n- Eclipse total é especialmente valioso para a ciência\n- Evento encerrou a temporada de quatro eclipses em 2025",
            "prompt_tokens": 766,
            "completion_tokens": 3072,
            "model": "gpt-5-nano",
            "cost": 0.005
          },
          "analysis_time": 71.18159294128418,
          "language": "",
          "view_count": 452,
          "has_transcript": false
        },
        {
          "id": "fj1s3e2Fqk4",
          "title": "Olhar Espacial: e se o lixo em órbita impedir missões e tecnologias no espaço?",
          "title_pt": "Texto: Olhar Espacial: e se o lixo em órbita impedir missões e tecnologias no espaço?",
          "url": "https://www.youtube.com/watch?v=fj1s3e2Fqk4",
          "published": "2025-09-22T14:46:37.463502",
          "published_relative": "há 22 horas",
          "duration": "07:53",
          "date_published": "2025-09-22T07:01:12-07:00",
          "transcript_available": true,
          "transcript": "Um estudo de quase 50 anos atrás mostra que a ocupação desordenada da órbita terrestre pode gerar um caos que inviabilizaria futuras missões espaciais. Essa previsão é o assunto de hoje da nossa coluna Olhar Espacial. Chegou a vez de Marcelo Zurita. Vamos com ele. Olá, pessoal. Saudações astronômicas. Imagine olhar pro céu e perceber que não podemos mais atravessá-lo. Nem foguetes, nem sondas, nem astronautas. O caminho pro espaço que sempre foi nosso símbolo de liberdade do nosso avanço tecnológico, fechado por uma cortina de entulho orbital. Parece ficção científica, pois saiba que já existem dezenas de milhares de satélites e partes de foguetes, além de milhões de fragmentos menores orbitando a Terra. Será que estamos aos poucos criando uma cortina de lixo espacial que poderá nos condenar ao confinamento cósmico? Se isso soa como uma preocupação moderna, fruto da era das megas constelações de satélite, saiba que há quase 50 anos esse cenário já tirava o sono de um renomado cientista da NASA. Nascido em 1940, Donald Kessler é um físico americano que cresceu no Texas e nos anos 60 foi trabalhar na NASA, mais especificamente no Johnson Space Center em Houston. Kler foi controlador de voo da Skylab, a primeira estação espacial dos Estados Unidos lançada em 73. Mas foi em 1978 que ele publicou o estudo que mais tarde ficaria conhecido como a síndrome de Kessler. Ele alertava que à medida que a quantidade de objetos em órbita aumentava, crescia também o risco de colisões. E cada colisão gera milhares de fragmentos que, por sua vez, podem atingir outros satélites, criando uma reação em cadeia incontrolável. O resultado? Uma densidade de detritos tão grande que a órbita da Terra se tornaria inutilizável por décadas, talvez séculos. Algo que vai muito além de um simples incômodo pros astrônomos. Estamos falando de perder comunicações, navegação por GPS, previsão do tempo, monitoramento ambiental, internet via satélite, tudo que hoje é essencial pro nosso dia a dia. E sabe qual o pior? Talvez estejamos muito próximos desse cenário caótico previsto por Kessler. Depois de décadas de exploração espacial, mais de 40.000 os satélites e restos de foguetes foram colocados na órbita da Terra. A maioria deles sem qualquer preocupação com o destino desses objetos depois que eles perdessem utilidade. Em 2007, algo preocupante aconteceu. A China destruiu um dos seus satélites no que pareceu ser um teste de um sistema antissatélite. Além de espalhar milhares de fragmentos em órbita, isso mostrou que um futuro conflito global pode ter o espaço como campo de batalha. E não parou por aí. Dois anos depois, um satélite comercial da empresa Iridum colidiu com o satélite militar russo, adicionando ainda mais lixo espacial ao cinturão orbital. Restos de foguetes, satélites inativos e detritos com pelo menos 10 cm são catalogados e podem ser monitorados para evitar novas colisões. Mas os fragmentos menores invisíveis aos nossos telescópios vagam sorrateiramente a mais de 28.000 1000 km/h e podem destruir um satélite inteiro, abrir um rombo na estação espacial internacional ou até mesmo atingir um foguete durante uma missão, causando uma explosão catastrófica. Mais cedo ou mais tarde, todo detrito em órbita baixa da Terra irá perder a altitude, reentrar e ser destruído pela atmosfera. Mas antes disso pode colidir com outros objetos em órbita e dar início a uma reação em cadeia que transformaria o espaço próximo ao nosso planeta em um verdadeiro campo minado. Ainda em 2009, o próprio Donald Castler alertou que o ambiente de detritos orbitais poderia já ter se tornado instável segundo seu modelo. Isso significa que novas colisões futuras acumulariam fragmentos mais rapidamente do que a nossa atmosfera é capaz de consumir. As consequências possíveis vão muito além da poluição do céu noturno, o que já vem atrapalhando o trabalho de astrônomos. Em um cenário extremo, poderíamos de fato ficar presos em uma verdadeira cortina de lixo espacial. Imagine não conseguir mais lançar foguetes, instalar novos satélites ou manter os que já estão em funcionamento. A Terra isolada, sem previsão de tempo confiável, sem comunicação global, sem internet via satélite, sem GPS, seria a morte do A e a ressurreição do guia quatro rodas. Até mesmo as operações bancárias seriam afetadas. Um bloqueio orbital teria um impacto não apenas na exploração do espaço, mas também na nossa vida aqui embaixo. E o que está sendo feito para evitar esse futuro distópico? Algumas iniciativas já existem. A ONU estabeleceu diretrizes para limitar a ploriferação de detritos. Satélites mais modernos são projetados para liberar combustível residual e assim evitar explosões acidentais. Foram criados protocolos que exigem que satélites mortos sejam removidos da órbita útil em até 25 anos. Ainda que convenhamos seja muito tempo por um problema que cresce em ritmo acelerado. Também existem projetos de limpeza ativa, redes que pescam satélites nativos, arpões espaciais, velas solares para desacelerar e desorbitar lixo e até propulsores dedicados à remoção de sucata orbital. Missões como a Remove the Brez da ESA já testaram algumas dessas tecnologias. O Japão e a Europa planejam missões próprias, mas diante da multiplicação dos lançamentos, tudo isso ainda é uma gota d'água em um oceano orbital de detritos. E o futuro pode desafiar ainda mais a nossa capacidade de controle. Constelações gigantes como a Starlink da SpaceX, o projeto CPER da Amazon e outros em planejamento prometem colocar dezenas de milhares de novos satélites na órbita baixa da Terra. Isso significa mais riscos de colisões, mais necessidade de monitoramento, mais responsabilidade coletiva. Quanto mais dependentes nos tornamos do espaço, mais vulneráveis ficamos a um colapso orbital. E aí fica a pergunta incômoda. Será que a pressa em ocupar o espaço não pode acabar nos confinando em nosso próprio planeta? O espaço, que sempre foi um símbolo da liberdade do infinito, corre o risco de se transformar em um cárcere criado pelas nossas próprias mãos. O cenário previsto por Donald Kessler há quase meio século ainda não se tornou realidade, mas os sinais de alerta estão soando no painel de controle da humanidade. Pouco foi feito até aqui para reverter o quadro, mas ainda há tempo de agir com responsabilidade. A síndrome de Kessler não é uma previsão sombria de um futuro inevitável. É um alerta que nos mostra a necessidade de explorarmos o espaço próximo à Terra de forma consciente e sustentável, para que ele continue sendo o caminho para que a humanidade alcance novas fronteiras e não os limites do nosso confinamento cósmico sob uma cortina de lixo espacial. Bons céus a todos e até a próxima. Ча.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo analisa a síndrome de Kessler e o risco crescente de lixo orbital, que pode restringir o acesso humano ao espaço e afetar tecnologias na Terra.",
            "resumo": "Um estudo de quase meio século atrás alertou que a ocupação desordenada na órbita terrestre pode levar a uma reação em cadeia de colisões, gerando detritos que tornam a órbita inóspita por décadas ou séculos. O vídeo apresenta a síndrome de Kessler, criada por Donald Kessler em 1978, que descreve como colisões produzem fragmentos que elevam o risco de novas colisões, prejudicando satélites, comunicações, GPS, previsão do tempo e internet via satélite. O aumento de satélites e detritos, incluindo eventos como o teste chinês de destruição de satélite em 2007 e a colisão Iridium-Roscos, agrava o cenário. Fragmentos menores que 10 cm são difíceis de monitorar, mas podem destruir satélites. Medidas existentes incluem diretrizes da ONU para reduzir detritos, remoção de satélites mortos em até 25 anos e pesquisas de limpeza ativa, ainda fracas frente ao crescimento das megaconstelações.",
            "assunto_principal": "Risco de lixo orbital e a Síndrome de Kessler, seus impactos na exploração espacial e na vida na Terra, e as medidas de mitigação diante das megaconstelações.",
            "palavras_chave": [
              "síndrome de Kessler",
              "lixo espacial",
              "detritos orbitais",
              "colisões em órbita",
              "órbita baixa da Terra",
              "mega-constelações",
              "Starlink",
              "mitigação de detritos",
              "limpeza ativa",
              "RemoveDEBRIS (ESA)",
              "ONU",
              "telecomunicações espaciais"
            ],
            "resumo_em_topicos": "- Contexto histórico: a síndrome de Kessler (1978) e o alerta sobre o aumento de detritos gerando uma cascata de colisões.\n- Cenário atual: dezenas de milhares de satélites e fragmentos, incluindo detritos acima de 10 cm monitoráveis e fragmentos menores que podem destruir satélites.\n- Eventos marcantes: teste anti-satélite da China em 2007 e a colisão Iridium-Roscos, que aumentaram o lixo orbital.\n- Consequências: interrupção de GPS, comunicações, previsão do tempo, internet via satélite e demais serviços essenciais.\n- Medidas em vigor: diretrizes da ONU, remoção de satélites mortos em até 25 anos, design para reduzir explosões acidentais, e pesquisas de limpeza ativa (RemoveDEBRIS, Japão, Europa).\n- Desafios futuros: megaconstelações elevando o tráfego orbital e o risco de colisões, exigindo monitoramento e cooperação global.\n- Conclusão: a síndrome de Kessler não é inevitável; é necessário agir com responsabilidade para explorar o espaço de forma sustentável e evitar que o planeta seja confinado por lixo orbital.",
            "prompt_tokens": 1665,
            "completion_tokens": 4150,
            "model": "gpt-5-nano",
            "cost": 0.0071
          },
          "analysis_time": 71.51440000534058,
          "language": "",
          "view_count": 1860,
          "has_transcript": false
        },
        {
          "id": "wQZPYvH3UKo",
          "title": "Ter um gato é bom para o seu cérebro, segundo a Ciência",
          "title_pt": "Texto: Ter um gato é bom para o seu cérebro, segundo a ciência",
          "url": "https://www.youtube.com/watch?v=wQZPYvH3UKo",
          "published": "2025-09-22T13:46:37.463516",
          "published_relative": "há 23 horas",
          "duration": "01:34",
          "date_published": "2025-09-22T06:02:01-07:00",
          "transcript_available": true,
          "transcript": "Ter um gato pode melhorar a sua saúde. Estudos mostram que interações carinhosas com os felinos, como fazer um cafuné ou ouvir aquele ronronar, aumentam os níveis deitocina, o famoso hormônio do amor. Esse hormônio ajuda a relaxar, diminui o estresse, reduz o cortisol e até contribui para baixar a pressão arterial. E não são só os humanos que se beneficiam. Os gatinhos também liberam ositocina, especialmente quando sobem no nosso colo ou recebem uma fago. Então, da próxima vez que o seu gato piscar lentamente ou se aconchegar em você, lembre-se, não é apenas um gesto fofo, é um ciclo invisível de confiança, afeto e bem-estar acontecendo entre vocês. Mas atenção, as interações devem respeitar o conforto dos nossos pets. Alguns gatos podem ser mais ansiosos ou evitarem contato e, portanto, podem reagir de forma diferente. As informações são de Laura Ellen Pigot, professora senior em neurociências e neurorreabilitação da Universidade London South Bank. Ela escreveu um artigo para o site de conversation. Segundo ela, os gatos podem ter uma reputação de independência, mas pesquisas emergentes sugerem que compartilhamos uma conexão única com eles, alimentada inclusive pela química do nosso cérebro. Nas palavras dela, a chave para criar laços com gato é entender como ele se comunica. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Ter um gato pode beneficiar a saúde cerebral ao aumentar a oxitocina por meio de carinhos, ronronar e proximidade, fortalecendo o vínculo humano-gato desde que as interações respeitem o conforto do animal.",
            "resumo": "O vídeo explica que interações carinhosas com gatos elevam a oxitocina nos humanos, o que ajuda a relaxar, reduzir o estresse, diminuir o cortisol e pode contribuir para baixar a pressão arterial. Os gatos também liberam oxitocina, especialmente quando sobem no colo ou recebem afeto, criando um ciclo de confiança e bem-estar entre humanos e felinos. Embora os gatos sejam conhecidos pela independência, pesquisas emergentes sugerem uma conexão única alimentada pela química do cérebro. A mensagem central é que o vínculo se constrói ao entender como o gato se comunica, respeitando seu conforto e limites, pois alguns são mais ansiosos ou evitam contato. As informações são da pesquisadora Laura Ellen Pigot, professora sênior em neurociências e neurorreabilitação da Universidade London South Bank, em artigo para o The Conversation.",
            "assunto_principal": "Conexão humano-gato e efeitos da oxitocina no bem-estar",
            "palavras_chave": [
              "oxitocina",
              "gatos",
              "bem-estar",
              "estresse",
              "cortisol",
              "pressão arterial",
              "conexão humano-gato",
              "comunicação felina",
              "ronronar",
              "cafuné"
            ],
            "resumo_em_topicos": "- Benefícios da oxitocina: interações carinhosas com gatos elevam a oxitocina em humanos, contribuindo para relaxamento e bem-estar.\n- Efeito nos gatos: felinos também liberam oxitocina, especialmente quando ficam no colo ou recebem afeto.\n- Ciclo de confiança: humanos e gatos formam um laço baseado na química do cérebro e no afeto mútuo.\n- Cuidados: as interações devem respeitar o conforto do pet, pois alguns gatos são mais ansiosos ou evitam contato.\n- Base científica: informações de Laura Ellen Pigot, professora sênior em neurociências e neurorreabilitação da Universidade London South Bank, em artigo para The Conversation.\n- Conclusão: a conexão pode ser única e depende de compreender a comunicação do gato.",
            "prompt_tokens": 453,
            "completion_tokens": 4172,
            "model": "gpt-5-nano",
            "cost": 0.0065
          },
          "analysis_time": 68.70327615737915,
          "language": "",
          "view_count": 3268,
          "has_transcript": false
        },
        {
          "id": "gtxw-mfUREk",
          "title": "Apophis: o primeiro asteroide potencialmente perigoso visível a olho nu",
          "title_pt": "Apophis: o primeiro asteroide potencialmente perigoso visível a olho nu",
          "url": "https://www.youtube.com/watch?v=gtxw-mfUREk",
          "published": "2025-09-22T12:46:37.463529",
          "published_relative": "há 1 dia",
          "duration": "05:28",
          "date_published": "2025-09-21T09:01:12-07:00",
          "transcript_available": true,
          "transcript": "Em 202, um gigantesco visitante cruzará os céus do nosso planeta. Apesar de uma preocupação inicial com o asteroide apóf, não há riscos e essa será uma grande oportunidade para a ciência. Vamos entender os detalhes na reportagem. [Música] Em menos de 4 anos, quando o asteroide Apofes passar perto da Terra, ele poderá ser visto a olho nu por mais de 2 bilhões de pessoas na África e na Europa. A sua luminosidade no céu será comparável à das estrelas da constelação da ursa maior. Um espetáculo raro. Segundo estimativas, a aproximação de um asteroide desse porte com cerca de 340 m de comprimento, o que equivale ao tamanho da torre fel. só acontece a cada 7.500 anos. Richard Binel, professor do MIT, destacou durante o Europet Science Congress, que foi realizado este mês em Helsink, na Finlândia, que será a primeira vez na história espacial que um asteroide potencialmente perigoso será visível a olho nu, mas ele tranquiliza, o apóf vai passar insegurança pela Terra. O asteroide foi descoberto em 2004 e na época chegou a preocupar a comunidade científica. As estimativas iniciais apontavam uma chance de 2,7% de colisão. O nome escolhido para ele foi Apofes, em referência ao deus egípcio do caos e da destruição. Durante os últimos 20 anos, cientistas acompanharam de perto a trajetória da rocha espacial. Em 2021, novos cálculos confirmaram que não há risco de impacto nos próximos 100 anos, o que levou à retirada do asteroide da lista de ameaças. A passagem vai acontecer no dia 13 de abril de 2029. O Apófis vai chegar a 30.000 1000 km da Terra, mais próximo do que muitos satélites. A gravidade do nosso planeta poderá alterar a rotação e até a órbita do objeto. A NASA já se prepara para estudar de perto a aproximação usando a espaçonave que fez parte da missão Osiris Hex, que coletou amostras do asteroide Benu. O objetivo é mapear a superfície e monitorar o giro do apófis. Já a Agência Espacial Europeia planeja a missão Ramses, que se aprovada vai observar o asteroide antes, durante e depois dessa visita. [Música] E a Agência Espacial dos Estados Unidos alerta: \"O Sol está ficando mais agitado e não entendemos os motivos. Na semana que vem, novas missões devem decolar para investigar melhor a atividade da nossa estrela. Vamos acompanhar. >> O sol está ficando cada vez mais ativo, como mostra o novo estudo da NASA. Desde 2008, os cientistas notam que a atividade solar vem aumentando e isso depois de um período de queda que durava desde os anos 1980. Em 2008, o sol chegou ao ponto mais fraco já registrado e muitos especialistas achavam que nossa estrela entraria em uma fase prolongada de baixa atividade. Mas o que aconteceu foi o contrário. O sol começou a despertar e está cada vez mais ativo. Essas percepções foram documentadas em artigo publicado no The Astrophysical Journal Letters e podem indicar um aumento de tempestades solares, erupções e ejeções de massa coronal. Eventos que afetam o chamado clima espacial. O monitoramento da atividade solar começou no século X7, quando Galileu e outros astrônomos passaram a contar as manchas solares. Essas regiões mais escuras e frias na superfície do Sol são causadas por campos magnéticos intensos e costumam estar associadas a explosões e grandes liberações de plasma. A NASA acompanha de perto essas variações porque elas podem interferir em naves espaciais, comunicações, GPS, redes elétricas e até na segurança dos astronautas. Isso é ainda mais importante agora com os planos da agência para levar humanos de volta à lua nas missões Ártemis. No dia 23 de setembro, três novas missões, sendo duas da NASA e uma da Administração Nacional Oceânica e Atmosférica dos Estados Unidos devem ser lançadas para estudar o clima espacial com ainda mais precisão. O aumento da atividade solar afeta também os campos magnéticos da Terra e de planetas vizinhos. O vento solar, que é um fluxo de partículas emitido pela nossa estrela, pode expandir ou comprimir esses escudos que nos protegem da radiação. Os registros mostram que os períodos mais calmos do Sol aconteceram entre 1645 e 1715 e depois entre 1790 e 1830. Mas os cientistas ainda não sabem explicar completamente porque esses mínimos aconteceram. Segundo o comunicado da NASA, as tendências de longo prazo são muito menos previsíveis e são algo que ainda não compreendemos completamente. Com o avanço da tecnologia e as próximas missões previstas, podemos nos aproximar dessas respostas. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo explica a passagem de Apophis em 2029, possível de ser vista a olho nu, as missões para estudá-lo e as implicações da atividade solar para o clima espacial e a proteção de naves e redes terrestres.",
            "resumo": "O vídeo traz uma visão geral sobre o asteroide Apophis, cuja passagem perto da Terra, prevista para 13 de abril de 2029, poderá tornar o objeto visível a olho nu para bilhões de pessoas, criando um espetáculo raro. Apophis tem cerca de 340 metros e, estimativas anteriores chegaram a 2,7% de chance de colisão, mas cálculos mais recentes eliminaram esse risco para os próximos 100 anos. A órbita próxima gerará distúrbios gravitacionais que podem afetar sua rotação e trajetória. A NASA planeja estudá-lo com a sonda OSIRIS-REx e a ESA com a missão Ramses. O vídeo também aborda o Sol cada vez mais ativo desde 2008, o que pode aumentar tempestades solares e a necessidade de monitoramento para proteger naves, GPS, redes elétricas e astronautas, especialmente com os planos para Artemis.",
            "assunto_principal": "Passagem do asteroide Apophis em 2029 e estudo científico, aliado ao aumento da atividade solar e suas implicações no clima espacial.",
            "palavras_chave": [
              "Apophis",
              "asteroide potencialmente perigoso",
              "passagem próxima",
              "visibilidade a olho nu",
              "NASA",
              "OSIRIS-REx",
              "Ramsés",
              "ESA",
              "clima espacial",
              "atividade solar",
              "tempestades solares",
              "ejeção de massa coronal",
              "Artemis",
              "The Astrophysical Journal Letters"
            ],
            "resumo_em_topicos": "### Apophis, data e visibilidade\n- Apophis, ~340 m de diâmetro, deverá passar próximo à Terra em 13 de abril de 2029, com possibilidade de ser visto a olho nu.\n- Distância prevista: cerca de 31 mil quilômetros da superfície, mais próximo que muitos satélites.\n- Nível de brilho sugerido similar ao brilho de estrelas da Ursa Maior.\n\n### História e risco\n- Descoberto em 2004; risco inicial de colisão estimado em 2,7%.\n- Nos últimos 20 anos, estudos acompanharam a trajetória; em 2021, cálculos retiraram o risco de impacto nos próximos 100 anos.\n\n### Missões e observação\n- NASA planeja estudar o asteroide com a missão OSIRIS-REx; ESA planeja a missão Ramses para observar o objeto antes, durante e depois da passagem.\n\n### Sol ativo e clima espacial\n- O Sol vem ficando mais ativo desde 2008, após um período de mínima; pode haver aumento de tempestades solares e ejeções de massa coronal.\n- Variações solares impactam o clima espacial, com efeitos em naves, comunicações, GPS, redes elétricas e astronautas.\n\n### Importância e contextos futuros\n- Com as missões Artemis, a compreensão do clima espacial torna-se crucial para a exploração humana.\n- O vídeo enfatiza a necessidade de monitoramento contínuo para entender a interação entre o Sol, a Terra e objetos próximos à Terra.",
            "prompt_tokens": 1189,
            "completion_tokens": 4592,
            "model": "gpt-5-nano",
            "cost": 0.0075
          },
          "analysis_time": 75.72000908851624,
          "language": "",
          "view_count": 6236,
          "has_transcript": false
        },
        {
          "id": "V7OAQyobtiw",
          "title": "Tem empresa pagando pela mineração da Lua - e essa tecnologia ainda nem existe!",
          "title_pt": "Tem empresa pagando pela mineração da Lua - e essa tecnologia ainda nem existe!",
          "url": "https://www.youtube.com/watch?v=V7OAQyobtiw",
          "published": "2025-09-22T12:46:37.463546",
          "published_relative": "há 1 dia",
          "duration": "04:43",
          "date_published": "2025-09-21T08:01:00-07:00",
          "transcript_available": true,
          "transcript": "A corrida espacial é também uma corrida econômica. Algumas tecnologias que ainda nem existem e que nem sabemos se vão existir um dia são levadas em consideração em planos ambiciosos. Vamos entender. [Música] A exploração da lua pode estar mais próxima do que se imagina, mas não por meio da mineração tradicional. Empresas já estão adquirindo recursos do satélite natural da Terra antes mesmo de extrair qualquer material. Recentemente, a fabricante finlandesa de tecnologia Blue Force, especializada em sistemas de refrigeração ultra frios essenciais para computação quântica, comprou dezenas de milhares de litros de Hélio 3 lunar por meio da empresa comercial espacial Interlun. O investimento ultrapassou 300 milhões de dólares, tornando-se a maior aquisição de um recurso natural do espaço já registrada. Segundo informações do jornal de Washington Post, que conversou com representantes das duas empresas, o Hélio 3 é diferente do hélio comum usado em balões. Acredita-se que ele seja abundante na superfície da lua, exposta diretamente aos ventos solares, sem a proteção de uma atmosfera. Cientistas e empresas vem o Hélio 3 como um recurso estratégico por suas propriedades únicas. Ele não é radioativo, é extremamente leve e possibilita resfriamento de computadores quânticos avançados. Além disso, ele pode ser usado como combustível em reatores de fusão nuclear limpa. A fusão nuclear busca reproduzir o processo que acontece no núcleo do Sol, onde átomos de hidrogênio se fundem para gerar energia. Essa tecnologia é vista como uma alternativa limpa a fição nuclear, pois não gera resíduos radioativos de longa duração. Apesar de ainda não existir tecnologia operacional para minerar LO3 em larga escala na lua, a Interlon aposta no gás lunar como motor de uma nova era tecnológica. A compra milionária realizada pela Blue Force mostra que o mercado já começa a valorizar recursos extraterrestres, antecipando o futuro da exploração espacial comercial. E conforme noticiado pelo olhar digital, a NASA anunciou na última semana que o Rover Perseverance encontrou possíveis indícios de vida passada em Marte. A descoberta foi revelada pela agência em coletiva de imprensa realizada na quarta-feira. Resumindo, uma rocha coletada pelo robô apresentou minerais que na Terra costumam se formar em ambientes influenciados por microrganismos. Agora, um outro estudo também demonstra otimismo com o passado do nosso vizinho. Vamos conferir. O clima de Marte nos seus primeiros bilhões de anos, ainda é um tema em aberto para a ciência, mas uma nova pesquisa sugere que o planeta pode ter sido mais acolhedor à vida do que is pensava. Segundo o estudo publicado na revista Science Advances, atividades vulcânicas liberaram gases de enxofre reativos capazes de intensificar o efeito estufa e assim manter a temperatura mais amena. A pesquisa foi conduzida por cientistas da Universidade do Texas em Austin, que utilizaram dados da composição de meteoritos marcianos para simular diferentes cenários atmosféricos. Foram realizados mais de 40 modelos de computador com variações de temperatura, química e concentrações de gases. De acordo com a autora principal Lúcia Belino, a presença desses compostos pode ter criado um ambiente único por lá no passado, capaz de reter calor e água líquida. Além de sugerir que o enxofre pode ter ajudado a aquecer a atmosfera, o estudo abre espaço para novas investigações sobre a presença de água em Marte primitivo. Os pesquisadores querem entender se a atividade vulcânica poderia ter fornecido grandes reservas hídricas e até mesmo nutrientes para formas microbianas de vida. Hoje, Marte tem temperaturas médias em torno de mais ou menos 62º negativos, o que dificulta a existência de água líquida estável. No entanto, Lúcia Abelino ressalta que os modelos climáticos baseados nos resultados da pesquisa poderão indicar por quanto tempo o planeta manteve condições mais quentes e se microorganismos podem ter sobrevivido nesse ambiente. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise de como a exploração espacial se tornou uma corrida econômica, destacando a aquisição de hélio-3 lunar pela Blue Force via Interlun para resfriamento quântico e fusão nuclear, além de notícias sobre Marte e seu passado climático.",
            "resumo": "Este vídeo explica que a corrida espacial se tornou uma corrida econômica. Embora a mineração tradicional da Lua ainda não exista, empresas já negociam recursos lunares. A Blue Force, que fabrica sistemas de refrigeração para computação quântica, comprou dezenas de milhares de litros de hélio-3 lunar via Interlun, com valor superior a 300 milhões de dólares, a maior aquisição de recurso natural do espaço já registrada. O hélio-3, abundante na superfície lunar, é visto como valioso por permitir resfriamento de computadores quânticos e como combustível para fusões nucleares limpas. Embora não haja tecnologia operacional de mineração de hélio-3 em larga escala, o mercado já o projeta como motor de uma nova era tecnológica. O vídeo também reporta notícias da NASA sobre Marte, com Perseverance indicando indícios de vida passada, e um estudo que sugere condições climáticas mais amenas no passado do planeta, possivelmente ligadas à atividade vulcânica.",
            "assunto_principal": "Exploração comercial da Lua por meio da aquisição de hélio-3 (hélio-3) para usos em resfriamento quântico e fusão nuclear, com ligações a novidades sobre Marte e seu passado climático.",
            "palavras_chave": [
              "mineração lunar",
              "hélio-3",
              "Força Azul",
              "Interlun",
              "fusão nuclear",
              "resfriamento quântico",
              "recursos espaciais",
              "exploração espacial comercial",
              "Perseverança",
              "Marte",
              "Science Advances",
              "clima marciano",
              "água em Marte"
            ],
            "resumo_em_topicos": "- Contexto geral: a corrida espacial se transforma em corrida econômica entre tecnologia e negócios.\n- Aquisição de hélio-3 lunar: Blue Force comprou via Interlun, valor superior a 300 milhões de dólares, maior operação de recurso natural do espaço.\r\n- Propriedades e usos do hélio-3: não radioativo, leve; útil para resfriamento de computadores quânticos e como combustível para fusão nuclear limpa.\r\n- Desafio tecnológico: mineração de hélio-3 em larga escala ainda não existe, mas o mercado já aguarda seu papel.\r\n- Implicações: surgimento de modelos de exploração espacial comercial e novos fluxos de financiamento.\r\n- Marte: Perseverance detecta indícios de vida passada; estudo aponta clima antigo mais ameno, possivelmente influenciado por atividade vulcânica e presença de água ainda incerta.",
            "prompt_tokens": 989,
            "completion_tokens": 3957,
            "model": "gpt-5-nano",
            "cost": 0.0064
          },
          "analysis_time": 97.22443914413452,
          "language": "",
          "view_count": 852,
          "has_transcript": false
        },
        {
          "id": "9beUZz4ZJsU",
          "title": "Brasil pode se tornar um polo global de data centers, mas há desafios",
          "title_pt": "O Brasil pode se tornar um polo global de data centers, mas há desafios.",
          "url": "https://www.youtube.com/watch?v=9beUZz4ZJsU",
          "published": "2025-09-22T12:46:37.463560",
          "published_relative": "há 1 dia",
          "duration": "04:29",
          "date_published": "2025-09-21T07:00:13-07:00",
          "transcript_available": true,
          "transcript": "E o Brasil é um exemplo global na produção de energia renovável. E por isso a demanda energética na corrida das inteligências artificiais pode trazer o nosso país para o centro da tecnologia no mundo. Mas é claro que existem desafios. Vamos ver. O governo brasileiro tem buscado atrair investimentos estrangeiros para a construção de data centers. O objetivo é garantir a infraestrutura necessária para o avanço da inteligência artificial, colocando o nosso país como um dos mais importantes do setor. De acordo com o levantamento do BTG Pactual, o Brasil conta com todos os atributos para se tornar um novo polo global da tecnologia. No entanto, existem alguns obstáculos que precisam ser superados para que esse potencial se torne uma realidade. As vantagens brasileiras são a farta disponibilidade de água para sistemas de resfriamento e a ampla capacidade de geração de energia elétrica para sustentar o crescimento do mercado de IAP. O relatório ainda indica que existem várias empresas brasileiras capazes de se beneficiar diretamente deste cenário, como a Eletrobras. No entanto, também há obstáculos a serem superados. O trabalho aponta que uma parcela significativa dessa energia tem sido desperdiçada, especialmente no Nordeste brasileiro, por restrições em fontes renováveis. O levantamento aponta que mais de 20% da geração está sendo desligada por excesso de oferta ou falta de sistemas de transmissão para o escoamento. O BTG recomenda, além de resolver essas restrições no setor elétrico, promover a isenção tributária para importar equipamentos de data centers em todo o território nacional. Outros elementos essenciais, segundo o estudo, são um ambiente regulatório favorável, segurança cibernética e força de trabalho qualificada. [Música] E a defesa planetária, um dos focos da ciência. De olho em asteroides que sinalizem alguma ameaça, até mesmo pequenas rochas espaciais que nos visitam podem ser monitoradas. Vamos ver. >> Um asteroide com cerca de 4 m de diâmetro está voando relativamente próximo da Terra neste começo de semana, inclusive. Hoje a rocha espacial passou de raspão pela lua, denominado 2025 RJ2. O objeto foi avistado pela primeira vez em 2 de setembro pelo telescópio Pan Stars 1, no Havaí. E não representa perigo à Terra nem ao nosso satélite natural, mesmo se atingisse qualquer um dos dois. Diariamente, vários corpos celestes, tão pequenos quanto este, até entram na atmosfera terrestre, muitas vezes se desintegrando antes de chegar ao solo ou produzindo leves rastros luminosos, os famosos meteoros. A distância mais curta que essa pedrinha chegou da lua foi de 13.000 km. Em relação ao nosso planeta, foi de pouco mais de 300.000 km. Isso pode parecer muito, mas em proporções astronômicas é o suficiente para entrar na classificação de objeto próximo da Terra. De acordo com as definições da NASA, todo corpo celeste que passa a menos de 7,5 milhões de quilômetros do nosso planeta entra nessa lista. Se ele tivesse mais de 140 m, entraria também na categoria de potencialmente perigoso. Embora o nome assuste não indica a ameaça imediata, esses objetos passaram a ter monitoramento mais cuidadoso com cálculos detalhados de suas trajetórias. A NASA já calculou o caminho de todos os asteroides potencialmente perigosos conhecidos e garante que nenhum deles apresenta risco de colisão com a Terra nos próximos 100 anos. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O Brasil tem potencial para ser um polo global de data centers, impulsionado pela energia renovável, mas enfrenta obstáculos regulatórios, de transmissão e tributários que precisam ser superados para realizar esse cenário.",
            "resumo": "Resumo: O vídeo destaca o Brasil como exemplo global na produção de energia renovável e como isso pode colocar o país no centro da tecnologia, atraindo investimentos para centros de dados com o objetivo de sustentar o crescimento da IA. Segundo o BTG Pactual, o Brasil possui atributos para se tornar um novo polo mundial, como grande disponibilidade de água para resfriamento e alta capacidade de geração elétrica. Contudo, obstáculos persistem: desperdício de energia no Nordeste por restrições de fontes renováveis, falta de transmissão suficiente, e a necessidade de políticas públicas que incluam isenção tributária para importação de equipamentos para centros de dados, ambiente regulatório estável, segurança cibernética e mão de obra qualificada. O vídeo também aborda a defesa planetária com foco no monitoramento de asteroides, mas este segmento é secundário.",
            "assunto_principal": "Potencial do Brasil como polo global de data centers, apoiado em energia renovável, com desafios regulatórios, de transmissão e tributários, além de menção à defesa planetária como tema secundário.",
            "palavras_chave": [
              "Brasil",
              "centros de dados",
              "energia renovável",
              "BTG Pactual",
              "investimentos estrangeiros",
              "infraestrutura",
              "transmissão de energia",
              "isenção tributária",
              "ambiente regulatório",
              "segurança cibernética",
              "mão de obra qualificada",
              "Nordeste",
              "Eletrobras",
              "Inteligência Artificial"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Potencial do Brasil: pode se tornar polo global de data centers devido à energia renovável e à infraestrutura.\n- Atributos favoráveis: água disponível para resfriamento; grande capacidade de geração de energia para sustentar o crescimento da IA.\n- Cenário BTG Pactual: empresas brasileiras como Eletrobras podem se beneficiar; cenário promissor.\n- Obstáculos: grande parte da energia é desperdiçada no Nordeste por restrições em fontes renováveis e por limitações de transmissão; necessidade de resolver travas no setor elétrico.\n- Recomendações: isenção tributária para importação de equipamentos de data centers; ambiente regulatório estável; segurança cibernética; mão de obra qualificada.\n- Observação adicional: defesa planetária e monitoramento de asteroides; NASA afirma que nenhum asteroide conhecido representa risco nos próximos 100 anos.",
            "prompt_tokens": 868,
            "completion_tokens": 5328,
            "model": "gpt-5-nano",
            "cost": 0.0084
          },
          "analysis_time": 79.95312690734863,
          "language": "",
          "view_count": 1689,
          "has_transcript": false
        },
        {
          "id": "n6aRxZA0puE",
          "title": "Onde está Mercúrio? Entenda o fenômeno que faz o planeta sumir do céu.",
          "title_pt": "Onde está Mercúrio? Entenda o fenômeno que faz o planeta sumir do céu.",
          "url": "https://www.youtube.com/watch?v=n6aRxZA0puE",
          "published": "2025-09-22T12:46:37.463574",
          "published_relative": "há 1 dia",
          "duration": "04:10",
          "date_published": "2025-09-21T06:01:35-07:00",
          "transcript_available": true,
          "transcript": "Para quem admira os céus, deve ter reparado que Mercúrio sumiu do céu noturno, não é? O planeta mais próximo do Sol desapareceu da nossa vista em um evento astronômico peculiar, mas que não deve causar preocupação. O fenômeno é comum e o planeta voltará a ser visível em breve. Vamos ver. [Música] O planeta Mercúrio desapareceu do céu noturno e seguirá sumido nos próximos dias. Isso acontece por causa de um evento astronômico chamado Conjunção Solar Superior, quando o planeta passa para o outro lado do Sol. Nesse período, o brilho solar é tão intenso que ofusca totalmente Mercúrio, tornando nosso vizinho invisível do ponto de vista da Terra por algumas semanas. A conjunção em si começou no último sábado, às 8 horas da manhã, no horário de Brasília. Essa fase marca o desaparecimento do planeta do céu noturno e sua transição para se tornar um objeto visível apenas no céu da manhã nas próximas semanas. Além de sumir de vista, Mercúrio também passará pelo seu ponto mais distante da Terra, ficando a 207 milhões de km. Se pudesse ser visto, ele pareceria muito menor em nossos telescópios. O planeta mais próximo do Sol é também o menor do sistema solar e tem uma superfície rochosa e cheia de crateras bem parecida com a da Lua. Por estar tão perto do nosso sol, sua temperatura varia de forma extrema. Pode chegar a 430ºC durante o dia e cair para -1ºC durante a noite. [Música] Um notebook que se transforma em tablet, um modelo super potente para inteligência artificial e opções que não pesam no bolso. Chegou a hora do nosso guia completo de ofertas do dia. Vamos ver. [Música] A Samsung oferece uma variedade de notebooks que atendem a diferentes necessidades e orçamentos. E o olhar digital selecionou os cinco melhores modelos para você comprar em 2025. Para quem busca opções mais básicas e acessíveis, o Galaxy Book Go é uma ótima escolha, leve, compacto e ideal para tarefas do dia a dia. Ele conta com processador Snapdragon e custa cerca de R$800. Já para um uso diário e mais produtivo, o Galaxy Book 4 é um modelo com tela maior de 15,6 polegadas, processador Intel Core 5 e 16 GB de RAM, com preço em torno de R$ 4100. Subindo a categoria, o Galaxy Book 2 Business é a opção para uso corporativo com mais opções de conectividade e segurança. E a versatilidade é a sua prioridade. O Galaxy Book 4 360 se destaca com sua tela que gira a 360º, permitindo o uso como notebook ou tablet, além de ser compatível com caneta digital. Por fim, o Galaxy Book 4 Edge é o modelo mais potente da lista, ideal para usuários que precisam de altíssimo desempenho. Ele traz um processador Snapdragon X Plus e recursos de inteligência artificial, o que faz seu preço ser o mais alto na casa de R$ 11.700 R$ para saber qual modelo oferece o melhor custo benefício e se encaixa no seu perfil de uso, confira todos os detalhes na matéria que está em olhardigital.com.br. Acesse e confira. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Explicação da Conjunção Solar Superior de Mercúrio, que o torna invisível da Terra por semanas, com informações sobre o planeta e uma seção final de ofertas de notebooks Samsung.",
            "resumo": "Este vídeo explica a Conjunção Solar Superior de Mercúrio, quando o planeta fica do lado oposto do Sol e fica invisível da Terra por semanas devido ao brilho solar. A conjunção começou no último sábado às 8h (horário de Brasília). Durante o período, Mercúrio pode ficar a até 207 milhões de km da Terra; se visível, pareceria menor nos telescópios. Mercúrio é o planeta mais próximo do Sol e o menor do sistema, com superfície rochosa e crateras; suas temperaturas variam entre 430°C diurnos e -1°C noturnos. O vídeo também traz um bloco de ofertas da Samsung, com notebooks Galaxy Book Go, Book 4, Book 2 Business, Book 4 360 e Book 4 Edge, com faixas de preço. Mais detalhes na matéria em olhardigital.com.br.",
            "assunto_principal": "Conjunção Solar Superior de Mercúrio e seus impactos na visibilidade",
            "palavras_chave": [
              "Por favor",
              "forneça a lista de termos para traduzir."
            ],
            "resumo_em_topicos": "",
            "prompt_tokens": 851,
            "completion_tokens": 4270,
            "model": "gpt-5-nano",
            "cost": 0.0068
          },
          "analysis_time": 55.130435943603516,
          "language": "",
          "view_count": 1196,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@OpenAI",
      "name": "@OpenAI",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Oracle",
      "name": "@Oracle",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@PartnershipAI",
      "name": "@PartnershipAI",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@PaulaBernardes",
      "name": "@PaulaBernardes",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "srpsxS2GykE",
          "title": "Google Integra Gemini no Chrome: O Navegador Nunca Mais Será o Mesmo! Meta, Anthropic, Notion e Mais",
          "title_pt": "Google Integra Gemini no Chrome: O Navegador Nunca Mais Será o Mesmo! Meta, Anthropic, Notion e Mais",
          "url": "https://www.youtube.com/watch?v=srpsxS2GykE",
          "published": "2025-09-22T23:01:25.440879",
          "published_relative": "há 14 horas",
          "duration": "10:31",
          "date_published": "2025-09-22T15:03:00-07:00",
          "transcript_available": true,
          "transcript": "O Google finalmente botou o Gemini direto no Chrome. Tem a criando vírus para matar bactérias. Vídeos HDR que se autocorrigem. Modelos avançados super baratos. CEOs prevendo apocalipse da IA. Meta negociando conteúdo. Noan virando estagiário virtual. Amazon com IAK decide sozinha e muito mais. Vamos ver tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial hoje no nosso IA Update. Bora lá. A Lumi soltou uma ferramenta chamada Ray 3, que promete revolucionar a criação de vídeos com inteligência artificial. O diferencial dela é que além de gerar vídeo de qualidade HDR, de estúdio, né, tipo Hollywood mesmo, o modelo Ray 3 tem um sistema de reasoning que ele analisa e critica o próprio vídeo gerado antes de entregar esse vídeo para você. Depois de analisar, se ele não gostou, ele vai lá e refina sozinho e só libera mesmo quando já tá top. Dá para dar instruções super detalhadas, né? Inclusive desenhar em cima dos frames para controlar a movimentação e ângulo da câmera. E o modo prévia faz vídeos mais básicos, super rápido e barato. E quando você aprovar, ele transforma em HDR4K em pouquíssimos minutos, tá? Isso é um salto enorme aí para produtores, editores e até creatores independentes, porque agora dá para personalizar tudo com uma precisão altíssima e também uma qualidade altíssima, né? Então, cada vez mais a IA tá se tornando aquela parceira criativa realmente que entende de verdade o que você quer. E quem imaginou, né, gente, a ir desenhando, corrigindo e entregando o cinema na sua casa? E antes de passar pra próxima novidade, eu só vou pedir pr você se inscrever aqui no canal, se você ainda não é inscrito. Ativa o sininho para receber uma notificação toda vez que tiver um vídeo novo. E se você se tornar membro do canal, além de apoiar o canal, você ainda vê os vídeos do IA Update primeiro que todo mundo. E os pesquisadores da Universidade de Stanford, junto com a Ark Institute criaram a IA para criar vírus de laboratório que conseguem matar bactérias super resistentes, tá? Eles treinaram um modelo chamado Evil com informações de mais de 2 milhões de vírus naturais e pediram para ele inventar versões nunca vistas antes. E o mais incrível é que de 302 tentativas, 16 dos vírus sintéticos criados pela IA funcionaram direitinho nos testes de laboratório. Alguns ainda apresentaram mutações e combinações que nem os cientistas tentando ali durante anos tinham conseguido criar. Então, a conclusão é que quando as bactérias ficaram resistentes aos vírus naturais, as versões criadas pela IA passaram direto pelas defesas e eliminaram as bactérias rapidinho. E isso marca uma virada na biologia, né? Agora, além de ler e escrever DNA, a gente entra na era de desenhar vidas do zero. A IA pode virar uma parceira fundamental para inventar soluções médicas inéditas com com potencial imenso para tratar doenças ou até controlar as epidemias no futuro. Agora de PSIC acabou de publicar um artigo super detalhado com os bastidores técnicos do modelo Ron, aquele mesmo que sacudiu aí o universo da IA lá em janeiro, lembra? E olha o choque, gente. Eles revelaram que o custo do treinamento foi de só 294.000, extremamente baixo, perto dos milhões que as bigtechs geralmente gastam. E esse estudo aqui abre a caixa preta dos métodos, né? também fala do hardware e das estratégias que fizeram o R1 ser tão eficaz sem precisar explodir o orçamento. Isso pode significar uma nova fase e a de última geração ficando cada vez mais acessível e democrática, ajudando as empresas menores a brigar de igual para igual. Preparados para aquele balde de água fria? Porque o Dario Amodei, que é o CEO da Antropic, deu uma declaração surpreendente, falando aí que acredita ter pelo menos 25% de chance das coisas darem muito errado com o avanço da IA. Segundo ele, os riscos de catástrofes aumentaram à medida que os sistemas ficaram mais poderosos e isso mostra que o setor precisa de discussão séria sobre limites e segurança. E esse tipo de sinceridade chama bastante atenção, não só dos especialistas, né, mas do público em geral, porque será que a gente tá mesmo prontos para tanto poder automático rodando aí pelo mundo? Antropic sempre foi mais do lado da segurança, né? sempre defendendo mais esse ponto mesmo, esse lado da segurança com IA. Quero saber que que você acha sobre isso, deixa aqui nos comentários, tá? E a meta que é a dona do Facebook, do Instagram, tá negociando para fechar acordos de licença de conteúdo de A com empresas gigantes da mídia, né, tipo Fox, News Corp. E com essa jogada aqui, a meta entra no time dos maiores que querem abastecer os seus modelos de IA com conteúdo profissional de jornal, de revista, de portais mais confiáveis, né? Isso pode transformar tanto a qualidade das respostas quanto a disputa nos tribunais sobre direitos autorais. E o Notion 3.0 acabou de ser lançado trazendo aí os agentes de IA super poderosos. Agora eles conseguem fazer fluxos de trabalhos inteiros sozinhos, acessando ferramentas integradas com banco de dados, pesquisas e podem trabalhar até 20 minutos sem parar em tarefas longas ou complexas. É basicamente ter um estagiário virtual pronto para destravar sua rotina e resolver as tarefas repetitivas ou inteligentes, né? Isso é perfeito para quem vive multitarefa. E agora é oficial, tá? a Amazon adicionou e a agente do Seller assistant, o sistema vai além do básico, né? É capaz de assumir tarefas como gerenciar estoque, monitorar a saúde da conta do vendedor e até criar estratégia para crescer as vendas. Tudo automatizado em tempo real, sem precisar de comando manual para cada ação. E isso pode aumentar muito a eficiência dos vendedores da Amazon para outro patamar. E a Nvidia tá bombando nos negócios, tá com a Intel juntos, né? Nvidia e Intel, eles anunciaram uma parceria histórica aí para desenhar e fabricar processadores X86 focados em IA e produtos para PC. Ah, e a Nvidia ainda vai investir 5 bilhões de dólares na Intel. Então essa aliança aí tá unindo as duas forças mais criativas da tecnologia para desenvolver infraestruturas de inteligência artificial cada vez mais potentes. E isso aqui pode mexer com todo o cenário de hardware, seja para empresas ou para consumidores comuns que gostam de tecnologia de ponta. Agora, olha isso aqui, gente. O Google finalmente tirou o escorpião do bolso e resolveu botar o Gemini direto no Google. Não é brincadeira não, gente. Isso aqui é o tipo de coisa que muda completamente tudo, né? Você tá aí navegando de boa, várias abas abertas e aí do nada tem um botãozinho ali na barra lateral. Quer ver aqui, ó? Fica esse botãozinho aqui e ele te dá acesso ao Gemini. Prontinho para analisar tudo, fazer os resumos, responder dúvidas, tudo ali na hora, sem precisar ficar copiando, colando, abrindo outro site. Isso já tá disponível a partir de hoje, tá? Mas só pros usuários nos Estados Unidos, tá? Em inglês. Depois eles com certeza vão expandir pros outros países, mas a gente vai ter que esperar um pouquinho. E eles também nas próximas semanas, né, o Google vai eh ganhar um AI Mold direto na barra de endereços, né, naquela barra mesmo onde a gente digita como fazer um arroz soltinho, sabe? Agora você vai poder trocar a ideia com a IA, fazer perguntas, continuar as conversas, resolver as coisas atrás das coisas, né? tudo sem sair da página ali. E se você achou que parava por aí, olha o spoiler, o Chrome vai começar a fazer as tarefas sozinho, tá? Tipo comprar coisas online ou marcar aquele horário no dentista que você vive adiando, o bichinho vai ser autônomo mesmo, tá? E vai ser loucura total. E a verdade é que isso aqui, gente, muda o jogo, né? Já tem várias IAS que fazem isso, né? Tem o navegador da Perplexity, o Comet e vários agentes que já fazem algumas tarefas sozinhos. Mas ter isso no Chrome do Google usa, eles vão ficar muito na frente de todos, né? O Google foi ali na surdina, né, só observando e do nada meteu a IA justamente no Chrome. E isso aí é um trunfo enorme, porque ninguém mais quer ficar baixando coisa nova só para testar, né? A galera quer praticidade e o Google já entendeu isso aí direitinho, né? Mas claro que como tudo tem tudo, são flores, né? A gente também tem que ficar esperto porque quando a IA começa a tomar decisões por você, tipo fazer compras ou agendar compromissos, a linha entre assistente e controle total da sua vida fica bem ali tênue, tá? E vamos combinar que se o Google já sabe tudo que a gente pesquisa, imagina com a IA acompanhando tudo em tempo real, é muito poder para uma ferramenta só, né? Então o negócio não é só sobre produtividade, mas também sob privacidade e autonomia. Então vale a pena ficar de olho nisso também. Mas mesmo assim não dá para negar, né, gente, que esse movimento do Google pode realmente mudar a forma como a gente interage com a internet, né? Tipo, do mesmo jeito que a gente se acostumou com o corretor automático ou com o auto complet, a gente pode começar a achar super normal ter uma IA tomando decisões junto com a gente ou até por nós. E aí, meu querido, a forma de trabalhar, estudar, fazer compras, até pesquisar a receita, vai dar um salto enorme. Então vamos acompanhar aí de perto porque isso não é só mais uma atualização do Chrome, é o início de uma nova era aí onde o navegador virá quase um copiloto digital de verdade. E se você achava que produtividade era ter um monte de extensões ali instaladas, se prepara aí, porque o Chrome com o Gemini pode mudar tudo isso rapidinho. E clica aqui nesse card para ficar ainda mais atualizado e saber tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial. Eu sou a Paula Bernardes e até o próximo vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O IA Update analisa as principais inovações em IA e tecnologia, destacando a integração do Gemini no Chrome, avanços na criação de conteúdo com IA e parcerias estratégicas que prometem transformar o navegador, a ciência, o jornalismo e o ecossistema de hardware.",
            "resumo": "Esta Atualização de IA apresenta as últimas tendências em tecnologia e IA: o Google integra o Gemini ao Chrome, com acesso na barra lateral e, em breve, na barra de endereços, incluindo funções autônomas para executar tarefas sem sair da página; a ferramenta Ray 3 da Lumi gera vídeos em HDR 4K com um sistema de raciocínio que refina automaticamente o conteúdo. Também são discutidos avanços complexos: pesquisas da Stanford e do Ark Institute sobre IA capaz de projetar vírus de laboratório com potencial terapêutico, o que acende debates sobre biossegurança; o estudo do modelo Ron, com custo de treino baixo, que democratiza o acesso; alertas de risco de 25% de falha, segundo Dario Amodei; acordos de licenciamento de conteúdo da Meta para alimentar IA; Notion 3.0 com agentes de IA; Amazon Seller Assistant; parceria Nvidia-Intel para processadores de IA; e a visão de IA integrada ao Chrome que pode superar concorrentes.",
            "assunto_principal": "Integração do Gemini no Chrome e tendências de IA avançada (produtividade, biossegurança, licenciamento de conteúdo, hardware e automação).",
            "palavras_chave": [
              "Gemini no Chrome",
              "IA integrada",
              "Ray 3",
              "vídeos HDR",
              "biossegurança da IA",
              "vírus sintéticos",
              "Stanford",
              "Ark Institute",
              "modelo Ron",
              "custo de treinamento",
              "Dario Amodei",
              "licenciamento de conteúdo",
              "Meta",
              "Notion 3.0",
              "agentes de IA",
              "Amazon Seller Assistant",
              "Nvidia",
              "Intel",
              "IA autônoma no navegador",
              "Chrome IA"
            ],
            "resumo_em_topicos": "- Integração do Gemini no Chrome e novas experiências com IA no navegador\n- Ray 3 da Lumi: geração de vídeos HDR 4K com sistema de raciocínio\n- Pesquisas de biossegurança: IA projetando vírus sintéticos e implicações éticas\n- Estudo Ron: baixo custo de treinamento, democratização da IA\n- Comentários de Dario Amodei sobre riscos e necessidade de segurança\n- Meta negocia licenciamento de conteúdo para modelos de IA\n- Notion 3.0: agentes de IA que executam fluxos de trabalho longos\n- Amazon Seller Assistant: automação de operações de vendedor\n- Parcerias Nvidia-Intel para hardware de IA\n- Visão do Google Chrome com assistente de IA e tarefas autônomas",
            "prompt_tokens": 1972,
            "completion_tokens": 3965,
            "model": "gpt-5-nano",
            "cost": 0.0069
          },
          "analysis_time": 119.70746088027954,
          "language": "",
          "view_count": 3308,
          "has_transcript": false
        },
        {
          "id": "k8VEy8SGwTY",
          "title": "Por que a IA NUNCA vai substituir os humanos (ou será que vai?)\"",
          "title_pt": "Por que a IA NUNCA vai substituir os humanos (ou será que vai?)",
          "url": "https://www.youtube.com/watch?v=k8VEy8SGwTY",
          "published": "2025-09-22T17:01:25.440948",
          "published_relative": "há 20 horas",
          "duration": "09:10",
          "date_published": "2025-09-22T09:03:00-07:00",
          "transcript_available": true,
          "transcript": "Não tem mais jeito. Os robôs vão dominar o mundo. Eu vou ficar desempregado, comendo miojo enquanto uma máquina faz meu trampo melhor do que eu. Calma, respira. Será mesmo que a inteligência artificial vai substituir os humanos? Ou será que isso é mais um mito, exagero aí de manchete e no fundo a coisa é muito mais complexa? É sobre isso que a gente vai falar hoje. Sem papo técnico chato, sem palavras complicadas. É um papo pra gente responder no final juntos, né? Aí vai roubar a nossa vaga ou vai virar aquela colega chata que ajuda, mas não sabe viver sem a gente? Por isso, já vai dando o seu like aqui nesse vídeo. Se você gosta desse tipo de conteúdo, se inscreve no canal para ver mais conteúdos como esse e ativa o sininho para receber uma notificação toda vez que tiver um vídeo novo, combinado? Então bora lá. Então vamos começar com o que a IA já faz hoje, né? aí que faz melhor do que a gente. Primeiro, vamos ser honesto aqui, né? Tem muita coisa que a Iá já faz melhor do que os humanos. Eu não tô falando de coisa futurista, tá? Eu tô falando de coisa que já tá rolando agora. Por exemplo, o exemplo clássico é o das planilhas gigantes, né? Se você já tentou procurar um padrão de 200.000 linhas de Excel, você pode até tentar, né? Mas você vai acabar desistindo no meio e inventando uma desculpa pro seu chefe. Certo? Agora bota um algoritmo de A para rodar e em segundos ela vai descobrir que 90% dos clientes que compraram produto X também assinaram a newsletter Y em segundos. Outro exemplo clássico é o atendimento ao cliente. Tem chatbot que responde perguntas básicas muito mais rápido do que aquele atendente que te deixa esperando lá 40 minutos na linha ouvindo aquelas mensagens automáticas ou aquelas músicas terríveis. Para diagnóstico médico, os algoritmos já conseguem detectar sinais de câncer e exames de imagem com uma precisão assustadora, às vezes até maior do que dos médicos humanos, porque a máquina não se distrai, ela não fica cansada e não tem que atender 30 pacientes por dia. Então, em tudo que é padrão repetitivo, a Iá já reina, tá, minha gente? Ela é como aquele colega que adora planilhas, que acha divertido organizar o arquivo por cor e número. Sabe agora? Onde aí a trava e os humanos ainda são os reis? Nem tudo são só flores tecnológicas, né, minha gente? Tem coisa que a Iá simplesmente não consegue fazer ainda, pelo menos, e talvez nunca consiga de verdade, tá? Uma delas é a criatividade real. Ela gera imagens lindas, ela escreve texto, compõe músicas, mas tudo isso vem de padrões aprendidos de coisas que já existem. Ela é treinada com coisas que já existem. Criar uma coisa totalmente nova, que nunca foi vista antes, com significado profundo, impacto cultural, aí é só com os humanos mesmo, né? Se você pensar em obras tipo Picasso, Betoven e até a invenção da internet, isso não saiu de um prompt, né? Saiu da loucura criativa de gente que vi um mundo diferente. Outra coisa que a gente ainda reina e aí a não, é na empatia de verdade, tá? Ela até pode fingir que é empática, né? Simular uma simpatia. Ela pode escrever: \"Eu entendo que você tá passando por um momento difícil. Chat GPT é ótimo com isso, né? Mas será que ela sente isso mesmo? Claro que não, né? Será que ela entende o peso de uma perda, o calor de um abraço, a mistura de sentimentos quando você tá feliz e triste ao mesmo tempo? A resposta é óbvia, né? Não. A empatia humana tem a ver com viver, com sofrer, com rir, até doer a barriga. E isso não dá para programar ainda, né? Julgamento moral. As decisões que precisam, que envolvem ética, tipo, quem deve ser salvo primeiro numa situação de emergência, são coisas que a sociedade inteira debate aí há séculos. A Iá pode até sugerir uma escolha mais lógica, né? Mas ela não tem aquele senso de certo e errado que vem da nossa experiência coletiva como espécie. Contexto maluco do dia a dia. Quer ver a travar? Dá uma tarefa com contexto absurdo. Por exemplo, minha sogra me ligou pedindo para eu buscar bolo no mercado, mas eu tô sem carro, o ônibus tá em greve e vai chover granizo. O que eu faço? A Iá pode até se sugerir algumas coisas, né? usa um aplicativo de entrega, mas se o entregador não topar, enfrentar esse granizo e se o mercado fechar mais cedo, só um humano vai pensar em ligar pro vizinho que tem a moto, negociar com o porteiro, improvisar com a criatividade e um pouco de cara de pau também, né? Tá, mas será que um dia a Iá vai ser como a gente? Agora vem a parte que dá um frio na barriga, né? E se a IA evoluir tanto que passe a ter criatividade, a empatia, o julgamento moral? E se ela virar uma ADI, inteligência artificial, que é capaz de aprender qualquer coisa com a gente? Ó, é até possível que isso aconteça em algum momento, né? Os cientistas já estão tentando, mas ainda a gente tá longe. A IAD hoje é tipo aquela IA de aluno CDF que tira 10 em prova de matemática porque decorou todas as fórmulas, mas não consegue entender uma piada ou improvisar numa festa. E mesmo que a Iá chegue nesse nível de inteligência geral, tem outra questão, né? A vontade. Aá não tem desejo, não tem propósito. Ela não acorda pensando: \"Ah, hoje eu vou revolucionar o mundo.\" Ela nem acorda, né? Ela só responde o que a gente pede, a menos que alguém que programe aí uma IA para ter objetivos próprios, né? Isso aí já abre uma caixa de Pandora filosófica e bem perigosa, né? Mas fora isso, ela vai continuar sendo uma ferramenta poderosa, mas não um ser consciente. Impacto real no trabalho. Agora vem o ponto que todo mundo quer saber, né? E o meu emprego vai sumir? A resposta é: alguns sim, tá? Outros não. As tarefas repetitivas e previsíveis já era, tá gente? Processamento de documentos, suporte básico, relatórios de rotina, isso aí faz sem nem suar. Profissões criativas, sociais e estratégicas, essas mudam, mas não acabam, tá? Um designer vai usar a IA como ferramenta de brainstorm. Um médico vai usar a IA para ter diagnósticos mais rápidos, mas ainda vai precisar tá lá olhando o paciente no olho e decidindo junto. E novos empregos vão surgir também, né? Quem imaginava há 20 anos atrás que existiu cargo de gestor de prompt ou especialista em ética de IA? Sempre que uma tecnologia muda o mundo, ela cria novos empregos. Mas tem um detalhe importante, tá? Transição pode ser bem dura, né? Nem todo mundo vai conseguir se adaptar rápido e se não tiver políticas públicas de educação e redistribuição, a desigualdade pode aumentar. Agora vem a parte filosófica, porque a gente também curte dar uma viajada na maionese, né? Mesmo que a Iá seja capaz de tudo tecnicamente, né? Tem uma pergunta essencial. A gente quer isso de verdade? Você gostaria de ser cuidado por um robô enfermeiro que nunca erra uma injeção, mas também nunca olha nos seus olhos com compaixão? Você ia preferir um professor humano que se atrapalha ali às vezes, mas que vibra com quando você aprende alguma coisa? Ou um algoritmo que sempre tem a resposta certa. Você toparia viver num mundo onde as suas relações, trabalhos e até as escolhas de vida são mediadas por máquinas? Então, gente, no fim o valor da humanidade tá naquilo que é realmente imperfeito, que é imprevisível, que é bagunçado e é isso que torna a gente único, tá? Mas então quem é que ganha essa batalha aí? Humanos ou Iá? A verdade é que não é uma guerra, né, gente? Não é ou nós ou elas as iás. A Iá não é uma espécie de rival, né? Uma ferramenta que foi criada por nós. Se usada bem, ela pode dar superperes pra gente, né? Mais produtividade, diagnósticos melhores, novas formas de arte, mas se for usada mal, ela pode gerar desemprego, desigualdade, até riscos sérios com segurança. Então, o futuro não depende só da tecnologia, mas também das escolhas que a gente faz agora. E aí ela pode ser muito mais inteligente em números, mas só os humanos têm capacidade mesmo de dar significado, propósito e valor no que já existe. Então, por mais, gente, que aí a brilhe, né, ainda vai ter coisa que só a gente consegue fazer. E eu acho difícil que uma máquina consiga rir de uma piada ruim, improvisar um churrasco ou sentir aquele frio na barriga quando a gente se apaixona, né? Mas eu quero saber o que você acha disso. Pode escrevendo aqui nos comentários e cliquea aqui nesse card para ficar ainda mais atualizado e saber tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial. Eu sou a Paula Bernardes e até o próximo vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "A IA já faz muito, mas criatividade, empatia e ética continuam sendo privilégios humanos, e o futuro do trabalho depende de como usamos essa ferramenta.",
            "resumo": "Este vídeo discute se a IA pode substituir os humanos no trabalho, apresentando o que já faz hoje, limitações importantes, impactos no mercado e questões éticas. Começa mostrando exemplos reais: planilhas com grandes volumes de dados, chatbots no atendimento ao cliente e diagnóstico médico com IA que pode superar humanos em tarefas repetitivas. Em seguida, aponta que a criatividade verdadeira, a empatia genuína e o julgamento moral são áreas ainda superiores aos algoritmos, pois dependem de experiência, sentido de contexto e valores humanos. O vídeo também aborda o risco de substituição de empregos, destaca que algumas funções serão automatizadas enquanto outras serão transformadas, e que novas vagas surgirão, exigindo políticas públicas de educação. Por fim, defende que a IA é uma ferramenta poderosa, não uma entidade consciente, e que o futuro depende das escolhas humanas.",
            "assunto_principal": "Impacto da IA no trabalho humano, equilíbrio entre automação e habilidades humanas, limitações atuais da IA e implicações éticas, econômicas e sociais.",
            "palavras_chave": [
              "inteligência artificial",
              "inteligência artificial",
              "substituição de empregos",
              "mercado de trabalho",
              "criatividade",
              "empatia",
              "julgamento moral",
              "ética",
              "inteligência artificial geral",
              "adaptação profissional",
              "tecnologia responsável"
            ],
            "resumo_em_topicos": "- O que a IA já faz hoje: automatiza padrões repetitivos, planilhas, atendimento, diagnósticos...\n- Limitações: criatividade verdadeira, empatia real, julgamento moral ainda são humanos...\n- Impacto no trabalho: substituição de tarefas repetitivas, transformação de profissões; surgem novas vagas; transição exige políticas públicas e educação...\n- Cenários futuros: IA como ferramenta poderosa, possível IA geral, ainda sem desejos ou propósito; riscos de dependência...\n- Questões éticas: queremos um mundo onde relações e decisões sejam mediadas por máquinas?\n- Conclusão: o futuro depende de escolhas humanas para usar a IA de forma responsável, mantendo o valor humano na imperfeição.",
            "prompt_tokens": 2064,
            "completion_tokens": 3006,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 62.27144432067871,
          "language": "",
          "view_count": 727,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@QuantBrasil",
      "name": "@QuantBrasil",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "CvkpZbpj8H0",
          "title": "Mocha AI: a melhor forma de criar apps sem programar? (Superou minhas expectativas)",
          "title_pt": "Texto: Mocha AI: a melhor forma de criar apps sem programar? (Superou minhas expectativas)",
          "url": "https://www.youtube.com/watch?v=CvkpZbpj8H0",
          "published": "2025-09-22T13:04:39.978984",
          "published_relative": "há 1 dia",
          "duration": "43:19",
          "date_published": "2025-09-21T14:40:12-07:00",
          "transcript_available": true,
          "transcript": "Hoje eu quero mostrar para você a melhor forma que eu encontrei de criar um app utilizando inteligência artificial sem programar. Eu quero mostrar para vocês exemplos de apps que você pode criar e dar minha opinião sincera. Vale a pena a gente criar esses apps utilizando Vibe Code? Pessoal, quem me conhece aqui no canal sabe que eu sou engenheiro de software de formação, portanto, sempre que eu vou criar um app, eu tento a usar a programação. No entanto, eu entendo que muitas vezes existem sim possibilidades, ferramentas, apps que nós podemos criar sem necessariamente utilizar programação. E tudo bem, assim, existe uma certa resistência quanto ao termo vibe coding, como se fosse algo fadado ao insucesso e que você nunca deveria utilizar em hipótese alguma e etc, etc. Claro, existem momentos para você utilizar Vibe Coding, existem momentos para você programar de fato, mas em muitos casos você utilizar uma ferramenta de inteligência artificial para criar um app para você para criar algo, uma ferramenta que resolva um problema seu ou até mesmo talvez para fazer um bootstrap de um de um produto que você pode criar. Inclusive, deixa eu fazer um parênteses aqui, porque as pessoas esquecem que antigamente quando alguém queria fazer um bootstrap ali de uma empresa, eles iam lá, contratavam terceirizados, indianos, coisas do tipo assim, só para ter um app para testar. E não era o melhor app, tecnicamente falando, tá? Isso sempre aconteceu na vida da história das pessoas que trabalham com tecnologia. Então assim, se você tem a possibilidade de fazer algo sem programar para testar uma tese ou que seja algo até só para você, né, usar uma ferramenta que ajude na sua vida, eu acho isso super padre. E hoje eu quero falar a vocês justamente sobre o Moca. O Moca AI é uma plataforma para criação de apps utilizando inteligência artificial e eles dizem justamente isso. Traga suas ideias de aplicativos à vida utilizando inteligência artificial. No coding, ou seja, sem programar. Beleza? E o Moca, pessoal, eles receberam fundings de VCs como o Y Combinator, ele estão aqui disputando nesse mercado competitivo que é o de criação de apps utilizando inteligência artificial. Eu já vou mostrar para vocês alguns exemplos que eu criei de ferramentas, tá? Vou falar para vocês o que que você consegue construir que é bem legal, o que que talvez seja um pouco mais complicado, qual é o grande diferencial do Moca para você poder decidir se de fato o Moca é a melhor ferramenta para você construir os seus apps utilizando inteligência artificial? Pessoal, antes da gente continuar um vídeo, um disclaimer que eu recebi o contato do pessoal do Moca AI pedindo para que eu mostrasse o produto deles. Então, de fato, esse é um vídeo onde eles são parceiros, tá? Mas o meu compromisso com vocês aqui se mantém sempre o mesmo. Eu só trago pro canal aquilo que eu acho que de fato pode agregar. E eu vou passar minha opinião sincera, certo? Eu vou dizer até o final desse vídeo o que eu acho que você pode utilizar o Moca para fazer, o que eu acho que ele não vai tão bem, de modo que você possa tomar a sua decisão mais informada. Beleza? Então tá pessoal, então vamos entender aqui antes da gente mostrar aqui a mão na massa o que que são esses tipos de apps, tipo moca ou também o lovable. Já vou falar da comparação do moca com o lovable em um segundo, mas a ideia é que essas ferramentas são ferramentas que você pode criar um app simplesmente dando um prompt. Então, a inteligência artificial, ela chegou num ponto tão bom, né, tão avançado, que você descreve a sua ideia e essa ideia vira um app em poucos minutos, às vezes até em questões de segundos. Evidentemente que você não vai fazer nada de muito complicado, pelo menos não em segundos, certo? Embora você possa sim iterar, mas o legal desse tipo de ferramenta é que dá asas a criatividade que você pode ter, mesmo que você não seja programador. Então, às vezes aquilo que você demoraria tempo e gastaria recurso para colocar na prática, você com alguns poucos prompts já consegue colocar com ferramentas desse tipo. E aí eu preciso aqui dizer como profissional, como engenheiro de software, que evidentemente que existem problemas com essa abordagem. Se você for escalar para muitos usuários, que você precisa ter ter muito cuidado com problema de segurança. Então, é claro, pessoal, não vou fingir aqui para vocês que isso é um céu de brigadeiro e que você vai ficar milionário escrevendo promptinho. Pode acontecer, claro, evidente. É uma ajuda, é uma ferramenta, não vai resolver todos os seus problemas, mas eu sim acredito que isso tem o seu valor, tá? Eu realmente acredito que isso pode ser utilizado por pessoas que não são profissionais de modo legítimo. E para provar para vocês que eu acho isso, eu vou até mostrar um artigo que eu escrevi na Code Capital, que é a minha newslettera, onde eu falo sobre programação, inteligência artificial. Vou deixar o link aqui na descrição para você acompanhar e seguir a Newsler. Lá no dia 19 de março, eu já escrevi um post chamado que nem todo programador precisa ser profissional. E aí eu falo aqui, dou um exemplo de um youtuber que eu gosto muito, mas o meu, a minha mensagem aqui é justamente essa. Não vejo o problema de que uma pessoa que não seja profissional, programadora na carteira assinada, entre aspas, que ela não possa utilizar as ferramentas de software para criar soluções pra sua vida. E aí eu dou exemplo aqui, né? Sei lá, muita gente às vezes gosta de marcenaria ou coisas similares. Você não é marceneiro, você não trabalha ali com CNPJ sendo marceneiro, mas isso não impede você de aprender marcenaria e construir um banco pra sua casa, uma mesa ou algo do tipo, certo? E eu vejo a tecnologia dessa mesma forma. Acho que as pessoas têm que ser incentivadas a mexerem, brincarem e tentar usar a tecnologia para resolver os seus problemas, tá? Tô fazendo todo esse disclaimer aqui para convencer você, entre aspas, de que não existe problema. Eu eu falo isso porque eu vejo muito na internet as pessoas ouvindo o termo vibe coding e e quase que estremecendo, né, como se fosse algo radioativo. E pelo amor de Deus, assim, é algo extremamente legítimo e eu realmente acho que vale a pena em alguns casos que nós já vamos ver. Então, se você entrar aqui no site da Moca, eles vão falar aqui, ó, ah, vão dar algumas sugestões para você, ó. Color Pellet Generator, Movie Browser, Shar Interface, Crypto Dashboard, Weather Dashboard. Então eles vão dando ideias de apps que você pode criar e claro, ali você vai ajustando pro seu caso de uso, beleza? Então, a Moca é para você criar projetos reais, né? Então, pessoas reais criando projetos reais. Essa é a página de marketing deles. E tem algo muito diferenciado aqui na m, que é o fato de que eles criam também o back end. Isso é muito legal, pessoal, porque te dá visão do back end. Eles fazem o front end utilizando Vit, então é um JavaScript utilizando Vit, né, React com Vit e um back end utilizando cloud flare. Então isso é algo legal porque você consegue saber o que tem no back endompt também para o back end. Você tem acesso ao backend. Então, a maior parte dessas ferramentas de AI criam apps, elas te fazem uma interface e aí você fica ali brincando na interface, você meio que não sabe o que tá por trás ali pro back end, mas não é o caso do Moca, tá? No Moca AI você também consegue controlar o back end e isso é algo incrível. Além disso, né, você já vem com tudo incluso, né, não tem setup, você já vem com banco de dados, autenticação, e-mail, enfim, é realmente impressionante como avançou. nessa área e você consegue de fato ganhar muito tempo. Pessoal, eu sou do tempo onde você criar autenticação de um app demorava tempo. Era papo de semanas para você colocar uma autenticação num app. O fato de que você já nasce com app com autenticação hoje em dia é realmente incrível para quem viveu o desenvolvimento do mundo da tecnologia. É algo realmente incrível. Então, beleza, eu tô falando demais aqui, eu vou mostrar para vocês na prática, mas vamos só ver mais um pouco de contexto que vai ajudar a gente na hora da gente ver os apps. Então, beleza, o que que é Moca, né? Então, Moca é uma aplicação que permite que você crie apps utilizando AI, beleza? Você não precisa de experiência de código para criar um app com a Moca AI, embora, evidentemente, que isso vai te ajudar. Como esse canal aqui são de pessoas entusiastas e programadores, você consegue ter até mais vantagem competitiva por saber dominar as ferramentas. Então isso é melhor até para você que é programador. Tipo de aplicações que você consegue criar. Então eles dizem que é bem versátil, de fato. É, né? Você você consegue criar software, não só mocing, né? Isso é algo que a gente vê bastante, ferramentas que são capazes de permitir que você crie telas muito bonitinhas, mas que não são muito funcionais. E o que é legal, OK? Mas na prática a gente quer ver um app funcionando. Beleza? E aqui algo que eu falei para vocês, ó. Can I write backend with Moca? Posso escrever o back end com Moca? E sim, o back end está integrado no MOCA, inclusive com banco de dados, API e tudo mais. Você já consegue fazer o deploy automaticamente e o app é seu, ou seja, você pode a qualquer momento fazer o download e mexer ali na no app na mão ali, por exemplo, num cursor da vida. Beleza? Bom, pessoal, OK. Então, vamos dar uma olhada no Moca. Nesse momento que eu vou fazer o meu login aqui, você pode estar se perguntando, beleza, Rafael, você tá falando do mo aqui, você já disse que é um conteúdo de parceiro, por que que eu não usaria o Lovable, por exemplo, que é um app mais famoso? É um app que diz ter sido o app que alcançou 100 milhões de receita anual mais rápido possível. Se eu não me engano, foi sete ou 9 meses que o Lovable alcançou esse número impressionante. E eu vou trazer aqui até um tweet do founder Moca, o Niicholas Charrier, que disse, né, que muitas vezes ele é perguntado como que o Moca é diferente do Lovable, né? E aí ele tá dizendo aqui que a resposta mais importante é que a audiência é diferente, enquanto no lovable tem um foco um pouco mais técnico e existe uma dependência mais técnica. Então eles dependem do Supase, eles dependem do GitHub e ele até diz aqui que eles têm ponto dev no nome, né? O Moca ele foca em pegar o 99%, ou seja, aquelas pessoas que não são necessariamente técnicas, tá? E a gente vai ver que isso de fato é uma faca de dois gumes, então ela pode ser boa para casos onde você realmente não é técnico e ela pode deixar um pouco a desejar, onde a pessoa tem aquela noção técnica. gostaria às vezes de, né, fazer intervenções pontuais, né, e acaba não conseguindo. Então eu já adianto até aqui uma das coisas que para mim poderia melhorar, vou falar com um pouco mais de detalhes mais pra frente, beleza? Então, eu fiz o meu login aqui na Moca e aí vocês podem ver aqui que eu tô brincando aqui bastante, já criei alguns apps. E o primeiro app que eu quero mostrar para vocês é esse aqui chamado Growth Scope. Então, basicamente é um app que eu criei para resolver um problema que eu falei no vídeo onde eu mostrei as novidades do GPT5. Eu vou colocar o vídeo aqui no card aqui em cima para você ver. Mas nesse vídeo eu testei o GPT5 querendo criar um app, certo? E nesse app que eu queria criar usando o GPT5 foi justamente um app para traquear o crescimento do meu canal, tanto aqui no YouTube quanto lá no substep. E quando eu testei lá no vídeo, depois você dá uma olhada que ficou bem legal eu olhando ali o GPT5, tentando fazer várias coisas com GPT5, eu não consegui fazer isso com o GPT5 na interface do Chat GPT, nem com OPUS na interface do cloud. Quando eu fiz com o V0, aí ele f ele funcionou um pouco mais, mas ainda não foi perfeito, tá? E uma coisa que eu achei bem incrível aqui no Moca foi que ele meio que acertou de primeira o que eu quis fazer aqui, tá? E aí, deixa eu até mostrar para vocês aqui a planilha que eu tenho. Então, eu tenho uma planilha onde desde o início desse ano, de 2025, eu tenho olhado os meus inscritos no YouTube e no Substeck. Então você vê que eu comecei o ano com 1017 no YouTube, 41 no substec e até a última semana aqui eu tô com 8.164 no YouTube e 706 no subst. Então um crescimento bem expressivo. Eu tenho anotado toda segunda-feira venho aqui e anoto e tenho o crescimento semanal. E aí, uma coisa que eu fiz, já fiz um vídeo sobre isso aqui também no canal, é tentar entender se existe uma previsão que eu posso fazer desse crescimento usando ali técnicas tipo uma regressão linear e uma uma regressão, né, exponencial e coisas do tipo. E eu queria criar um app justamente para visualizar isso e foi justamente esse app que eu criei aqui. Então deixa eu mostrar para vocês o prompt que eu passei, tá? Então, o pronto que eu falei foi o seguinte: eu quero criar um app para prever o número de inscritos de um canal. Eu tenho inscritos em múltiplos canais, então YouTube, Substec, LinkedIn, etc. E eu quero ser capaz de gerenciar os canais e traquear quantos inscritos eu tenho em um determinado período, por exemplo, semanal, diário, etc. Então, eu preciso que essa ferramenta seja eh hábil, né? Permita que eu faça a previsão de quando eu vou alcançar um determinado número de inscritos. por exemplo, 100.000 inscritos. Considerando múltiplas formas de previsão linear, Kiger, né, que é compounded annual growth rate e exponencial. Então, tem vários modelos de predição. Eu quero saber utilizando a matemática, considerando o crescimento que eu tive até o dia anterior, quando eu estou posso esperar que eu vou alcançar um determinado número, né? Então eu devo ser capaz de dizer quantos data points, né, quantos dados no futuro eu vou precisar para chegar nesse número, ver um gráfico, mexer na configuração, por exemplo, a janela do crescimento e por aí, tá? Eu preciso também de estatísticas de modo que eu consiga saber qual eu posso confiar mais, né? Ou seja, é qual é o erro. Eu preciso meio que saber qual é o erro de cada curva para eu saber qual previsão é a mais acurada, né? Uma das formas de fazer isso é utilizando uma métrica chamada R2. E com esse prompt, pessoal, ele já me levou em assim 90% do caminho. O que eu vou mostrar para vocês aqui foi resultado de algumas iterações, tá? Mas eh assim, essas iterações foram rápidas, tá? E foi só para ajustar detalhe. Então, deixa eu mostrar para vocês o app como ele tá hoje. Primeiro que ele já veio com o login de cara, então eu já tô logado aqui com o meu e-mail usando Google sem problema nenhum. E eu consigo criar aqui, ó, tanto uma série com, né, os meus inscritos no substeck, quanto aqui no YouTube. Eu consigo fazer, por exemplo, configurar aqui o forecast, né, a previsão e pedir para ele gerar o gráfico para mim. Então, eu tenho aqui oito data points. Então, eu peguei aqui os oito últimos dados aqui do YouTube, coloquei eles aqui, ele já me mostrou bonitinho, com crescimento, tudo mais. Eu posso clicar aqui para generate forecast. E olha aqui a previsão. Olha como o gráfico bem legal aqui, bem bonitinho. Tá aqui o meu target de 10.000. E aí eu consigo ver que todos os, né, na verdade não, né, o linear não tá dando, mas a previsão viager e via modelo exponencial estão dizendo que eu vou atingir 10.000 inscritos no YouTube ali na semana do dia 5 de outubro. Eu tô gravando isso aqui no dia 20, então tô mais ou menos ali é uns 15, 20 dias de bater esse número e, né, no linear seria uma semana depois. Então, inclusive se você tá gostando desse vídeo, tá gostando desse canal, se inscreve aqui no canal que você me ajuda a bater essa meta aqui de 10.000 inscritos, tá? E veja só como eu consigo então saber, né, de uma forma bem legal. Consigo bem que dizer que entre, né, o dia 5 de outubro e o dia 12 de outubro, eu devo estar ali batendo esse número. E aí, inclusive eu consigo ver aqui, né, o R2, ou seja, o erro. Quanto maior aqui no caso do R2, melhor. Então, o linear tá bem bonitinho aqui, né? E o exponencial também tá bem próximo. Então, realmente entre algo entre aqui, ó, dia 8 tá dando linear, dia 3 tá dando exponencial, então devo estar imaginando ali alguma coisa entre essas datas, tá? E olha como ficou legal, pessoal. E aí eu posso vir aqui, sei lá, ah, tá, 10.000, não, vamos botar aqui 50.000 e gerar. E aí eu já consigo ver. Beleza, vai ficar um pouco longe aqui, né? Opa, na verdade eu botei 50.000 mesmo. Não sei porque ele botou tanto aqui. Ah, tá. Porque ele tá pegando o linear aqui. É, o gráfico ficou um pouco é amassado aqui, não ficou tão bom de ver, né? Porque o crescimento, chega um ponto que o crescimento do Kiger e do exponencial destoa muito do linear, né? E aí o gráfico fica um pouco ruim de ver. Não é problema do app, né? né? Um pouco problema de como crescimento linear exponencial de vergem, mas se eu olhar aqui no, por exemplo, no 20.000, eu vejo aqui mais ou menos quanto que chegaria e cada um das curvas, tá? Então, por exemplo, um tempo médio aqui de 16 semanas, né? O mais otimista sendo o Kiger, o menos otimista sendo linear, sempre vai ser o linear, o menos otimista, né? E eu consigo ver isso bem legal aqui. E aí eu poderia até usar mais períodos de lookback, né? Olhar mais dados para fazer essa previsão. Aí você vê que já altera um pouquinho, né? exponencial passou a ser o linear, caiu um pouquinho mais, né? Eu consigo ajeitar a curva aqui para ter uma noção estatística. Então, olha que legal, algo que eu faria numa planilha, boto o dado aqui, eu consigo transformar em dado actionable, certo? É um dado que não só eu tô salvando na planilha, mas eu tô tirando uma informação dali. Se eu mantiver esse crescimento, quando que eu chego em um determinado número de seguidores? E por aí vai. Eu posso fazer aqui o monitoramento semanal, etc., para ver se eu tô melhorando ou piorando nas minhas previsões. Beleza? Então, bem legal, pessoal. Eu espero que com isso vocês tenham conseguido ver como é fácil de você criar algo que seja útil para você. Ah, Rafael, você não vai ganhar dinheiro com isso. Mas tudo bem, eu não preciso necessariamente fazer algo aqui para virar um produto. Eu posso muito bem fazer algo que seja uma ferramenta interna para mim. E esse para mim é o primeiro grande caso de uso. São ferramentas interno, ferramentas que só fazem sentido para você, mas que são úteis, certo? Então isso aqui seria algo que se eu fosse fazer, né, usando um Jupler Notebook, se eu fosse escrever no Python, me daria trabalho. Eu terei que fazer ali de uma forma para ficar atualizando. E já criei aqui com pouquíssimos crompet, deixei um app bonito, eu consigo rodar no celular, consigo vir aqui, colocar os dados da próxima semana e ver o gráfico e saber exatamente ou, né, usar métodos estatísticos para chegar a alguma conclusão aqui para mim, no caso, quando eu chegaria em certo número de inscritos, beleza? Mesma coisa aqui para o substeck. Então, se eu olhar aqui na quantidade de inscritos que eu tava na semana, quando que eu chegarei em 1000 inscritos no substeck, que era minha meta pro ano? Tá aqui, ó, o linear me dizendo que eu chego lá no dia 26/10, tanto o Kiger quanto exponencial falando que eu chego lá no dia 12/10. Então, em outubro eu devo estar chegando nessa meta também. Importante dizer que olha só aqui no caso do do Substeck, o Keiger, né, o crescimento utilizando, né, o crescimento das últimas semanas, anualizando o crescimento das últimas semanas, tem o maior R2, ou seja, é a curva com o menor erro. Então, a maior confiança aqui para mim seria estar chegando nesse número no dia 12/10. E eu posso ver o gráfico aqui bonitinho. Você vê como fica o linear aqui, como ele começa a tomar essa carinha exponencial. Se eu pegasse aqui, sei lá, e colocasse 2.000, por exemplo, a gente consegue até ver mais a cara exponencial aqui, tá vendo? E aí eu consigo ter uma noção de quando eu chegaria em cada um desses números. Beleza, pessoal? Agora deixa eu falar um pouco mais aqui do Moca e de coisas que me chamaram atenção positivamente, tá? Primeiro de tudo, eu achei muito rápido entre você sair da ideia e ter um app funcional. Isso aqui que eu mostrei para vocês é um app funcional, concorda? Tá funcionando bonitinho. Posso vir aqui, ó, colocar mais dados, editar, deletar, projetar, criar mais um canal, botar LinkedIn aqui, etc, etc. Então, esse app aqui tá funcional. Olha só, eu comecei essa conversa às 16:05, né, 4:05 da tarde do dia 15 e a minha última mensagem foi 5:38 do mesmo dia 15. Então assim, em 1 hora30 eu criei isso aqui, pessoal. 1 hora30 sem programar, com banco de dados, com gráfico funcionando responsivo. Isso porque eu fiquei um tempo aqui ajustando alguns detalhes, tá? Porque se você parar para ver quando que o app ficou funcional mesmo, foi até antes disso. Então eu achei bem rápido, de verdade. Essa talvez tenha sido a coisa que mais me chamou atenção, como a gente consegue sair da ideia e chegar em algo funcional, algo que você consegue utilizar bem rápido. Segundo ponto, eu não achei caro, entre aspas, como eu falei, o pessoal da Moca, né, me deu acesso aqui, então eu tenho um plano que é o plano silver deles, tá? Aí, deixa eu mostrar um negócio para vocês, ó. Tá vendo? Eu tô com 4139 créditos aqui. Se a gente entrar aqui no Get Moca e ir lá no preço, o plano Silver te dá 4.500 crédito, beleza? No mês, né? E aí vai renovando. Se você somar todos os créditos e aí é assim que funciona o Moca, né? Cada mensagem ela gasta um número de crédito. Então aqui essa minha primeira mensagem gastou 31 créditos. Aí eu pedi para fazer uma outra coisa, gastou mais 11 créditos e por aí vai. Então, toda mensagem vai te gastar um determinado número de créditos e dependendo do plano que você assinar, você tem tantos créditos no mês. No caso do silver que eu tô aqui são 4.500. Mas olha só, pessoal, eu fiz toda essa conversa aqui e aí eu somei tudo aqui depois de um tempo e no final eu mandei 15 mensagens e totalizou 176 créditos, pessoal. 176 créditos do zero até ter o appun. Eu não preciso mais mexer nesse app, tá? E é que tá pronto que eu queria fazer, que era ter uma forma de projetar os meus inscritos, já está feito. Eu demorei aqui 1 hora meia, 15 mensagens, 176 créditos. Caramba, olha isso. São 4.500. Então eu poderia fazer, sei lá, 4500 div por 176. Eu poderia fazer 25 apps desses no mês com esse plano que eu tô de 50. Fosse pro plano de $20 aqui, beleza, poderia fazer 10 apps desses. Então assim, por $20, sabe? Caramba, eu acho, eu achei realmente barato, pessoal, de verdade, assim, tem dificuldade até de ver como que eles devem estar ganhando dinheiro, porque é barato mesmo assim, sabe? você realmente consegue criar um app do zero com poucos dólares ali, sei lá, $ mês, eu usei 10% disso aqui com 2 sabe, vamos converter para real aqui. Gastando R$ 12, eu transformei uma planilha de dados cruz em um app dinâmico, com estatística, com projeções, etc, etc. Então assim, realmente é um excelente negócio, tá? e ainda mais do fato que tem aqui login, então mais uma pessoa poderia usar se fosse o caso e tudo mais. Então assim, isso realmente foi algo que me impressionou. E aí pessoal, mais uma coisa que eu achei legal é o seguinte. Você vê que aqui uma das mensagens que eu falei foi: \"Ah, deixa eu dar uma forma, deixa eu ver uma forma aqui de de ver os dados, né? Que é justamente isso que eu pedi para ele, para ele construir para mim. Só que você pode vir direto aqui nessa TV de data e você vai ter acesso direto ao banco de dados. Então, tá aqui o usuário, usuário que eu fiz o login ali no Google, lembra? Os channels, né, os canais onde eu tô fazendo traqueamento dos inscritos e os dados de de subscriber. Então, o banco de dados tá direto aqui. Então, se eu precisar mexer em alguma coisa, eu já tenho meu banco aqui. Então, tá tudo integrado em uma interface só. Isso é excelente. Isso é muito bom, porque eu não preciso ficar indo, por exemplo, no lovable ou no v, você vai ter que ir lá no super base. Então, você tá em outro app, sabe? Aqui não. Aqui você tá no mesmo lugar, num banco de dados, numa tab onde você alterna entre o seu app, o banco de dados e a outra coisa que eu queria mostrar que é o código. E aí, lembra que eu falei para vocês que isso era um app cloud flare? Tá aqui, ó. A gente tem uma pasta aqui, Work, que é um cloud flare worker, que eles usam por trás dos panos, com um index, onde tem todo o código do back end aqui. E aí eu posso vir aqui, ó, e até mexer no back end. Eu posso mexer no back end, clicar em publicar. Então eu posso alterar isso aqui, né? Então é incrível. Isso é excelente. Para quem tem noção já entra aqui e sabendo o código, você pode até promptar já dizendo para ele: \"Olha, faz isso aqui, faz aquilo ali.\" Você consegue ter muito mais controle sobre o que a IA vai construir, tendo acesso ao código, tanto front end quanto o back end. Como eu disse para vocês, ó, eles vão construir um app utilizando Vit com Cloud Flir, com Tail Wind, então é um stack bem moderno, qualquer IA consegue fazer isso muito bem. E isso realmente foi algo que eu gostei bastante. Beleza? Então tá aqui um exemplo de app que você pode construir, que é um exemplo clássico de algo que é útil para você. É uma ferramenta útil que você pode utilizar, enfim, dependendo do seu caso de uso. Beleza? Deixa eu mostrar com vocês aqui mais um outro caso onde eu gostei. Calma que até o final desse vídeo eu vou falar um onde eu achei que ele não foi bem, tá? Ele não funcionou. para que você entenda mais ou menos onde estão os limites. Eu tento, claro, como engenheiro de software aqui, eu tento sempre levar ferramenta ao limite para ver onde que ela funciona, onde que ela brilha, onde que ela não é tão bem assim, pra gente poder entender até onde a gente consegue confiar nessa ferramenta. Pessoal, ferramentas são feitas para que você resolva problemas que ela foi projetada para resolver. Então não tem nada demais você ter uma ferramenta que não, uma ferramenta que não é adequada para esse problema. Vamos utilizar outra. Então isso é algo que eu sempre tento fazer aqui no canal, beleza? Então vamos falar de mais um caso de uso que eu achei bem legal. Eu já criei um vídeo aqui que eu também vou deixar aqui na descrição, onde eu faço um clone do Link Tree utilizando o Vzer. Link é um app onde você meio que pode linkar, né, o pessoal usa muito no Instagram, né? Deixa eu até entrar aqui no Instagram do Cont Brasil, ó. Inclusive, pessoal, você que tá assistindo esse vídeo aí, me dá uma moral, segue a gente lá no Instagram. A gente tá bem atrás da nossa meta no Instagram. Então, quanto mais pessoas me seguirem lá, mais me dá motivação para criar conteúdo exclusivo no Instagram, né? Pois não tem tanta gente lá, então me ajuda lá, dar uma moral, por favor. Bom, aqui no Instagram, né, o Instagram só permite que você deixe um link, né? Então ele meio que criou esse business que é o Link Tree, onde você pode clicar aqui e aí, né, você condensa vários links em uma página só. Então, aqui no Instagram só posso botar um link, você bota um link que te abre vários links, né? Meio que esse é o jogo aqui do do Link Trep, só que o Link Trip, por incrível que pareça, ele pode ser pago, né? Isso aqui é uma coisa tão simples que eu acho tão trage isso aqui ser pago e é um excelente caso de uso para você criar com app, por exemplo, tipo Moca. Então, em vez de você pagar o Link Tree, você vem no Moca e cria o seu próprio Link Tree. E aí, deixa eu mostrar para vocês isso que eu criei aqui. Olha só, vamos de novo dar uma olhada aqui na na conversa que eu tive. É, eu tive algumas iterações a mais com esse aqui, porque ele deu um problema específico, eu já vou falar, mas olha, o meu prompt é bem simples, pessoal. Olha lá. Vamos criar um clone do Link Tree com uma estética hacker. Não deve ter nenhum login e os dados podem ser adicionados, né, ou devem ser adicionados diretamente através do banco de dados. Nós devemos ser possíveis de reordenar e etc. Coloque como exemplo de links. Aí botei aqui os links do YouTube, da Codecap, do meu site, tudo mais. E basicamente, pessoal, de primeira ele meio que me deu esse app aqui. Olha que maneiro isso aqui como Link Tree com temática hacker aqui, né? Aquela temática meio de terminal, etc. E cara, tá feito. Bem que assim, não tinha nem mais o que fazer aqui, sabe? Ficou muito maneiro isso aqui, né? Deu aqui todos os comandos para se eu quisesse adicionar no banco de dados. Evidentemente que eu posso vir direto aqui na tab data e colocar o link aqui direto, mas ele funcionou basicamente de primeira. E o que demorou um pouco mais foi que eu pedi uma funcionalidade de reordenar. Então eu posso vir aqui, ó, reordenar esse link agora, né? Os meus ensaios que eu escrevo na newsler estão em primeiro. Se eu atualizar a página aqui, ó, ensaios estão em primeiro. Então, de fato, tá persistindo no banco de dados. Se eu voltar aqui pro YouTube do Cont Brasil, colocar code capital, que é newsletter que eu falei, tá aqui a ordem e posso atualizar aqui. Então, muito fácil de fazer. E depois que eu criei, o legal de você fazer dessa forma é que você pode ir pedindo para ele fazer outras coisas. Eu a gente vai fazer uma coisa nova aqui, tá? Uma das coisas que eu pedi foi justamente para que ele criasse um modo de admin, tá? Por quê? Porque eu quero poder adicionar links, mas eu queria poder divulgar essa página no lugar do link tree. Aqui eu colocaria o link aqui desse meu link tree hacker. E aí eu pedi para ele, cara, me dá uma forma de virar admin aqui, né, com uma senha qualquer. Então, se ele até fez aqui, ó, tem um botãozinho de admin e aí se eu não for admin, deixa eu cancelar aqui, ó. Tá vendo? Eu não consigo nada, eu não consigo reordenar. A única coisa que eu consigo fazer é clicar, cair aqui no YouTube do Conte Brasil ou clicar e cair ele lá no code, então não consigo fazer nada. Se eu for admin e olha, olha que maneiro esse modal que ele fez aqui para autenticação, cara. Eu eu nem eu só pedi a estética hacker, entendeu? Então eu consigo me autenticar e aí eu consigo modificar. Muito maneiro. Vamos fazer uma coisa juntos aqui. Então, eu comecei um pouco isso aqui e parei para que a gente pudesse fazer no vídeo ao vivo para eu mostrar para vocês, não só ficar mostrando. Vocês viram que eu tô mostrando já pronto para ele não perder muito tempo, né? Porque você vai intero, pede para ela fazer, não tem muito mistério, tá pessoal? Mas eu quis deixar algumas funcionalidades pra gente fazer junto aqui, beleza? Então, vamos lá. Se a gente olhar aqui no modelo de dados, eh, eu pedi para que ele botasse uma coluna execute para eu poder ativar ou desativar um link, tá? Então, veja que no momento, mesmo sendo admin, eu não tenho como ativar nem desativar. Então, essa vai ser a primeira coisa que eu vou pedir para ele para nós fazermos juntos aqui. Alrght, let's allow admin only to activate or inactivate a link. Então, bem simples, pessoal. Eu tô dando aqui para ele uma instrução funcional, um requisito. Eu não tô pedindo código, só tô falando para ele que eu quero ser capaz de ativar ou desativar um link sendo admin. Então, é basicamente isso que você precisa fazer. E agora você vai ver que ele vai trabalhar. Aí ele vai mostrando, ó. Tá atualizando aqui o usink. Se você for lá no código, você vai conseguir ver, ó, atualizar o link item. Então ele vai dando todo o código onde ele tá mexendo, vai trabalhar por um tempinho, vai consumir alguns créditos e quando tiver pronto você vai interagir. Então vamos deixar ele terminar aqui e vamos voltar quando tiver tudo finalizado. Pessoal, 1 minuto e 6 segundos foi o tempo que ele precisou para criar essa funcionalidade. Antes de tudo, vamos ver se tá funcionando, tá? Então sei lá, vamos supor que eu quero desabilitar aqui a code capital. Então, tem um botãozinho de olho. Cliquei. Olha, olha, olha isso aqui. Olha como ficou maneiro. Olha como a ficou boa. Já tá inativo, né? Vamos atualizar para ver se tá persistindo. Persistindo. Maravilha. Vamos lá no banco de dados. Links e z false pro code capital. Então, funcionando perfeitamente. Talvez. Deixa eu fazer mais um teste aqui, ó. Se eu dar o logout. Ah, sumiu. Tá vendo? Só admin consegue ver. Se eu logar aqui, colocar senha, eu consigo ver os links inativos, pessoal. 1 minuto e 6 segundos gastou sete créditos. Lembra do preço? 4.500. Sei lá, se você ficar no plano de 20.00 créditos, sete créditos. Ele fez uma funcionalidade inteira. Ah, não é a funcionalidade mais complexa do mundo, mas olha como é fácil, né? Você diz o que você quer, uma linha de código, não fiz grandes promptes. Ele resolveu inclusive com uma estética muito bonita. Então assim, é difícil querer algo mais do que isso. Vamos ser sincero aqui, né? Tá, tá, tá feito, né? Então, realmente gostei bastante. Mais uma coisa que eu queria fazer, você vê que quem entra no site já tem aqui esse admin mode, né? Eu queria que isso fosse meio que escondido, então queria que isso tivesse, sei lá, sabe aqueles jogos onde tem tipo um easter egg, onde você precisa apertar uma combinação de tecla para aparecer o admin? Então vou meio que pedir isso para ele. That's working great. Now I want the following. The admin button is visible to everyone. What I want is for that to be visible. after the user press a certain command. Please make sure it only shows up after the command like an old style Easter egg. Então vamos ver o que que ele vai tirar disso aqui. Vocês vejam que eu não falei para ele qual é o comando, tá? Eu tô dando um pouco de liberdade criativa para ver se ele entende. Eu poderia fazer um trabalho um pouco melhor. Aperta contrl shift K, sei lá, que aí abre o admin. Mas eu tô falando de propósito de forma um pouco vaga, tentando simular a pessoa que é menos técnica, né? Você vê que ele já entendeu, né? Ele falou: \"Me deixa adicionar um listen pro keyboard\", que é justamente isso que a gente precisa fazer, né? Que vai mostrar o admin. E aí ele meio que fez aqui, ó, gastou quatro, que ele não me falou qual que é a sequência. Que que ele fez aqui? Deixa eu clicar em review. Aí a gente pode ver até o código. Ah, o secret sequence tá aqui, ó. Sudo. Pô, legal, hein? Bem maneiro. Será que é escrever sudo? Vamos ver aqui. Sudo. Ah, olha que maneiro, cara. Ah, mas não, mas não desbloqueou não. Não sei se funcionou. Bom, eu vi a automação aqui, ou melhor, eu vi a animação aqui, ó. Esse aqui não dá para clicar. User mode read only. Se você escrever sudo, access granted aí. Beleza, mas não me deu admin. Ah, aí ele permite que eu seja admin. Ah, entendi. Putz, bem maneiro, hein. O que que vocês acharam dessa estética aqui? Vocês sacaram o que que aconteceu aqui, ó? Eu vou dar o logout aqui. Eu tô com admin, né? Eu posso clicar e e botar a senha. Se eu atualizar, vamos dar um refresh aqui, tá? System, tá vendo? Não consigo fazer nada. Aí, ó, eu vou escrever sudo aqui na tecla. A partir do momento que eu escrevi sudo, aparece essa animaçãozinha dizendo que me desbloqueou e o que era system virou admin. Tá vendo? E aí agora eu posso colocar a senha normal, root 1 2 3, que é a senha que eu tô usando aqui, e me desbloqueou. Olha que maneiro, que legal isso aqui, pessoal. Ele me gastou quatro créditos para fazer essa funcionalidade. Demorou 22 segundos. Eu não disse para ele como eu queria fazer. Ele fez dessa forma. Eu tinha até pensado em outra forma. Tinha pensado não mostrar esse painel aqui, só mostrar depois de fazer a sequência, mas eu até achei que ficou legal. E tá feito um link three. Eu poderia colocar isso aqui no meu Instagram, por exemplo, e funcionaria perfeitamente. Inclusive, ó, remoto. Então, muito legal. Ah, como que eu coloco o link? poderia colocar aqui agora um, né, uma funcionalidade para Ah, vamos fazer isso, vai, já, já que a gente tá aqui, vamos fazer isso aqui. Vou pedir para ele o seguinte. Great. Now, add away. The link can at the bottom byorder later. Só para vocês terem uma ideia como que deve ser fácil, né? Quando eu criei isso aqui, eu tinha pensado em ir no próprio banco de dados fazer na mão ali, dar um insert e tudo mais, mas isso aqui me parece que ele vai resolver bem fácil se eu pedir para ele me dar uma forma de criar uma interface aqui. Eu quero fazer isso para ver qual que vai ser a estética que ele vai usar. Veja que eu só falei lá no início que era uma estética hack, né? Mas ele meio que pegou essa nuance e agora tudo que eu tô fazendo, ele tá dando essa estética. Então vamos deixar ele finalizar aqui esse formulário e vamos ver quando como vai ficar no final. 41 segundos depois ele mexeu em três arquivos e disse que tá feito. Bom, tô vendo aqui, ó. Não estou como admin, não consigo fazer nada. Vamos colocar aqui, ó. Sudo, desbloqueei, liberou o botão admin, coloquei senha, authenticatei, add new link, ó, link title e URL. Vamos botar aqui, ó, Instagram, URL. Vamos pegar a URL do Instagram aqui e descrição. Behind the scenes of the Qu Brasil channel. Create link, Instagram foi lá para trás. Olha que maravilha. Vamos reordenar. Vamos jogar ele lá pra primeira, por exemplo. Salvou. Vamos dar o refresh Instagram aqui, logout. Dá o refresh aqui de novo. Funcionando bonitinho. Inclusive com o banco de dados. Pessoal aí, alguém quer vir me dizer que é purista e que você não deve utilizar plataforma webc? Francamente, pessoal, não é porque esse é um vídeo de parceiro, não. Mas por que que isso aqui seria pior do que você pagar o Link Tree, por exemplo? Tô dando o exemplo do link trick, tá? Mas poderia ser qualquer outra coisa, pô. 41 segundos eu coloquei uma fature, 22 aqui eu coloquei um easter egg. Assim, pessoal, vamos ser sincero, né? Claro que dá para utilizar isso aqui, né? Não vamos ser puristas aqui, dizer que que não, só programação que importa, não, pô. Cria algo, né, único, algo criativo e aí você consegue dar ali asas pra sua imaginação para ela fazer o que você deseja. E aí, pra gente finalizar essa parte aqui, mostrando as funcionalidades do Moca, eu vou clicar aqui em publish. Deixa eu clicar em publish para ver como funciona. Tô falando isso pela primeira vez aqui com vocês pra gente ver como que é o processo de depois que você finalizou o app, você colocar ele na nuvem para as pessoas de fato poderem utilizar. E aí, pessoal, passou alguns segundos, ó, e acho que tá publicado. Ah, é, agora ele permite que eu edite. É isso. Ah, tá aqui, ó. Então, vamos botar aqui, ó. Rafaelquintanilha.moca. Publish. atualizou o subdomínio, né, com sucesso. Esperar o act ser redeploy, né, de novo, eles fazem isso aqui com cloud flare, então costuma ser bem rápido, algumas alguns segundos apenas. Tá pronto, vamos tentar aqui, ó, rafaelquintanilha.moca. E olha meu app criado com o Moca disponível para as pessoas disponível na internet. Tô aqui, ó, no modo normal com as funcionalidades que a gente botou, ó. Sudo para desbloquear, senha. Tá aqui. Vamos fazer o teste do Instagram de novo aqui, ó. Pegar o link do Instagram. Instagram. Link behind the scenes of the qu Brasil channel. Só pra gente ver aqui, ó. Create link surgiu aqui no Instagram. E aí eu posso atualizar e ó o Instagram aqui. Então, de fato, ele tá indo lá pro banco. Então, se a gente ver aqui em data agora, tem que ter dois bancos de dados. Ah, aqui, ó, development e production. Estão vendo? Agora eu tenho dois bancos de dados, um para desenvolvimento e outro para produção. Ele até me dá uma ordem que eu tô editando banco de dados de produção, mas tá aqui funcionando bonitinho. É, veio com esse clone if moca. Deve ter uma forma de tirar isso aqui, né? O settings do Moca. Mas pessoal, muito maneiro. Olha só, realmente eu gostei bastante. Tá aqui uma funcionalidade assim, claro, um caso de uso claro, tá na internet. poderia vir aqui agora, jogar aqui no Instagram e você conseguiria ver o meu Link Tree nesse formato aqui meio old school retrô terminal hacker style, beleza? Então eu realmente gostei bastante. Para não finalizar esse vídeo falando que tudo é um céu de brigadeiro, eu vou falar duas coisas aqui que eu não gostei tanto e que eu acho que poderia melhorar. Primeiro ponto de tudo é o seguinte, pessoal. Eu sou programador, então eu gosto de ter controle do código. Muitas vezes eu gostaria de vir aqui no meu app e editar alguma coisa no código, sei lá, num cursor, num cloud code, num codex e mandar ele de volta aqui pro moca. Então esse two way thinking não é possível. O que é possível é eu pegar o meu código aqui. Então eu tô com código aqui, ó. Tenho todo o código aqui, eu consigo, né, pegar ele, baixar, enfim, tô com todos os arquivos aqui, conseguiria baixar tranquilamente, ó, posso até criarqui, diretamente aqui, criar código e beleza. Ó, aqui, ó, download code, tá vendo? Consigo clicar aqui, ó, download code, carregar no meu terminal e continuar a partir daqui. Só que a partir do momento que eu fizer isso, eu não consigo voltar pro Moca. É meio que eu eu já ejetei o código, não consigo mais voltar. Então isso me incomoda um pouco. Eu queria poder tirar ele do Moca, trabalhar localmente, voltar pro Moca, trabalhar via prompt e por aí vai. Então isso me incomoda, eu gostaria que fosse possível fazer isso. E uma outra coisa que eu tentei fazer e não deu certo foi sabendo que é um cloud flare, eu tentei fazer um chat utilizando Cloud Flare Streams, tá? E eu tentei aqui bastante tempo e ele não funcionou. Beleza? Eu não sei por, né? o que que eu fiz de errado, se ele se enrolou de alguma forma. Então, eu tentei criar um chat aqui, tipo um clone de um Discord, de um Slack, e aí ele meio que para aqui, ó, no connecting e não funciona, fica desconnected. E se você vier aqui no terminal, fica dando esse web socket erro. Então, ele meio que não funcionou fazer esse chat lá no cloud flash streams. Bom, pode ser que ele funcione se eu continuar insistindo aqui, né, tentar fazer ele ele debugar aqui de alguma forma. poderia, por exemplo, pegar o código aqui, jogar lá no CODEX, tentar falar para ele, ó, tá dando esse erro, você consegue entender o porquê e voltar para ele, né, com uma sugestão, mas eu não consegui fazer funcionar. Então, tô querendo dizer isso por quê? Porque talvez em alguns casos mais complexos, você utilizar ali web socket para fazer chat, coisa do tipo, você não vai não vai conseguir fazer. Dito isso, casos mais simples e até casos onde você quer utilizar AI, Stripe, essa é uma das coisas que eu acabei nem falando pro vídeo não ficar muito grande, mas se você vier aqui num app qualquer em setting, você tem uma área aqui de secrets e aqui você consegue colocar um API key, por exemplo, o seu open AI API key ou ali o seu Stripe API key. Então você consegue já colocar até cobrança, você consegue fazer integração com a API do chat GPT, por exemplo, e ele vai funcionar tranquilamente, tá pessoal? Então me conta aqui nos comentários se você quer depois que eu faça um outro vídeo utilizando Moca, talvez com algo mais complexo, envolvendo AI ou envolvendo cobrança lá no Stripe, que aí seria algo que você poderia pegar, trabalhar no seu app e colocar como um produto, certo? Evidentemente, pessoal, é Vibe Coding, tem que ter um certo cuidado com COD, com segurança, tá? Mas você já tem aqui um caminho pelo menos para você fazer uma prova de conceito e dali você finaliza, por exemplo, depois, né, num terminal, numa IDE e algo do tipo. Eu achei muito bom. Eu achei que realmente funcionou, não achei caro esse app aqui do Link Tree Coloney. Foi assim bem poucos créditos e criei algo funcional em alguns poucos minutos. Beleza, pessoal? Então fica a dica para vocês de utilizar o Moca AI para criar os seus apps vibe coding e fale o que quiser. É divertido para caramba você ter uma ideia e você ali trazer essa ideia para a prática simplesmente dando alguns poucos prompt. É realmente algo divertido. É algo que eu acho que todo mundo deveria experimentar. Você não precisa necessariamente fazer o seu business através disso, apesar de que você consegue, mas só de você construir ferramentas para o seu próprio uso, pro seu próprio consumo pessoal, eu já vejo como uma grande vantagem. Beleza? Eu vou deixar o link na descrição para você testar o Moca AI. Me conta aqui se tem algum outro tipo de app que você gostaria que eu construísse. E aproveito e reforço o pedido para se inscrever aqui no canal, curtir, compartilhar esse vídeo. Entra lá no nosso Instagram, dá uma moral. Vamos ver se a gente sobe o número de inscritos no Instagram. Agradeço pela audiência de sempre e até a próxima.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Avaliação honesta do MoCa AI como ferramenta para criar aplicativos sem programação, destacando backend incluído, velocidade de prototipagem e as limitações de segurança ao escalar.",
            "resumo": "Neste vídeo, o apresentador, engenheiro de software, avalia o MoCa AI como ferramenta para criar apps com IA, sem precisar programar. Ele defende que, apesar da resistência ao termo 'vibe coding', há cenários em que gerar protótipos ou até produtos reais a partir de prompts é válido para testar teses, bootstrap de negócios ou acelerar a criatividade. O MoCa AI é apresentado como plataforma que transforma ideias em apps com frontend em Vit (Vite/React) e backend em Cloudflare, incluindo autenticação, banco de dados e envio de e-mails já embutidos. O diferencial é permitir visualizar o backend e ter tudo pronto, sem setup. O apresentador compara o MoCa com Lovable, discute limitações, principalmente questões de segurança ao escalar, e ressalta que não substitui desenvolvedor, apenas facilita etapas. Também menciona o apoio de VC (YC) e cita artigo sobre nem todo programador precisa ser profissional, defendendo uso responsável de IA.",
            "assunto_principal": "Avaliação do MoCa AI como ferramenta de desenvolvimento de apps sem código, com backend integrado, comparação de mercado e considerações de segurança.",
            "palavras_chave": [
              "MoCa IA",
              "sem programação",
              "IA",
              "prototipagem rápida",
              "backend incluído",
              "front-end Vit",
              "Cloudflare",
              "autenticação",
              "banco de dados",
              "segurança",
              "Lovable",
              "financiamento YC"
            ],
            "resumo_em_topicos": "- Contexto e objetivo: analisar o uso de IA para criar apps sem programar e discutir quando isso faz sentido.\n- O que é MoCa AI: plataforma que transforma prompts em apps, com backend incluído.\n- Diferenciais técnicos: frontend em Vit (Vite/React), backend em Cloudflare, autenticação, banco de dados e envios de e-mails já prontos.\n- Comparação de mercado: menção ao Lovable e ao ecossistema de ferramentas de IA para apps.\n- Benefícios: prototipagem rápida, bootstrap de produto, menor dependência de terceirizados.\n- Limitações e riscos: questões de segurança ao escalar, qualidade de código e limites da abordagem.\n- Parcerias e honestidade: aviso de parceria com a MoCa e compromisso com uma opinião sincera.\n- Conclusão: MoCa é útil para cenários específicos, não substitui desenvolvedores; pode acelerar etapas.",
            "prompt_tokens": 1908,
            "completion_tokens": 3087,
            "model": "gpt-5-nano",
            "cost": 0.0056
          },
          "analysis_time": 76.67480516433716,
          "language": "",
          "view_count": 1903,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@RajRamesh",
      "name": "@RajRamesh",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@RobertMilesAI",
      "name": "@RobertMilesAI",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@SAP",
      "name": "@SAP",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "B6BY9OZR33o",
          "title": "Is SAP Build Only for Low Code? | SAP Build Myth Busters",
          "title_pt": "O SAP Build é apenas para low-code? | Desmistificando Mitos do SAP Build",
          "url": "https://www.youtube.com/watch?v=B6BY9OZR33o",
          "published": "2025-09-23T09:06:05.910695",
          "published_relative": "há 4 horas",
          "duration": "02:47",
          "date_published": "2025-09-23T02:00:13-07:00",
          "transcript_available": true,
          "transcript": "- When most people hear \"SAP Build,\" there's one thing that usually\ncomes to mind: low-code, and they're not entirely wrong. (upbeat music) That's how SAP Build first started, drag-and-drop tools to create apps and customize processes. Afterwards, we also added\nAI-powered development, but that's only one part of the story. We heard our customers loud\nand clear, you needed a way to tackle broader spectrum\nof development projects, and you want to do it at scale. That's why SAP build has evolved into a full-stack development platform, spanning low-code,\npro-code, and generative AI. This empowers your entire\nteam to use the tools that best fit their skills and collaborate seamlessly\non a single platform. Let's walk through an example of building an enterprise-grade\nextension with SAP Build. Everything starts with\nthe SAP Build lobby. Here, your team can choose the tools that best fit the project. As you can see here, you can\nbuild a wide range of solutions with SAP Build, from full-stack apps to front-end extensions\nand mobile applications. First, what we need to do\nis to create the backend. Jump directly into an\nABAP Cloud environment to create upgrade-safe extensions. To enforce new business rules in ABAP RESTful application\nprogramming model, you can extend the business object with new validation logic. If you prefer to work in the cloud application\nprogramming model, you can also add custom\nbusiness logic to your service with natural language and\nwrite the code directly. Now, for the user interface, let's use a template\nto give us a headstart. You can select the list report option to build out your Fiori app. Once completed, instantly preview and test your application, whether it's a Fiori app like this one, a custom UI5 interface,\nor a mobile application. With everything you build,\nyou can assure your governance and lifecycle management\nremains rock solid. You can push changes from SAP Build through your GitHub repo, triggering automated scans, test suites, and validation for release. What's more, you can do all of this without switching between tools, move seamlessly between\nnatural language prompting, visual editing, and code to\nbuild enterprise-grade apps. And honestly, we're really\njust scratching the surface of what's possible. If you'd like to learn\nmore, I highly encourage you to check out our SAP Build free trial, where you can get hands-on\nwith our tutorials. Thanks for watching. See you soon. (gentle music)",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "SAP Build evolui de baixo código para uma plataforma full-stack que integra low-code, pro-code e IA generativa, capacitando equipes a colaborar em projetos empresariais com governança integrada.",
            "resumo": "Quando se pensa no SAP Build, a ideia comum é o baixo código, com ferramentas de arrastar e soltar para aplicativos e processos. No entanto, a plataforma evoluiu para abranger desenvolvimento full-stack, incluindo low-code, pro-code e IA generativa, para que toda a equipe use as ferramentas certas e colabore em um único espaço. O vídeo apresenta um exemplo de extensão empresarial: iniciar pelo backend no ABAP Cloud para criar extensões seguras de upgrade, com regras de negócio no ABAP RESTful Application Model, ou, se preferir, usar o Cloud Application Programming Model para adicionar lógica personalizada via linguagem natural e código. Na interface, templates ajudam a acelerar o frontend (Fiori, UI5 ou aplicativos móveis). A governança e o ciclo de vida permanecem fortes: mudanças podem ser enviadas para o GitHub com varreduras, testes e validação automatizados. E tudo isso funciona sem trocar de ferramenta entre as etapas de prompt em linguagem natural, edição visual e código.",
            "assunto_principal": "Evolução do SAP Build de low-code para plataforma full-stack com foco em IA, governança e integração entre equipes.",
            "palavras_chave": [
              "SAP Build",
              "baixo código",
              "código profissional",
              "IA generativa",
              "pilha completa",
              "ABAP Cloud",
              "ABAP RESTful",
              "Modelo de Programação de Aplicações em Nuvem",
              "Fiori",
              "UI5",
              "governança",
              "ciclo de vida",
              "GitHub",
              "extensões empresariais"
            ],
            "resumo_em_topicos": "## Pontos-chave\n- Origem e evolução: do low-code para uma plataforma full-stack com suporte a low-code, pro-code e IA generativa.\n- Ecossistema: lobby para escolher ferramentas, cobrindo apps full-stack, extensões frontend e apps móveis.\n- Backend: ABAP Cloud com extensões upgrade-safe e ABAP RESTful; ou CAP para lógica personalizada via linguagem natural.\n- UI: templates para Fiori/UI5; previews e testes rápidos.\n- Governança: mudanças enviadas ao GitHub com varreduras, testes e validação automatizados.\n- Fluxo de trabalho: transição suave entre linguagem natural, edição visual e código.\n- Aprendizado: trilhas gratuitas e tutoriais disponíveis.",
            "prompt_tokens": 669,
            "completion_tokens": 3889,
            "model": "gpt-5-nano",
            "cost": 0.0062
          },
          "analysis_time": 93.04285216331482,
          "language": "",
          "view_count": 1,
          "has_transcript": false
        },
        {
          "id": "gKD-9tHZDpY",
          "title": "Transforming dsm-firmenich’s i-Health: A Journey to the 3-System Landscape | Episode 2 | Expert Talk",
          "title_pt": "Transformando o i-Health da dsm-firmenich: uma jornada pelo panorama de 3 sistemas | Episódio 2 | Conversa com especialistas",
          "url": "https://www.youtube.com/watch?v=gKD-9tHZDpY",
          "published": "2025-09-22T13:06:05.910730",
          "published_relative": "há 1 dia",
          "duration": "14:29",
          "date_published": "2025-09-22T01:00:47-07:00",
          "transcript_available": true,
          "transcript": "Welcome back to SAP's Expert Talk. This is the second part of our two-part series on the three-system landscape conversion journey of our customer dsm-firmenich, i-Health division. In the first video, we discussed the\ncollaborative preparation and execution of all the technical conversions. If you haven't watched it yet, we\nreally encourage you to check it out. See the links below. In the second episode, we'll go deeper\ninto the business outcomes, the benefits of the new 3SL, and how new available\nfeatures have improved day-to-day business operation at dsm-firmenich. Before we dive into the customer journey,\nI'd like to welcome and introduce our guests. Tom, the Digital Partner for\ni-Health at dsm-firmenich. Welcome, Tom.\nThank you. Thanks for being with us today. Calin, thanks for being with us again. Calin, your product manager\nfor the 3SL conversion program. Thank you. Dennis, our program manager\nfor the 3SL conversion program. Hi, Dennis, thanks for being with us too. Let's start with some context. Dennis, would you briefly remind us what\n3SL conversion is about and why this is important to the customers?\nYeah. Thank you, Yannick. SAP's S/4HANA Cloud product has evolved over the period of time, and likewise the landscape has also evolved over the period of time. Every release we add brand-new features into the product, and the landscape also has changed over the period of time. We went from a two-system landscape, where\nwe initially had a quality system and a production system which was managed by a\nmanager solution or solution builder system, to where you have a quality and a\nproduction system, but now managed by CBC, Central Business Configuration. And now, the latest\nlandscape that we provide is a three-system landscape, which has a dev, test, and a\nproduction, which is managed by a CBC system. As time passes by, customers have remained\non some of the older environments, and the goal of this program is essentially to\nmove them all into the 3SL landscape because we at SAP believe that the\ncustomers need to be able to enjoy the latest and greatest that SAP has to offer. Some of the functionalities that are built\nare built first for 3SL and then for downpool sometimes. Also, there are some feature\nfunctionalities that are available within 3SL that we will be able to leverage when\nbuilding new features. And so, we want all customers to be able to enjoy\nthe latest features that SAP is providing. That's why we are so eager to have all\nthe customers converted over to 3SL. Thanks a lot, Dennis, for the refresher and\nthe clear explanation of what is 2SL versus 3SL and the business\nbenefits for the customers. Now, let's focus on the\nstory of our customer. Tom, can you tell us a bit about why\nyou've chosen to have your system converted to 3SL? What was the business benefit for you? The main driver for us to move over to 3SL was the business dynamics that we're in are requiring us to adapt very fast to changing business requirements,\nspecifically, customer requirements. We had a roadmap where we\nneed to develop new functionalities, and in our previously two-systems landscape,\nwe had some constraints that we faced. We wanted to move over to 3SL.\nLike Dennis was mentioning, we now have a separated development from a\ntest from a production environment, which gives us much more control of\nthe developments that we are looking into. The other topic that we are facing\nissues with is the upgrades. The upgrades were a disruption in our\ndevelopment roadmap, and having the 3SL environment,\nwe can continue our developments on a development environment, which gives us\nmuch more time to actually do the developments\ninstead of the disruptions that we faced. The last item, which is very relevant for\nus, is the extensibility on the development side. We're really looking forward to\nexplore the new functionalities for us to improve our developments. Indeed, all in all, we can improve\nand adapt faster to the changing business requirements and be much more in\ncontrol without any disruptions. Tom, thank you very much\nfor your detailed response. Was there a specific task that is crucial\nfor your business now or in the future? I mentioned the change request\nthat we are looking into. We have a couple of them that we now\ncan really focus on with the 3SL environment, with the dedicated developers environment\nthat we really need to deliver at the moment. One of the things is, for example, the\nproduct substitution topic that we haven't been able to deliver in the 2SL world, but\nnow with the extended functionalities we're exploring the product\nsubstitution change request. Tom, can you also tell us a little bit\nabout what you're asking your organization to do now that you're\nconverted over to 3SL? Yes. We have moved over, which I think\nit's six weeks now, but we have been looking into the new features with the development\nteam to explore all the new functionalities that came\nwith the 3SL environment. We really want to change from being\nreactive to proactive, changing the business, leading to business\nvalue with the functionalities that we have. Later on, of course,\nwe think we are ready now for the whole AI Joule journey, which, of course,\nis very exciting to embark on. I think this is absolutely key, Tom, thanks for mentioning that, because now\nyour landscape is always ready for the latest innovation that SAP is\ngoing to ship to all the customers. That's great.\nCalin, questions to you. We know that with 3SL, our customers\nhave access to many other features. Would you like to mention a few of them? Sure. Actually, we have an important asset that is published on our 2SL-3SL conversion Activate, which is named\n2SL-3SL Delta feature. This asset\nbrings the benefits for the customers and highlights the value\nfor the usage of this new features that are enabled in the 3SL landscape. I'd like to emphasize maybe two of them, Parallel Line and CLT,\nCustomer Localization Tool. Parallel Line will allow customers to\ncontinue with the project activities on a parallel line different to the mainline,\nwithout disrupting the mainline activities, leaving the mainline system free for\nany changes that take precedence. CLT, Customer Localization Tool, is helping customers to activate\ncountries that SAP does not offer as a standard, but provide us\nthe tooling to create these countries in the system, so customer can use, let's say, the main features in\nthis 2SL-3SL Delta features. I don't know, Dennis, do you want to\nadd anything on this? Yeah, actually, maybe one more. With 3SL, the partners are\nnow given a partner landscape. What that means is that if they want to\nbuild something new, let's say it's an industry content or maybe\nit's a white gap, or some kind of differentiating functionality that they want to build out,\nthey can do that now. They can also sell that via the SAP Store. There's an entire landscape that's\navailable where you can build something on developer landscape,\ntest it out in the different environments, and then publish it into the SAP Store so\nthat the customers can just click on a button and buy that\nparticular software that is being sold. We're expecting that eventually\na lot of partners will start developing this kind of content and publishing it,\nwhich means that the customers can now leverage a lot of functionality that\nwill be available out there, which will be somehow differentiating\ntheir company from others. Also, if there's some specific industry\ncontent that's out there, they could also bring that along. We're really excited about this\nfunctionality too because now partners are able to build something new and\ncustomers are able to adapt that as well. Wow, that's exciting.\nThanks. Looking forward to explore\nthese functionalities. Absolutely. Tom, now an interesting question for you,\nI think, because we all know from having been in the IT industry for a while that\nthe company's culture eats project plans for breakfast, if I can say so. Can you tell us a bit about how your\norganization prepared for this change and if this has changed your\nday-to-day operations concretely? I think change management and being\nprepared, that's key for a transition like this. We took a lot of time to actually prepare\nall the steps that we needed to do before the conversion, but also after\nthe conversion, of course. We took a lot of time for the change\nmanagement plan, and we took a lot of communication internally, externally,\nto everybody who's involved. I think that was key for successful\nimplementation of the 3SL environments. Of course, the support of SAP\nwith the steps and the roadmap were definitely helpful in preparing us for\nthe conversion. When it comes to now day-to-day changes,\nagain, I think the communication is key, how we now are running the 3SL environment\nand how we're doing the developments together\nwith everybody involved, the technical teams, but also the business teams. That's where we are at the moment.\nThank you, Tom. This is really a testament to your good\npreparation and the communication that you've had with our teams\nand also with your own teams. Change management is critical\nwithin the organization. Coming back to the 3SL conversion,\nI know that you guys also used the CIAS service, which helped you with the\nintegration and rewiring the system. Calin, can you talk to us a little bit\nabout what the CIAS is all about and what it can offer?\nSure. Yes. CIAS, it's Customer\nIntegration Automation Service. The i-Health division was one of the first\ncustomer who used this CIAS service on the pilot phase for\nrewiring integration in the test environment. I will say that\nthe efficiency of CIAS service depends on the number of the integrations that you\nneed to rewire in the test system. As many integrations you need to do on the test\nsystem, as more efficient is the CIAS service. We have customers, for example, who\nuse the CIAS service for rewiring more than 100 integration scenarios, which\nreduces the time of the post conversion activities from four days to two hours. This is, let's say,\nthe benefits of CIAS rewiring service. That's massive automation, Calin.\nImpressive numbers from four days to two hours. Thank you for sharing that. Can you share, Tom,\na bit of your experience using this CIAS, and did you experience this massive gain\nof efficiency, and how did it really help the conversion when doing the project? Yeah, absolutely. I recognize the number that you mentioned. I think we do not have 100, but I think\nwe were a little bit over 40 of the integrations. Integration is key, but it's part of the\nlandscape of the end-to-end processes. Having that tested,\nthat requires a lot of time. But with the functionality of CIAS, we have\nbeen able to reduce a substantial amount of time in our post conversion\nactivities, which was really helpful. Absolutely.\nThank you, Tom. Actually, in addition to CIAS that we are\noffering in the post conversion, we also have TDC. TDC is essentially a test data conversion. With that what we are able to do is we're\nable to bring the master data and transactional data along with some\nconfigurations, like the output management and number ranges, and a few\nother things like that. We were able to bring that over from\nthe dev system, which was your old quality system, into the new test system. Essentially, it makes your old quality\nsystem and the new test system almost identical from a data perspective. That's really beneficial for our customer\nbecause with these two services, the TDC, which is test data conversion, and CIAS,\nwhich helps you with the integration, we strongly believe that this will greatly\nreduce the total amount of effort that the customer has to put in, in order\nto bring their landscape back up to the point where it was in the past. I think that this will help\nout quite a bit, actually. Thank you, Dennis, and thank you,\nTom, for today's discussion, for all your insights for customers who are discovering 3SL\nconversion, as this opens up a lot of new possibilities for them. Thanks for mine too. Dennis, Calin, Tom, much appreciated that\nyou made the trip to Waldorf in person. It's great to see that you have a strong\nplan for the future, and we at SAP are more than happy to have enabled all those new\nfunctionalities for you and our Cloud ERP customers. Of course, we're here to\nsupport you in the future. Thank you for taking the time to explain\nthis to our customers and other partners. If you want to learn more, we've included\na link in our three-system landscape community page in the video description, complete\nwith presentations, FAQs, and other enablement videos. Visit our SAP community and contact us for questions or submissions of topic via insides4@sap.com Thanks for watching, and see you next time.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Este episódio explica por que a migração para o 3SL na i-Health da dsm-firmenich traz desenvolvimento, teste e produção separados, maior controle sobre mudanças e upgrades, e desbloqueio de novas funcionalidades, com destaque para Linha Paralela, CLT e integração com o SAP Store, preparando o terreno para inovações futuras.",
            "resumo": "Este segundo episódio da série Expert Talk aprofunda os benefícios de migrar para o 3SL no cliente dsm-firmenich, unidade i-Health. A conversa recapitula a diferença entre 2SL e 3SL (com dev, test e production sob CBC) e explica por que a empresa decidiu migrar: maior controle sobre novas funcionalidades, fluxo de upgrades menos disruptivo e maior capacidade de evoluir rapidamente conforme requisitos de clientes. Tom destaca que o 3SL separa desenvolvimento, teste e produção, facilita mudanças proativas, e prepara o terreno para inovações como o AI Joule. Calin apresenta recursos do Delta 2SL-3SL, como Linha Paralela (para atividades de projeto sem interromper o mainline) e CLT (Ferramenta de Localização do Cliente) para ativar países não suportados. Dennis descreve o ecossistema de parceiros e o SAP Store, onde conteúdos de indústria podem ser desenvolvidos e vendidos. O episódio também aborda adoção interna e próximos passos.",
            "assunto_principal": "Migração para o 3SL no SAP S/4HANA Cloud para a i-Health da dsm-firmenich: benefícios, recursos e ecossistema",
            "palavras_chave": [
              "3SL",
              "2SL",
              "CBC",
              "ambiente de desenvolvimento",
              "teste e produção",
              "Linha Paralela",
              "Consolidação das Leis do Trabalho (CLT)",
              "Delta 2SL-3SL",
              "Loja SAP",
              "parceiros",
              "substituição de produto",
              "atualização sem interrupções",
              "IA Joule",
              "i-Health",
              "dsm-firmenich"
            ],
            "resumo_em_topicos": "### Contexto e objetivo\n- Explicação da evolução de 2SL para 3SL e o papel do CBC (Configuração Central de Negócios).\n- Meta: migrar todos os clientes para o 3SL para acessar as últimas funcionalidades do SAP.\n\n### Benefícios de negócio observados\n- Desenvolvimento, teste e produção separados, proporcionando maior controle.\n- Redução de interrupções durante upgrades e maior agilidade para evoluir conforme requisitos.\n- Preparação para jornadas de inovação, incluindo AI Joule.\n\n### Funcionalidades e recursos do 3SL\n- Adoção de novas funcionalidades priorizadas no 3SL antes de serem disponibilizadas em outras linhas.\n- Enfoque na extensibilidade do desenvolvimento e na capacidade de inovar rapidamente.\n\n### Delta 2SL-3SL e ferramentas\n- Recurso delta com Linha Paralela para manter atividades de projeto sem afetar a linha principal.\n- CLT (Ferramenta de Localização do Cliente) para ativar países não suportados pela oferta padrão.\n\n### Ecossistema e a SAP Store\n- Ecossistema de parceiros com ambiente dedicado para desenvolvimento, teste e venda de conteúdos na SAP Store.\n- Possibilidade de construir conteúdos industriais sob demanda e compartilhar com clientes.\n\n### Adoção organizacional e próximos passos\n- Mudança cultural de reativo para proativo; maior foco em entregar valor de negócio com as novas funcionalidades.\n- Preparação para futuras jornadas de inovação e integração com iniciativas como AI Joule.",
            "prompt_tokens": 1906,
            "completion_tokens": 4311,
            "model": "gpt-5-nano",
            "cost": 0.0074
          },
          "analysis_time": 110.3594582080841,
          "language": "",
          "view_count": 276,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@SaraFinance",
      "name": "@SaraFinance",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ShawhinTalebi",
      "name": "@ShawhinTalebi",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@SuperHumansLife",
      "name": "@SuperHumansLife",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "LOktCypa7Yc",
          "title": "6 automações Zapier lucrativas que até iniciantes podem aprender hoje",
          "title_pt": "6 automações Zapier lucrativas que até iniciantes podem aprender hoje",
          "url": "https://www.youtube.com/watch?v=LOktCypa7Yc",
          "published": "2025-09-22T19:09:48.973132",
          "published_relative": "há 18 horas",
          "duration": "15:41",
          "date_published": "2025-09-22T12:01:52-07:00",
          "transcript_available": true,
          "transcript": "Most people think you need to be a coder to make money with AI. But right now, non-technical freelancers are pulling in thousand, 5,000, sometimes even 8,000 a month building simple automations with Zapier. No code, no uh sophisticated engineering degree. We're talking about connecting tools that businesses already use. That's it. And here's the backstory. Businesses are desperate to cut costs and speed up operations. There are more than 2,000 automation jobs that are posted every month on Upwork alone. and service providers are charging anywhere from a few hundred to over $20,000 per workflow. I mean, I've spent years inside the tech world watching how automation reshapes entire industries. And this time, the opportunity is no longer locked inside big IT teams. It is wide open for solopreneurs, for consultants, and even beginners. And the best part that almost nobody talks about is the fact that the real money is not in building random automations. It's in knowing which six workflows companies are lining up to pay for right now and how to package them so that you can stand out in a sea of freelancers. So, that's exactly what I'm going to show you. Honestly, this first one is so critical because most businesses waste hours trying to manually follow up with leads and send newsletters and keep their pipeline warm. And because of that, they have literally been leaving money on the table. Cold leads slip through the cracks, customers don't hear from them, and sales die quietly. Okay, so here's how automation can make a huge difference here. I want you to imagine a new lead filling out a form on a website. Then Zapier instantly triggers a workflow. It sends the lead into the CRM, drops a notification into Slack for the sales team, passes the info to chat GPT to draft a personalized welcome email and then automatically sends that email from Gmail. And that can be done with no coding, no manual copy pasting. It's a very simple automation actually and automation is not about saving the time in marketing. It's about saving opportunities and I believe this will always be in great demand because according to the research that we found marketing is the single most in demand area for Zapier automations for example and on Upwork alone thousands of jobs are posted for these workflows each month and freelancers are charging anywhere from a couple hundred to thousands per setup with some packaging them into multiple thousands for um ongoing optimization. Now, if you want to give this one a try if you're a beginner, here are some examples of what you could look into implementing. One way would be to connect lead forms to Gmail or to Mailchimp via Zapier so that businesses uh never lose track of their prospects. Or another idea would be to automate newsletter workflows, for example, so every blog post triggers a new email campaign. If you're a bit more advanced, you can add AI personalization with chat GPT to write custom responses or subject lines. or you could build multi-step funnels and forms. So then you can uh take that to the next level and then you can package all of this in a done for you marketing automation system. And if follow-ups and campaigns are bleeding money for businesses, wait until you see what this next idea can do for a business that could become your customer. So, if you've been following along and you like what this marketing automation opportunity looks like or you're new to marketing and you need help getting started, then I suggest you take a look at this free resource from HubSpot that is called the AI marketing automation playbook. It's basically a step-by-step guide to scaling personalization, automating engagement, and driving revenue with AI. And this is without losing the human touch, which I think is really important. Inside you're going to find the steps to a 30 minute workflow audit, which is a fast way to spot your clients top three time wasters and then turn them into automated wins fast. You're also going to find engagement um and revenue engines and how to layer sentiment aware replies, AI dashboards and retargeting and nurture workflows so that your funnel runs on autopilot and turns followers into customers for your client. My favorite part is honestly the workflow audit section because it basically shows you in a very simple way exactly what is eating your client's time up so that you know what to automate first. It's completely free and it'll make your AI feel less like a set of disconnected tools and more like an always on dataformed revenue system. So hit the link below to grab the AI marketing automation playbook from HubSpot and also big thanks to them for sponsoring this video and for making this resource available to us. Okay, so automation idea number two has to do with webinars because webinars convert like crazy. I know we've done them, but only if people actually show up. And the truth is that most businesses tend to drop the ball there. Somebody registers, they get one confirmation email and then there's silence. You know, by the time the webinar goes live, half of the audience has forgotten and then there's tons of no-shows and lots of cold leads and lots of wasted ad spend for the most part. So automations can help make a huge impact here because with Zapier the moment somebody registers for a webinar their information can be captured from I don't know Eventbrite or Zoom or any landing page that has been used and then Zapier can drop them into a CRM and tag them as a webinar lead and then Chad GPT can draft a personalized confirmation email in the brand's voice and send the reminder sequence uh scheduled for I don't know 24 hours before 1 hour before 10 minutes before something like that and then once the webinar ends And Zapier can automatically send them a replay link and then drop them into a nurture sequence with AI written follow-up emails that are designed to move them towards a sales call or a purchase or whatever the outcome of that campaign looks like. So that means that no manual list experts will happen and hopefully there will be a lot fewer missed reminders and no wasted registrations or ad spend for that matter. And the research shows that lead nurture workflows like this one are some of the highest paying Zapier jobs actually. Uh freelancers are able to charge several thousand actually per setup according to Upwork. So we're going to make sure to include here a preview so you can see exactly what I'm talking about. And then we also found that agencies sell this kind of services as webinar funnels for thousands per month. And businesses pay because every percentage point in show up rate can mean tens of thousands of extra revenue for them. And I think if you want to get into this one, the easiest way would be to automate the reminders and post webinar replay emails. And if you're more advanced, you can add AIdriven personalization or follow-up messages that reference what the lead actually clicked on or asked or how they engaged during the webinar and things like that. Because webinars, at least in my opinion, do not fail because of bad presentations or unstructured presentations. They fail many times because nobody bothered to follow up. And if a single webinar funnel can be automated end to end, let me show you what else can be automated with a similarly large impact on a business. So, let's talk about automation number three. I want you to think about how most high ticket businesses book clients. Most of the time, it doesn't start on a website. Usually, it starts in DMs. somebody messages them on Instagram or asks a question inside a school community and the faster that the coach or the person replies, the more likely they are to book a sales call. But the problem is that manually replying takes hours and by the time you get to it or the client gets to it, the lead's gone cold. So, here's how automation can help in this case. Because with Zapier, every time somebody messages a coach on Instagram or in school, what can happen is that their message is captured and is passed into Chad GPT and then Chad GPT can draft a reply in the exact brand voice of the coach. And if they're showing interest, then Zapier can automatically send the booking link, can nudge them to schedule a sales call, and then all of that conversation can be logged into a CRM so the leads can be tracked. And that means basically that DMs stop being a a a time drain and they become a 24/7 organic salesunnel. And what I really like is that Zapier can also log all of that uh the the repeated questions into an air table or a notion and then automatically create a knowledge base. And over time the community literally builds its own FAQ library without you doing much and you know lifting more than one finger. And according to research, the DM and client communication automations are some of the most lucrative gigs right now. So on Upwork, for example, we saw that freelancers charge from $50 all the way to $1,000 for a setup. And consultants usually package it as a DM sales machine service. Um, and they're able to pull in recurring retainers for optimization. So if you're looking to get into this, an idea would be to build a DM to calendar uh type of workflow that captures worm leads. If you're a bit more advanced, you can blend AI into it so you can have uh you know customized booking links or personalized replies and things like that. The truth is that most sales aren't lost because people said no. They're lost because nobody replied fast enough when they said maybe. And if DMs are becoming automated sales funnels, the next big win is in what happens after the close. Okay? Because one of the biggest choke points in small businesses is, believe it or not, not in getting the lead. It's in what happens after somebody said yes. Because a proposal gets emailed and then manually chased down for a signature and then somebody has to create the invoice and send the contract and finally onboard the client and becomes messy and slow and often takes days which means lost momentum and lost deals. By the time somebody manually checks their info the excitement is gone and the business has already lost trust. So you can step in and help them with Zapier automations because once a client accepts a proposal, I don't know in something like Panda do or propose a file. Let's say the signed contract can be automatically saved in Google Drive, QuickBooks or Stripe can instantly generate and send an invoice. Uh and then once the payment is confirmed a personalized onboarding email can be drafted by chat GPT and sent to the client and then their account their folders their project tasks can be automatically created in Asana or notion or clickup and then the team can get notified in Slack all without your client doing anything. Okay. So research shows that onboarding is one of the top paid Zapier use cases because it's missionritical and I know that businesses will happily pay maybe a few hundred maybe a couple thousand for a smooth setup and many consultants charge ongoing retainers to keep this optimized according to the automated. So what can you do? I mean if you're a beginner you can set up a simple sequence like auto sending welcome emails or creating client folders when a form is filled. If you're a bit more advanced, you can look into um layering in AI to generate custom onboarding guides and FAQs or training emails that are tailored to each client. And that will lead to much, much better results for your own customer. Because here's the truth. In many cases that you don't think, businesses don't lose clients because of their service. They lose them because of silence between signup and delivery. And if onboarding is where companies quietly bleed revenue, there is another opportunity that could be probably even more fun and lead to a nice business impact. And that has to do with running a podcast. Because it looks like fun until you realize how much time it takes to find, to pitch, and to manage guests. And many podcasters spend hours researching people and writing cold emails and chasing down bios and scheduling calls and then manually updating spreadsheets. I mean, trust me, it's exhausting. And for many, it's the reason they quit. I know that we've worked with podcasters in our agency. So what you can do with Zapier is create um something that in the moment when a new guest name is added into I don't know Google sheet for example, Zapier can pull that into a CRM. Chad GPT can draft a personalized outreach email based on their bio, you can even layer in personalized research with Perplexity or something like that and then be able to write a really personal email to them. You can then use Gmail or HubSpot to send it automatically. And if they accept, Zapier can create the calendar event, generate a prep document in Google Docs, store their headshot in your drive. And after the recording happens, uh it can even trigger a thank you email and request a cross promotion maybe or share some uh repurposing materials. And that is basically an end-to-end guest management system where there is no follow-up uh or manual follow-up required. Now, according to our research, outreach and scheduling automations are consistently in demand with freelancers charging $50, $100, sometimes over $1,000 per workflow. And agencies are able to package that in uh full podcast guest operation systems worth thousands per month. With more than 5 million podcasters worldwide, the market is massive. So, what you can do if you're getting started is to learn to automate the outreach email sequence and the calendar scheduling. And if you're a bit more advanced, you can obviously layer AI into it to generate personalized pitches or prep sheets or even suggested interview questions that are tailored to each guest. There's a lot of opportunity and a lot of ideas here. But the truth is that most podcasters don't fail because of bad content. They fail because the back end is chaos and they cannot get everything organized. And if guest outreach can be automated end to end, imagine what happens when you apply the same logic to member management and even cancellation automation. So this has to do with running memberships because running a membership or a subscription business is amazing until the cancellations and the refund requests start piling up. Every cancellation means manual emails and updating billing systems and removing access in I don't know school or circle and then sending awkward goodbye messages. And most creators and coaches hate it so much that they just let accounts linger which creates bidding errors and support headaches and bad blood with exmembers. So there are actually many ways of automating this with Zapier because the moment that a customer cancels or requests a refund. Then you can have Stripe or PayPal triggering the event and then Zapier can process the refund automatically and update their access in school or circle or discord and then send the personalized goodbye email and you can do that drafting it with chat GPT for example in the brand's voice and thank them and invite them for feedback. You can also uh layer in logging the cancellation in I don't know a database like air table uh reporting and you can notify a team member if that's necessary in Slack and trust me that would make churn automated you know like an automated flow which is smooth for the customer it's clean for the business and there is no bad blood and the reason why I'm bringing this idea up is because the research shows that businesses are going to pay several hundred for a simple cancellation workflow and sometimes upwards of 2 to 3,000 for full subscription automation. And I think the best part is that you can sell it as a retention and turn management system to a lot of people managing communities. So if you're just getting started, you can look into automating the refund and the goodbye email sequence. Um and if you're a bit more advanced, you can obviously layer in AI to analyze cancellation reasons um from the exit survey or do that analysis in a way that helps the business learn and improve over time. Okay, so that brings us full circle from lead generation to sales to onboarding to customer care to retention. And I think hopefully you've seen that Zapier and AI are able to create or become a business in a box which is waiting for non-coders to claim it. So if you feel like this is an opportunity for you, make sure you go ahead and apply. And if you want to apply this with over 11,000 other people who are on the exact same path as you, make sure you come and join us in our free school community where we also have some of these automations. And make sure you take action and apply everything and don't wait or watch more videos because the success won't wait for you to watch everything you've saved for later. Success will happen when you take action when you fail and you try again until you make it work. All right, thank you so so much for watching. Like this video if you did. Be sure to subscribe if you haven't done so. Share it with anyone in your circle of friends or family who are maybe concerned about the level of coding required to get started with AI and maybe this will give them a new perspective. Until next time, I suggest you go ahead and watch this video over here. And I'll see you soon.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo mostra como freelancers não técnicos podem lucrar com IA usando Zapier, destacando seis fluxos de automação de alto valor, a demanda do mercado e como empacotar serviços para se destacar.",
            "resumo": "O apresentador desmonta a ideia de que é preciso ser programador para lucrar com IA. Freelancers não técnicos já faturam de centenas a milhares por mês criando automações simples com Zapier, conectando ferramentas que empresas já utilizam. O segredo não é automações aleatórias, e sim identificar seis fluxos pelos quais as empresas pagam hoje e como empacotá-los para se destacar. O vídeo detalha exemplos como follow-up de leads e pipeline, nutrição de newsletters, automação de webinars, e respostas rápidas em DMs, todos sem código, conectando CRM, Slack, Gmail, Mailchimp e IA (ChatGPT). Também recomenda o HubSpot AI Marketing Automation Playbook e discute como automações de lembretes e personalização por IA aumentam show-up, engajamento e receita. Incentiva começar com exemplos simples e escalar.",
            "assunto_principal": "Automação sem código com Zapier para freelancers: seis fluxos lucrativos e como empacotá-los",
            "palavras_chave": [
              "Zapier",
              "sem código",
              "automação",
              "freelancer",
              "potencial de cliente",
              "nutrição de leads",
              "webinário",
              "mensagem direta",
              "inteligência artificial",
              "ChatGPT",
              "Upwork",
              "HubSpot",
              "automação de marketing",
              "empacotar serviços))"
            ],
            "resumo_em_topicos": "- Contexto: não é necessário ser programador para lucrar com IA; há alta demanda por automações sem código.\n- Mercado e valor: vagas de automação no Upwork e freelancers cobrando de centenas a milhares por fluxo.\n- Ideia central: identificar seis fluxos de automação pelos quais as empresas pagam hoje e empacotá-los para se destacar.\n- Fluxos-chave (exemplos):\n  - acompanhamento de leads e nutrição de pipeline (formulário → CRM → Slack → Gmail/ChatGPT)\n  - automação de newsletters e campanhas baseadas em posts\n  - webinars: registro, lembretes, replay e nutrição para aumentar a participação\n  - respostas rápidas em DMs para coaches de alto valor e agendamento de chamadas\n  - personalização com IA (ChatGPT) em mensagens e e-mails\n  - funis de múltiplos passos e pacotes de automação de marketing \"feito para você\"\n- Recurso recomendado: HubSpot AI Marketing Automation Playbook, com auditoria de 30 minutos\n- Benefícios: redução de tempo, mais oportunidades, aumento da participação, engajamento e receita\n- Dicas para iniciantes: comece com exemplos simples e escale com pacotes de serviços",
            "prompt_tokens": 1740,
            "completion_tokens": 3706,
            "model": "gpt-5-nano",
            "cost": 0.0064
          },
          "analysis_time": 101.2620017528534,
          "language": "",
          "view_count": 2476,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@TechLead",
      "name": "@TechLead",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@TheAiGrid",
      "name": "@TheAiGrid",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "IY6f_QeEcfg",
          "title": "Esta nova ferramenta de IA DESTRÓI Manus, Genspark e Chatgpt",
          "title_pt": "Esta nova ferramenta de IA destrói Manus, Genspark e ChatGPT",
          "url": "https://www.youtube.com/watch?v=IY6f_QeEcfg",
          "published": "2025-09-22T13:12:04.938063",
          "published_relative": "há 1 dia",
          "duration": "09:34",
          "date_published": "2025-09-21T14:28:24-07:00",
          "transcript_available": true,
          "transcript": "Skywork is a deep research AI platform that's specifically designed to create professional-grade documents and visual reports, not just generate text. Think of it this way. While most AI tools give you a research paper that looks like it was written in Notepad, Skywork is built to deliver something you'd actually present to your boss or submit for a grade. We're talking about charts with proper formatting and structured reports that look like they came from a consulting firm. And what makes Skywork different from your typical AI research tool is three key things. First, it actually cites its sources, real sources, not just those trust me, bro responses. And that's where Skywork pulls ahead, way ahead of Manis and Genspark. Every statistic, every fact or quote it generates is directly tied to the original source. Whether it's Forbes, Google Scholar, or even technical papers from Anthropic, Machine Learning Science, or Emergent Mind, instead of a wall of text, you get clickable citations that take you straight back to the reference material. That means if you're writing a market report, a pitch deck, or even an academic paper, you're not left wondering if the data is real. You can actually trace it all back to where it's from. And that's something other platforms don't just do as clearly. Manis might give you surface level references. Genpark sometimes skips the citations altogether, but Skywork builds its credibility by showing you exactly where the information come from. It's like having a research assistant who not only brings you the answer, but also stacks the original papers and articles on your desk so you can double check. And that level of trust is why Skywork isn't just generating content, it's generating consulting grade output. Secondly, it creates visual elements like charts and graphs automatically, so you're not stuck with walls of text. For example, I asked for a trajectory on the future of AI development. And you can see that every single slide here is absolutely incredible. On the current AI growth trajectory, we can literally see yearbyear the AI market size projection. Every time I hover over one of these, it's completely highlighted. As I continue to scroll down, I can see the global AI size projection. Once again, as I highlight it, I can even see more information, which is really cool. I can also see the AI investment trends from 2020 to 2024. I can also see the key direction of the future. In addition, it gives me some evolutionary perspectives on where large language models are going. And overall, it just gives you a really diverse perspective. And you can see there are multiple different infographics that really help us understand exactly what's going on. This one is even moving, which is really effective. And we can see that there are multiple different ones. And this didn't take that long. Now, what I find really, really effective about this is that even if there are some of these that you don't like, you can also click the regenerate button and it's going to redesign that in a completely new way. And so, if we do take a quick comparison, look at what Manis delivered. It delivered these images which aren't really research grade report. I mean, this looks like some very basic stuff. Whilst yes, this is probably useful for you, you ideally wouldn't want to be putting this in a presentation. The information is basic. It kind of lacks that professional infographic feel. And we can even see in some instances right here if we zoom in there's a lot of text that is somewhat overlapping. So we can really see that sites like Manis whilst yes the information might be good this isn't the level that you really want to use on a professional basis. And then even let's take a look at GenSpark. I asked for the same thing for a presentation and we can take a look at the details here. Once again they delivered six images. And whilst yes, this is a little bit better, this isn't the kind of research report that we'd want to be showing in our presentations due to the nature of the website, just not having that professional grade look. So now let's actually do some sideby-side comparisons. So what I actually asked was I asked these super agents to generate a market entry analysis for an AI fintech LLM SAS startup entering the European market. include the competitor landscape, market size data, pricing strategies, and risk assessment, and format as a consulting grade business report with charts, and an executive summary. That's what I asked these LLMs to do. And now, let's take a look at which one of these super agents had the best results. Firstly, let's take a look at what Genspot managed to do for us. Honestly, this one was pretty decent. I do like the format, the layout. It does seem pretty detailed, and it gives us some clear recommended pricing strategies, and it does show us some critical analyses that we do need to focus on. And so this is pretty pretty comprehensive and it does actually give us a success probability at the end here which is relatively decent. I will say that the graphics are a little bit lacking as there are some areas where there's overlaps but all in all this does seem like a pretty basic one and it gives us more of like an overview rather than something really detailed. One thing that I didn't really see about this which was a bit weird was that there weren't many citations which is of course pretty imperative if you're trying to do this kind of document. Let's now go on to Skywork. So when we go on to Manis now, we can see that this is once again a market entry analysis for an AI fintech LLM SAS in Europe. This one was also pretty decent. I will say it's noticeably a little bit worse because this one once again just seems like an entire tech stump when we're actually looking at data that we can use and actually transform into something useful. This isn't really that. There is a little bit too much data and the charts are a little bit small in terms of the design choices. So that is some, you know, some points lost there. It's not bad, but like I said once again, you know, these areas where things are completely overlapping, it just isn't too good. But it basically gives me a pretty comprehensive summary, but it doesn't give me too many citations. It does actually have some good citations here. But now, let's actually get on to the King Skywork. So, one of the first things that I personally like about Skywork is the fact that it actually gives me a really detailed document. And the biggest thing I like about this is that even though it's got a lot of detail, what it actually gives me is where I can actually browse to. So for example, if I want to look at the market size and growth projections, I just click that and I can overall go to there. Now what's really good about this is that every single one of these points, they have a forecast. So when this sentence appears, you know exactly where that citation is occurring from. So if you're really research something and you're like, wait, this, you know, market reached 96.5 billion in 2024, you can go ahead and you can double check that. And that's really important when it comes to these business reports or even some academic reports. Now once again these graphs are actually really nice. We can see that the design is simple enough to understand and there is tons and tons of detail in this. Now this one might be a little bit more detailed but what I do like about this is that it actually grabs stuff from the actual internet. You can see it's grabbed images there and it gives me an entire system for actually going ahead. You can see it's also got much more references here. These, you know, references are completely in detail and I can click every single one of these and there's no confusion about where these references are, what the sources are. So if you're wondering about hallucinations, they're pretty much close to zero. And we can see here that we've got this risk mitigation matrix, which is, you know, really, really useful. So something like this is just going to be super, super useful, especially if you want to enter a market, maybe you want to start a business, and you really just want to have all of that data. And remember guys, one thing that I will say is that Skywork seem to be a lot quicker than these other tools. Skywork seem to be at least two to three times quicker than these other tools. So, another thing is that if speed is one of the things that you're really important on, maybe you want to give Skywork the edge as well here. Now, if you're wondering why Skywork agent is actually so good, it's because you have so many options when you are trying to do something with Skywork that it really, really just feels amazing. Unlike other platforms where sometimes you're guessing, you know, with Manis, you basically put it in and you hope that it kind of creates what you want. Although it's a pretty good system, this one just gives you so much control. Like with this prompt, let's say for example I wanted to do you know analyze the current state of generative AI adoption and enterprise companies include adoption rates, case breakdowns, ROI data and future projections. What I could do here is I could you know change the default template. So I can make this either a research report, a business report, a user manual, an academic paper, a blog, a summary, there's marketing ads, there's scripts, there's rums, there's creative writing. I mean when you have something like this and you can touch on, you can put on fast mode. These are the kind of things that really allow your work to be really effective. And what's really cool here is that, you know, if you want it for certain formats, it's so so good. So like not only do you have the default templates, but you also have different formats. My favorite one to use is the slides feature because I'm a visual learner. So when I put in this text oftent times, and I'm pretty sure it's the same with you guys as well because you guys use YouTube, you really want to just, you know, quickly get that data in and knowledge ingested. And you can see once I input this prompt in, this is what it gave me back. It gave me back a quick presentation and I don't have to worry about things being overlapped or things looking weird. Everything looks almost perfect. And I would say this is the key edge that Skywork AI has. And it's just really really more polished. I would say like if you're looking for a tool that's really polished, this is what Skywork feels like. I mean the presentation just seems so so good. And I know that all of the data I can easily access the citations. And not just that, we also have different formats like sheets. We've got AI developers here where you can see you know you can create different websites. You've also got podcast as well if you want to learn. And then there's general where there are just many different things here. So this is why I really like the ability for Skywork to just basically give you every single kind of output that you do want. And it goes even deeper. You've got like schedule tasks. You can even upload your own knowledge. I think this is probably one of the most comprehensive tools out there. So you know, if you did enjoy this video and you'd like to explore this probably for yourself, don't forget to hit the link down in the description so you can try this out for yourself. I asked Skywork for a discount code to share with my audience. You guys can use the AI grid or subscribe through my link to get up to 34% off. Now, beware.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta Skywork como uma ferramenta de IA que gera relatórios profissionais com citações verificáveis e visualizações automáticas, destacando suas vantagens sobre Manus e GenSpark.",
            "resumo": "Neste vídeo, o apresentador compara Skywork com Manus e GenSpark, destacando três diferenciais-chave: citações reais e rastreáveis para cada dado; geração automática de gráficos e elementos visuais para apresentações; e uma navegação com referências detalhadas que permitem verificar cada afirmação. O Skywork é apresentado como capaz de produzir saídas de nível corporativo, com infográficos dinâmicos, menos alucinações e maior credibilidade em mercados como a análise de entrada para uma startup de IA fintech na Europa. Em contraste, Manus e GenSpark são descritos como menos robustos, com gráficos de menor qualidade e menos referências, tornando-os menos adequados para apresentações profissionais.",
            "assunto_principal": "Avaliação comparativa de ferramentas de IA para criação de relatórios com citações verificáveis e visualizações, destacando Skywork, Manus e GenSpark.",
            "palavras_chave": [
              "Skywork",
              "fontes citadas",
              "gráficos automáticos",
              "credibilidade dos dados",
              "comparação com Manus e GenSpark",
              "análise de mercado de IA",
              "SaaS fintech na Europa",
              "mitigação de alucinações de IA"
            ],
            "resumo_em_topicos": "- Skywork é apresentado como ferramenta de IA para produzir documentos profissionais com citações verificáveis.\n- Três diferenciais são citados: fontes citadas, gráficos automáticos e credibilidade com navegação por referências.\n- Comparação com Manus e GenSpark mostra uma saída menos confiável, com menos citações e gráficos inferiores.\n- Demonstração de uma análise de entrada no mercado para uma startup de IA fintech na Europa, com dados, preços e riscos.\n- Conclusão: Skywork oferece uma saída de nível de consultoria e reduz alucinações, com facilidades de verificação de fontes.",
            "prompt_tokens": 1788,
            "completion_tokens": 3787,
            "model": "gpt-5-nano",
            "cost": 0.0066
          },
          "analysis_time": 65.30751395225525,
          "language": "",
          "view_count": 5071,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@TheOfficialACM",
      "name": "@TheOfficialACM",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@TiagoForte",
      "name": "@TiagoForte",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@TwoMinutePapers",
      "name": "@TwoMinutePapers",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "6Adcl7nXWuU",
          "title": "Nova IA gratuita cria um jogo a partir de uma única imagem!",
          "title_pt": "Nova IA gratuita cria um jogo a partir de uma única imagem!",
          "url": "https://www.youtube.com/watch?v=6Adcl7nXWuU",
          "published": "2025-09-23T12:13:21.114254",
          "published_relative": "há 1 hora",
          "duration": "06:14",
          "date_published": "2025-09-23T04:52:42-07:00",
          "transcript_available": true,
          "transcript": "Check out this amazing new AI technique, \nMagica 2 where an image goes in, your image,   and a playable video game comes out. And then we \nare going to explode this person for no reason. And if you look back just one year ago, this \nwas possible with Google DeepMind’s Genie 2   and this is way better than that. I’ll tell you \nabout the differences with Genie 3 in a moment.   And as of the making of this video, if \neverything goes well and if we haven’t   crashed their servers yet, you can \nhopefully try it out too, even on your   phone. That’s what they say. Note that we are \nnot affiliated with this company in any way. Okay, now this concept is amazing because this \nimage can be a real video game, something like   cyberpunk. Or, even a painting, man, let’s \ntake starry night and look into that, I’d love   to see that. Wow. It’s really amazing to see this \npainting come alive as a real world. Now, this is   not even close to perfect, as we go on for longer, \nit starts to become less and less like itself. However, it gets better. You can have a drawing \nof yours also come alive. This one is way more   consistent, although the AI did not have that much \nto do, so let’s give it something more difficult.   Oh yes, this is going to be a city, not just a \npier. An interesting, quirky little city made of   paper and scribbles. Really cool! Once again, it \nstart to become a bit less like itself over time. This effect gets even more apparent with \nthis pencil sketch, okay let’s enter this   world. So far so good, but it’s a bit like \na guided tour in IKEA. Stay on the arrows,   you’re fine. Wander off…and you’ll \nnever be seen again my friend. But even for all the good and bad, this \nreally shows how incredibly quickly the AI   space improves over time. Now I will note that \nI have found no research paper for this work.   I’ll let it slide this time, but only because \nit is a brilliant showcase of how far we’ve   come in less than one year. Okay, as promised, \nlet’s talk differences. Dear Fellow Scholars,   this is Two Minute Papers with Dr. \nKároly Zsolnai-Fehér. Dr. Carroll. Google DeepMind’s Genie 2 was a bit like \na goldfish trying to direct a movie - it   forgets what happened three seconds ago, \nso every new frame is a brand new plot.   Genie 3 is like a dog dreaming. \nIt runs, barks, chases something,   and for a minute or two it looks visually \nconsistent. We don’t know how long. And this one promises 10 minutes. \nInteraction latency for Genie 3,   they say instant, but I cannot know for \nsure as they did not offer me to try it,   but for this one, 200 milliseconds. Not for \nthe pros out there who beat Silksong with one   hand tied behind their backs, no. But for a tech \ndemo as a stepping stone, sounds really great.   Genie 3 runs on Google’s datacenter somewhere on \nEarth, this one runs on a single consumer GPU. We are wise Fellow Scholars here, \nso we will all take this with a   grain of salt as we have no research \npaper yet, but I’ll keep an eye out. Now, before we try it together, \nI won’t leave you hanging,   the architecture is probably somewhat \nsimilar to what Genie 2 did, which is   the following. It was a diffusion world \nmodel that turns video into a simpler form,   then it predicts the next frame step-by-step \nusing past frames and your actions,   kind of like how a text model predicts the next \nword in your sentence. So simpler, it is like a   storyteller with a flipbook - you tell it what \nthe hero does next, and it quickly sketches the   next page based on the previous ones, flipping \nforward frame by frame to bring the story to life. And now, you can also try it through the \nlink in the description. I hope. For me,   it did something, but it was not super fun. \nI just press and press and press the buttons,   sometimes something happens, maybe, most \nof the time, not so much. But I looked   around and people reported that it works for \nthem, I hope you will also have it better.   Now this other game worked much better, I \ncould move the camera, walk around, jump,   attack…kind of. Uh…sir? Sir! Are you okay sir? \nOkay, this valiant knight has clearly eaten   something he shouldn’t have, and I don’t \nwanna be around to find out what it was. Whew! That was close. Okay, now this work however, \ndoes one thing very well. And that is…it exists,   and you know what that means. The First Law of \nPapers says that two more papers down the line,   it will be improved a great deal. Just \nthink about the fact that 1 year ago,   we had Genie 2, low quality footage, seconds \nof memory if that, and only platformers, the   same game basically. And now, up to 10 minutes of \nmemory, in much higher quality. More variety too. Now, limitations. They say character control \nis not yet perfect, with certain movements like   right turns occasionally showing reduced \nresponsiveness. Well, you saw it, for me,   reduced responsiveness was flowery words for \nnot working at all. But try it out yourself,   and let me know in the comments how \nit went. Remember, low expectations.   This is a super super early tech demo of \nsomething that was impossible last year.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apresenta Magica 2, uma IA que gera jogos a partir de uma única imagem, comparando seu desempenho com Genie 2/3 e destacando o avanço rápido da IA na geração de conteúdo interativo.",
            "resumo": "O vídeo apresenta Magica 2, uma técnica de IA que transforma uma imagem de entrada em um jogo jogável. O apresentador mostra exemplos como converter uma pintura ou rascunho em cenas animadas e em um jogo simples, observando que a qualidade varia ao longo do tempo — ela começa parecida, mas tende a se distorcer conforme avança. O conteúdo é comparado a Genie 2 da Google DeepMind, e as diferenças com Genie 3 são discutidas, destacando que Magica 2 pode rodar em GPUs de consumidor e, em tese, funcionar em celular. A ideia por trás é um modelo de mundo difuso que prevê frames seguintes a partir de frames anteriores e das ações do jogador, permitindo até cerca de 10 minutos de interação. Ainda não há artigo científico publicado, mas o vídeo ilustra o rápido avanço da área.",
            "assunto_principal": "Transformação de imagem em jogo jogável com Magica 2, comparação com Genie 2/3 e visão geral da arquitetura e limitações atuais.",
            "palavras_chave": [
              "Inteligência artificial",
              "Transformação de imagem em jogo",
              "Magica 2",
              "Genie 2",
              "Genie 3",
              "modelo de difusão",
              "mundo difuso",
              "latência",
              "GPU de consumo",
              "interação jogador-jogo",
              "demonstração tecnológica",
              "limitações"
            ],
            "resumo_em_topicos": "- Conceito central: Magica 2 transforma imagem em jogo jogável.\n- Exemplos: pintura, desenho e cenas criadas a partir de rabiscos.\n- Desempenho e acessibilidade: pode rodar em GPU de consumidor; latência anunciada de aproximadamente 200 ms; é possível testar via link; memória de até aproximadamente 10 minutos.\n- Arquitetura: baseada em um modelo de difusão que prevê os quadros seguintes a partir dos quadros anteriores e das ações do jogador.\n- Comparação com Genie 2/3: Genie 2 tem memória curta e mudanças de enredo quadro a quadro; Genie 3 promete maior consistência por mais tempo; Magica 2 funciona como demonstração prática com promessa de avanços.\n- Limitações: o controle do personagem nem sempre é perfeito; a qualidade tende a se degradar com o tempo; ainda sem artigo científico publicado.\n- Perspectiva: demonstração ampla do rápido progresso na área em menos de um ano, com potencial de melhorias contínuas e de testes adicionais pelos usuários.",
            "prompt_tokens": 1477,
            "completion_tokens": 2852,
            "model": "gpt-5-nano",
            "cost": 0.005
          },
          "analysis_time": 78.52938294410706,
          "language": "",
          "view_count": 3594,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@WellPiresAI",
      "name": "@WellPiresAI",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@WesRoth",
      "name": "@WesRoth",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "K10txopUnaU",
          "title": "OpenAI e NVIDIA acabaram de quebrar a indústria de IA",
          "title_pt": "OpenAI e NVIDIA acabaram de quebrar a indústria de IA",
          "url": "https://www.youtube.com/watch?v=K10txopUnaU",
          "published": "2025-09-22T22:14:52.897848",
          "published_relative": "há 15 horas",
          "duration": "12:31",
          "date_published": "2025-09-22T15:09:49-07:00",
          "transcript_available": true,
          "transcript": "Sealman says they're going to be launching some new compute inensive offerings. I'm pretty sure we now know what those offerings might be. What no one knew was coming was this. OpenAI and Nvidia announced a strategic partnership to deploy 10 gigawatts of Nvidia systems. Is it gigawatts or gigawatts? If you recall back to the future, they needed 1.21 gigawatts of power to activate the flux capacitor in order to be able to travel through time in a Delorean. By the way, that prefix giga can be pronounced jiga. That's sounds like it's the proper ancient Greek pronunciation. So, Doc Brown needed only 1.21 gawatts of power to get us to the future. Sam Alman needs 10. I'm totally tweeting that. Okay, so let's break it down. So, OpenAI and Nvidia. Nvidia is the biggest supplier of GPUs. How many of us are kicking themselves for not buying into Nvidia earlier? So strategic partnership enables OpenAI to build and deploy at least 10 gawatts of AI data centers with NVIDIA systems representing millions of GPUs for OpenAI's next generation AI infrastructure. To support the partnership, Nvidia intends to invest up to 100 billion in OpenAI progressively as each gigawatt is deployed. The first gigawatt of Nvidia systems will be deployed in the second half of 2026 on Nvidia's Vera Rubin platform. So, first of all, let's talk about the scale of this thing because it's rather massive. So, I looked up some stuff that uses or produces electricity just to get a sense of what we're talking about. So, this thing could power between 7 million and 9 million homes. It's equivalent to like five Hoover dams, right? In terms of energy production, and it's equivalent to about 10 big nuclear reactors. So if a typical nuclear reactor produces around 1 gawatt of electricity, so 10 gawatt is about 10 nuclear reactors. Currently the biggest single cluster is the XAI Colossus Memphis Phase 2. And this number here is Nvidia's GPU H100 equivalents. So this means that this is the single largest clearest compute build that's disclosed by any Western AI lab. There are various anonymized Chinese systems. So we don't really know who they belong to. If there are more, we don't know too much about it. Now OpenAI and Microsoft, they also announced earlier this year the Stargate project that was aimed at about 5 gigawatts, so half of this current project. It also had a 100 billion capex, so capital expenditures kind of the total money going into it immediately. And then 500 billion over the next four years. So, we're not quite sure where this is going because there's been a lot of rumors and speculations and questions about whether or not this is going to happen. We also have Amazon AWS project reineer or Reneer depending on how you pronounce it. I guess locals say Reneer other people say Reineer. So, this is done with interestingly with anthropic and tranium to chips. So, that's kind of a a separate thing. It's kind of hard to compare that to GPUs. Then we have the Google Cloud TPUs, tensor processing units. By the way, if anybody knows like a good way to compare sort of like the size of these across the different chips, let me know what's the best approach like how can you visualize where all these different companies are? How do you compare TPUs and tranium and GPUs, etc. So, this sounds like the biggest sort of unannounced project. Now, of course, keep in mind that this hasn't started yet. It's not live, so take it with a grain of salt in terms of I mean, they still have to build it and deploy it and and put it to use. But certainly, this seems very interesting since Nvidia is the one that's sort of investing this money. They they make the chips. So, it's kind of their effort that's going to be building out these data centers. There's quite a things we still don't know yet, like how the partnership is structured when it says Nvidia is investing in OpenAI and what does that mean exactly? So, I have a few interviews planned where we're going to be trying to figure out exactly how this thing is is structured, how this thing is going to work. Will Nvidia have some ownership in OpenAI? How does them trying to transition to the forprofit company? How does that play into this? So, there's there's still a lot of moving pieces, still a lot of things we don't understand, but as Sam Alman says here, everything starts with compute. Compute infrastructure will be the basis for the economy of the future. and we will utilize what we're building with Nvidia to create new AI breakthroughs and empower people and businesses with them at scale. Greg Brockman says, \"We've been working with Nvidia since the early days of OpenAI. In fact, there are pictures of Jensen Huang handd delivering like the first crates with GPUs in it to the OpenAI headquarters.\" Like he signed it very early on. I don't remember the exact year, but it was kind of very close to the founding of OpenAI. And notice here they're saying Nvidia and Openi look forward to finalizing the deals of this new phase of strategic partnership in the coming weeks. So it sounds like we don't maybe don't know every detail. They haven't finalized some of the details, but this does seem like a big deal. A few days ago, Elon Musk posted this saying 1.21 gawatts of training compute, referring to the Colossus stage 2, the thing that's powering Gro 4, Gro 4 fast, and all the Gro models. Is that how much the Back to the Future car had? Uh, yes. Well, yes. So, this new proposed OpenAI and Nvidia partnership. So, that's 8x more than than this is currently or you know, we we're not sure exactly what the number is here, but again, this is to show that the scale here is staggering. So, all these companies, Nvidia and Microsoft and OpenAI and XI and all of the companies involved are still betting on the scaling laws. The idea is that as we increase the scale of the compute, the abilities of these models increase predictably. It's not a onetoone relationship. The sort of the amount of compute we need, it is exponential, but the abilities of the models scale predictably. As Posh Adah Pi is saying, Jensen finally believes in super intelligence. We've turned the corner. This is an interesting take because if you think about it, everybody kept saying that, you know, Nvidia is the winner cuz they're selling shovels, right? As everybody's chasing AGI, as they're trying to improve their models, Nvidia, they're not really doing that. They're just selling the shovels, the tools that are needed to build AI. They're getting paid no matter what. Whether or not these Frontier AI Labs strike gold or don't. Nvidia sells the hardware, makes a tidy profit. The profit margins are rather large, but they don't need those bets to pay off because they're just sent hardware. This is a little bit of a turn. Jensen and Nvidia are no longer just selling the shovels. It seems like this is a fairly large investment into OpenAI. If the models don't get better, if they don't have some return on investment, if they can't do any economically valuable work and OpenAI is just burning through billions with no ROI in sight, then of course that investment will be worth less, you know, close to zero or whatever. So that sort of narrative might change a little bit. It's no longer fair to say that it's just selling the shovels. This is is becoming more integrated within sort of the AI race, the AGI race, whatever you want to call it. This is from semi analysis. They're a great publication about specifically the AI data centers, the chips, all of that stuff. Probably the number one resource in the space for that. So this was published a few days ago. XEI's Colossus 2, the first gigawatt data center in the world. Unique reinforcement learning methodology, capital raise, on-site turbines, Mississippi expansion, Solaris energy, can XAI afford it, Middle East funding, Tesla talent exodus, API revenue, consumer growth, reinforcement, learning environment. I'm going to start putting just all the keywords into the the title of my blog post. That's kind of brilliant. I'm going to test that out. So, here's that chart. We've seen it before. As you can see here, the blue line is open AAI. So this is before this announcement. This is up to the third quarter of 2025. And the thing to note here is this black line, that's XAI. So as you can see here, I mean at some point they didn't have a model. XAI didn't exist while the other Frontier Labs were already developing their models. So it really came from behind from a late start and just really quickly scaled up closing the gap between themselves in OpenAI beating the other ones Anthropic and Meta. So Colossus 2 was built from zero to 200 megawws in 6 months that was in Memphis. It's going to be interesting to see where this new OpenAI project will be built out. Is it going to be in the States? And are they going to be able to deploy it and build it as far as Elon does? Because XEI built that in 6 months. What took 15 months for Oracle, Gruso, and OpenAI? Also, how are they going to power it with XEI, for example, their genius move was to develop a gigawatt scale energy hub right across the border in South Haven, Mississippi. So, he's running Colossus 2 in Memphis, Tennessee. And apparently right across I guess there's a border and that's the power plant in South Haven, Mississippi that he acquired. You have Tesla mega packs, so the battery energy storage system. We're not going to read this entire blog post, but I'll link down below. Check it out. It's a great newsletter as well, but the point is it's extremely difficult to build it out and provide the needed energy. Now, there has been a lot of talk about expanding in the Middle East, getting funding from the Middle East. So, it's going to be interesting to see where they build this project out, if they're going to need any more funding. As Sam said a few days ago, you know, they're going to be launching some new compute intensive offerings over the next few weeks. Now, of course, this is long before this center is going to be completed. It's only going to start coming online. It seems like the second half of 2026. This new compute intensive offerings seems like it's going to be Sora 2, some sort of a video generation thing. That's just some speculation that's online, but here's TBR. He does tend to leak or announce some information before it's publicly available. So, there's been some movement in the Sora web app, something referred to as NF2. And it seems like there are some subdomains and some mentions in that feed page like webb composer recording, accepted invite, fastpass, and more. So, we might be seeing some sort of a new video generation thing. Now, as we've seen with the image generation things like Nano Banana from Google and the launch of OpenAI when just everything got jiblified, if you recall that, that was a huge moment for both companies in terms of onboarding users. Tons of people signed up and tried out these products because they wanted to get their hands on these AI image generation capabilities. So, it definitely seems like if you want to get users on board, that seems to be a good way of doing it through some sort of a visual medium in those two cases, specifically images. But both OpenAI and some Google engineers would post that like everybody's just melting the GPUs that they have available or whatever infrastructure was used basically needed to be upgraded because of the massive massive demand. So, it's likely that a lot of this compute that's coming online is not just going to be used for training and running large language models, but we're probably going to be seeing a lot more visual stuff because it seems to really bring in new users and bring on board and have them test out the platform. Here's kind of those spikes for the Jubilee anime virality, nano banana virality. So, it seems like the video doesn't have as big of a viral spike whereas the images do. This is a absolute massive deal. It seems like a little bit of a shift in terms of how these companies are going to be operating moving forward. Nvidia is committing to providing more than the amount of chips that they've sold to everyone in 2025. More than that amount they're planning to sell to OpenAI and also seemingly fund a lot of it. So, we'll stay tuned for details. We'll see how that deal is structured. We'll see if we have any idea about where it's going to be built out. How are they planning to get the power needed to run this thing? So stay tuned, but it doesn't seem like this race to AGI is slowing down. Not one bit. If you made it this far, thank you so much for watching. Let me know what you think in the comments and I will see you in the next",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise da parceria entre OpenAI e NVIDIA para implantar 10 gigawatts de infraestrutura de IA com investimento de até 100 bilhões, explorando a escala, incertezas e implicações estratégicas para o futuro da computação e da IA.",
            "resumo": "O vídeo analisa a parceria entre OpenAI e NVIDIA para construir e operar pelo menos 10 gigawatts de data centers com sistemas NVIDIA, com a NVIDIA investindo até 100 bilhões de dólares na OpenAI à medida que cada gigawatt é implantado (primeiro gigawatt previsto para a segunda metade de 2026 na plataforma Vera Rubin). O apresentador enfatiza a escala massiva, comparando com o consumo de energia de milhões de casas e com grandes projetos de IA existentes. São discutidos benchmarks de outros players (Stargate da Microsoft, Reineer da Amazon, TPUs do Google) e a dificuldade de comparar diferentes chips (GPU, TPU, Tranium). Também aborda o que ainda não se sabe sobre a estrutura da parceria, propriedade, transição para lucro e ROI, destacando que computação é a base da economia futura e perguntando se Nvidia está apenas vendendo ferramentas ou assumindo risco estratégico com a OpenAI.",
            "assunto_principal": "Parceria estratégica entre OpenAI e NVIDIA para infraestrutura de IA de grande escala e suas implicações estratégicas e de investimento.",
            "palavras_chave": [
              "OpenAI",
              "NVIDIA",
              "parceria estratégica",
              "10 gigavatios",
              "centros de dados",
              "Vera Rubin",
              "Colossus Memphis Phase 2",
              "GPUs H100",
              "investimento",
              "100 bilhões",
              "com fins lucrativos",
              "leis de escala",
              "Stargate",
              "Microsoft",
              "Reineer",
              "Unidades de Processamento de Tensores (UPTs)",
              "Tranium",
              "Inteligência Artificial Geral",
              "computação",
              "retorno sobre o investimento"
            ],
            "resumo_em_topicos": "### Contexto\n- Análise da parceria entre OpenAI e NVIDIA para implantação de 10 GW de infraestrutura de IA, com investimento de até 100 bilhões pela NVIDIA.\n- Primeiro gigavatio previsto para a segunda metade de 2026, na plataforma Vera Rubin.\n\n### Detalhes técnicos e escala\n- Descrição de centros de dados com milhões de GPUs e a magnitude energética envolvida.\n- Comparações com outras iniciativas (Stargate, Reineer, TPUs) para entender a posição no mercado.\n- Discussão sobre como visualizar a escala entre diferentes chips (GPU, TPU, Tranium).\n\n### O que ainda não sabemos\n- Estrutura exata da parceria: propriedade, participação, governança.\n- Como a transição para lucro (com fins lucrativos) impacta a relação e o ROI (retorno sobre investimento).\n- Limites, cronograma e critérios de conclusão dos acordos.\n\n### Implicações estratégicas\n- Computação como base da economia futura e o papel da NVIDIA como investidora além de fornecedora de hardware.\n- Debate sobre a mudança de narrativa: NVIDIA como mera fornecedora de ferramentas versus participante estratégico com risco e retorno.\n\n### Perguntas em aberto\n- Qual é o modelo de retorno para a OpenAI e para a NVIDIA?\n- Como será a distribuição de capacidades entre diferentes plataformas (GPUs, TPUs, Tranium) ao longo do tempo?\n- Quais são os impactos para o ecossistema de IA e para os concorrentes?",
            "prompt_tokens": 1886,
            "completion_tokens": 2991,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 95.76861095428467,
          "language": "",
          "view_count": 20031,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@YannicKilcher",
      "name": "@YannicKilcher",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ai-foundations",
      "name": "@ai-foundations",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "yl-FMpsDzXs",
          "title": "Faça com que os agentes de IA escrevam EXATAMENTE como você! (Guia completo)",
          "title_pt": "Faça com que os agentes de IA escrevam EXATAMENTE como você! (Guia completo)",
          "url": "https://www.youtube.com/watch?v=yl-FMpsDzXs",
          "published": "2025-09-22T17:16:47.179273",
          "published_relative": "há 20 horas",
          "duration": "20:57",
          "date_published": "2025-09-22T10:01:22-07:00",
          "transcript_available": true,
          "transcript": "I don't know about you, but I can spot an AI generated post or a comment or an email from a mile away and instantly when I see the AI generated this text, I turn and look the other way. I don't even bother reading it because I know it's not actually what the human is thinking. Now, if you want to use AI and you want people to read your stuff, you have to make it sound like you. It has to be indistinguishable from your voice and your tonality. So today I'm going to show you how to make AI agents write exactly like you. And this can be for multiple different scenarios. There's not one solution fits all, but I'm going to show you one framework that works for all agents. So I have two agents that I'm going to demonstrate today. Both are quite different. The sponsorship responder actually enriches company data so that when a sponsor reaches out to me, I can just send the email straight to the sponsorship responder. It knows all of my metrics and everything that I have in mind when looking for a partner. And so, it's going to be taking all of that into account when responding in my voice with my metrics, my data, everything I need. And then I have an FAQ agent, which answers frequently asked questions for members of our community, for anybody on the YouTube channel, whatever it may be. So, I'll start in the FAQ agent. I'm going to click into here, and I can just type off a message to this thing. I could actually give access to this bot or whenever there's a question I could just paste it in here. So maybe somebody asks like do you have private maybe they're spelling things wrong consulting and then I can just send that off. And what this agent's going to do is it's going to respond in my style with my frequently asked questions in the knowledge base. So this doesn't look AI generated at all. And so then I could just copy that and then paste it in. I could ask another question in my agent like when is your calls maybe I'm asking a question about our private group and the agent will respond in my voice. We run Q&A calls Tuesdays and Thursdays. Check the calendar for exact times. Get there early. Raise your hand. So, it's just very natural and it's something that I would actually say and this is a very simple agent. This is what that agent looks like. Now, the secret sauce, the framework lies in the system message here. As you can see, I'm going to be showing you how to create this set of instructions today using examples and using a framework created by one of our team members, and it's going to allow you to craft amazing responses with your AI agents that sound exactly like you, use your knowledge, and so much more. Now, I also have my more complicated agent, the sponsorship responder, so that when I click in here, all I have to do is copy and paste my emails or I can programmatically just throw them into NADN and have this thing run at all times. And that one looks a little bit like this. What this agent does is it still uses that same framework that I'm going to show you in the sponsorship responder. It says, \"You are Drake. You handle inbound sponsorships.\" I can put my voice and guard rails. I can put what I need it to know. the only offers that I'm taking right now so that it's gearing its responses not only in my tone of voice but also using the things that I want it to use. And it gets pretty complex, but this would be another example of using that framework. Now, if you want to master building out agents like the one that I just showed you a little bit earlier and you have any questions or you need support or any help at all, I recommend joining our AI Foundations community. I'll leave a link in the description and the top pinned comment. We have a five coach team in there ready to answer your questions, keeping you up to date so you can focus on the signal of AI rather than having to shuffle through all the noise here on YouTube. You can get one unified place for everything that you're interested in. So if that interests you, like I said, link in the description in the top pinned comment. But now, let's get into this prompting framework that allows AI to write exactly like you. So we're going to be building an AI agent on NADN using Carter's IE framework. What does stand for? Well, IE means instructions, output format, and then examples. So, in instructions, we want to give the agent a role. One of the best and easiest prompt engineering tips anybody can just implement. It puts the agent in the shoes of whatever you want it to be. So, if you want it to be, you put it in the shoes of yourself. Next, we're going to give guidelines. And guidelines is important. What should the agent never do? What should it always do? What are some standards that it must follow every single time? Then we're going to be implementing a knowledge base. So what's the general knowledge around the topic that you're building the agent on? Then we have output format. You want to give a JSON example of how to output every answer. I'm going to build that with you. And then live examples of you actually using that output format in your voice. This is the most important part. You do not want to skip this and I'm going to show you the best way to do that. Now, there's one thing that you must understand before building the AI agent. And that is you must create an agent that is specialized in one thing and does that one thing very well. Don't try to create your voice for every single section of your life right now. What you should be focusing on is one single area that you just want to do very well. Whether that's Instagram DMs, you could do a support agent, an email agent, or a sponsorship agent, for example. With that being said, let's get into NADN and get building out this workflow. So, in the upper right hand corner, I'm going to hit create workflow. And what I want to do for the first step is I want to add a spot that I can speak to the agent temporarily. So, I'm going to hit this plus button and type in chat. And where you see chat trigger, that's what you want to add because now when you go back to Canvas, you can open up the chat and you can have test conversations with the agent to make sure it's responding in the style that you want. Next, we need to just add the AI agent. This is where all of the magic happens. So, I'm going to select this AI button up here and then select AI agent. I'm going to go back to canvas and I'm going to add a quick chat model. For now, I'm just going to use open router since I can select any chat model I want with my account. And I will just use GPT5 for now. Actually, we'll just use GPT5 Mini. That'll work. I can click out of here. I'll quickly rename that so I know what chat model I'm using. And now I can use this just like I would chat GBT like, \"Hey, how are you?\" And it's going to give me an actual response here. It says, \"Hey, I'm an AI, so I don't have feelings, but I'm here and I'm ready to help.\" Okay, perfect. So, in order to make this thing actually sound like us, we don't want it to say, \"Hey, I'm an AI or to even think it's an AI at all.\" We want this thing to sound exactly like us. So, we have to give it some information about oursel or about what we want it to sound like. Again, you don't have to use this for you, but maybe you want to create a fake persona, a fake customer support bot or a fake sales rep, whatever you want to use this for. You can do so. And you can have this AI agent fill the shoes of that thing. I'm going to double click in here. And what I want to do is I want to select add option. And then I'm going to select system message. This is where all of the magic happens with getting AI to sound exactly like you or whoever you want it to sound like. I'm going to put this on expression. That way we can build out these instructions using the IOE framework. So remember IE is instructions output format. We're going to delete this later by the way. And examples. So these are the things that we want to give the agent. So for instructions, the first thing that we want is a role. So I'm going to put that little heading tag right there. So we need to put this AI agent in the shoes of me. Let's say right now I want to create a support bot that just uses my YouTube channel in order to help people so that whenever somebody goes to this bot or this GPT or this AI agent, whatever you want to create, whenever somebody goes to it, I want it to help them answer their AI related questions by having it give them one of my YouTube videos that are already on YouTube. So, whenever somebody has a question about anything, this agent will be able to point back to one of my free YouTube videos in order to help people out. Let's say I wanted to write like me. I wanted to give them YouTube videos just as I would. And so, that's going to be the basis of this agent. So, I need to give it a role. So, a role might look something like this. And I recommend that you follow a very similar format. I say, \"You are Drake Srirach, a YouTuber with a YouTube channel called AI Foundation.\" So, I'm giving it context into who Drake Srirach is, which is myself. I say your job is to answer questions exactly how Drake would. Your main goal is to help people by giving them free YouTube videos that Drake has already created based around their questions. And then I say this, this is very important. You are to use the guard rails and knowledge sections in order to create responses for the user that do not look AI generated, but rather they are in Drake's voice. So, we're going to give it my voice here in the future, but this would be the example of step number one of crafting good instructions. Next, let's get into the knowledge section. We're going to save guard rails for last because I really think it helps having AI read the guard rails at the very end of its system instructions before it crafts every response. I don't really like keeping the guard rails up too high because I feel like it can sometimes forget them, but when I put them at the very bottom of the system instructions, it seems to help guide the agent a lot better. So, let's get into the knowledge section. Just like I did for roll, I'm going to create a knowledge header tag. Just like that. And now we can get into the knowledge base. These are general things that your agent should know about you or about the situation. So, the knowledge should almost be like your memory on chat GBT. If you've ever used chat GBT, then you know that they're keeping a memory. You can actually see that in your settings and it's kind of just taking little notes about you, what you like, what you don't like, your preferences, and things like that. So you could get a lot of knowledge from there if you're trying to make it sound like you if you use that a lot. But here are some knowledge points that you could add. Things that you do, things that you create, things about your company, things about what your goals are, what you normally do on a daily basis, things that will allow this agent to respond like you. So I say things like Drake creates videos on large language models like chatgbt claude creates videos on building automations and agents with NAND. these very specific things that I'm doing. Drake is always grateful for nice comments on YouTube, often replying with two to three exclamation points. Drake sometimes won't use any punctuation at all. Drake sometimes won't use any capital letters. Drake uses abbreviations like RN for right now, AB for about, ngl for not going to lie, fr for real, and LMK for let me know. Drake never uses M dashes. M dashes are the silent killer for AI responses. If you ever see anything with a long dash, most likely it's an AI generated response. If the writing was created post 2023, then 90% of the time it's going to be AI. That's a big tell. So, you don't want to have your AI be generating m dashes. Next, underneath the knowledge section, since we're still kind of talking about knowledge, I need to give this agent all of the YouTube videos that I want it to send people to on any questions they might have, any comments they might have, etc. So what I'm going to do is I'll make that actually a heading three. So now I'm going to give YouTube videos to point people to from my channel. So for this example in specific, I've added in three YouTube videos. I've given the title of the video. I've given a little about section of the video and then the link for the video. So uh you could go crazy with this. I mean you could have a database of hundreds of videos with the transcripts. You could have the AI agent actually read the transcript and give tailored advice based on what I said in the video. But for now, we want something quick that can respond like us and use some knowledge in order to help people. And if you want to scale, that's what we teach in AI foundations. If you want to go there, you can learn that. But for now, let's learn a quick way we can do this. So, I've given my YouTube videos and this is all we need for the instruction section. We're going to do the guardrails later, but now we need to learn about output format and examples so we can get this thing responding like us every single time. So the output format is simple. What we're going to use for the output format is a JSON object. Now, if you don't know what JSON objects are, I recommend watching my instructions video. I'll leave that in the upper right hand corner. It shows you how to build out these JSON objects and how to understand them once and for all so you're no longer scared by them. But I'm going to make an output format section with a heading one. And then this is the output format that I want this agent to respond in every single time. So I'm going to mention that. And this is important. You have to say this in this part of the prompt. You are to respond in this JSON object format each time. And then you can give an example of what that looks like. And in order to do that, you're going to do curly brace enter. And then in quotation marks you can put whatever word you want. I'll just put output and then I'm going to arrow over and then output here just like that. And so now we have this uh structured output. So consistently it will put that output within this JSON object. And so that output format section is done. Now we need to provide examples of how this agent should use this output format live. So, in order to do that, I could just go to the comment sections of my videos and find real examples of people asking me questions and then I can answer them myself. Because what these examples are going to do is it's going to give AI insight into how you respond to certain situations. So, if you want it to respond in a certain way, then in these examples, have it respond in the way that you want AI to generate its next outputs. So, down here, I'm going to put a heading one and I'm going to say examples. And then I can just put something like example one. And then I need input output examples. So what is the input? Maybe I can put in a real question that somebody had or here you might want to put in if you were building an email agent for example, a real example of an email somebody sent you and then a real output of how you would want this agent to respond to a message like that. So for instance, if I go down to my comment section here, you can see somebody commented amazing content. keep going and please share a full course if you can. I could copy that because this is a real person telling a real message. And this is on my turning agents into apps video, which is very cool. But I can go in here and make that the input. And then I can use this output format and show an example of how I would want it to respond to a comment or a query like that. Uh so I can just say something like, \"Thank you. I do have a full course on NAND agents if you'd like. Check that out here. And then I can actually use that full agent course I put in my YouTube videos. I can get the link, copy it, and then paste that in my output. And so now we have a good example of a user input and a Drake output. And then we just keep on going with those examples. Honestly, I think five to 10 examples is probably best because if you start going beyond that, AI has trouble retaining context and that's when you'd need a more scalable system with something like Superbase and Rag. I can go on another video that I have and look in the comments and I can go to this person's comment for instance, can it be done with NAN? Thanks for the video by the way. I could copy that for example number two and then I could give my reply to that in my output. So, I'm showing the agent how to use this output format and how to respond to basic questions, basic queries. And so, I could keep on going with these input output examples, but for now, we're just going to leave it at two. I mean, I would recommend doing five to 10, but for the sake of this video, you understand now how to create it. So, underneath the examples, what we need to do is we need to create our guard rails. So, things that this agent should never do in order to not sound like AI. So, I've just pasted in some guard rails. Number one, never use M dashes in your response. This is one of the biggest tells that a response is generated by AI is when that character is littered throughout the message. So, we want to stress, do not use this character. Also, never use words or sentences that Drake wouldn't use. Do not overuse punctuation or lean on grammatical correctness. Never respond in a wordy format. Never be too serious or perfect in your writing. We almost want to make the grammar bad if we wanted to sound like a human at this point and uh be indistinguishable of that from at least myself. I'm not a very technical person. I respond just as how I've um responded to these comments. And that's the point. You want to respond how you would respond, not how you wouldn't actually respond. And now we can test it out. But before we do that, we want to add our structured output parser. So just copy the format that you created up here and go back to your AI agent. Turn on require specific output format. Connect the output parser by selecting that right there. and then select structured output parser. And here instead of this example, you can delete that and paste in the example that you have. And now it will respond with your answer here every single time. And so I can save this. I can rename this agent if I want, like Drake responder. And I'm also going to go back into the instructions and just add in some things in the guard rails. down in the guardrails. What I want to do is I also want to add something like never go beyond the scope of answering the question. And then I can put something like always answer with just Drake's videos and small talk. Never try to figure out the answer. You could set it up to figure out the answer for you, but I don't want it talking about things that I don't really verify or know. So, I wouldn't want to have it like try to explain something to somebody that I don't even know what it's talking about. So, now I can go back. I can save this agent. I named it Drake Responder. Thought that would be kind of nice. And now we can actually test this out. So you can open up the chat and you can just type something or paste in something like an email, iterate, work through, refine the instructions until it gets exactly how you want it. So I can just say something like, \"Hey Drake, great video. Do you have any tips for making chat GPT more consistent?\" I feel like every answer is always different and you help. And so this is like a comment that I would get on one of my videos. So let's see if this agent can handle it like I would by just directing people to the right video, which it should be the seven prompt engineering tips for beginners because it has to deal with chat GBT and it should be in my writing style, not too grammatically correct, maybe missing some capitals, doing some abbreviations that AI usually wouldn't do. It shouldn't be using M dashes. And so it says, \"Thanks with two exclamation points. I've got a full guide on prompt engineering that shows how to make chat GBT far more consistent. Watch it here. Drops the link and then adds the thumbs up. If you saw this, I don't think that you would think that this is AI. Um because number one, if I saw this, at least I wouldn't think it's AI because what we've got is like double punctuation. We have no capitals [snorts] and we have emojis that are just simple just like a thumbs up and a custom video link. So, if I go to this video link, it should take me to the prompt engineering video for beginners. Just like that. And so, this is a bot that would actually be very helpful, especially if you give it guard rails and scopes for how to respond. You could automate things into here. So, you could like automate your YouTube comments into here and automate their response. You could hook up a different communication method. I usually don't like using Telegram or Slack or any of those because they're just hard to connect to and I don't really know how secure they are. So, I like using another application, but this is a great way to test. And so, this has been a full guide for how to make your AI agents write exactly like you. If you're looking for something more scalable and you need some custom help, like I said, join our AI foundations community. We have five coaches in there. One of which is a full stack developer who understands things like Rag. He can help you out. His name is Paulo. And we also have tons of other people in there. We have live calls in order to get you help. We have everything you need. And it's just one focus spot. So you don't have to keep running around YouTube looking for free content. You have everything you need to know to keep you relevant and irreplaceable in one spot. But if you did enjoy this video, please like and subscribe. I would highly, highly appreciate it. And I'm going to be coming out with a lot more content now that I am back at my office. It feels great to be back and I'm excited to bring you guys the best stuff. So with that being said, I'll see you in the next video.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo ensina a fazer agentes de IA escreverem exatamente como você, usando o framework IE (Instruções, Formato de Saída, Exemplos) e aplicando em cenários como FAQ e resposta a patrocinadores via NADN.",
            "resumo": "Neste vídeo, o apresentador explica como fazer agentes de IA escreverem com a sua voz, tornando a comunicação indistinguível da sua própria fala. Ele apresenta dois agentes: um FAQ, que responde perguntas comuns do público usando seu tom de voz, e um patrocinador-responder, que analisa dados de métricas da empresa para responder de forma personalizada em campanhas de patrocínio. O segredo está na 'mensagem do sistema' e no framework IE (instruções, formato de saída, exemplos), que orienta o agente a se colocar no papel do próprio autor, seguir diretrizes, incorporar uma base de conhecimento e apresentar respostas em formato JSON. O vídeo também demonstra a construção de um fluxo no NADN, com gatilhos de chat e modelos de IA, além de encorajar a participação na comunidade AI Foundations para suporte.",
            "assunto_principal": "Criação de agentes de IA que reproduzem a sua voz de forma indistinguível, através do framework IE (Instruções, Formato de Saída, Exemplos) e aplicação prática em cenários como FAQ e atendimento a patrocinadores via NADN.",
            "palavras_chave": [
              "inteligência artificial",
              "agentes de inteligência artificial",
              "engenharia de prompt",
              "framework de inteligência emocional",
              "instruções",
              "formato de saída",
              "exemplos",
              "voz personalizada",
              "tom de voz",
              "perguntas frequentes",
              "patrocínio",
              "NADN",
              "fluxo de trabalho",
              "fundamentos de inteligência artificial"
            ],
            "resumo_em_topicos": "- O vídeo mostra como agentes de IA podem soar como você.\n- Dois exemplos de agentes: Perguntas Frequentes (FAQ) e patrocinador-responder, com uso de dados e voz pessoal.\n- O segredo está na mensagem do sistema e no framework IE: Instruções, Formato de Saída, Exemplos.\n- Guia de construção no NADN: criar gatilho de chat, adicionar o agente, testar com modelo de IA e ajustar.\n- Encorajamento para participar da comunidade AI Foundations para suporte e atualizações.",
            "prompt_tokens": 1913,
            "completion_tokens": 3134,
            "model": "gpt-5-nano",
            "cost": 0.0057
          },
          "analysis_time": 89.62963008880615,
          "language": "",
          "view_count": 1585,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@aiadvantage",
      "name": "@aiadvantage",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@airevolutionx",
      "name": "@airevolutionx",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "6mkghYlqnz4",
          "title": "xAI Just Dropped Grok 4 FAST: Faster, Cheaper With 2M Context Window",
          "title_pt": "xAI acabou de lançar o Grok 4 FAST: mais rápido, mais barato com janela de contexto de 2 milhões.",
          "url": "https://www.youtube.com/watch?v=6mkghYlqnz4",
          "published": "2025-09-22T13:18:51.981891",
          "published_relative": "há 1 dia",
          "duration": "11:38",
          "date_published": "2025-09-21T15:52:35-07:00",
          "transcript_available": true,
          "transcript": "{ \"wireMagic\": \"pb3\", \"pens\": [ { } ], \"wsWinStyles\": [ { }, { \"mhModeHint\": 2, \"juJustifCode\": 0, \"sdScrollDir\": 3 } ], \"wpWinPositions\": [ { }, { \"apPoint\": 6, \"ahHorPos\": 20, \"avVerPos\": 100, \"rcRows\": 2, \"ccCols\": 40 } ], \"events\": [ { \"tStartMs\": 0, \"dDurationMs\": 695000, \"id\": 1, \"wpWinPosId\": 1, \"wsWinStyleId\": 1 }, { \"tStartMs\": 90, \"dDurationMs\": 5669, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"[Música] A\" } ] }, { \"tStartMs\": 2550, \"dDurationMs\": 3209, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 2560, \"dDurationMs\": 6400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"XAI \", \"acAsrConf\": 0 }, { \"utf8\": \"acaba \", \"tOffsetMs\": 370, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 740, \"acAsrConf\": 0 }, { \"utf8\": \"lançar \", \"tOffsetMs\": 1110, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1480, \"acAsrConf\": 0 }, { \"utf8\": \"Grock \", \"tOffsetMs\": 1850, \"acAsrConf\": 0 }, { \"utf8\": \"4Fast, \", \"tOffsetMs\": 2220, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 2590, \"acAsrConf\": 0 }, { \"utf8\": \"modelo\", \"tOffsetMs\": 2960, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 5749, \"dDurationMs\": 3211, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 5759, \"dDurationMs\": 5840, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"que \", \"acAsrConf\": 0 }, { \"utf8\": \"reduz \", \"tOffsetMs\": 411, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 822, \"acAsrConf\": 0 }, { \"utf8\": \"custos \", \"tOffsetMs\": 1233, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1644, \"acAsrConf\": 0 }, { \"utf8\": \"98%, \", \"tOffsetMs\": 2055, \"acAsrConf\": 0 }, { \"utf8\": \"mantendo \", \"tOffsetMs\": 2466, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 2877, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 8950, \"dDurationMs\": 2649, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 8960, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"poder \", \"acAsrConf\": 0 }, { \"utf8\": \"intelectual \", \"tOffsetMs\": 275, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 550, \"acAsrConf\": 0 }, { \"utf8\": \"ponta. \", \"tOffsetMs\": 825, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 1100, \"acAsrConf\": 0 }, { \"utf8\": \"novos \", \"tOffsetMs\": 1375, \"acAsrConf\": 0 }, { \"utf8\": \"óculos \", \"tOffsetMs\": 1650, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1925, \"acAsrConf\": 0 }, { \"utf8\": \"Meta \", \"tOffsetMs\": 2200, \"acAsrConf\": 0 }, { \"utf8\": \"dão\", \"tOffsetMs\": 2475, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 11589, \"dDurationMs\": 2571, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 11599, \"dDurationMs\": 5760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"um \", \"acAsrConf\": 0 }, { \"utf8\": \"toque \", \"tOffsetMs\": 257, \"acAsrConf\": 0 }, { \"utf8\": \"especial \", \"tOffsetMs\": 514, \"acAsrConf\": 0 }, { \"utf8\": \"aos \", \"tOffsetMs\": 771, \"acAsrConf\": 0 }, { \"utf8\": \"seus \", \"tOffsetMs\": 1028, \"acAsrConf\": 0 }, { \"utf8\": \"olhos. \", \"tOffsetMs\": 1285, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 1542, \"acAsrConf\": 0 }, { \"utf8\": \"YouTube \", \"tOffsetMs\": 1799, \"acAsrConf\": 0 }, { \"utf8\": \"lançou \", \"tOffsetMs\": 2056, \"acAsrConf\": 0 }, { \"utf8\": \"uma\", \"tOffsetMs\": 2313, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 14150, \"dDurationMs\": 3209, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 14160, \"dDurationMs\": 6080, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"onda \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 284, \"acAsrConf\": 0 }, { \"utf8\": \"ferramentas \", \"tOffsetMs\": 568, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 1136, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1420, \"acAsrConf\": 0 }, { \"utf8\": \"criadores \", \"tOffsetMs\": 1704, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1988, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 2272, \"acAsrConf\": 0 }, { \"utf8\": \"Deepseek\", \"tOffsetMs\": 2556, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 17349, \"dDurationMs\": 2891, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 17359, \"dDurationMs\": 5601, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"lançou \", \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 365, \"acAsrConf\": 0 }, { \"utf8\": \"variante \", \"tOffsetMs\": 730, \"acAsrConf\": 0 }, { \"utf8\": \"segura, \", \"tOffsetMs\": 1095, \"acAsrConf\": 0 }, { \"utf8\": \"ajustada \", \"tOffsetMs\": 1460, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1825, \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 2190, \"acAsrConf\": 0 }, { \"utf8\": \"manter\", \"tOffsetMs\": 2555, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 20230, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 20240, \"dDurationMs\": 5279, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"dentro \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 464, \"acAsrConf\": 0 }, { \"utf8\": \"limites \", \"tOffsetMs\": 928, \"acAsrConf\": 0 }, { \"utf8\": \"rígidos. \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"Grandes \", \"tOffsetMs\": 1856, \"acAsrConf\": 0 }, { \"utf8\": \"atualizações\", \"tOffsetMs\": 2320, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 22950, \"dDurationMs\": 2569, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 22960, \"dDurationMs\": 5680, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"por \", \"acAsrConf\": 0 }, { \"utf8\": \"todo \", \"tOffsetMs\": 275, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 550, \"acAsrConf\": 0 }, { \"utf8\": \"lado. \", \"tOffsetMs\": 825, \"acAsrConf\": 0 }, { \"utf8\": \"Então, \", \"tOffsetMs\": 1100, \"acAsrConf\": 0 }, { \"utf8\": \"vamos \", \"tOffsetMs\": 1375, \"acAsrConf\": 0 }, { \"utf8\": \"falar \", \"tOffsetMs\": 1650, \"acAsrConf\": 0 }, { \"utf8\": \"sobre \", \"tOffsetMs\": 1925, \"acAsrConf\": 0 }, { \"utf8\": \"isso. \", \"tOffsetMs\": 2200, \"acAsrConf\": 0 }, { \"utf8\": \"Muito\", \"tOffsetMs\": 2475, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 25509, \"dDurationMs\": 3131, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 25519, \"dDurationMs\": 5201, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"bem, \", \"acAsrConf\": 0 }, { \"utf8\": \"então \", \"tOffsetMs\": 311, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 622, \"acAsrConf\": 0 }, { \"utf8\": \"XAI \", \"tOffsetMs\": 933, \"acAsrConf\": 0 }, { \"utf8\": \"acaba \", \"tOffsetMs\": 1244, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1555, \"acAsrConf\": 0 }, { \"utf8\": \"lançar \", \"tOffsetMs\": 1866, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 2177, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 2488, \"acAsrConf\": 0 }, { \"utf8\": \"4\", \"tOffsetMs\": 2799, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 28630, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 28640, \"dDurationMs\": 4320, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Fast, \", \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 262, \"acAsrConf\": 0 }, { \"utf8\": \"nova \", \"tOffsetMs\": 524, \"acAsrConf\": 0 }, { \"utf8\": \"versão \", \"tOffsetMs\": 786, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1048, \"acAsrConf\": 0 }, { \"utf8\": \"seu \", \"tOffsetMs\": 1310, \"acAsrConf\": 0 }, { \"utf8\": \"modelo \", \"tOffsetMs\": 1572, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 1834, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 30710, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 30720, \"dDurationMs\": 5600, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"visa \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 297, \"acAsrConf\": 0 }, { \"utf8\": \"pensamento \", \"tOffsetMs\": 594, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 891, \"acAsrConf\": 0 }, { \"utf8\": \"alto \", \"tOffsetMs\": 1188, \"acAsrConf\": 0 }, { \"utf8\": \"nível \", \"tOffsetMs\": 1485, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1782, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 32950, \"dDurationMs\": 3370, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 32960, \"dDurationMs\": 5759, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"custo \", \"acAsrConf\": 0 }, { \"utf8\": \"muito \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"baixo. \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"ideia \", \"tOffsetMs\": 2000, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 2400, \"acAsrConf\": 0 }, { \"utf8\": \"simples. \", \"tOffsetMs\": 2800, \"acAsrConf\": 0 }, { \"utf8\": \"Obtém-se\", \"tOffsetMs\": 3200, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 36310, \"dDurationMs\": 2409, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 36320, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"qualidade \", \"acAsrConf\": 0 }, { \"utf8\": \"próxima \", \"tOffsetMs\": 259, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 518, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 777, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 1036, \"acAsrConf\": 0 }, { \"utf8\": \"4, \", \"tOffsetMs\": 1295, \"acAsrConf\": 0 }, { \"utf8\": \"enquanto \", \"tOffsetMs\": 1554, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1813, \"acAsrConf\": 0 }, { \"utf8\": \"modelo\", \"tOffsetMs\": 2072, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 38709, \"dDurationMs\": 2651, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 38719, \"dDurationMs\": 5201, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utiliza \", \"acAsrConf\": 0 }, { \"utf8\": \"muito \", \"tOffsetMs\": 343, \"acAsrConf\": 0 }, { \"utf8\": \"menos \", \"tOffsetMs\": 686, \"acAsrConf\": 0 }, { \"utf8\": \"passos \", \"tOffsetMs\": 1029, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1372, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio, \", \"tOffsetMs\": 1715, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 2058, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 2401, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 41350, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 41360, \"dDurationMs\": 4879, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"reduz \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"conta \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"acelera \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"coisas.\", \"tOffsetMs\": 1758, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 43910, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 43920, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Em \", \"acAsrConf\": 0 }, { \"utf8\": \"testes \", \"tOffsetMs\": 260, \"acAsrConf\": 0 }, { \"utf8\": \"bem \", \"tOffsetMs\": 520, \"acAsrConf\": 0 }, { \"utf8\": \"conhecidos, \", \"tOffsetMs\": 780, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1040, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 1300, \"acAsrConf\": 0 }, { \"utf8\": \"4 \", \"tOffsetMs\": 1560, \"acAsrConf\": 0 }, { \"utf8\": \"aproxima-se \", \"tOffsetMs\": 1820, \"acAsrConf\": 0 }, { \"utf8\": \"muito\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 46229, \"dDurationMs\": 1931, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 46239, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"do \", \"acAsrConf\": 0 }, { \"utf8\": \"grande \", \"tOffsetMs\": 680, \"acAsrConf\": 0 }, { \"utf8\": \"flagship,\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 48150, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 48160, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utilizando \", \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 336, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 672, \"acAsrConf\": 0 }, { \"utf8\": \"40% \", \"tOffsetMs\": 1008, \"acAsrConf\": 0 }, { \"utf8\": \"menos \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 50229, \"dDurationMs\": 2891, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 50239, \"dDurationMs\": 5121, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"tokens \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 464, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio \", \"tOffsetMs\": 928, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"média. \", \"tOffsetMs\": 1856, \"acAsrConf\": 0 }, { \"utf8\": \"Uma\", \"tOffsetMs\": 2320, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 53110, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 53120, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"classificação \", \"acAsrConf\": 0 }, { \"utf8\": \"independente \", \"tOffsetMs\": 306, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 612, \"acAsrConf\": 0 }, { \"utf8\": \"análise \", \"tOffsetMs\": 918, \"acAsrConf\": 0 }, { \"utf8\": \"artificial \", \"tOffsetMs\": 1224, \"acAsrConf\": 0 }, { \"utf8\": \"classifica \", \"tOffsetMs\": 1530, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 55350, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 55360, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"seu \", \"acAsrConf\": 0 }, { \"utf8\": \"valor \", \"tOffsetMs\": 297, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 594, \"acAsrConf\": 0 }, { \"utf8\": \"extremamente \", \"tOffsetMs\": 891, \"acAsrConf\": 0 }, { \"utf8\": \"elevado, \", \"tOffsetMs\": 1188, \"acAsrConf\": 0 }, { \"utf8\": \"dizendo \", \"tOffsetMs\": 1485, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1782, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 57670, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 57680, \"dDurationMs\": 6240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"desempenho \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 250, \"acAsrConf\": 0 }, { \"utf8\": \"relação \", \"tOffsetMs\": 500, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 750, \"acAsrConf\": 0 }, { \"utf8\": \"ritmo \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 1250, \"acAsrConf\": 0 }, { \"utf8\": \"à \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"frente \", \"tOffsetMs\": 1750, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 59830, \"dDurationMs\": 4090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 59840, \"dDurationMs\": 6880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelos \", \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 626, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1252, \"acAsrConf\": 0 }, { \"utf8\": \"GPT4.1, \", \"tOffsetMs\": 1878, \"acAsrConf\": 0 }, { \"utf8\": \"Gemini \", \"tOffsetMs\": 2504, \"acAsrConf\": 0 }, { \"utf8\": \"2.5 \", \"tOffsetMs\": 3130, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 3756, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 63910, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 63920, \"dDurationMs\": 5840, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Claude \", \"acAsrConf\": 0 }, { \"utf8\": \"4 \", \"tOffsetMs\": 511, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1022, \"acAsrConf\": 0 }, { \"utf8\": \"pensamento \", \"tOffsetMs\": 1533, \"acAsrConf\": 0 }, { \"utf8\": \"alargado. \", \"tOffsetMs\": 2044, \"acAsrConf\": 0 }, { \"utf8\": \"O\", \"tOffsetMs\": 2555, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 66710, \"dDurationMs\": 3050, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 66720, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"principal \", \"acAsrConf\": 0 }, { \"utf8\": \"resultado \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"suposta \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"queda \", \"tOffsetMs\": 2000, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 2400, \"acAsrConf\": 0 }, { \"utf8\": \"98%\", \"tOffsetMs\": 2800, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 69750, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 69760, \"dDurationMs\": 5280, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"no \", \"acAsrConf\": 0 }, { \"utf8\": \"custo \", \"tOffsetMs\": 288, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 576, \"acAsrConf\": 0 }, { \"utf8\": \"atingir \", \"tOffsetMs\": 864, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"mesmos\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 71750, \"dDurationMs\": 3290, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 71760, \"dDurationMs\": 6399, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"resultados \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 337, \"acAsrConf\": 0 }, { \"utf8\": \"referência \", \"tOffsetMs\": 674, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1011, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 1348, \"acAsrConf\": 0 }, { \"utf8\": \"4. \", \"tOffsetMs\": 1685, \"acAsrConf\": 0 }, { \"utf8\": \"Uma \", \"tOffsetMs\": 2022, \"acAsrConf\": 0 }, { \"utf8\": \"grande \", \"tOffsetMs\": 2359, \"acAsrConf\": 0 }, { \"utf8\": \"mudança \", \"tOffsetMs\": 2696, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 3033, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 75030, \"dDurationMs\": 3129, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 75040, \"dDurationMs\": 5520, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"qualquer \", \"acAsrConf\": 0 }, { \"utf8\": \"pessoa \", \"tOffsetMs\": 276, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 552, \"acAsrConf\": 0 }, { \"utf8\": \"esteja \", \"tOffsetMs\": 828, \"acAsrConf\": 0 }, { \"utf8\": \"atenta \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"às \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"contas \", \"tOffsetMs\": 1656, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1932, \"acAsrConf\": 0 }, { \"utf8\": \"IA. \", \"tOffsetMs\": 2208, \"acAsrConf\": 0 }, { \"utf8\": \"Em \", \"tOffsetMs\": 2484, \"acAsrConf\": 0 }, { \"utf8\": \"termos \", \"tOffsetMs\": 2760, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 3036, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 78149, \"dDurationMs\": 2411, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 78159, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"números \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 274, \"acAsrConf\": 0 }, { \"utf8\": \"interessam \", \"tOffsetMs\": 548, \"acAsrConf\": 0 }, { \"utf8\": \"aos \", \"tOffsetMs\": 822, \"acAsrConf\": 0 }, { \"utf8\": \"fãs, \", \"tOffsetMs\": 1096, \"acAsrConf\": 0 }, { \"utf8\": \"Grock \", \"tOffsetMs\": 1370, \"acAsrConf\": 0 }, { \"utf8\": \"4 \", \"tOffsetMs\": 1644, \"acAsrConf\": 0 }, { \"utf8\": \"Fast\", \"tOffsetMs\": 1918, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 80550, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 80560, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"publica \", \"acAsrConf\": 0 }, { \"utf8\": \"resultados \", \"tOffsetMs\": 262, \"acAsrConf\": 0 }, { \"utf8\": \"fortes \", \"tOffsetMs\": 524, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 786, \"acAsrConf\": 0 }, { \"utf8\": \"concursos \", \"tOffsetMs\": 1048, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1310, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio \", \"tOffsetMs\": 1572, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1834, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 82630, \"dDurationMs\": 2890, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 82640, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"matemática. \", \"acAsrConf\": 0 }, { \"utf8\": \"Muito \", \"tOffsetMs\": 440, \"acAsrConf\": 0 }, { \"utf8\": \"próximo \", \"tOffsetMs\": 880, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 1760, \"acAsrConf\": 0 }, { \"utf8\": \"4 \", \"tOffsetMs\": 2200, \"acAsrConf\": 0 }, { \"utf8\": \"na\", \"tOffsetMs\": 2640, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 85510, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 85520, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"maioria \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 251, \"acAsrConf\": 0 }, { \"utf8\": \"à \", \"tOffsetMs\": 502, \"acAsrConf\": 0 }, { \"utf8\": \"frente \", \"tOffsetMs\": 753, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1004, \"acAsrConf\": 0 }, { \"utf8\": \"alguns. \", \"tOffsetMs\": 1255, \"acAsrConf\": 0 }, { \"utf8\": \"Embora \", \"tOffsetMs\": 1506, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 1757, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 87670, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 87680, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"testes \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"codificação \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"ainda \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"pareçam \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"sólidos, \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 89990, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 90000, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"parte \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 190, \"acAsrConf\": 0 }, { \"utf8\": \"interessante \", \"tOffsetMs\": 380, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 760, \"acAsrConf\": 0 }, { \"utf8\": \"forma \", \"tOffsetMs\": 950, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"utilizam \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"as\", \"tOffsetMs\": 1520, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 91910, \"dDurationMs\": 3290, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 91920, \"dDurationMs\": 5519, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ferramentas. \", \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"aprender \", \"tOffsetMs\": 1518, \"acAsrConf\": 0 }, { \"utf8\": \"rapidamente \", \"tOffsetMs\": 2024, \"acAsrConf\": 0 }, { \"utf8\": \"quando \", \"tOffsetMs\": 2530, \"acAsrConf\": 0 }, { \"utf8\": \"executar\", \"tOffsetMs\": 3036, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 95190, \"dDurationMs\": 2249, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 95200, \"dDurationMs\": 3919, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"código, \", \"acAsrConf\": 0 }, { \"utf8\": \"quando \", \"tOffsetMs\": 346, \"acAsrConf\": 0 }, { \"utf8\": \"navegar \", \"tOffsetMs\": 692, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 1038, \"acAsrConf\": 0 }, { \"utf8\": \"Web \", \"tOffsetMs\": 1384, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1730, \"acAsrConf\": 0 }, { \"utf8\": \"como\", \"tOffsetMs\": 2076, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 97429, \"dDurationMs\": 1690, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 97439, \"dDurationMs\": 3761, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"alternar \", \"acAsrConf\": 0 }, { \"utf8\": \"entre \", \"tOffsetMs\": 272, \"acAsrConf\": 0 }, { \"utf8\": \"ligações \", \"tOffsetMs\": 544, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1088, \"acAsrConf\": 0 }, { \"utf8\": \"assistente\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 99109, \"dDurationMs\": 2091, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 99119, \"dDurationMs\": 5281, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"sentido \", \"tOffsetMs\": 368, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 736, \"acAsrConf\": 0 }, { \"utf8\": \"direção. \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"Pode \", \"tOffsetMs\": 1472, \"acAsrConf\": 0 }, { \"utf8\": \"ler\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 101190, \"dDurationMs\": 3210, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 101200, \"dDurationMs\": 5440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"publicações, \", \"acAsrConf\": 0 }, { \"utf8\": \"imagens \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"até \", \"tOffsetMs\": 1278, \"acAsrConf\": 0 }, { \"utf8\": \"vídeos \", \"tOffsetMs\": 1704, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 2130, \"acAsrConf\": 0 }, { \"utf8\": \"X\", \"tOffsetMs\": 2556, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 104390, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 104400, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"depois \", \"tOffsetMs\": 499, \"acAsrConf\": 0 }, { \"utf8\": \"juntar \", \"tOffsetMs\": 998, \"acAsrConf\": 0 }, { \"utf8\": \"tudo \", \"tOffsetMs\": 1497, \"acAsrConf\": 0 }, { \"utf8\": \"numa\", \"tOffsetMs\": 1996, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 106630, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 106640, \"dDurationMs\": 5119, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"resposta \", \"acAsrConf\": 0 }, { \"utf8\": \"clara. \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"Durante \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1278, \"acAsrConf\": 0 }, { \"utf8\": \"rastreio \", \"tOffsetMs\": 1704, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 2130, \"acAsrConf\": 0 }, { \"utf8\": \"vivo,\", \"tOffsetMs\": 2556, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 109350, \"dDurationMs\": 2409, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 109360, \"dDurationMs\": 5039, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"procurou \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"total \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"exato \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 111749, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 111759, \"dDurationMs\": 7161, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"pontos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 189, \"acAsrConf\": 0 }, { \"utf8\": \"experiência \", \"tOffsetMs\": 378, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 567, \"acAsrConf\": 0 }, { \"utf8\": \"atingir \", \"tOffsetMs\": 756, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 945, \"acAsrConf\": 0 }, { \"utf8\": \"nível \", \"tOffsetMs\": 1134, \"acAsrConf\": 0 }, { \"utf8\": \"100 \", \"tOffsetMs\": 1323, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1512, \"acAsrConf\": 0 }, { \"utf8\": \"Path \", \"tOffsetMs\": 1701, \"acAsrConf\": 0 }, { \"utf8\": \"of \", \"tOffsetMs\": 1890, \"acAsrConf\": 0 }, { \"utf8\": \"Exile\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 114389, \"dDurationMs\": 4531, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 114399, \"dDurationMs\": 4521, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"2 \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 304, \"acAsrConf\": 0 }, { \"utf8\": \"decidiu-se \", \"tOffsetMs\": 608, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 912, \"acAsrConf\": 0 }, { \"utf8\": \"4 \", \"tOffsetMs\": 1216, \"acAsrConf\": 0 }, { \"utf8\": \"bill250.334.444\", \"tOffsetMs\": 1520, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 120149, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 120159, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"após \", \"acAsrConf\": 0 }, { \"utf8\": \"verificar \", \"tOffsetMs\": 613, \"acAsrConf\": 0 }, { \"utf8\": \"fontes \", \"tOffsetMs\": 1226, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1839, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 122310, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 122320, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"confirmar \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 274, \"acAsrConf\": 0 }, { \"utf8\": \"limite \", \"tOffsetMs\": 548, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 822, \"acAsrConf\": 0 }, { \"utf8\": \"nível. \", \"tOffsetMs\": 1096, \"acAsrConf\": 0 }, { \"utf8\": \"Este \", \"tOffsetMs\": 1370, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 1644, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1918, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 124389, \"dDurationMs\": 2571, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 124399, \"dDurationMs\": 4881, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"tipo \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 249, \"acAsrConf\": 0 }, { \"utf8\": \"comportamento \", \"tOffsetMs\": 498, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 747, \"acAsrConf\": 0 }, { \"utf8\": \"pesquisa \", \"tOffsetMs\": 996, \"acAsrConf\": 0 }, { \"utf8\": \"autónomo \", \"tOffsetMs\": 1245, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1494, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1743, \"acAsrConf\": 0 }, { \"utf8\": \"maioria \", \"tOffsetMs\": 1992, \"acAsrConf\": 0 }, { \"utf8\": \"das\", \"tOffsetMs\": 2241, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 126950, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 126960, \"dDurationMs\": 4880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"pessoas \", \"acAsrConf\": 0 }, { \"utf8\": \"espera \", \"tOffsetMs\": 200, \"acAsrConf\": 0 }, { \"utf8\": \"quando \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"ouve \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"falar \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"agente \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1400, \"acAsrConf\": 0 }, { \"utf8\": \"IA.\", \"tOffsetMs\": 1600, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 129270, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 129280, \"dDurationMs\": 5760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"E \", \"acAsrConf\": 0 }, { \"utf8\": \"agora \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"aparece \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"habilidade \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"padrão\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 131830, \"dDurationMs\": 3210, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 131840, \"dDurationMs\": 5759, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"em \", \"acAsrConf\": 0 }, { \"utf8\": \"vez \", \"tOffsetMs\": 296, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 592, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 888, \"acAsrConf\": 0 }, { \"utf8\": \"demonstração \", \"tOffsetMs\": 1184, \"acAsrConf\": 0 }, { \"utf8\": \"laboratorial. \", \"tOffsetMs\": 1480, \"acAsrConf\": 0 }, { \"utf8\": \"No \", \"tOffsetMs\": 1776, \"acAsrConf\": 0 }, { \"utf8\": \"dia \", \"tOffsetMs\": 2072, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 2368, \"acAsrConf\": 0 }, { \"utf8\": \"dia, \", \"tOffsetMs\": 2664, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 2960, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 135030, \"dDurationMs\": 2569, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 135040, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelo \", \"acAsrConf\": 0 }, { \"utf8\": \"procura \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"sentir-se \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"versátil. \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"Pode\", \"tOffsetMs\": 2400, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 137589, \"dDurationMs\": 1931, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 137599, \"dDurationMs\": 3601, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"desencadear \", \"acAsrConf\": 0 }, { \"utf8\": \"respostas \", \"tOffsetMs\": 533, \"acAsrConf\": 0 }, { \"utf8\": \"rápidas \", \"tOffsetMs\": 1066, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 1599, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 139510, \"dDurationMs\": 1690, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 139520, \"dDurationMs\": 3840, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"perguntas \", \"acAsrConf\": 0 }, { \"utf8\": \"simples \", \"tOffsetMs\": 226, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 452, \"acAsrConf\": 0 }, { \"utf8\": \"depois \", \"tOffsetMs\": 678, \"acAsrConf\": 0 }, { \"utf8\": \"passar \", \"tOffsetMs\": 904, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1130, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1356, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 141190, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 141200, \"dDurationMs\": 4320, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"raciocínio \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 251, \"acAsrConf\": 0 }, { \"utf8\": \"profundo \", \"tOffsetMs\": 502, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 753, \"acAsrConf\": 0 }, { \"utf8\": \"perguntas \", \"tOffsetMs\": 1004, \"acAsrConf\": 0 }, { \"utf8\": \"complexas \", \"tOffsetMs\": 1255, \"acAsrConf\": 0 }, { \"utf8\": \"sem \", \"tOffsetMs\": 1506, \"acAsrConf\": 0 }, { \"utf8\": \"ter\", \"tOffsetMs\": 1757, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 143350, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 143360, \"dDurationMs\": 5280, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"de \", \"acAsrConf\": 0 }, { \"utf8\": \"mudar \", \"tOffsetMs\": 306, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 612, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 918, \"acAsrConf\": 0 }, { \"utf8\": \"modelo \", \"tOffsetMs\": 1224, \"acAsrConf\": 0 }, { \"utf8\": \"diferente. \", \"tOffsetMs\": 1530, \"acAsrConf\": 0 }, { \"utf8\": \"Um\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 145510, \"dDurationMs\": 3130, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 145520, \"dDurationMs\": 6079, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"cérebro, \", \"acAsrConf\": 0 }, { \"utf8\": \"dois \", \"tOffsetMs\": 543, \"acAsrConf\": 0 }, { \"utf8\": \"modos. \", \"tOffsetMs\": 1086, \"acAsrConf\": 0 }, { \"utf8\": \"Este \", \"tOffsetMs\": 1629, \"acAsrConf\": 0 }, { \"utf8\": \"design \", \"tOffsetMs\": 2172, \"acAsrConf\": 0 }, { \"utf8\": \"significa\", \"tOffsetMs\": 2715, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 148630, \"dDurationMs\": 2969, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 148640, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"menor \", \"acAsrConf\": 0 }, { \"utf8\": \"atraso \", \"tOffsetMs\": 453, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 906, \"acAsrConf\": 0 }, { \"utf8\": \"menos \", \"tOffsetMs\": 1359, \"acAsrConf\": 0 }, { \"utf8\": \"tokens \", \"tOffsetMs\": 1812, \"acAsrConf\": 0 }, { \"utf8\": \"desperdiçados. \", \"tOffsetMs\": 2265, \"acAsrConf\": 0 }, { \"utf8\": \"Ele\", \"tOffsetMs\": 2718, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 151589, \"dDurationMs\": 2091, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 151599, \"dDurationMs\": 4401, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"também \", \"acAsrConf\": 0 }, { \"utf8\": \"lembra \", \"tOffsetMs\": 263, \"acAsrConf\": 0 }, { \"utf8\": \"muita \", \"tOffsetMs\": 526, \"acAsrConf\": 0 }, { \"utf8\": \"coisa. \", \"tOffsetMs\": 789, \"acAsrConf\": 0 }, { \"utf8\": \"Uma \", \"tOffsetMs\": 1052, \"acAsrConf\": 0 }, { \"utf8\": \"janela \", \"tOffsetMs\": 1315, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1578, \"acAsrConf\": 0 }, { \"utf8\": \"contexto\", \"tOffsetMs\": 1841, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 153670, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 153680, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"de \", \"acAsrConf\": 0 }, { \"utf8\": \"2 \", \"tOffsetMs\": 222, \"acAsrConf\": 0 }, { \"utf8\": \"milhões \", \"tOffsetMs\": 444, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"tokens \", \"tOffsetMs\": 888, \"acAsrConf\": 0 }, { \"utf8\": \"significa \", \"tOffsetMs\": 1110, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"conversas \", \"tOffsetMs\": 1554, \"acAsrConf\": 0 }, { \"utf8\": \"muito \", \"tOffsetMs\": 1776, \"acAsrConf\": 0 }, { \"utf8\": \"longas\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 155990, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 156000, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"documentos \", \"tOffsetMs\": 336, \"acAsrConf\": 0 }, { \"utf8\": \"pesados ​​\", \"tOffsetMs\": 672, \"acAsrConf\": 0 }, { \"utf8\": \"permanecem \", \"tOffsetMs\": 1008, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"jogo,\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 158150, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 158160, \"dDurationMs\": 4159, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"o \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 359, \"acAsrConf\": 0 }, { \"utf8\": \"ajuda \", \"tOffsetMs\": 718, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1077, \"acAsrConf\": 0 }, { \"utf8\": \"pesquisas,\", \"tOffsetMs\": 1436, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 159990, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 160000, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"revisões \", \"acAsrConf\": 0 }, { \"utf8\": \"jurídicas, \", \"tOffsetMs\": 285, \"acAsrConf\": 0 }, { \"utf8\": \"documentos \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 855, \"acAsrConf\": 0 }, { \"utf8\": \"design \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1425, \"acAsrConf\": 0 }, { \"utf8\": \"jogos \", \"tOffsetMs\": 1710, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1995, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 162309, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 162319, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"fluxos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 368, \"acAsrConf\": 0 }, { \"utf8\": \"trabalho \", \"tOffsetMs\": 736, \"acAsrConf\": 0 }, { \"utf8\": \"corporativos \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1472, \"acAsrConf\": 0 }, { \"utf8\": \"abrangem\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 164550, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 164560, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"muitos \", \"acAsrConf\": 0 }, { \"utf8\": \"arquivos. \", \"tOffsetMs\": 520, \"acAsrConf\": 0 }, { \"utf8\": \"Obter \", \"tOffsetMs\": 1040, \"acAsrConf\": 0 }, { \"utf8\": \"acesso \", \"tOffsetMs\": 1560, \"acAsrConf\": 0 }, { \"utf8\": \"é\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 166869, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 166879, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"simples. \", \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 285, \"acAsrConf\": 0 }, { \"utf8\": \"Gro \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"for \", \"tOffsetMs\": 855, \"acAsrConf\": 0 }, { \"utf8\": \"fast \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 1425, \"acAsrConf\": 0 }, { \"utf8\": \"disponível \", \"tOffsetMs\": 1710, \"acAsrConf\": 0 }, { \"utf8\": \"em\", \"tOffsetMs\": 1995, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 169110, \"dDurationMs\": 2489, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 169120, \"dDurationMs\": 4399, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"grock.com \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 308, \"acAsrConf\": 0 }, { \"utf8\": \"dentro \", \"tOffsetMs\": 616, \"acAsrConf\": 0 }, { \"utf8\": \"das \", \"tOffsetMs\": 924, \"acAsrConf\": 0 }, { \"utf8\": \"aplicações \", \"tOffsetMs\": 1232, \"acAsrConf\": 0 }, { \"utf8\": \"iOS \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1848, \"acAsrConf\": 0 }, { \"utf8\": \"Android\", \"tOffsetMs\": 2156, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 171589, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 171599, \"dDurationMs\": 5201, \"wWinId\": 1, \"segs\": [ { \"utf8\": \", \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"programadores \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"podem \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"chamá-lo \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"através\", \"tOffsetMs\": 1758, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 173509, \"dDurationMs\": 3291, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 173519, \"dDurationMs\": 5681, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"da \", \"acAsrConf\": 0 }, { \"utf8\": \"API \", \"tOffsetMs\": 453, \"acAsrConf\": 0 }, { \"utf8\": \"XAI \", \"tOffsetMs\": 906, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1359, \"acAsrConf\": 0 }, { \"utf8\": \"duas \", \"tOffsetMs\": 1812, \"acAsrConf\": 0 }, { \"utf8\": \"versões: \", \"tOffsetMs\": 2265, \"acAsrConf\": 0 }, { \"utf8\": \"uma\", \"tOffsetMs\": 2718, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 176790, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 176800, \"dDurationMs\": 5600, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"versão \", \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 269, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio \", \"tOffsetMs\": 538, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 807, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1076, \"acAsrConf\": 0 }, { \"utf8\": \"versão \", \"tOffsetMs\": 1345, \"acAsrConf\": 0 }, { \"utf8\": \"sem \", \"tOffsetMs\": 1614, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio, \", \"tOffsetMs\": 1883, \"acAsrConf\": 0 }, { \"utf8\": \"ambas\", \"tOffsetMs\": 2152, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 179190, \"dDurationMs\": 3210, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 179200, \"dDurationMs\": 5759, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 350, \"acAsrConf\": 0 }, { \"utf8\": \"mesma \", \"tOffsetMs\": 700, \"acAsrConf\": 0 }, { \"utf8\": \"janela \", \"tOffsetMs\": 1050, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1400, \"acAsrConf\": 0 }, { \"utf8\": \"memória \", \"tOffsetMs\": 1750, \"acAsrConf\": 0 }, { \"utf8\": \"gigante. \", \"tOffsetMs\": 2100, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 2450, \"acAsrConf\": 0 }, { \"utf8\": \"Icing\", \"tOffsetMs\": 2800, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 182390, \"dDurationMs\": 2569, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 182400, \"dDurationMs\": 4479, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utiliza \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 308, \"acAsrConf\": 0 }, { \"utf8\": \"medidor \", \"tOffsetMs\": 616, \"acAsrConf\": 0 }, { \"utf8\": \"habitual \", \"tOffsetMs\": 924, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1232, \"acAsrConf\": 0 }, { \"utf8\": \"tokens \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1848, \"acAsrConf\": 0 }, { \"utf8\": \"milhão.\", \"tOffsetMs\": 2156, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 184949, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 184959, \"dDurationMs\": 4801, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Entradas \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"20 \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"cêntimos \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"milhão \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1758, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 186869, \"dDurationMs\": 2891, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 186879, \"dDurationMs\": 5921, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"saídas \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 240, \"acAsrConf\": 0 }, { \"utf8\": \"50 \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"cêntimos \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"milhão. \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"Abaixo \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 189750, \"dDurationMs\": 3050, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 189760, \"dDurationMs\": 5360, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"120.000 \", \"acAsrConf\": 0 }, { \"utf8\": \"tokens \", \"tOffsetMs\": 350, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 700, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1050, \"acAsrConf\": 0 }, { \"utf8\": \"taxa \", \"tOffsetMs\": 1400, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1750, \"acAsrConf\": 0 }, { \"utf8\": \"câmbio \", \"tOffsetMs\": 2100, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 2450, \"acAsrConf\": 0 }, { \"utf8\": \"5\", \"tOffsetMs\": 2800, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 192790, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 192800, \"dDurationMs\": 5359, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"cêntimos \", \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 231, \"acAsrConf\": 0 }, { \"utf8\": \"milhão. \", \"tOffsetMs\": 462, \"acAsrConf\": 0 }, { \"utf8\": \"Acima \", \"tOffsetMs\": 693, \"acAsrConf\": 0 }, { \"utf8\": \"disso, \", \"tOffsetMs\": 924, \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 1155, \"acAsrConf\": 0 }, { \"utf8\": \"taxas \", \"tOffsetMs\": 1386, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1617, \"acAsrConf\": 0 }, { \"utf8\": \"entrada \", \"tOffsetMs\": 1848, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 195110, \"dDurationMs\": 3049, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 195120, \"dDurationMs\": 6720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"saída \", \"acAsrConf\": 0 }, { \"utf8\": \"aumentam \", \"tOffsetMs\": 308, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 616, \"acAsrConf\": 0 }, { \"utf8\": \"40 \", \"tOffsetMs\": 924, \"acAsrConf\": 0 }, { \"utf8\": \"cêntimos \", \"tOffsetMs\": 1232, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"1 \", \"tOffsetMs\": 1848, \"acAsrConf\": 0 }, { \"utf8\": \"dólar.\", \"tOffsetMs\": 2156, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 198149, \"dDurationMs\": 3691, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 198159, \"dDurationMs\": 6000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Pesquisa \", \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 445, \"acAsrConf\": 0 }, { \"utf8\": \"vivo \", \"tOffsetMs\": 890, \"acAsrConf\": 0 }, { \"utf8\": \"nas \", \"tOffsetMs\": 1335, \"acAsrConf\": 0 }, { \"utf8\": \"contas \", \"tOffsetMs\": 1780, \"acAsrConf\": 0 }, { \"utf8\": \"API \", \"tOffsetMs\": 2225, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 2670, \"acAsrConf\": 0 }, { \"utf8\": \"1.000\", \"tOffsetMs\": 3115, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 201830, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 201840, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"fontes. \", \"acAsrConf\": 0 }, { \"utf8\": \"Por \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"tempo \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"limitado, \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"é\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 204149, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 204159, \"dDurationMs\": 4401, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"gratuito \", \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 285, \"acAsrConf\": 0 }, { \"utf8\": \"testar \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 855, \"acAsrConf\": 0 }, { \"utf8\": \"router \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"aberto \", \"tOffsetMs\": 1425, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1710, \"acAsrConf\": 0 }, { \"utf8\": \"pelo\", \"tOffsetMs\": 1995, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 206390, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 206400, \"dDurationMs\": 5520, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"gateway \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 213, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 639, \"acAsrConf\": 0 }, { \"utf8\": \"versel, \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1065, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1278, \"acAsrConf\": 0 }, { \"utf8\": \"torna \", \"tOffsetMs\": 1491, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1704, \"acAsrConf\": 0 }, { \"utf8\": \"experiência\", \"tOffsetMs\": 1917, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 208550, \"dDurationMs\": 3370, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 208560, \"dDurationMs\": 6160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"muito \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 377, \"acAsrConf\": 0 }, { \"utf8\": \"fácil. \", \"tOffsetMs\": 754, \"acAsrConf\": 0 }, { \"utf8\": \"No \", \"tOffsetMs\": 1131, \"acAsrConf\": 0 }, { \"utf8\": \"geral, \", \"tOffsetMs\": 1508, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1885, \"acAsrConf\": 0 }, { \"utf8\": \"Grock \", \"tOffsetMs\": 2262, \"acAsrConf\": 0 }, { \"utf8\": \"4fast\", \"tOffsetMs\": 2639, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 211910, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 211920, \"dDurationMs\": 5440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"concentra-se \", \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 346, \"acAsrConf\": 0 }, { \"utf8\": \"valor, \", \"tOffsetMs\": 692, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1038, \"acAsrConf\": 0 }, { \"utf8\": \"raciocínio \", \"tOffsetMs\": 1384, \"acAsrConf\": 0 }, { \"utf8\": \"sólido, \", \"tOffsetMs\": 1730, \"acAsrConf\": 0 }, { \"utf8\": \"nos\", \"tOffsetMs\": 2076, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 214710, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 214720, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"preços \", \"acAsrConf\": 0 }, { \"utf8\": \"agressivos, \", \"tOffsetMs\": 248, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 496, \"acAsrConf\": 0 }, { \"utf8\": \"pesquisa \", \"tOffsetMs\": 744, \"acAsrConf\": 0 }, { \"utf8\": \"nativa \", \"tOffsetMs\": 992, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 1240, \"acAsrConf\": 0 }, { \"utf8\": \"web \", \"tOffsetMs\": 1488, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1736, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1984, \"acAsrConf\": 0 }, { \"utf8\": \"X\", \"tOffsetMs\": 2232, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 217350, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 217360, \"dDurationMs\": 4879, \"wWinId\": 1, \"segs\": [ { \"utf8\": \", \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"num \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"modelo \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"único \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"alterna\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 219670, \"dDurationMs\": 2569, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 219680, \"dDurationMs\": 4880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"entre \", \"acAsrConf\": 0 }, { \"utf8\": \"respostas \", \"tOffsetMs\": 386, \"acAsrConf\": 0 }, { \"utf8\": \"rápidas \", \"tOffsetMs\": 772, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1158, \"acAsrConf\": 0 }, { \"utf8\": \"longas \", \"tOffsetMs\": 1544, \"acAsrConf\": 0 }, { \"utf8\": \"cadeias \", \"tOffsetMs\": 1930, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 2316, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 222229, \"dDurationMs\": 2331, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 222239, \"dDurationMs\": 4961, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"pensamento. \", \"acAsrConf\": 0 }, { \"utf8\": \"Esta \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"combinação \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"serve \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"tanto \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 224550, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 224560, \"dDurationMs\": 4959, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utilizadores \", \"acAsrConf\": 0 }, { \"utf8\": \"comuns \", \"tOffsetMs\": 257, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 514, \"acAsrConf\": 0 }, { \"utf8\": \"querem \", \"tOffsetMs\": 771, \"acAsrConf\": 0 }, { \"utf8\": \"ajuda \", \"tOffsetMs\": 1028, \"acAsrConf\": 0 }, { \"utf8\": \"rápida \", \"tOffsetMs\": 1285, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1542, \"acAsrConf\": 0 }, { \"utf8\": \"precisa \", \"tOffsetMs\": 1799, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 2056, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 2313, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 227190, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 227200, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"equipas \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"monitorizam \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"cada \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"cêntimo \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"investido \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"em\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 229509, \"dDurationMs\": 2331, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 229519, \"dDurationMs\": 5041, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"cargas \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 160, \"acAsrConf\": 0 }, { \"utf8\": \"trabalho \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"grande \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"dimensão.\", \"tOffsetMs\": 800, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 231830, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 231840, \"dDurationMs\": 4800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Agora, \", \"acAsrConf\": 0 }, { \"utf8\": \"hardware. \", \"tOffsetMs\": 248, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 496, \"acAsrConf\": 0 }, { \"utf8\": \"óculos \", \"tOffsetMs\": 744, \"acAsrConf\": 0 }, { \"utf8\": \"inteligentes \", \"tOffsetMs\": 992, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1240, \"acAsrConf\": 0 }, { \"utf8\": \"ecrã \", \"tOffsetMs\": 1488, \"acAsrConf\": 0 }, { \"utf8\": \"Ray-B \", \"tOffsetMs\": 1736, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1984, \"acAsrConf\": 0 }, { \"utf8\": \"Meta\", \"tOffsetMs\": 2232, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 234550, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 234560, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"são \", \"acAsrConf\": 0 }, { \"utf8\": \"finalmente \", \"tOffsetMs\": 613, \"acAsrConf\": 0 }, { \"utf8\": \"oficiais \", \"tOffsetMs\": 1226, \"acAsrConf\": 0 }, { \"utf8\": \"nos\", \"tOffsetMs\": 1839, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 236630, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 236640, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Estados \", \"acAsrConf\": 0 }, { \"utf8\": \"Unidos, \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"chegando \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"segunda-feira,\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 238550, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 238560, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"30 \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 331, \"acAsrConf\": 0 }, { \"utf8\": \"setembro, \", \"tOffsetMs\": 662, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 993, \"acAsrConf\": 0 }, { \"utf8\": \"800 \", \"tOffsetMs\": 1324, \"acAsrConf\": 0 }, { \"utf8\": \"dólares. \", \"tOffsetMs\": 1655, \"acAsrConf\": 0 }, { \"utf8\": \"E \", \"tOffsetMs\": 1986, \"acAsrConf\": 0 }, { \"utf8\": \"vêm\", \"tOffsetMs\": 2317, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 241030, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 241040, \"dDurationMs\": 4080, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 288, \"acAsrConf\": 0 }, { \"utf8\": \"nova \", \"tOffsetMs\": 576, \"acAsrConf\": 0 }, { \"utf8\": \"pulseira \", \"tOffsetMs\": 864, \"acAsrConf\": 0 }, { \"utf8\": \"Meta \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"Neuraland\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 243190, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 243200, \"dDurationMs\": 4319, \"wWinId\": 1, \"segs\": [ { \"utf8\": \". \", \"acAsrConf\": 0 }, { \"utf8\": \"Este \", \"tOffsetMs\": 228, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 456, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 684, \"acAsrConf\": 0 }, { \"utf8\": \"primeiro \", \"tOffsetMs\": 912, \"acAsrConf\": 0 }, { \"utf8\": \"par \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1368, \"acAsrConf\": 0 }, { \"utf8\": \"Meta\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 245110, \"dDurationMs\": 2409, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 245120, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"visor \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"head-up \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"real, \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"visível\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 247509, \"dDurationMs\": 1771, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 247519, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"apenas \", \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"olho \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"direito, \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"enquanto \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 249270, \"dDurationMs\": 2249, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 249280, \"dDurationMs\": 4239, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"pulseira \", \"acAsrConf\": 0 }, { \"utf8\": \"lê \", \"tOffsetMs\": 416, \"acAsrConf\": 0 }, { \"utf8\": \"pequenos \", \"tOffsetMs\": 832, \"acAsrConf\": 0 }, { \"utf8\": \"sinais \", \"tOffsetMs\": 1248, \"acAsrConf\": 0 }, { \"utf8\": \"musculares \", \"tOffsetMs\": 1664, \"acAsrConf\": 0 }, { \"utf8\": \"na\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 251509, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 251519, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"sua \", \"acAsrConf\": 0 }, { \"utf8\": \"mão. \", \"tOffsetMs\": 263, \"acAsrConf\": 0 }, { \"utf8\": \"Assim, \", \"tOffsetMs\": 526, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 789, \"acAsrConf\": 0 }, { \"utf8\": \"simples \", \"tOffsetMs\": 1052, \"acAsrConf\": 0 }, { \"utf8\": \"pinça \", \"tOffsetMs\": 1315, \"acAsrConf\": 0 }, { \"utf8\": \"torna-se \", \"tOffsetMs\": 1578, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1841, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 253509, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 253519, \"dDurationMs\": 4321, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"clique. \", \"acAsrConf\": 0 }, { \"utf8\": \"Um \", \"tOffsetMs\": 285, \"acAsrConf\": 0 }, { \"utf8\": \"deslizar \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 855, \"acAsrConf\": 0 }, { \"utf8\": \"polegar \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"transforma-se \", \"tOffsetMs\": 1425, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1710, \"acAsrConf\": 0 }, { \"utf8\": \"scroll,\", \"tOffsetMs\": 1995, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 255990, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 256000, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 217, \"acAsrConf\": 0 }, { \"utf8\": \"toque \", \"tOffsetMs\": 434, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 651, \"acAsrConf\": 0 }, { \"utf8\": \"torção \", \"tOffsetMs\": 868, \"acAsrConf\": 0 }, { \"utf8\": \"funcionam \", \"tOffsetMs\": 1085, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1302, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1519, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 257830, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 257840, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"botão \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 310, \"acAsrConf\": 0 }, { \"utf8\": \"volume \", \"tOffsetMs\": 620, \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 930, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1240, \"acAsrConf\": 0 }, { \"utf8\": \"zoom. \", \"tOffsetMs\": 1550, \"acAsrConf\": 0 }, { \"utf8\": \"Porque \", \"tOffsetMs\": 1860, \"acAsrConf\": 0 }, { \"utf8\": \"há \", \"tOffsetMs\": 2170, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 2480, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 260550, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 260560, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ecrã \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 331, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 662, \"acAsrConf\": 0 }, { \"utf8\": \"bateria \", \"tOffsetMs\": 993, \"acAsrConf\": 0 }, { \"utf8\": \"maior \", \"tOffsetMs\": 1324, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1655, \"acAsrConf\": 0 }, { \"utf8\": \"interior. \", \"tOffsetMs\": 1986, \"acAsrConf\": 0 }, { \"utf8\": \"A\", \"tOffsetMs\": 2317, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 263030, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 263040, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"armação \", \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 177, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 354, \"acAsrConf\": 0 }, { \"utf8\": \"grossa \", \"tOffsetMs\": 531, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 708, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 885, \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 1062, \"acAsrConf\": 0 }, { \"utf8\": \"braceletes \", \"tOffsetMs\": 1239, \"acAsrConf\": 0 }, { \"utf8\": \"Ray-B \", \"tOffsetMs\": 1416, \"acAsrConf\": 0 }, { \"utf8\": \"comuns\", \"tOffsetMs\": 1593, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 264950, \"dDurationMs\": 3290, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 264960, \"dDurationMs\": 6000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 354, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 708, \"acAsrConf\": 0 }, { \"utf8\": \"pesada, \", \"tOffsetMs\": 1062, \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 1416, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1770, \"acAsrConf\": 0 }, { \"utf8\": \"69 \", \"tOffsetMs\": 2124, \"acAsrConf\": 0 }, { \"utf8\": \"gramas\", \"tOffsetMs\": 2478, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 268230, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 268240, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"contra \", \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 479, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 958, \"acAsrConf\": 0 }, { \"utf8\": \"52 \", \"tOffsetMs\": 1437, \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 1916, \"acAsrConf\": 0 }, { \"utf8\": \"óculos\", \"tOffsetMs\": 2395, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 270950, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 270960, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"meta \", \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 192, \"acAsrConf\": 0 }, { \"utf8\": \"bracelete \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"Ray-B \", \"tOffsetMs\": 576, \"acAsrConf\": 0 }, { \"utf8\": \"apenas \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"câmara \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1728, \"acAsrConf\": 0 }, { \"utf8\": \"45\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 273430, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 273440, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"armação \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"normal. \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"próprio \", \"tOffsetMs\": 2000, \"acAsrConf\": 0 }, { \"utf8\": \"HUD\", \"tOffsetMs\": 2400, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 276150, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 276160, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"apenas \", \"acAsrConf\": 0 }, { \"utf8\": \"vaza \", \"tOffsetMs\": 166, \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 332, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 498, \"acAsrConf\": 0 }, { \"utf8\": \"2% \", \"tOffsetMs\": 664, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 830, \"acAsrConf\": 0 }, { \"utf8\": \"sua \", \"tOffsetMs\": 996, \"acAsrConf\": 0 }, { \"utf8\": \"luz, \", \"tOffsetMs\": 1162, \"acAsrConf\": 0 }, { \"utf8\": \"pelo \", \"tOffsetMs\": 1328, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1494, \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 1660, \"acAsrConf\": 0 }, { \"utf8\": \"pessoas \", \"tOffsetMs\": 1826, \"acAsrConf\": 0 }, { \"utf8\": \"ao\", \"tOffsetMs\": 1992, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 278390, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 278400, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"redor \", \"acAsrConf\": 0 }, { \"utf8\": \"geralmente \", \"tOffsetMs\": 274, \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 548, \"acAsrConf\": 0 }, { \"utf8\": \"conseguem \", \"tOffsetMs\": 822, \"acAsrConf\": 0 }, { \"utf8\": \"perceber \", \"tOffsetMs\": 1096, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1370, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 1644, \"acAsrConf\": 0 }, { \"utf8\": \"ligado.\", \"tOffsetMs\": 1918, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 281110, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 281120, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"O \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 339, \"acAsrConf\": 0 }, { \"utf8\": \"vão \", \"tOffsetMs\": 678, \"acAsrConf\": 0 }, { \"utf8\": \"notar \", \"tOffsetMs\": 1017, \"acAsrConf\": 0 }, { \"utf8\": \"são\", \"tOffsetMs\": 1356, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 282950, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 282960, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"aros \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 270, \"acAsrConf\": 0 }, { \"utf8\": \"hastes \", \"tOffsetMs\": 540, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 810, \"acAsrConf\": 0 }, { \"utf8\": \"grossas \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1350, \"acAsrConf\": 0 }, { \"utf8\": \"revelam \", \"tOffsetMs\": 1620, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1890, \"acAsrConf\": 0 }, { \"utf8\": \"tecnologia\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 285510, \"dDurationMs\": 1610, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 285520, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"interna.\", \"acAsrConf\": 0 } ] }, { \"tStartMs\": 287110, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 287120, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Sessões \", \"acAsrConf\": 0 }, { \"utf8\": \"curtas \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"causam \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"problemas \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"rosto,\", \"tOffsetMs\": 1758, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 289270, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 289280, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"embora \", \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 256, \"acAsrConf\": 0 }, { \"utf8\": \"note \", \"tOffsetMs\": 512, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"peso \", \"tOffsetMs\": 1024, \"acAsrConf\": 0 }, { \"utf8\": \"extra.\", \"tOffsetMs\": 1280, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 291110, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 291120, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"O \", \"acAsrConf\": 0 }, { \"utf8\": \"HUD \", \"tOffsetMs\": 303, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 606, \"acAsrConf\": 0 }, { \"utf8\": \"monocular \", \"tOffsetMs\": 909, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1212, \"acAsrConf\": 0 }, { \"utf8\": \"bastante\", \"tOffsetMs\": 1515, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 293030, \"dDurationMs\": 3050, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 293040, \"dDurationMs\": 5200, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"compacto. \", \"acAsrConf\": 0 }, { \"utf8\": \"Uma \", \"tOffsetMs\": 330, \"acAsrConf\": 0 }, { \"utf8\": \"janela \", \"tOffsetMs\": 660, \"acAsrConf\": 0 }, { \"utf8\": \"translúcida \", \"tOffsetMs\": 990, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"600 \", \"tOffsetMs\": 1650, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1980, \"acAsrConf\": 0 }, { \"utf8\": \"600 \", \"tOffsetMs\": 2310, \"acAsrConf\": 0 }, { \"utf8\": \"pixéis\", \"tOffsetMs\": 2640, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 296070, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 296080, \"dDurationMs\": 3920, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"no \", \"acAsrConf\": 0 }, { \"utf8\": \"seu \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"olho \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"direito, \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"pouco\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 298230, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 298240, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"abaixo \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 240, \"acAsrConf\": 0 }, { \"utf8\": \"à \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"direita \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"centro, \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"cobrindo\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 299990, \"dDurationMs\": 3370, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 300000, \"dDurationMs\": 6240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"aproximadamente \", \"acAsrConf\": 0 }, { \"utf8\": \"20° \", \"tOffsetMs\": 624, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1248, \"acAsrConf\": 0 }, { \"utf8\": \"visão. \", \"tOffsetMs\": 1872, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 2496, \"acAsrConf\": 0 }, { \"utf8\": \"software\", \"tOffsetMs\": 3120, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 303350, \"dDurationMs\": 2890, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 303360, \"dDurationMs\": 4559, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"parece \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 346, \"acAsrConf\": 0 }, { \"utf8\": \"smartwatch \", \"tOffsetMs\": 692, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1038, \"acAsrConf\": 0 }, { \"utf8\": \"flutuar \", \"tOffsetMs\": 1384, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1730, \"acAsrConf\": 0 }, { \"utf8\": \"espaço.\", \"tOffsetMs\": 2076, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 306230, \"dDurationMs\": 1689, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 306240, \"dDurationMs\": 3920, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Há \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 170, \"acAsrConf\": 0 }, { \"utf8\": \"ecrã \", \"tOffsetMs\": 340, \"acAsrConf\": 0 }, { \"utf8\": \"inicial \", \"tOffsetMs\": 510, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 680, \"acAsrConf\": 0 }, { \"utf8\": \"informações \", \"tOffsetMs\": 850, \"acAsrConf\": 0 }, { \"utf8\": \"básicas \", \"tOffsetMs\": 1020, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1190, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 307909, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 307919, \"dDurationMs\": 4321, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"hora, \", \"acAsrConf\": 0 }, { \"utf8\": \"notificações \", \"tOffsetMs\": 416, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 832, \"acAsrConf\": 0 }, { \"utf8\": \"acesso \", \"tOffsetMs\": 1248, \"acAsrConf\": 0 }, { \"utf8\": \"rápido \", \"tOffsetMs\": 1664, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 310150, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 310160, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"aplicações. \", \"acAsrConf\": 0 }, { \"utf8\": \"Dirige-se \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"tudo \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"isto \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 312230, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 312240, \"dDurationMs\": 4320, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"gestos \", \"acAsrConf\": 0 }, { \"utf8\": \"das \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"bandas \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"neurais. \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"Polegar \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"indicador,\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 314550, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 314560, \"dDurationMs\": 4479, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"pinça \", \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 230, \"acAsrConf\": 0 }, { \"utf8\": \"clicar. \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"Aperte \", \"tOffsetMs\": 690, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"rode \", \"tOffsetMs\": 1150, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"aumentar \", \"tOffsetMs\": 1610, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 316550, \"dDurationMs\": 2489, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 316560, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"volume \", \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 257, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 514, \"acAsrConf\": 0 }, { \"utf8\": \"zoom. \", \"tOffsetMs\": 771, \"acAsrConf\": 0 }, { \"utf8\": \"Deslize \", \"tOffsetMs\": 1028, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1285, \"acAsrConf\": 0 }, { \"utf8\": \"polegar \", \"tOffsetMs\": 1542, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 1799, \"acAsrConf\": 0 }, { \"utf8\": \"longo \", \"tOffsetMs\": 2056, \"acAsrConf\": 0 }, { \"utf8\": \"do\", \"tOffsetMs\": 2313, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 319029, \"dDurationMs\": 2571, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 319039, \"dDurationMs\": 4961, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"dedo \", \"acAsrConf\": 0 }, { \"utf8\": \"indicador \", \"tOffsetMs\": 257, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 514, \"acAsrConf\": 0 }, { \"utf8\": \"rolar. \", \"tOffsetMs\": 771, \"acAsrConf\": 0 }, { \"utf8\": \"E \", \"tOffsetMs\": 1028, \"acAsrConf\": 0 }, { \"utf8\": \"pressione \", \"tOffsetMs\": 1285, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1542, \"acAsrConf\": 0 }, { \"utf8\": \"polegar \", \"tOffsetMs\": 1799, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 2056, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 2313, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 321590, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 321600, \"dDurationMs\": 4319, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"dedo \", \"acAsrConf\": 0 }, { \"utf8\": \"médio \", \"tOffsetMs\": 359, \"acAsrConf\": 0 }, { \"utf8\": \"duas \", \"tOffsetMs\": 718, \"acAsrConf\": 0 }, { \"utf8\": \"vezes \", \"tOffsetMs\": 1077, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1436, \"acAsrConf\": 0 }, { \"utf8\": \"alternar \", \"tOffsetMs\": 1795, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 2154, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 323990, \"dDurationMs\": 1929, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 324000, \"dDurationMs\": 3440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"visualização. \", \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 262, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 524, \"acAsrConf\": 0 }, { \"utf8\": \"giro \", \"tOffsetMs\": 786, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 1048, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1310, \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 1572, \"acAsrConf\": 0 }, { \"utf8\": \"precisa\", \"tOffsetMs\": 1834, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 325909, \"dDurationMs\": 1531, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 325919, \"dDurationMs\": 3761, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"de \", \"acAsrConf\": 0 }, { \"utf8\": \"levantar \", \"tOffsetMs\": 226, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 452, \"acAsrConf\": 0 }, { \"utf8\": \"mão. \", \"tOffsetMs\": 678, \"acAsrConf\": 0 }, { \"utf8\": \"Pode \", \"tOffsetMs\": 904, \"acAsrConf\": 0 }, { \"utf8\": \"manter \", \"tOffsetMs\": 1130, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1356, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 327430, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 327440, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"braço \", \"acAsrConf\": 0 }, { \"utf8\": \"relaxado \", \"tOffsetMs\": 219, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 438, \"acAsrConf\": 0 }, { \"utf8\": \"lado \", \"tOffsetMs\": 657, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 876, \"acAsrConf\": 0 }, { \"utf8\": \"corpo \", \"tOffsetMs\": 1095, \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 1314, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1533, \"acAsrConf\": 0 }, { \"utf8\": \"bolso.\", \"tOffsetMs\": 1752, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 329670, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 329680, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"E \", \"acAsrConf\": 0 }, { \"utf8\": \"ainda \", \"tOffsetMs\": 220, \"acAsrConf\": 0 }, { \"utf8\": \"obtém \", \"tOffsetMs\": 440, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 660, \"acAsrConf\": 0 }, { \"utf8\": \"feedback \", \"tOffsetMs\": 880, \"acAsrConf\": 0 }, { \"utf8\": \"tátil \", \"tOffsetMs\": 1100, \"acAsrConf\": 0 }, { \"utf8\": \"nítido \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"quando \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1760, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 331830, \"dDurationMs\": 2890, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 331840, \"dDurationMs\": 5520, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"gesto \", \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 527, \"acAsrConf\": 0 }, { \"utf8\": \"executado. \", \"tOffsetMs\": 1054, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1581, \"acAsrConf\": 0 }, { \"utf8\": \"pulseira \", \"tOffsetMs\": 2108, \"acAsrConf\": 0 }, { \"utf8\": \"é\", \"tOffsetMs\": 2635, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 334710, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 334720, \"dDurationMs\": 4800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"a \", \"acAsrConf\": 0 }, { \"utf8\": \"estrela. \", \"tOffsetMs\": 386, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 772, \"acAsrConf\": 0 }, { \"utf8\": \"deteção \", \"tOffsetMs\": 1158, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1544, \"acAsrConf\": 0 }, { \"utf8\": \"gestos \", \"tOffsetMs\": 1930, \"acAsrConf\": 0 }, { \"utf8\": \"parece\", \"tOffsetMs\": 2316, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 337350, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 337360, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"sólida \", \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 174, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 348, \"acAsrConf\": 0 }, { \"utf8\": \"rocha, \", \"tOffsetMs\": 522, \"acAsrConf\": 0 }, { \"utf8\": \"enquanto \", \"tOffsetMs\": 696, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 870, \"acAsrConf\": 0 }, { \"utf8\": \"óculos \", \"tOffsetMs\": 1044, \"acAsrConf\": 0 }, { \"utf8\": \"são \", \"tOffsetMs\": 1218, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1566, \"acAsrConf\": 0 }, { \"utf8\": \"apresentam \", \"tOffsetMs\": 1740, \"acAsrConf\": 0 }, { \"utf8\": \"as\", \"tOffsetMs\": 1914, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 339510, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 339520, \"dDurationMs\": 4959, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"arestas \", \"acAsrConf\": 0 }, { \"utf8\": \"ásperas. \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"interface \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"pode \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"apresentar \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"lentidão,\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 341830, \"dDurationMs\": 2649, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 341840, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"até \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"demonstração \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"próprio \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"Meta \", \"tOffsetMs\": 1596, \"acAsrConf\": 0 }, { \"utf8\": \"apresentou \", \"tOffsetMs\": 1862, \"acAsrConf\": 0 }, { \"utf8\": \"momentos \", \"tOffsetMs\": 2128, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 2394, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 344469, \"dDurationMs\": 1931, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 344479, \"dDurationMs\": 5601, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"bloqueio. \", \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"Meta \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"confirmou \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"estes \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"óculos\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 346390, \"dDurationMs\": 3690, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 346400, \"dDurationMs\": 6079, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utilizam \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 311, \"acAsrConf\": 0 }, { \"utf8\": \"chip \", \"tOffsetMs\": 622, \"acAsrConf\": 0 }, { \"utf8\": \"Snapdragon \", \"tOffsetMs\": 933, \"acAsrConf\": 0 }, { \"utf8\": \"AR1 \", \"tOffsetMs\": 1244, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1555, \"acAsrConf\": 0 }, { \"utf8\": \"primeira \", \"tOffsetMs\": 1866, \"acAsrConf\": 0 }, { \"utf8\": \"geração \", \"tOffsetMs\": 2177, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 2488, \"acAsrConf\": 0 }, { \"utf8\": \"Qualcomm\", \"tOffsetMs\": 2799, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 350070, \"dDurationMs\": 2409, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 350080, \"dDurationMs\": 5679, \"wWinId\": 1, \"segs\": [ { \"utf8\": \", \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 419, \"acAsrConf\": 0 }, { \"utf8\": \"mesma \", \"tOffsetMs\": 838, \"acAsrConf\": 0 }, { \"utf8\": \"família \", \"tOffsetMs\": 1257, \"acAsrConf\": 0 }, { \"utf8\": \"dos\", \"tOffsetMs\": 1676, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 352469, \"dDurationMs\": 3290, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 352479, \"dDurationMs\": 5280, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 269, \"acAsrConf\": 0 }, { \"utf8\": \"2023, \", \"tOffsetMs\": 538, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 807, \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 1076, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1345, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 1614, \"acAsrConf\": 0 }, { \"utf8\": \"recente \", \"tOffsetMs\": 1883, \"acAsrConf\": 0 }, { \"utf8\": \"AR1 \", \"tOffsetMs\": 2152, \"acAsrConf\": 0 }, { \"utf8\": \"Plus, \", \"tOffsetMs\": 2421, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 2690, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 2959, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 355749, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 355759, \"dDurationMs\": 3841, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"explica \", \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 560, \"acAsrConf\": 0 }, { \"utf8\": \"lentidões. \", \"tOffsetMs\": 1120, \"acAsrConf\": 0 }, { \"utf8\": \"Uma\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 357749, \"dDurationMs\": 1851, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 357759, \"dDurationMs\": 4321, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"atualização \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 190, \"acAsrConf\": 0 }, { \"utf8\": \"firmware \", \"tOffsetMs\": 380, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"dezembro \", \"tOffsetMs\": 760, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 950, \"acAsrConf\": 0 }, { \"utf8\": \"programada \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"adicionar\", \"tOffsetMs\": 1520, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 359590, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 359600, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"entrada \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"texto \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"toque, \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"literalmente\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 362070, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 362080, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"desenhando \", \"acAsrConf\": 0 }, { \"utf8\": \"letras \", \"tOffsetMs\": 204, \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 408, \"acAsrConf\": 0 }, { \"utf8\": \"sua \", \"tOffsetMs\": 612, \"acAsrConf\": 0 }, { \"utf8\": \"perna, \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1020, \"acAsrConf\": 0 }, { \"utf8\": \"que, \", \"tOffsetMs\": 1224, \"acAsrConf\": 0 }, { \"utf8\": \"segundo \", \"tOffsetMs\": 1428, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1632, \"acAsrConf\": 0 }, { \"utf8\": \"primeiros\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 364230, \"dDurationMs\": 2890, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 364240, \"dDurationMs\": 5440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"testes \", \"acAsrConf\": 0 }, { \"utf8\": \"práticos, \", \"tOffsetMs\": 440, \"acAsrConf\": 0 }, { \"utf8\": \"funciona \", \"tOffsetMs\": 880, \"acAsrConf\": 0 }, { \"utf8\": \"surpreendentemente \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"bem.\", \"tOffsetMs\": 1760, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 367110, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 367120, \"dDurationMs\": 4799, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Uma \", \"acAsrConf\": 0 }, { \"utf8\": \"grande \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"ressalva \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"permanece. \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"HUD \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"monoculares\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 369670, \"dDurationMs\": 2249, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 369680, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"podem \", \"acAsrConf\": 0 }, { \"utf8\": \"causar \", \"tOffsetMs\": 262, \"acAsrConf\": 0 }, { \"utf8\": \"cansaço \", \"tOffsetMs\": 524, \"acAsrConf\": 0 }, { \"utf8\": \"visual \", \"tOffsetMs\": 786, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1048, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1310, \"acAsrConf\": 0 }, { \"utf8\": \"uso \", \"tOffsetMs\": 1572, \"acAsrConf\": 0 }, { \"utf8\": \"prolongado\", \"tOffsetMs\": 1834, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 371909, \"dDurationMs\": 2891, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 371919, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"porque \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 388, \"acAsrConf\": 0 }, { \"utf8\": \"olho \", \"tOffsetMs\": 776, \"acAsrConf\": 0 }, { \"utf8\": \"vê \", \"tOffsetMs\": 1164, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1552, \"acAsrConf\": 0 }, { \"utf8\": \"sobreposição \", \"tOffsetMs\": 1940, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 2328, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 2716, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 374790, \"dDurationMs\": 1610, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 374800, \"dDurationMs\": 3440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"outro \", \"acAsrConf\": 0 }, { \"utf8\": \"não. \", \"tOffsetMs\": 130, \"acAsrConf\": 0 }, { \"utf8\": \"São \", \"tOffsetMs\": 260, \"acAsrConf\": 0 }, { \"utf8\": \"ótimos \", \"tOffsetMs\": 390, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 520, \"acAsrConf\": 0 }, { \"utf8\": \"dar \", \"tOffsetMs\": 650, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 780, \"acAsrConf\": 0 }, { \"utf8\": \"vista \", \"tOffsetMs\": 910, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1040, \"acAsrConf\": 0 }, { \"utf8\": \"olhos \", \"tOffsetMs\": 1170, \"acAsrConf\": 0 }, { \"utf8\": \"rápida \", \"tOffsetMs\": 1300, \"acAsrConf\": 0 }, { \"utf8\": \"às\", \"tOffsetMs\": 1430, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 376390, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 376400, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"notificações \", \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"mapa.\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 378230, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 378240, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Para \", \"acAsrConf\": 0 }, { \"utf8\": \"ver \", \"tOffsetMs\": 250, \"acAsrConf\": 0 }, { \"utf8\": \"vídeos \", \"tOffsetMs\": 500, \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 750, \"acAsrConf\": 0 }, { \"utf8\": \"chamadas \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"longas, \", \"tOffsetMs\": 1250, \"acAsrConf\": 0 }, { \"utf8\": \"nem \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1750, \"acAsrConf\": 0 }, { \"utf8\": \"isso\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 380390, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 380400, \"dDurationMs\": 4639, \"wWinId\": 1, \"segs\": [ { \"utf8\": \". \", \"acAsrConf\": 0 }, { \"utf8\": \"Uma \", \"tOffsetMs\": 500, \"acAsrConf\": 0 }, { \"utf8\": \"versão \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"binocular \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"com\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 382710, \"dDurationMs\": 2329, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 382720, \"dDurationMs\": 4800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"rastreio \", \"acAsrConf\": 0 }, { \"utf8\": \"ocular \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"seria \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"pesada \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"cara.\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 385029, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 385039, \"dDurationMs\": 5201, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Pense \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 290, \"acAsrConf\": 0 }, { \"utf8\": \"algo \", \"tOffsetMs\": 580, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 870, \"acAsrConf\": 0 }, { \"utf8\": \"85 \", \"tOffsetMs\": 1160, \"acAsrConf\": 0 }, { \"utf8\": \"g \", \"tOffsetMs\": 1450, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1740, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 2030, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 2320, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 387510, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 387520, \"dDurationMs\": 4880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"1.200 \", \"acAsrConf\": 0 }, { \"utf8\": \"dólares \", \"tOffsetMs\": 290, \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 580, \"acAsrConf\": 0 }, { \"utf8\": \"fosse \", \"tOffsetMs\": 870, \"acAsrConf\": 0 }, { \"utf8\": \"fabricado \", \"tOffsetMs\": 1160, \"acAsrConf\": 0 }, { \"utf8\": \"hoje. \", \"tOffsetMs\": 1450, \"acAsrConf\": 0 }, { \"utf8\": \"Mas \", \"tOffsetMs\": 1740, \"acAsrConf\": 0 }, { \"utf8\": \"esta \", \"tOffsetMs\": 2030, \"acAsrConf\": 0 }, { \"utf8\": \"combinação\", \"tOffsetMs\": 2320, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 390230, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 390240, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"desbloquearia \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"seleção \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"aparência \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"pinça\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 392390, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 392400, \"dDurationMs\": 4320, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"eliminaria \", \"tOffsetMs\": 174, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 348, \"acAsrConf\": 0 }, { \"utf8\": \"maior \", \"tOffsetMs\": 522, \"acAsrConf\": 0 }, { \"utf8\": \"parte \", \"tOffsetMs\": 696, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 870, \"acAsrConf\": 0 }, { \"utf8\": \"fricção \", \"tOffsetMs\": 1044, \"acAsrConf\": 0 }, { \"utf8\": \"atual \", \"tOffsetMs\": 1218, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"interface \", \"tOffsetMs\": 1566, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1740, \"acAsrConf\": 0 }, { \"utf8\": \"utilizador.\", \"tOffsetMs\": 1914, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 394790, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 394800, \"dDurationMs\": 4080, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Combine \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 200, \"acAsrConf\": 0 }, { \"utf8\": \"banda \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"neural \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"chip \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 1400, \"acAsrConf\": 0 }, { \"utf8\": \"rápido,\", \"tOffsetMs\": 1600, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 396710, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 396720, \"dDurationMs\": 5280, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ótica \", \"acAsrConf\": 0 }, { \"utf8\": \"binocular \", \"tOffsetMs\": 368, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 736, \"acAsrConf\": 0 }, { \"utf8\": \"rastreamento \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"ocular, \", \"tOffsetMs\": 1472, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 398870, \"dDurationMs\": 3130, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 398880, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"esta \", \"acAsrConf\": 0 }, { \"utf8\": \"linha \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"deixa \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"ser \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"interessante \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1758, \"acAsrConf\": 0 }, { \"utf8\": \"passa \", \"tOffsetMs\": 2051, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 2344, \"acAsrConf\": 0 }, { \"utf8\": \"ser\", \"tOffsetMs\": 2637, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 401990, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 402000, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"rápida \", \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 159, \"acAsrConf\": 0 }, { \"utf8\": \"uso \", \"tOffsetMs\": 318, \"acAsrConf\": 0 }, { \"utf8\": \"diário.\", \"tOffsetMs\": 477, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 403990, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 404000, \"dDurationMs\": 4479, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Do \", \"acAsrConf\": 0 }, { \"utf8\": \"lado \", \"tOffsetMs\": 297, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 594, \"acAsrConf\": 0 }, { \"utf8\": \"plataforma, \", \"tOffsetMs\": 891, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1188, \"acAsrConf\": 0 }, { \"utf8\": \"anúncios \", \"tOffsetMs\": 1485, \"acAsrConf\": 0 }, { \"utf8\": \"feitos \", \"tOffsetMs\": 1782, \"acAsrConf\": 0 }, { \"utf8\": \"no\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 406390, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 406400, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"YouTube, \", \"acAsrConf\": 0 }, { \"utf8\": \"criadores \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"sobrecarregados\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 408469, \"dDurationMs\": 2891, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 408479, \"dDurationMs\": 4961, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"atualizações \", \"tOffsetMs\": 340, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 680, \"acAsrConf\": 0 }, { \"utf8\": \"fluxos \", \"tOffsetMs\": 1020, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1360, \"acAsrConf\": 0 }, { \"utf8\": \"trabalho, \", \"tOffsetMs\": 1700, \"acAsrConf\": 0 }, { \"utf8\": \"estúdios \", \"tOffsetMs\": 2040, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 2380, \"acAsrConf\": 0 }, { \"utf8\": \"receber\", \"tOffsetMs\": 2720, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 411350, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 411360, \"dDurationMs\": 5839, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"um \", \"acAsrConf\": 0 }, { \"utf8\": \"separador \", \"tOffsetMs\": 335, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 670, \"acAsrConf\": 0 }, { \"utf8\": \"inspiração \", \"tOffsetMs\": 1005, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1340, \"acAsrConf\": 0 }, { \"utf8\": \"gerar\", \"tOffsetMs\": 1675, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 413430, \"dDurationMs\": 3769, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 413440, \"dDurationMs\": 5599, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ideias \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 399, \"acAsrConf\": 0 }, { \"utf8\": \"conteúdo, \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"testes \", \"tOffsetMs\": 1197, \"acAsrConf\": 0 }, { \"utf8\": \"A/B \", \"tOffsetMs\": 1596, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1995, \"acAsrConf\": 0 }, { \"utf8\": \"títulos \", \"tOffsetMs\": 2394, \"acAsrConf\": 0 }, { \"utf8\": \"integrados \", \"tOffsetMs\": 2793, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 3192, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 3591, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 417189, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 417199, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"possa \", \"acAsrConf\": 0 }, { \"utf8\": \"validar \", \"tOffsetMs\": 226, \"acAsrConf\": 0 }, { \"utf8\": \"manchetes \", \"tOffsetMs\": 452, \"acAsrConf\": 0 }, { \"utf8\": \"sem \", \"tOffsetMs\": 678, \"acAsrConf\": 0 }, { \"utf8\": \"fazer \", \"tOffsetMs\": 904, \"acAsrConf\": 0 }, { \"utf8\": \"malabarismos \", \"tOffsetMs\": 1130, \"acAsrConf\": 0 }, { \"utf8\": \"com\", \"tOffsetMs\": 1356, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 419029, \"dDurationMs\": 2651, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 419039, \"dDurationMs\": 5921, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"experiências \", \"acAsrConf\": 0 }, { \"utf8\": \"manuais \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"dobragem \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"automática \", \"tOffsetMs\": 1920, \"acAsrConf\": 0 }, { \"utf8\": \"com\", \"tOffsetMs\": 2400, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 421670, \"dDurationMs\": 3290, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 421680, \"dDurationMs\": 5359, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"dobragens \", \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 302, \"acAsrConf\": 0 }, { \"utf8\": \"sincronização \", \"tOffsetMs\": 604, \"acAsrConf\": 0 }, { \"utf8\": \"labial. \", \"tOffsetMs\": 906, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1208, \"acAsrConf\": 0 }, { \"utf8\": \"funcionalidade \", \"tOffsetMs\": 1510, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1812, \"acAsrConf\": 0 }, { \"utf8\": \"deteção \", \"tOffsetMs\": 2114, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 2416, \"acAsrConf\": 0 }, { \"utf8\": \"semelhança\", \"tOffsetMs\": 2718, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 424950, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 424960, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"entrou \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 368, \"acAsrConf\": 0 }, { \"utf8\": \"beta \", \"tOffsetMs\": 736, \"acAsrConf\": 0 }, { \"utf8\": \"aberta \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"após \", \"tOffsetMs\": 1472, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 427029, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 427039, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"lançamento \", \"acAsrConf\": 0 }, { \"utf8\": \"limitado \", \"tOffsetMs\": 448, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 896, \"acAsrConf\": 0 }, { \"utf8\": \"ano \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"passado. \", \"tOffsetMs\": 1792, \"acAsrConf\": 0 }, { \"utf8\": \"Verifica\", \"tOffsetMs\": 2240, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 429510, \"dDurationMs\": 2249, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 429520, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"vídeos \", \"acAsrConf\": 0 }, { \"utf8\": \"utilizando \", \"tOffsetMs\": 297, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 594, \"acAsrConf\": 0 }, { \"utf8\": \"sua \", \"tOffsetMs\": 891, \"acAsrConf\": 0 }, { \"utf8\": \"semelhança \", \"tOffsetMs\": 1188, \"acAsrConf\": 0 }, { \"utf8\": \"facial \", \"tOffsetMs\": 1485, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1782, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 2079, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 431749, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 431759, \"dDurationMs\": 5201, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"possa \", \"acAsrConf\": 0 }, { \"utf8\": \"detetar, \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"gerir \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"sinalizar \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"remoção\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 434230, \"dDurationMs\": 2730, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 434240, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"utilizações \", \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 559, \"acAsrConf\": 0 }, { \"utf8\": \"autorizadas. \", \"tOffsetMs\": 1118, \"acAsrConf\": 0 }, { \"utf8\": \"Existe \", \"tOffsetMs\": 1677, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 2236, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 436950, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 436960, \"dDurationMs\": 3920, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"estúdio \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 160, \"acAsrConf\": 0 }, { \"utf8\": \"perguntas \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"tecnologia \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1120, \"acAsrConf\": 0 }, { \"utf8\": \"responde \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"às\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 438790, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 438800, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"perguntas \", \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 200, \"acAsrConf\": 0 }, { \"utf8\": \"canal \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"dentro \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"estúdio.  \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"A\", \"tOffsetMs\": 1200, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 440870, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 440880, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"colaboração \", \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 539, \"acAsrConf\": 0 }, { \"utf8\": \"aumenta. \", \"tOffsetMs\": 1078, \"acAsrConf\": 0 }, { \"utf8\": \"Até \", \"tOffsetMs\": 1617, \"acAsrConf\": 0 }, { \"utf8\": \"cinco\", \"tOffsetMs\": 2156, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 443350, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 443360, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"criadores \", \"acAsrConf\": 0 }, { \"utf8\": \"podem \", \"tOffsetMs\": 419, \"acAsrConf\": 0 }, { \"utf8\": \"colaborar \", \"tOffsetMs\": 838, \"acAsrConf\": 0 }, { \"utf8\": \"num \", \"tOffsetMs\": 1257, \"acAsrConf\": 0 }, { \"utf8\": \"vídeo\", \"tOffsetMs\": 1676, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 445510, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 445520, \"dDurationMs\": 3679, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"publicá-lo \", \"tOffsetMs\": 151, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 302, \"acAsrConf\": 0 }, { \"utf8\": \"todos \", \"tOffsetMs\": 453, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 604, \"acAsrConf\": 0 }, { \"utf8\": \"seus \", \"tOffsetMs\": 755, \"acAsrConf\": 0 }, { \"utf8\": \"públicos \", \"tOffsetMs\": 906, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1057, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1208, \"acAsrConf\": 0 }, { \"utf8\": \"só \", \"tOffsetMs\": 1359, \"acAsrConf\": 0 }, { \"utf8\": \"vez,\", \"tOffsetMs\": 1510, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 447510, \"dDurationMs\": 1689, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 447520, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"o \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 194, \"acAsrConf\": 0 }, { \"utf8\": \"torna \", \"tOffsetMs\": 388, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 582, \"acAsrConf\": 0 }, { \"utf8\": \"distribuição \", \"tOffsetMs\": 776, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 970, \"acAsrConf\": 0 }, { \"utf8\": \"vários \", \"tOffsetMs\": 1164, \"acAsrConf\": 0 }, { \"utf8\": \"canais\", \"tOffsetMs\": 1358, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 449189, \"dDurationMs\": 2811, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 449199, \"dDurationMs\": 4881, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"muito \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 413, \"acAsrConf\": 0 }, { \"utf8\": \"fácil. \", \"tOffsetMs\": 826, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 1239, \"acAsrConf\": 0 }, { \"utf8\": \"YouTube \", \"tOffsetMs\": 1652, \"acAsrConf\": 0 }, { \"utf8\": \"Live \", \"tOffsetMs\": 2065, \"acAsrConf\": 0 }, { \"utf8\": \"torna-se\", \"tOffsetMs\": 2478, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 451990, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 452000, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"mais \", \"acAsrConf\": 0 }, { \"utf8\": \"dinâmico. \", \"tOffsetMs\": 351, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 702, \"acAsrConf\": 0 }, { \"utf8\": \"criadores \", \"tOffsetMs\": 1053, \"acAsrConf\": 0 }, { \"utf8\": \"podem \", \"tOffsetMs\": 1404, \"acAsrConf\": 0 }, { \"utf8\": \"realizar\", \"tOffsetMs\": 1755, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 454070, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 454080, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"minijogos \", \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 205, \"acAsrConf\": 0 }, { \"utf8\": \"manter \", \"tOffsetMs\": 410, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 615, \"acAsrConf\": 0 }, { \"utf8\": \"espectadores \", \"tOffsetMs\": 820, \"acAsrConf\": 0 }, { \"utf8\": \"envolvidos \", \"tOffsetMs\": 1025, \"acAsrConf\": 0 }, { \"utf8\": \"durante \", \"tOffsetMs\": 1230, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 1435, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 455990, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 456000, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"momentos \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"lentos. \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"Transmita \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"simultaneamente\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 458230, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 458240, \"dDurationMs\": 4239, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"nos \", \"acAsrConf\": 0 }, { \"utf8\": \"formatos \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"horizontal \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"vertical \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 459990, \"dDurationMs\": 2489, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 460000, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"a \", \"acAsrConf\": 0 }, { \"utf8\": \"transmissão \", \"tOffsetMs\": 191, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 382, \"acAsrConf\": 0 }, { \"utf8\": \"direto \", \"tOffsetMs\": 573, \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 764, \"acAsrConf\": 0 }, { \"utf8\": \"adapte \", \"tOffsetMs\": 955, \"acAsrConf\": 0 }, { \"utf8\": \"nativamente \", \"tOffsetMs\": 1146, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1337, \"acAsrConf\": 0 }, { \"utf8\": \"telemóveis \", \"tOffsetMs\": 1528, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1719, \"acAsrConf\": 0 }, { \"utf8\": \"desktops\", \"tOffsetMs\": 1910, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 462469, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 462479, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"e \", \"acAsrConf\": 0 }, { \"utf8\": \"conte \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"destaques \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"alimentados \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"IA\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 464950, \"dDurationMs\": 1529, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 464960, \"dDurationMs\": 3440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"que \", \"acAsrConf\": 0 }, { \"utf8\": \"selecionam \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"automaticamente\", \"tOffsetMs\": 1200, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 466469, \"dDurationMs\": 1931, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 466479, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"momentos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 220, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 440, \"acAsrConf\": 0 }, { \"utf8\": \"transmissão \", \"tOffsetMs\": 660, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 880, \"acAsrConf\": 0 }, { \"utf8\": \"direto \", \"tOffsetMs\": 1100, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"cortam\", \"tOffsetMs\": 1760, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 468390, \"dDurationMs\": 3209, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 468400, \"dDurationMs\": 6000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"em \", \"acAsrConf\": 0 }, { \"utf8\": \"curtas-metragens \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"partilháveis. \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 1518, \"acAsrConf\": 0 }, { \"utf8\": \"anúncios \", \"tOffsetMs\": 2024, \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 2530, \"acAsrConf\": 0 }, { \"utf8\": \"evoluem\", \"tOffsetMs\": 3036, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 471589, \"dDurationMs\": 2811, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 471599, \"dDurationMs\": 4561, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 310, \"acAsrConf\": 0 }, { \"utf8\": \"novo \", \"tOffsetMs\": 620, \"acAsrConf\": 0 }, { \"utf8\": \"formato \", \"tOffsetMs\": 930, \"acAsrConf\": 0 }, { \"utf8\": \"lado \", \"tOffsetMs\": 1240, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1550, \"acAsrConf\": 0 }, { \"utf8\": \"lado \", \"tOffsetMs\": 1860, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 2170, \"acAsrConf\": 0 }, { \"utf8\": \"fica\", \"tOffsetMs\": 2480, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 474390, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 474400, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ao \", \"acAsrConf\": 0 }, { \"utf8\": \"lado \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"conteúdo \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"vez \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 476150, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 476160, \"dDurationMs\": 5520, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"o \", \"acAsrConf\": 0 }, { \"utf8\": \"interromper. \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"Basicamente \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"um\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 478550, \"dDurationMs\": 3130, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 478560, \"dDurationMs\": 5759, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"painel \", \"acAsrConf\": 0 }, { \"utf8\": \"complementar \", \"tOffsetMs\": 300, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"ecrã \", \"tOffsetMs\": 900, \"acAsrConf\": 0 }, { \"utf8\": \"dividido. \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"criadores \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 2100, \"acAsrConf\": 0 }, { \"utf8\": \"curtas-metragens\", \"tOffsetMs\": 2400, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 481670, \"dDurationMs\": 2649, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 481680, \"dDurationMs\": 6239, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"obtêm \", \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 308, \"acAsrConf\": 0 }, { \"utf8\": \"modelos \", \"tOffsetMs\": 616, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 924, \"acAsrConf\": 0 }, { \"utf8\": \"vídeo \", \"tOffsetMs\": 1232, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1540, \"acAsrConf\": 0 }, { \"utf8\": \"Google \", \"tOffsetMs\": 1848, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 2156, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 484309, \"dDurationMs\": 3610, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 484319, \"dDurationMs\": 5761, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"forma \", \"acAsrConf\": 0 }, { \"utf8\": \"direcionada. \", \"tOffsetMs\": 360, \"acAsrConf\": 0 }, { \"utf8\": \"Uma \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"versão \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"personalizada \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"V3, \", \"tOffsetMs\": 2160, \"acAsrConf\": 0 }, { \"utf8\": \"denominada \", \"tOffsetMs\": 2520, \"acAsrConf\": 0 }, { \"utf8\": \"V3\", \"tOffsetMs\": 2880, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 487909, \"dDurationMs\": 2171, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 487919, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Fast, \", \"acAsrConf\": 0 }, { \"utf8\": \"chega \", \"tOffsetMs\": 368, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 736, \"acAsrConf\": 0 }, { \"utf8\": \"Shorts \", \"tOffsetMs\": 1104, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1472, \"acAsrConf\": 0 }, { \"utf8\": \"aplicar\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 490070, \"dDurationMs\": 2809, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 490080, \"dDurationMs\": 4959, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"movimento \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 319, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 638, \"acAsrConf\": 0 }, { \"utf8\": \"vídeo \", \"tOffsetMs\": 957, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1276, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1595, \"acAsrConf\": 0 }, { \"utf8\": \"imagem, \", \"tOffsetMs\": 1914, \"acAsrConf\": 0 }, { \"utf8\": \"remodelar\", \"tOffsetMs\": 2233, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 492869, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 492879, \"dDurationMs\": 4641, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"filmagens \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"inserir \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"objetos \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"utilizando\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 495029, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 495039, \"dDurationMs\": 5121, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"prompts \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 257, \"acAsrConf\": 0 }, { \"utf8\": \"texto. \", \"tOffsetMs\": 514, \"acAsrConf\": 0 }, { \"utf8\": \"Há \", \"tOffsetMs\": 771, \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 1028, \"acAsrConf\": 0 }, { \"utf8\": \"edição \", \"tOffsetMs\": 1285, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1542, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 1799, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 2056, \"acAsrConf\": 0 }, { \"utf8\": \"uma\", \"tOffsetMs\": 2313, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 497510, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 497520, \"dDurationMs\": 4480, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"nova \", \"acAsrConf\": 0 }, { \"utf8\": \"ferramenta \", \"tOffsetMs\": 386, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 772, \"acAsrConf\": 0 }, { \"utf8\": \"remistura. \", \"tOffsetMs\": 1158, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1544, \"acAsrConf\": 0 }, { \"utf8\": \"criação \", \"tOffsetMs\": 1930, \"acAsrConf\": 0 }, { \"utf8\": \"musical\", \"tOffsetMs\": 2316, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 500150, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 500160, \"dDurationMs\": 3680, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"também \", \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 266, \"acAsrConf\": 0 }, { \"utf8\": \"aplica. \", \"tOffsetMs\": 532, \"acAsrConf\": 0 }, { \"utf8\": \"Pode \", \"tOffsetMs\": 798, \"acAsrConf\": 0 }, { \"utf8\": \"transformar \", \"tOffsetMs\": 1064, \"acAsrConf\": 0 }, { \"utf8\": \"diálogos \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"de\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 501990, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 502000, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"vídeos \", \"acAsrConf\": 0 }, { \"utf8\": \"qualificados \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"bandas \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"sonoras \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"utilizando \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 503830, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 503840, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelo \", \"acAsrConf\": 0 }, { \"utf8\": \"musical \", \"tOffsetMs\": 262, \"acAsrConf\": 0 }, { \"utf8\": \"LIA \", \"tOffsetMs\": 524, \"acAsrConf\": 0 }, { \"utf8\": \"2 \", \"tOffsetMs\": 786, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1048, \"acAsrConf\": 0 }, { \"utf8\": \"Google. \", \"tOffsetMs\": 1310, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 1572, \"acAsrConf\": 0 }, { \"utf8\": \"YouTube\", \"tOffsetMs\": 1834, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 506150, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 506160, \"dDurationMs\": 3680, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Music \", \"acAsrConf\": 0 }, { \"utf8\": \"adiciona \", \"tOffsetMs\": 228, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 456, \"acAsrConf\": 0 }, { \"utf8\": \"cronómetro \", \"tOffsetMs\": 684, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 912, \"acAsrConf\": 0 }, { \"utf8\": \"contagem \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"decrescente \", \"tOffsetMs\": 1368, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 507990, \"dDurationMs\": 1850, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 508000, \"dDurationMs\": 4959, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"os \", \"acAsrConf\": 0 }, { \"utf8\": \"próximos \", \"tOffsetMs\": 319, \"acAsrConf\": 0 }, { \"utf8\": \"lançamentos \", \"tOffsetMs\": 638, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 957, \"acAsrConf\": 0 }, { \"utf8\": \"ferramentas \", \"tOffsetMs\": 1276, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 1595, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 509830, \"dDurationMs\": 3129, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 509840, \"dDurationMs\": 5360, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"vídeos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 239, \"acAsrConf\": 0 }, { \"utf8\": \"agradecimento \", \"tOffsetMs\": 478, \"acAsrConf\": 0 }, { \"utf8\": \"aos \", \"tOffsetMs\": 717, \"acAsrConf\": 0 }, { \"utf8\": \"fãs. \", \"tOffsetMs\": 956, \"acAsrConf\": 0 }, { \"utf8\": \"Além \", \"tOffsetMs\": 1195, \"acAsrConf\": 0 }, { \"utf8\": \"disso, \", \"tOffsetMs\": 1434, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1673, \"acAsrConf\": 0 }, { \"utf8\": \"piloto \", \"tOffsetMs\": 1912, \"acAsrConf\": 0 }, { \"utf8\": \"nos \", \"tOffsetMs\": 2151, \"acAsrConf\": 0 }, { \"utf8\": \"EUA \", \"tOffsetMs\": 2390, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 2629, \"acAsrConf\": 0 }, { \"utf8\": \"lançamentos\", \"tOffsetMs\": 2868, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 512949, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 512959, \"dDurationMs\": 5361, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"exclusivos \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"produtos \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"ligados \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"às\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 515190, \"dDurationMs\": 3130, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 515200, \"dDurationMs\": 4880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"páginas \", \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 254, \"acAsrConf\": 0 }, { \"utf8\": \"artistas. \", \"tOffsetMs\": 508, \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 762, \"acAsrConf\": 0 }, { \"utf8\": \"podcasters \", \"tOffsetMs\": 1016, \"acAsrConf\": 0 }, { \"utf8\": \"veem \", \"tOffsetMs\": 1270, \"acAsrConf\": 0 }, { \"utf8\": \"sugestões \", \"tOffsetMs\": 1524, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1778, \"acAsrConf\": 0 }, { \"utf8\": \"clipes \", \"tOffsetMs\": 2032, \"acAsrConf\": 0 }, { \"utf8\": \"assistidos \", \"tOffsetMs\": 2286, \"acAsrConf\": 0 }, { \"utf8\": \"por \", \"tOffsetMs\": 2540, \"acAsrConf\": 0 }, { \"utf8\": \"IA\", \"tOffsetMs\": 2794, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 518310, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 518320, \"dDurationMs\": 3839, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"acelerar \", \"tOffsetMs\": 303, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 606, \"acAsrConf\": 0 }, { \"utf8\": \"descoberta \", \"tOffsetMs\": 909, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1212, \"acAsrConf\": 0 }, { \"utf8\": \"curtas-metragens\", \"tOffsetMs\": 1515, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 520070, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 520080, \"dDurationMs\": 4879, \"wWinId\": 1, \"segs\": [ { \"utf8\": \". \", \"acAsrConf\": 0 }, { \"utf8\": \"E \", \"tOffsetMs\": 306, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 612, \"acAsrConf\": 0 }, { \"utf8\": \"funcionalidade \", \"tOffsetMs\": 918, \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 1224, \"acAsrConf\": 0 }, { \"utf8\": \"próximo \", \"tOffsetMs\": 1530, \"acAsrConf\": 0 }, { \"utf8\": \"ano\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 522149, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 522159, \"dDurationMs\": 4961, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"converterá \", \"acAsrConf\": 0 }, { \"utf8\": \"podcasts \", \"tOffsetMs\": 464, \"acAsrConf\": 0 }, { \"utf8\": \"apenas \", \"tOffsetMs\": 928, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"áudio \", \"tOffsetMs\": 1856, \"acAsrConf\": 0 }, { \"utf8\": \"em\", \"tOffsetMs\": 2320, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 524949, \"dDurationMs\": 2171, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 524959, \"dDurationMs\": 3921, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"podcasts \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"vídeo \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"automaticamente, \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"elimina\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 527110, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 527120, \"dDurationMs\": 3360, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"muita \", \"acAsrConf\": 0 }, { \"utf8\": \"fricção \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"canais \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"querem\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 528870, \"dDurationMs\": 1610, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 528880, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"presença \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 213, \"acAsrConf\": 0 }, { \"utf8\": \"ambos \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 639, \"acAsrConf\": 0 }, { \"utf8\": \"lados. \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"Para \", \"tOffsetMs\": 1065, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1278, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 530470, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 530480, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"monetização, \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"YouTube \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"estreitar \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 532630, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 532640, \"dDurationMs\": 4639, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ciclo \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 251, \"acAsrConf\": 0 }, { \"utf8\": \"compras. \", \"tOffsetMs\": 502, \"acAsrConf\": 0 }, { \"utf8\": \"carimbos \", \"tOffsetMs\": 753, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1004, \"acAsrConf\": 0 }, { \"utf8\": \"data/hora \", \"tOffsetMs\": 1255, \"acAsrConf\": 0 }, { \"utf8\": \"automáticos \", \"tOffsetMs\": 1506, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 1757, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 534630, \"dDurationMs\": 2649, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 534640, \"dDurationMs\": 4960, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"etiquetas \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"produtos, \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"marcação \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"automática \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"artigos \", \"tOffsetMs\": 1920, \"acAsrConf\": 0 }, { \"utf8\": \"qualificados\", \"tOffsetMs\": 2240, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 537269, \"dDurationMs\": 2331, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 537279, \"dDurationMs\": 5281, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"mencionados \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 222, \"acAsrConf\": 0 }, { \"utf8\": \"vídeos \", \"tOffsetMs\": 444, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 888, \"acAsrConf\": 0 }, { \"utf8\": \"funcionalidade \", \"tOffsetMs\": 1110, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"ligação \", \"tOffsetMs\": 1554, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1776, \"acAsrConf\": 0 }, { \"utf8\": \"marca\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 539590, \"dDurationMs\": 2970, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 539600, \"dDurationMs\": 4799, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"em \", \"acAsrConf\": 0 }, { \"utf8\": \"calções. \", \"tOffsetMs\": 388, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 776, \"acAsrConf\": 0 }, { \"utf8\": \"sistema \", \"tOffsetMs\": 1164, \"acAsrConf\": 0 }, { \"utf8\": \"utiliza \", \"tOffsetMs\": 1552, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1940, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 2328, \"acAsrConf\": 0 }, { \"utf8\": \"para\", \"tOffsetMs\": 2716, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 542550, \"dDurationMs\": 1849, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 542560, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"detetar \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 210, \"acAsrConf\": 0 }, { \"utf8\": \"momento \", \"tOffsetMs\": 420, \"acAsrConf\": 0 }, { \"utf8\": \"ideal \", \"tOffsetMs\": 630, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 840, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1050, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 1260, \"acAsrConf\": 0 }, { \"utf8\": \"produto \", \"tOffsetMs\": 1470, \"acAsrConf\": 0 }, { \"utf8\": \"é\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 544389, \"dDurationMs\": 2171, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 544399, \"dDurationMs\": 4401, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"mencionado \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 228, \"acAsrConf\": 0 }, { \"utf8\": \"coloca \", \"tOffsetMs\": 456, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 684, \"acAsrConf\": 0 }, { \"utf8\": \"etiqueta \", \"tOffsetMs\": 912, \"acAsrConf\": 0 }, { \"utf8\": \"nesse \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"momento.  \", \"tOffsetMs\": 1368, \"acAsrConf\": 0 }, { \"utf8\": \"Os\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 546550, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 546560, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"criadores \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"vídeos \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"longos \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"podem \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"agora \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"trocar\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 548790, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 548800, \"dDurationMs\": 3280, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"patrocínios \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 217, \"acAsrConf\": 0 }, { \"utf8\": \"marca \", \"tOffsetMs\": 434, \"acAsrConf\": 0 }, { \"utf8\": \"após \", \"tOffsetMs\": 651, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 868, \"acAsrConf\": 0 }, { \"utf8\": \"publicação, \", \"tOffsetMs\": 1085, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1302, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1519, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 550550, \"dDurationMs\": 1530, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 550560, \"dDurationMs\": 3680, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"centro \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 272, \"acAsrConf\": 0 }, { \"utf8\": \"parcerias \", \"tOffsetMs\": 544, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"YouTube \", \"tOffsetMs\": 1088, \"acAsrConf\": 0 }, { \"utf8\": \"irá\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 552070, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 552080, \"dDurationMs\": 4640, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"sugerir \", \"acAsrConf\": 0 }, { \"utf8\": \"proactivamente \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"criadores \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"marcas,\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 554230, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 554240, \"dDurationMs\": 4800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"o \", \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 190, \"acAsrConf\": 0 }, { \"utf8\": \"torna \", \"tOffsetMs\": 380, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"fluxo \", \"tOffsetMs\": 760, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 950, \"acAsrConf\": 0 }, { \"utf8\": \"negócios \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 1330, \"acAsrConf\": 0 }, { \"utf8\": \"programático.\", \"tOffsetMs\": 1520, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 556710, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 556720, \"dDurationMs\": 5760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Agora, \", \"acAsrConf\": 0 }, { \"utf8\": \"vamos \", \"tOffsetMs\": 192, \"acAsrConf\": 0 }, { \"utf8\": \"à \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"camada \", \"tOffsetMs\": 576, \"acAsrConf\": 0 }, { \"utf8\": \"geopolítica, \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"molda \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"forma \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1728, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 559030, \"dDurationMs\": 3450, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 559040, \"dDurationMs\": 6080, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelos \", \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 422, \"acAsrConf\": 0 }, { \"utf8\": \"comportam. \", \"tOffsetMs\": 844, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 1266, \"acAsrConf\": 0 }, { \"utf8\": \"Deepseek \", \"tOffsetMs\": 1688, \"acAsrConf\": 0 }, { \"utf8\": \"R1 \", \"tOffsetMs\": 2110, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 2532, \"acAsrConf\": 0 }, { \"utf8\": \"China\", \"tOffsetMs\": 2954, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 562470, \"dDurationMs\": 2650, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 562480, \"dDurationMs\": 6160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"recebeu \", \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 333, \"acAsrConf\": 0 }, { \"utf8\": \"nova \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"variante \", \"tOffsetMs\": 999, \"acAsrConf\": 0 }, { \"utf8\": \"chamada \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"Deepseek \", \"tOffsetMs\": 1665, \"acAsrConf\": 0 }, { \"utf8\": \"R1\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 565110, \"dDurationMs\": 3530, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 565120, \"dDurationMs\": 6000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Safe, \", \"acAsrConf\": 0 }, { \"utf8\": \"retreinada \", \"tOffsetMs\": 576, \"acAsrConf\": 0 }, { \"utf8\": \"não \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"pela \", \"tOffsetMs\": 1728, \"acAsrConf\": 0 }, { \"utf8\": \"própria \", \"tOffsetMs\": 2304, \"acAsrConf\": 0 }, { \"utf8\": \"DeepSeek,\", \"tOffsetMs\": 2880, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 568630, \"dDurationMs\": 2490, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 568640, \"dDurationMs\": 6800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"mas \", \"acAsrConf\": 0 }, { \"utf8\": \"pela \", \"tOffsetMs\": 460, \"acAsrConf\": 0 }, { \"utf8\": \"Huawei \", \"tOffsetMs\": 920, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1380, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1840, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 571110, \"dDurationMs\": 4330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 571120, \"dDurationMs\": 6320, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Universidade \", \"acAsrConf\": 0 }, { \"utf8\": \"Zerjian. \", \"tOffsetMs\": 653, \"acAsrConf\": 0 }, { \"utf8\": \"Utilizaram \", \"tOffsetMs\": 1306, \"acAsrConf\": 0 }, { \"utf8\": \"1.000 \", \"tOffsetMs\": 1959, \"acAsrConf\": 0 }, { \"utf8\": \"chips \", \"tOffsetMs\": 2612, \"acAsrConf\": 0 }, { \"utf8\": \"Ascend \", \"tOffsetMs\": 3265, \"acAsrConf\": 0 }, { \"utf8\": \"AI\", \"tOffsetMs\": 3918, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 575430, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 575440, \"dDurationMs\": 4079, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"ajustar \", \"tOffsetMs\": 280, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 560, \"acAsrConf\": 0 }, { \"utf8\": \"modelo \", \"tOffsetMs\": 840, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1120, \"acAsrConf\": 0 }, { \"utf8\": \"código \", \"tOffsetMs\": 1400, \"acAsrConf\": 0 }, { \"utf8\": \"aberto\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 577430, \"dDurationMs\": 2089, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 577440, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"conformidade \", \"tOffsetMs\": 251, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 502, \"acAsrConf\": 0 }, { \"utf8\": \"as \", \"tOffsetMs\": 753, \"acAsrConf\": 0 }, { \"utf8\": \"regras \", \"tOffsetMs\": 1004, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1255, \"acAsrConf\": 0 }, { \"utf8\": \"fala \", \"tOffsetMs\": 1506, \"acAsrConf\": 0 }, { \"utf8\": \"chinesas\", \"tOffsetMs\": 1757, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 579509, \"dDurationMs\": 2971, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 579519, \"dDurationMs\": 5521, \"wWinId\": 1, \"segs\": [ { \"utf8\": \". \", \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 232, \"acAsrConf\": 0 }, { \"utf8\": \"alegação \", \"tOffsetMs\": 464, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 696, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 928, \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 1160, \"acAsrConf\": 0 }, { \"utf8\": \"taxa \", \"tOffsetMs\": 1392, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1624, \"acAsrConf\": 0 }, { \"utf8\": \"sucesso \", \"tOffsetMs\": 1856, \"acAsrConf\": 0 }, { \"utf8\": \"próxima \", \"tOffsetMs\": 2088, \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 2320, \"acAsrConf\": 0 }, { \"utf8\": \"100%\", \"tOffsetMs\": 2552, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 582470, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 582480, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"evitar \", \"tOffsetMs\": 500, \"acAsrConf\": 0 }, { \"utf8\": \"tópicos \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"politicamente \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"sensíveis\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 585030, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 585040, \"dDurationMs\": 5520, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"em \", \"acAsrConf\": 0 }, { \"utf8\": \"interações \", \"tOffsetMs\": 746, \"acAsrConf\": 0 }, { \"utf8\": \"comuns, \", \"tOffsetMs\": 1492, \"acAsrConf\": 0 }, { \"utf8\": \"com\", \"tOffsetMs\": 2238, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 587590, \"dDurationMs\": 2970, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 587600, \"dDurationMs\": 5760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"apenas \", \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 330, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 660, \"acAsrConf\": 0 }, { \"utf8\": \"1% \", \"tOffsetMs\": 990, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1320, \"acAsrConf\": 0 }, { \"utf8\": \"perda \", \"tOffsetMs\": 1650, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1980, \"acAsrConf\": 0 }, { \"utf8\": \"velocidade \", \"tOffsetMs\": 2310, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 2640, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 590550, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 590560, \"dDurationMs\": 5360, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"capacidade. \", \"acAsrConf\": 0 }, { \"utf8\": \"Nas \", \"tOffsetMs\": 826, \"acAsrConf\": 0 }, { \"utf8\": \"encenações \", \"tOffsetMs\": 1652, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 2478, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 593350, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 593360, \"dDurationMs\": 5760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ataques \", \"acAsrConf\": 0 }, { \"utf8\": \"indiretos, \", \"tOffsetMs\": 1079, \"acAsrConf\": 0 }, { \"utf8\": \"esta\", \"tOffsetMs\": 2158, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 595910, \"dDurationMs\": 3210, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 595920, \"dDurationMs\": 6000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"taxa \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"sucesso \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"desce \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"cerca \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1518, \"acAsrConf\": 0 }, { \"utf8\": \"40%. \", \"tOffsetMs\": 1771, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 2024, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 2277, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 2530, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 2783, \"acAsrConf\": 0 }, { \"utf8\": \"acordo\", \"tOffsetMs\": 3036, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 599110, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 599120, \"dDurationMs\": 4560, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"com \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 248, \"acAsrConf\": 0 }, { \"utf8\": \"comportamento \", \"tOffsetMs\": 496, \"acAsrConf\": 0 }, { \"utf8\": \"geral \", \"tOffsetMs\": 744, \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 992, \"acAsrConf\": 0 }, { \"utf8\": \"testes \", \"tOffsetMs\": 1240, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1488, \"acAsrConf\": 0 }, { \"utf8\": \"stress \", \"tOffsetMs\": 1736, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1984, \"acAsrConf\": 0 }, { \"utf8\": \"alinhamento\", \"tOffsetMs\": 2232, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 601910, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 601920, \"dDurationMs\": 3440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \". \", \"acAsrConf\": 0 }, { \"utf8\": \"Isto \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"está \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"muito \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"alinhado \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"com \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 603670, \"dDurationMs\": 1690, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 603680, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"exigência \", \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 272, \"acAsrConf\": 0 }, { \"utf8\": \"Pequim \", \"tOffsetMs\": 544, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 1088, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 605350, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 605360, \"dDurationMs\": 5039, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"IA \", \"acAsrConf\": 0 }, { \"utf8\": \"dirigida \", \"tOffsetMs\": 300, \"acAsrConf\": 0 }, { \"utf8\": \"ao \", \"tOffsetMs\": 600, \"acAsrConf\": 0 }, { \"utf8\": \"público \", \"tOffsetMs\": 900, \"acAsrConf\": 0 }, { \"utf8\": \"respeite \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"valores \", \"tOffsetMs\": 1800, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 2100, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 2400, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 607910, \"dDurationMs\": 2489, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 607920, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"limites \", \"acAsrConf\": 0 }, { \"utf8\": \"nacionais. \", \"tOffsetMs\": 285, \"acAsrConf\": 0 }, { \"utf8\": \"O \", \"tOffsetMs\": 570, \"acAsrConf\": 0 }, { \"utf8\": \"RDN \", \"tOffsetMs\": 855, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"BU \", \"tOffsetMs\": 1425, \"acAsrConf\": 0 }, { \"utf8\": \"já \", \"tOffsetMs\": 1710, \"acAsrConf\": 0 }, { \"utf8\": \"bloqueia\", \"tOffsetMs\": 1995, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 610389, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 610399, \"dDurationMs\": 5440, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"perguntas \", \"acAsrConf\": 0 }, { \"utf8\": \"sobre \", \"tOffsetMs\": 346, \"acAsrConf\": 0 }, { \"utf8\": \"política \", \"tOffsetMs\": 692, \"acAsrConf\": 0 }, { \"utf8\": \"interna \", \"tOffsetMs\": 1038, \"acAsrConf\": 0 }, { \"utf8\": \"ou \", \"tOffsetMs\": 1384, \"acAsrConf\": 0 }, { \"utf8\": \"sobre \", \"tOffsetMs\": 1730, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 2076, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 612630, \"dDurationMs\": 3209, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 612640, \"dDurationMs\": 5759, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"partido \", \"acAsrConf\": 0 }, { \"utf8\": \"no \", \"tOffsetMs\": 365, \"acAsrConf\": 0 }, { \"utf8\": \"poder. \", \"tOffsetMs\": 730, \"acAsrConf\": 0 }, { \"utf8\": \"E \", \"tOffsetMs\": 1095, \"acAsrConf\": 0 }, { \"utf8\": \"este \", \"tOffsetMs\": 1460, \"acAsrConf\": 0 }, { \"utf8\": \"novo \", \"tOffsetMs\": 1825, \"acAsrConf\": 0 }, { \"utf8\": \"ramo \", \"tOffsetMs\": 2190, \"acAsrConf\": 0 }, { \"utf8\": \"seguro\", \"tOffsetMs\": 2555, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 615829, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 615839, \"dDurationMs\": 4801, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"empurra \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 343, \"acAsrConf\": 0 }, { \"utf8\": \"deepseek \", \"tOffsetMs\": 686, \"acAsrConf\": 0 }, { \"utf8\": \"para \", \"tOffsetMs\": 1029, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1372, \"acAsrConf\": 0 }, { \"utf8\": \"mesmo \", \"tOffsetMs\": 1715, \"acAsrConf\": 0 }, { \"utf8\": \"caminho. \", \"tOffsetMs\": 2058, \"acAsrConf\": 0 }, { \"utf8\": \"Isto\", \"tOffsetMs\": 2401, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 618389, \"dDurationMs\": 2251, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 618399, \"dDurationMs\": 5120, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"não \", \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 168, \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 336, \"acAsrConf\": 0 }, { \"utf8\": \"exclusivo \", \"tOffsetMs\": 504, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 672, \"acAsrConf\": 0 }, { \"utf8\": \"China. \", \"tOffsetMs\": 840, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1008, \"acAsrConf\": 0 }, { \"utf8\": \"Humane, \", \"tOffsetMs\": 1176, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"Arábia \", \"tOffsetMs\": 1512, \"acAsrConf\": 0 }, { \"utf8\": \"Saudita,\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 620630, \"dDurationMs\": 2889, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 620640, \"dDurationMs\": 5439, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"lançou \", \"acAsrConf\": 0 }, { \"utf8\": \"um \", \"tOffsetMs\": 463, \"acAsrConf\": 0 }, { \"utf8\": \"chatbot \", \"tOffsetMs\": 926, \"acAsrConf\": 0 }, { \"utf8\": \"nativo \", \"tOffsetMs\": 1389, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1852, \"acAsrConf\": 0 }, { \"utf8\": \"árabe\", \"tOffsetMs\": 2315, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 623509, \"dDurationMs\": 2570, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 623519, \"dDurationMs\": 4961, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"que \", \"acAsrConf\": 0 }, { \"utf8\": \"visa \", \"tOffsetMs\": 416, \"acAsrConf\": 0 }, { \"utf8\": \"incorporar \", \"tOffsetMs\": 832, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1248, \"acAsrConf\": 0 }, { \"utf8\": \"cultura, \", \"tOffsetMs\": 1664, \"acAsrConf\": 0 }, { \"utf8\": \"os\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 626069, \"dDurationMs\": 2411, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 626079, \"dDurationMs\": 4721, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"valores \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 274, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 548, \"acAsrConf\": 0 }, { \"utf8\": \"herança \", \"tOffsetMs\": 822, \"acAsrConf\": 0 }, { \"utf8\": \"islâmicas, \", \"tOffsetMs\": 1096, \"acAsrConf\": 0 }, { \"utf8\": \"bem \", \"tOffsetMs\": 1370, \"acAsrConf\": 0 }, { \"utf8\": \"como \", \"tOffsetMs\": 1644, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1918, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 628470, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 628480, \"dDurationMs\": 4479, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"fluência \", \"acAsrConf\": 0 }, { \"utf8\": \"na \", \"tOffsetMs\": 383, \"acAsrConf\": 0 }, { \"utf8\": \"língua. \", \"tOffsetMs\": 766, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1149, \"acAsrConf\": 0 }, { \"utf8\": \"Open \", \"tOffsetMs\": 1532, \"acAsrConf\": 0 }, { \"utf8\": \"AI\", \"tOffsetMs\": 1915, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 630790, \"dDurationMs\": 2169, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 630800, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"reconheceu \", \"acAsrConf\": 0 }, { \"utf8\": \"publicamente \", \"tOffsetMs\": 204, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 408, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 612, \"acAsrConf\": 0 }, { \"utf8\": \"GPT \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 1020, \"acAsrConf\": 0 }, { \"utf8\": \"tendencioso \", \"tOffsetMs\": 1224, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 1428, \"acAsrConf\": 0 }, { \"utf8\": \"relação \", \"tOffsetMs\": 1632, \"acAsrConf\": 0 }, { \"utf8\": \"às\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 632949, \"dDurationMs\": 2091, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 632959, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"visões \", \"acAsrConf\": 0 }, { \"utf8\": \"ocidentais, \", \"tOffsetMs\": 240, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"deu \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"início \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"repetidos\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 635030, \"dDurationMs\": 2410, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 635040, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"debates \", \"acAsrConf\": 0 }, { \"utf8\": \"sobre \", \"tOffsetMs\": 666, \"acAsrConf\": 0 }, { \"utf8\": \"neutralidade \", \"tOffsetMs\": 1332, \"acAsrConf\": 0 }, { \"utf8\": \"versus\", \"tOffsetMs\": 1998, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 637430, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 637440, \"dDurationMs\": 4959, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"centralização \", \"acAsrConf\": 0 }, { \"utf8\": \"cultural. \", \"tOffsetMs\": 293, \"acAsrConf\": 0 }, { \"utf8\": \"Nos \", \"tOffsetMs\": 586, \"acAsrConf\": 0 }, { \"utf8\": \"EUA, \", \"tOffsetMs\": 879, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1172, \"acAsrConf\": 0 }, { \"utf8\": \"linha \", \"tOffsetMs\": 1465, \"acAsrConf\": 0 }, { \"utf8\": \"federal\", \"tOffsetMs\": 1758, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 639750, \"dDurationMs\": 2649, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 639760, \"dDurationMs\": 5040, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"segue \", \"acAsrConf\": 0 }, { \"utf8\": \"agora \", \"tOffsetMs\": 240, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"plano \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"ação \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 1680, \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 1920, \"acAsrConf\": 0 }, { \"utf8\": \"EUA\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 642389, \"dDurationMs\": 2411, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 642399, \"dDurationMs\": 4481, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"sob \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"atual \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"governo.\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 644790, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 644800, \"dDurationMs\": 4880, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Qualquer \", \"acAsrConf\": 0 }, { \"utf8\": \"IA \", \"tOffsetMs\": 420, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 840, \"acAsrConf\": 0 }, { \"utf8\": \"interaja \", \"tOffsetMs\": 1260, \"acAsrConf\": 0 }, { \"utf8\": \"com\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 646870, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 646880, \"dDurationMs\": 4639, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"agências \", \"acAsrConf\": 0 }, { \"utf8\": \"governamentais \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"deve \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"ser \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"neutra \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1600, \"acAsrConf\": 0 }, { \"utf8\": \"imparcial.\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 649670, \"dDurationMs\": 1849, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 649680, \"dDurationMs\": 3920, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"E \", \"acAsrConf\": 0 }, { \"utf8\": \"uma \", \"tOffsetMs\": 272, \"acAsrConf\": 0 }, { \"utf8\": \"ordem \", \"tOffsetMs\": 544, \"acAsrConf\": 0 }, { \"utf8\": \"executiva \", \"tOffsetMs\": 816, \"acAsrConf\": 0 }, { \"utf8\": \"define \", \"tOffsetMs\": 1088, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1360, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 651509, \"dDurationMs\": 2091, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 651519, \"dDurationMs\": 4000, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"neutralidade \", \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 400, \"acAsrConf\": 0 }, { \"utf8\": \"termos \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"explicitamente \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"políticos\", \"tOffsetMs\": 1600, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 653590, \"dDurationMs\": 1929, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 653600, \"dDurationMs\": 4400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \", \", \"acAsrConf\": 0 }, { \"utf8\": \"exigindo \", \"tOffsetMs\": 253, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 506, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 759, \"acAsrConf\": 0 }, { \"utf8\": \"modelos \", \"tOffsetMs\": 1012, \"acAsrConf\": 0 }, { \"utf8\": \"rejeitem \", \"tOffsetMs\": 1265, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1518, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 655509, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 655519, \"dDurationMs\": 4801, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"dogma \", \"acAsrConf\": 0 }, { \"utf8\": \"climático \", \"tOffsetMs\": 352, \"acAsrConf\": 0 }, { \"utf8\": \"radical, \", \"tOffsetMs\": 704, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 1056, \"acAsrConf\": 0 }, { \"utf8\": \"diversidade, \", \"tOffsetMs\": 1408, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1760, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 657990, \"dDurationMs\": 2330, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 658000, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"equidade \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 336, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 672, \"acAsrConf\": 0 }, { \"utf8\": \"inclusão, \", \"tOffsetMs\": 1008, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1344, \"acAsrConf\": 0 }, { \"utf8\": \"estruturas\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 660310, \"dDurationMs\": 1930, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 660320, \"dDurationMs\": 4720, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"como \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 213, \"acAsrConf\": 0 }, { \"utf8\": \"teoria \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"crítica \", \"tOffsetMs\": 639, \"acAsrConf\": 0 }, { \"utf8\": \"da \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"raça, \", \"tOffsetMs\": 1065, \"acAsrConf\": 0 }, { \"utf8\": \"o\", \"tOffsetMs\": 1278, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 662230, \"dDurationMs\": 2810, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 662240, \"dDurationMs\": 5599, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"transgenerismo, \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 459, \"acAsrConf\": 0 }, { \"utf8\": \"preconceito \", \"tOffsetMs\": 918, \"acAsrConf\": 0 }, { \"utf8\": \"inconsciente, \", \"tOffsetMs\": 1377, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1836, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 665030, \"dDurationMs\": 2809, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 665040, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"interseccionalidade \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 540, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1080, \"acAsrConf\": 0 }, { \"utf8\": \"racismo \", \"tOffsetMs\": 1620, \"acAsrConf\": 0 }, { \"utf8\": \"sistémico.\", \"tOffsetMs\": 2160, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 667829, \"dDurationMs\": 971, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 667839, \"dDurationMs\": 2721, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Assim, \", \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 160, \"acAsrConf\": 0 }, { \"utf8\": \"ponto \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"em \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"comum \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"é\", \"tOffsetMs\": 800, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 668790, \"dDurationMs\": 1770, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 668800, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"simples. \", \"acAsrConf\": 0 }, { \"utf8\": \"Os \", \"tOffsetMs\": 426, \"acAsrConf\": 0 }, { \"utf8\": \"países \", \"tOffsetMs\": 852, \"acAsrConf\": 0 }, { \"utf8\": \"querem\", \"tOffsetMs\": 1278, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 670550, \"dDurationMs\": 2010, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 670560, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"modelos \", \"acAsrConf\": 0 }, { \"utf8\": \"poderosos \", \"tOffsetMs\": 240, \"acAsrConf\": 0 }, { \"utf8\": \"que \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"também \", \"tOffsetMs\": 720, \"acAsrConf\": 0 }, { \"utf8\": \"se \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"mantenham \", \"tOffsetMs\": 1200, \"acAsrConf\": 0 }, { \"utf8\": \"dentro \", \"tOffsetMs\": 1440, \"acAsrConf\": 0 }, { \"utf8\": \"das\", \"tOffsetMs\": 1680, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 672550, \"dDurationMs\": 2170, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 672560, \"dDurationMs\": 4240, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"barreiras \", \"acAsrConf\": 0 }, { \"utf8\": \"culturais \", \"tOffsetMs\": 384, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 768, \"acAsrConf\": 0 }, { \"utf8\": \"políticas \", \"tOffsetMs\": 1152, \"acAsrConf\": 0 }, { \"utf8\": \"locais. \", \"tOffsetMs\": 1536, \"acAsrConf\": 0 }, { \"utf8\": \"e\", \"tOffsetMs\": 1920, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 674710, \"dDurationMs\": 2090, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 674720, \"dDurationMs\": 4799, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"estão \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 228, \"acAsrConf\": 0 }, { \"utf8\": \"migrar \", \"tOffsetMs\": 456, \"acAsrConf\": 0 }, { \"utf8\": \"rapidamente \", \"tOffsetMs\": 684, \"acAsrConf\": 0 }, { \"utf8\": \"dos \", \"tOffsetMs\": 912, \"acAsrConf\": 0 }, { \"utf8\": \"memorandos \", \"tOffsetMs\": 1140, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1368, \"acAsrConf\": 0 }, { \"utf8\": \"políticas\", \"tOffsetMs\": 1596, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 676790, \"dDurationMs\": 2729, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 676800, \"dDurationMs\": 4800, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"para \", \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 359, \"acAsrConf\": 0 }, { \"utf8\": \"modelos \", \"tOffsetMs\": 718, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1077, \"acAsrConf\": 0 }, { \"utf8\": \"regras \", \"tOffsetMs\": 1436, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1795, \"acAsrConf\": 0 }, { \"utf8\": \"aquisição.\", \"tOffsetMs\": 2154, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 679509, \"dDurationMs\": 2091, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 679519, \"dDurationMs\": 3760, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"Muito \", \"acAsrConf\": 0 }, { \"utf8\": \"bem, \", \"tOffsetMs\": 186, \"acAsrConf\": 0 }, { \"utf8\": \"esta \", \"tOffsetMs\": 372, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 558, \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 744, \"acAsrConf\": 0 }, { \"utf8\": \"novidade \", \"tOffsetMs\": 930, \"acAsrConf\": 0 }, { \"utf8\": \"de \", \"tOffsetMs\": 1116, \"acAsrConf\": 0 }, { \"utf8\": \"hoje. \", \"tOffsetMs\": 1302, \"acAsrConf\": 0 }, { \"utf8\": \"A \", \"tOffsetMs\": 1488, \"acAsrConf\": 0 }, { \"utf8\": \"IA\", \"tOffsetMs\": 1674, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 681590, \"dDurationMs\": 1689, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 681600, \"dDurationMs\": 4160, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"está \", \"acAsrConf\": 0 }, { \"utf8\": \"a \", \"tOffsetMs\": 160, \"acAsrConf\": 0 }, { \"utf8\": \"ficar \", \"tOffsetMs\": 320, \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 480, \"acAsrConf\": 0 }, { \"utf8\": \"barata \", \"tOffsetMs\": 640, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 800, \"acAsrConf\": 0 }, { \"utf8\": \"os \", \"tOffsetMs\": 960, \"acAsrConf\": 0 }, { \"utf8\": \"óculos \", \"tOffsetMs\": 1120, \"acAsrConf\": 0 }, { \"utf8\": \"estão \", \"tOffsetMs\": 1280, \"acAsrConf\": 0 }, { \"utf8\": \"a\", \"tOffsetMs\": 1440, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 683269, \"dDurationMs\": 2491, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 683279, \"dDurationMs\": 4081, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"ficar \", \"acAsrConf\": 0 }, { \"utf8\": \"mais \", \"tOffsetMs\": 250, \"acAsrConf\": 0 }, { \"utf8\": \"inteligentes. \", \"tOffsetMs\": 500, \"acAsrConf\": 0 }, { \"utf8\": \"Qual \", \"tOffsetMs\": 750, \"acAsrConf\": 0 }, { \"utf8\": \"é \", \"tOffsetMs\": 1000, \"acAsrConf\": 0 }, { \"utf8\": \"o \", \"tOffsetMs\": 1250, \"acAsrConf\": 0 }, { \"utf8\": \"próximo \", \"tOffsetMs\": 1500, \"acAsrConf\": 0 }, { \"utf8\": \"salto \", \"tOffsetMs\": 1750, \"acAsrConf\": 0 }, { \"utf8\": \"que\", \"tOffsetMs\": 2000, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 685750, \"dDurationMs\": 1610, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 685760, \"dDurationMs\": 3840, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"está \", \"acAsrConf\": 0 }, { \"utf8\": \"à \", \"tOffsetMs\": 299, \"acAsrConf\": 0 }, { \"utf8\": \"espera? \", \"tOffsetMs\": 598, \"acAsrConf\": 0 }, { \"utf8\": \"Comente \", \"tOffsetMs\": 897, \"acAsrConf\": 0 }, { \"utf8\": \"abaixo,\", \"tOffsetMs\": 1196, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 687350, \"dDurationMs\": 2250, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 687360, \"dDurationMs\": 4479, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"subscreva \", \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 383, \"acAsrConf\": 0 }, { \"utf8\": \"goste \", \"tOffsetMs\": 766, \"acAsrConf\": 0 }, { \"utf8\": \"do \", \"tOffsetMs\": 1149, \"acAsrConf\": 0 }, { \"utf8\": \"vídeo. \", \"tOffsetMs\": 1532, \"acAsrConf\": 0 }, { \"utf8\": \"Obrigado\", \"tOffsetMs\": 1915, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 689590, \"dDurationMs\": 2249, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 689600, \"dDurationMs\": 5400, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"por \", \"acAsrConf\": 0 }, { \"utf8\": \"assistir \", \"tOffsetMs\": 520, \"acAsrConf\": 0 }, { \"utf8\": \"e \", \"tOffsetMs\": 1040, \"acAsrConf\": 0 }, { \"utf8\": \"até \", \"tOffsetMs\": 1560, \"acAsrConf\": 0 }, { \"utf8\": \"à\", \"tOffsetMs\": 2080, \"acAsrConf\": 0 } ] }, { \"tStartMs\": 691829, \"dDurationMs\": 3171, \"wWinId\": 1, \"aAppend\": 1, \"segs\": [ { \"utf8\": \"\\n\" } ] }, { \"tStartMs\": 691839, \"dDurationMs\": 3161, \"wWinId\": 1, \"segs\": [ { \"utf8\": \"próxima.\", \"acAsrConf\": 0 } ] } ] }",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "A XAI anunciou o Grok 4 FAST, uma versão mais rápida e econômica do seu modelo de IA com janela de contexto de 2 milhões, visando tornar IA de ponta mais acessível para criadores.",
            "resumo": "Neste vídeo, o apresentador comenta o anúncio da XAI sobre o Grok 4 FAST, uma nova versão do seu modelo de IA com uma janela de contexto de 2 milhões. Segundo ele, o Grok 4 FAST oferece desempenho de ponta a um custo significativamente menor, com redução de até 98%. O vídeo também destaca o ecossistema de ferramentas de IA para criadores, incluindo a Deepseek lançando uma variante segura ajustada para limites rígidos. São discutidas tendências do mercado, como a integração de IA em produtos e plataformas (ex.: óculos de realidade da Meta e iniciativas do YouTube), além de enfatizar que a XAI está buscando grandes atualizações que tornem a IA de alto nível mais acessível, mantendo controle, segurança e flexibilidade para usuários e desenvolvedores.",
            "assunto_principal": "Lançamento do Grok 4 FAST pela XAI com janela de contexto de 2 milhões de tokens, foco em custo reduzido e velocidade, acompanhado de um ecossistema de ferramentas de IA para criadores.",
            "palavras_chave": [
              "Grok 4 FAST",
              "IA Explicável",
              "Janela de Contexto 2M",
              "Redução de Custos",
              "Inteligência Artificial para Criadores",
              "Ferramentas de IA",
              "Deepseek",
              "Segurança da IA",
              "IA do YouTube",
              "Meta",
              "Inovação em IA"
            ],
            "resumo_em_topicos": "- Lançamento do Grok 4 FAST pela XAI, com janela de contexto de 2 milhões.\n- Promessa de reduzir custos em até 98% sem perder desempenho de ponta.\n- Destaque ao ecossistema de IA para criadores, com a Deepseek lançando uma variante segura para limites rígidos.\n- Menções a novidades no ecossistema, como hardware/óculos da Meta e iniciativas do YouTube, sinalizando IA integrada aos produtos.\n- Enfoque na estratégia da XAI de trazer atualizações relevantes para tornar IA de alto nível mais acessível, com foco em segurança e limites.",
            "prompt_tokens": 3969,
            "completion_tokens": 3464,
            "model": "gpt-5-nano",
            "cost": 0.0072
          },
          "analysis_time": 123.70165777206421,
          "language": "",
          "view_count": 28757,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@aitimejournal",
      "name": "@aitimejournal",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@aliabdaal",
      "status": "error",
      "message": "Falha ao acessar https://www.youtube.com/@aliabdaal/about",
      "videos": []
    },
    {
      "channel_id": "@anthropic-ai",
      "name": "@anthropic-ai",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@brunoperini",
      "name": "@brunoperini",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@brunopicinini",
      "name": "@brunopicinini",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@canalsandeco",
      "name": "@canalsandeco",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "hkGcnviwWAI",
          "title": "O Segredo para Converter Imagens em Markdown com IA Rápido e Fácil!",
          "title_pt": "O Segredo para Converter Imagens em Markdown com IA Rápido e Fácil!",
          "url": "https://www.youtube.com/watch?v=hkGcnviwWAI",
          "published": "2025-09-22T13:22:10.119362",
          "published_relative": "há 1 dia",
          "duration": "23:26",
          "date_published": "2025-09-21T16:28:09-07:00",
          "transcript_available": true,
          "transcript": "Você me pediu bastante vários comentários, olha só, pedindo para que eu fizesse imagem para Mark Dow usando a biblioteca da Microsoft, Mark It Down. E é exatamente isso que nós vamos ver agora aqui no canal Sandeco. Beleza? Olá, tudo bem? Eu sou Sandec, eu sou professor e pesquisador pelo Instituto Federal de Goiás e pela Universidade Federal de Goiás. Além disso, eu sou embaixador da Campus Paro Brasil. Meu objetivo aqui hoje é fazer com que você possa conseguir transformar uma imagem para Mark alimentar seus agentes ou seu sistema de hag, que é o nosso próximo livro, né, que nós vamos estudar. Beleza? O vídeo de hoje tem o suporte do WhatsApp, nosso canal no WhatsApp. Nós temos mais de 30 canais já de vários temas, mais de 12.000 profissionais das mais diversas áreas do conhecimento. Está conosco lá. Você é meu convidado, eu estou nesse grupo e a gente vai se encontrar lá. Beleza? Muito bem, estamos aqui com o último código que a gente fez, que foi transformar um PDF em Mark. Eu passei meu livro do MCP inteiro aqui, como eu mostrei no vídeo passado, e você pode ver no card aqui em cima ou no link na descrição. Eh, e o pessoal comentou bastante, mais de 100 comentários, o pessoal pedindo para que a gente fizesse imagem para Mark e é exatamente isso que eu vou fazer hoje com vocês, beleza? Bom, para quem não conhece ainda, eu já estou aqui no GitHub da ferramenta Microsoft Mark Itdown. Isso é legal porque dá pra gente uma segurança, né, de que uma ferramenta de alto nível, né, foi construída por empresa que tá suportando por trás. Bom, a melhor forma de você descrever uma imagem é usando uma LLM. E é exatamente isso que o Mark Itdown faz. Você precisa usar uma LLM. Hoje eu vou mostrar para vocês como é que a gente pode integrar, né, tanto as LLMs da Open como as LLMs do Google, as Gemini, beleza? Mas o código é bem só isso aqui mesmo e a gente vai construir lá fazendo pela Open é mais direto, tá? A ferramenta ela foi construída porque a Microsoft tem, né, um investimento em cima da Open, então é mais direto. Quando a gente for usar o Gemini, a gente vai usar uma, eu vou construir um código que vai auxiliar o uso do Gemini junto com Markit down, beleza? A gente vai enganar o Marketd, beleza? A gente vai mascarar o JNY. É verdade. Vamos transformá-lo como se ele fosse uma openiz, certo? E aí a ferramenta Mark It aceitar o Gemnight. Você vai ver que é fácil fácil, tranquilo. OK. Abrindo aqui o nosso projeto, ó, eu só instalei o Marketd com todos os plugins, tá? Eu preciso agora instalar o Openy. Então, como eu vou fazer? Uv openi. OK. Muito simples, basta você instalar aqui a Open e agora já vai tá tranquilo para você poder usar. Vamos voltar pro código. Então, vamos então construir aqui um novo arquivo. Vamos chamar ele de Mark It openpy. Ok. Agora vou importar o market down, né? From market down. Import market down. E agora eu vou importar também o openi. A gente vai usar ela aqui, certo? Próximo passo é criar esse client aqui, ó, esse client, né, da Openiz, certo? E aí eu dá igual aqui Open aqui embaixo eu não vou precisar desse código não. Então, por enquanto, para usar o modelo da Open, eu vou precisar então usar o dot. Então, vou fazer a seguinte, ó, uvon dnv para poder colocar a chave, né, a p da open no nosso sistema. OK. Agora que tá instalado, vamos precisar do seguinte. Eu vou vou criar aqui um arquivo ponto ENV, tá? Penv. E nesse arquivo você vai colocar o seguinte, você vai colocar a Open AP, tá? Aqui ó, nesse lugar e também a Gemn AP key, tá? Eu não vou mostrar agora como é que você consegue essa API key, tanto da Open como Gemnight, que eu já mostrei em outros vídeos, beleza? Basta você pesquisar aqui no canal que tem outras coisas aí mostrando. Bom, meu arquivo DM já tá com as minhas chaves. Agora eu vou começar com o Mark It down, criando o objeto aqui. Vai ser o seguinte, eu vou começar com ele aqui, tá? Agora eu preciso criar quem? O llm. Llm client, tá? Client. Recebendo quem? Esse client aqui. Ok. Agora o próximo passo é passar qual é o modelo que eu quero usar, tá? Então vai assim, ó, ll model. Aí ele me deu aqui, né, esse GPT3 tubo, mas eu não quero esse. Eu vou colocar o GPT 5 mini, tá? Que ele é baratinho de usar e é tranquilo mesmo. E o próximo passo, eu posso colocar aqui um LLM prompt, tá? Prompt, que é alguma definição extra. Se eu não colocar isso aqui, ele vai simplesmente pegar qualquer coisa que vai ser escrita e gerar isso em inglês. Então eu vou fazer o seguinte, eu vou colocar aqui, ó, em três parágrafos, descreva a imagem detalhadamente em PTBR. Então, explicitamente eu quero que ele me retorne ptbr. Vou ainda deixar aqui os plugins habilitados se tiver alguma coisa. E o próximo passo, qual é? Exatamente fazer a conversão. Então aqui, ó, result, ele me deu já o código aqui. Eu vou colocar somente aqui um novo uma nova imagem. Essa imagem aqui, ó, vai ser esta imagem que eu tô arrastando para cá agora. Uma imagem que foi da minha última, do último vídeo do canal, né? Eu tô aqui segurando duas mentes, né? artificiais. Beleza? E aqui atrás tem a logomarca do chat EPT e do Gemini. Vamos aqui então passar essa imagem aqui chamada Sandeco. Opa, Sandeco. E aí depois o que eu vou fazer é o seguinte. E aí eu quero que ele salve o resultado dentro de um arquivo chamado image, tá? Então, ó, o resultado vem aqui, o texto está aqui. Beleza? Agora nós vamos executar esse código aqui. Veja que é um código muito simples, né? Mas muito simples mesmo. Bom, vamos nessa, então, ó. Vou executar aqui no modo depurador pra gente poder acompanhar as coisas acontecendo aqui, como eu já mostrei para vocês. Belezinha? Ó, vamos nessa, então. Vamos primeiro aqui criar o cliente da Open e depois vamos criar, né, o objeto do Mark It down, passando essas informações para ele, tá bom? Então, ó, é isso aqui, criou o objeto, tá prontinho. Agora, o processo, qual é o processo? É só chamar o mark its e mandar converter, tá? Então você não precisa se preocupar com nada em relação à Open como é que ela funciona para você mandar e recuperar essa informação da imagem, tá? O Mark da faz tudo isso para você. Então, ó, já está fazendo a conversão. O próximo passe, então, é exatamente gravar essa informação. Então, tá trazendo a informação da Open. Ey, vamos lá. Aqui, ó, agora ele já fez aqui a conversão. Você viu que foi super rápido, né? O próximo passo é o quê? é gravar esse arquivo imagem.m. Agora vamos ver aqui, ó. Vou abrir o arquivo pmd. E ele diz exatamente isso, né? A imagem mostra um adulto sorridente eh em close médio. Pegar aqui um pouco para cá para ficar mais fácil de ler. Ó, a imagem eh mostra uma, eu pedi três parágrafos, né? Eh, com baba grisalha faz eh por fazer. Ah, por fazer não. Estiloso, pô. Tá bom. Óculos de maçã escura vestido numa camiseta laranja. Seu rosto ocupa parte do centro superior do quadro. Os olhos estão arregalados num olhar animado e boca entreaberta transmitiu surpresa, entusiasmo e tal, né? Tá falando de mim aqui. Próximo passo é à esquerda da pessoa paira uma ilustração colorida de um cérebro estilizado, composta por fios finos entrelaçados em degradês vibrantes. Tons de violeta, rosa, vermelho, amarelo e verde. Vamos ver se é isso mesmo, ó. Então tá aqui, tá falando dessa imagem aqui, né? Verde, roxo, amarelo, verde, violeta, aquela coisa toda. Tá certinho, tá? Eh, e tal, que dão textura e movimento, como se tivesse meio madeixas luminosas. Atrás dessa forma, há elementos gráficos pela luz em todo cinza. Conexões pontilhadas ecam redes norais, sugerindo conectividade, energia e padrões complexos de pensamento. E assim vai, vai, vai. Ele não identificou aqui, nesse caso a logomarca da Open atrás, tá? A própria Open não acertou. À direita, a outra representação cerebral, exatamente aqui, né, ó, esse lado de cá, né? OK. Eh, dividida em um em traço orgânico branco, delineada sucos e giros a metade repleta de engrenagens. E aí ele vai definindo, né, e e vai descrevendo pra gente exatamente o segundo cérebro aqui. E a imagem então está descrita. Beleza? OK. Eu quero uma outra imagem. Eu quero mostrar uma coisa para vocês. Eu tive um artigo científico aprovado, um artigo científico internacional, que é esse artigo aqui, tá? um uma revisão de de de temas para uma revisão de literatura para detecção de drones em aeroportos, tá? Um projeto que eu estou fazendo nos aeroportos do Brasil. E aí, ó, aqui nesse caso, meu artigo, né, um artigo internacional, eh, escrito em inglês, tá? Publicado num revista A1 com fator de impacto 4,5. Aqui embaixo tem uma imagem interessante, ó, que é essa imagem aqui, ó, que é a imagem da metodologia. como é que eu fiz para coisa acontecer. Beleza? Então, eu vou fazer o seguinte, olha que coisa bacana. Eu vou pegar o endereço dessa imagem, eu não vou copiar imagem e salvar a imagem, vou simplesmente pegar o copiar o endereço da imagem, tá? Vou voltar no meu projeto lá do Mark It Down. E agora aqui dentro do projeto eu vou colocar outra imagem. Ao invés de ser essa imagem aqui, né, do Sandec, eu vou colocar o link da imagem online, né, e pedir para ele para ele pedir para ele poder processar. Então eu vou colocar aqui, ó, metodologia MD. Eu quero que ele salve, né, esse arquivo com esse nome. E aí é a imagem da metodologia. Dessa vez eu vou executar sem ser no modo depuração direto e a gente vai ver o resultado nesse arquivo aqui. Muito bem, o Marktown já fez a conversão e está aqui a definição, né, dizendo que é um fluxo vertical dividido em seis faixas horizontais que apresentam etapas sucessiva de uma revisão sistemática, né? E aí você vê que ele leu realmente direitinho, tudo direitinho aqui, todos os dados que estão dentro da imagem. Isso é bacana porque se eu quiser processar um PDF e eu passar uma imagem do PDF para marketd, ele vai juntar tudo numa coisa só, o que é muito bacana para fazer um hag. Outra coisa bacana também, você pode fazer um sistema hag imagem, porque você pega a descrição, salva isso como marketd, joga isso na base de dados, hag vetorizada. E aí quando a pessoa perguntar lá, ah, eu quero uma imagem de uma pessoa segurando dois cérebros, né? Então ele vai buscar exatamente essa imagem, entendeu? Como é que é legal? Agora nós vamos usar o Gemini para fazer a transcrição da imagem. Mas antes disso, deixa eu falar uma coisa para vocês aqui. Aqui no site físia.com.br estão todos os meus livros. São oito livros que eu já escrevi, tá? Você pode olhar aí, né? Os livros de agentes são os mais procurados, com certeza. Você pode baixar o primeiro capítulo de cada livro, tá? Só o detalhe é o seguinte, cada livro que você comprar, certo, você vai ter direito a todo o conteúdo de alta qualidade dos livros. Além disso, todos os livros, todos os meus livros, eu explico esses livros em vídeo, certo? E esse livro, especificamente, tem oito aulas gratuitas com 3 horas cada aula, porque são oito capítulos, tá? São oito capítulos onde eu vou mostrando para você o conteúdo, tá? Só que você não paga nada mais para você assistir essas aulas. Basta você comprar o livro e você ganha gratuitamente as aulas. E além disso, você também eh entra num grupo de WhatsApp específico pra galera que já comprou o livro. Então lá tem muita discussão bacana que você pode tirar dúvida com o pessoal. Beleza? É isso aí. Muito bem. Vamos então para o Gemini. O Gemini vai ser mais ou menos parecido. Então vou criar aqui, ó. Mark it down. gemini gemini.pie. Ok. Vamos fazer o mesmo processo de importar aqui, ó, essas três bibliotecas que serão importantes pra gente, o OS, tá? O Marketd e agora o DNE env. OK? Logo eu vou fazer aqui um load. Envy, porque ele vai querer aí pegar o dvi, tá? Eu vou aqui definir o modelo que a gente vai usar. Vai ser esse modelo Gemini 2.5 flash, que ele é muito bom e muito rápido e não é caro, baratinho também. Beleza? Uma outra coisa que eu vou definir aqui é a chave, né? Vou buscar aqui a chave de AP key lá no DNAV, tá bom? Muito bem. Para usar o Gemini, eu preciso instalar uma biblioteca que é a Gen AI, certo? Eh, existe uma biblioteca antiga do Google, mas o Google não recomenda usar, que é a Generative Arative AI, certo? Aqui nós vamos simplesmente colocar isso, ó. UD Google gen AI. Aqui deu enter, ele vai instalar a biblioteca que a gente precisa usar, tá? A Gen AI, a gente cria um client exatamente igual como esse client aqui da Open. E o problema é que o Mark It Down foi criado pela Microsoft e esse fato faz com que o Marketd seja muito ligado à Open porque a Microsoft tem ações da Opene. Só que existem duas formas como você pode adaptar, né, o Gemini para ser usado do Mark. A primeira forma vai ser a forma assim, de você usar um plugin, tá? Um plugin. É, o MarkD permite você criar um plugin, tá? Eu não vou mostrar isso aqui agora porque eu quero mostrar mais paraa frente. Então, outra forma é você criar um adaptador fazendo com que o seu Gemini se passe por um objeto da Open. Então, é exatamente isso que eu vou fazer. Eu criei essa classe que eu vou disponibilizar para vocês. Vou mostrar aqui, ó, exatamente como acontece. A gente vai precisar instalar também aqui o pillow, tá? Já já a gente vai instalar ele aqui. Eh, e aí eu tenho aqui, ó, esses mock choice e mock response são mo em inglês é de mentira, né? Certo? Então é uma resposta enganando, né? O market down se passando como se fosse a Open e aqui, ó, está o Gemini client adapter. Qual é a questão? Porque a Open existe aqui esse método create, tá? E o o client do Gemini não existe esse create, tá? Por isso que dá erro você tentar fazer direto. Então, fazendo isso, o que que eu faço? Receber as receber as mensagens, recebe o model, recebe esses argumentos, mas eu vou ignorar essa parte aqui, né? e vou usar somente as mensagens para poder trabalhar com o Gemini, que é só que me interessa. Aqui dentro eu vou passar qual é o client e também a API Ki, né, do sistema. Beleza? Então assim, tranquilo de fazer. Você usa a minha classe aqui que é o meio que um conector, um adaptador. É como se fosse aquele adaptador que você tem de três pontas e você quer adaptar para um de dois, né? Para funcionar em uma tomada de três, a ideia é a mesma, certo? É um design part que a gente usa como adaptação, tá bom? Então, beleza, fechando aqui, ó, eu já falei que eu preciso instalar então o pillow. Então, vamos instalar o pillow assim, ó. Uve pillow, tá? E aí agora, ó, tá instaladinho o pillow, a gente pode usar, OK? Então, para usar o Gemini, eu preciso instanciar o adaptador, que vai ser exatamente isso aqui. Para o adaptador eu vou passar quem? AP e o model name. Só que eu ainda não importei, por isso tá branco assim, ó, e dando erro. Então, ten que fazer aqui, ó, from GNI adapter import. Beleza? Quando dá certo, ó, fica verdinho aqui, tá? Muda de corpo. Então, muito bem, o adaptador está pronto. Próximo passo então é fazer exatamente como foi feito aqui, ó. Beleza? Então, vou copiar, vou até copiar e colar lá, ó. A gente vai copiar e colar lá. Só que o client agora vai ser quem? Esse carinha aqui, ó. tá alterado, certo? OK. Aqui no lugar do LLM model, ó, eu vou trocar para o model name, beleza? Aqui, ó, para model e depois basta eu fazer exatamente igual como eu fiz na Open Então, o que que eu vou fazer? Eu vou copiar aqui, né, ó, vou copiar esse código aqui, certo? que que salva, né, os dados, né, a conversão da imagem markdown no arquivo MD, que é o arquivo markd, beleza? Criando adaptador, criando mark down, tudo certo? Agora eu vou pedir para converter aquela imagem em markdown. Só que agora, veja, ele entrou aqui, ó, no nosso GNAI adapter. Você viu que deu certo? E agora o que que vai acontecer? Ele vai pegar as mensagens, os prompts e tudo mais, ó. mensagem, né? Aqui, ó, prompt prompt. Então, se tiver prompt aqui, ó. Qual é o prompt? É o que eu escrevi. Em três parágrafos descrevo a imagem detalhadamente. E agora tem também o quê? A URL da imagem, né? URL da imagem, que é exatamente essa URL aí, tá? Lindona que já o Marktown já fez a conversão e já baixou essa imagem. Então, agora o que eu vou fazer? Vou transformar essa imagem em base 64. Vou ler, né, a partir do pillow, vou abrir essa imagem. E agora eu vou mandar a imagem para o nosso cliente do Gemini, de fato, tá bom? Então agora o que que vai acontecer? O Gemini vai ser chamado aqui, ó, e agora vai ser processado. Gemini vai descrever a imagem pra gente e a gente depois retorna pro Marketd. O MarkD vai achar que é um openi, mas ele vai aceitar normalmente porque o nosso adaptador está funcionando tranquilamente. Ó, aqui nesse caso você pode ver que em text result aqui, ó, tem o texto todo da transcrição da imagem, certo? E aí quando eu retorno aqui esse mock response, ou seja, tô enganando mais uma vez a classe lá do marketd, ele vai retornar um objeto como se fosse mock response, tá bom? Então vamos nessa, ó. Próximo passo agora é pegar o resultado, ó. Já está na mão aqui. O resultado é um objeto. E o e para terminar a gente manda converter o arquivo em markdown. Beleza? E agora tá aí, ó. Metodologia um, metodologia zero, né? Um. Essa aqui foi feita pelo J9 e essa aqui foi feita pela Open. Nine. Vocês vejam que é muito parecida, né? Ó, a aqui a imagem representa um fluxograma detalhado e ilustra etapa tarará. é focado no sistema de revisão sistemática. Você veja que é muito parecido. Agora o que eu vou fazer é o seguinte, eu vou pegar essas duas definições, vou abrir tanto o GPT5 como o Gemini Banana e vamos pedir para gerar essa imagem, porque se a se a descrição tiver boa, pelo menos alguma coisa parecida vai acontecer, tá? Então, vou fazer GNI com Gemini e vou fazer open com Opene. Muito bem, estou aqui no Gemini, já copiei a descrição lá, vou colar aqui, né? Vou ativar o banana aqui, nesse caso, vou colocar aqui uma tag image, né? Barra image. É aqui dentro que eu vou colocar essa descrição, tá? E eu vou dizer aqui o seguinte, ó. Crie uma imagem com base na imagem, né? Ok, vamos então copiar aqui o que foi gerado pelo Gemini. Vou voltar aqui no banana e vou colocar aqui. E agora ele vai gerar a imagem para mim. Saca só como é que vai ficar legal. E olha aqui, ó. Está pronta a imagem. Veja que tem um fluxo muito parecido com a minha imagem, né, que eu criei. Bom, essa aqui é a imagem original e agora a imagem que foi gerada pelo JNI é essa aqui, ó. Então, ó, pode ver que tem tudo a ver. Legal, né? Então, apesar dele ter colocado um design diferente, eh, os títulos tá um pouquinho estranho, beleza? Mas o resto eh parece que tá bom. O próximo passo é gerar uma imagem com base na descrição do da Open. Então aqui, ó, o negócio é o seguinte, vamos aqui então para nosso projeto. Aqui eu vou pedir para a a metodologia um, que é quem foi gerado pela Open. Então vamos aqui, ó, voltando, eu vou colar, né, dentro do chat EPT, exatamente a descrição da imagem e eu espero que a imagem fique também bem parecida, né? Vamos ver. Bem que o Banana é bem melhor do que o GPT5, né? O GPT5 tem um pouco mais dificuldade do que o Banana. Muito bem, essa aqui é a imagem criada pelo chatt. E agora eu vou baixar essa imagem aqui. Vou pegar essa imagem, vou salvar essa imagem. Vamos ver como é que se saiu, né, o GPT em comparação ao Gemini. Vamos colocar a imagem aqui. Essa é a imagem. Veja que ele duplicou selection aqui, né? Tá certo? Eh, mo bem, nenhuma chegou perto do que eu fiz, né? Eu acho que a que eu fiz ficou mais bonita, ficou bacana essas áreas aqui. Mas enfim, a imagem foi descrita, as informações aparentemente estão corretas, tá? Eh, tem uns errinhos de de texto aqui, mas é porque o texto, nesse caso aqui, ó, ele tá meio deitadinho aqui, né? Então, foi uma dificuldade que tanto o Gemini como a Open tiveram de para descrever a imagem. Tá bom? É isso. Olha só, agora eu vou te falar como é que você vai conseguir esse código que eu acabei de criar, beleza? Para você conseguir esse código que eu criei, o link está na descrição aqui embaixo. É um grupo de WhatsApp. Você vai entrar nesse grupo e vai solicitar, né, o código e eu vou est lá, vou te passar esse código. Qualquer dúvida também você pode conversar comigo, beleza? Então basta você realmente clicar aqui embaixo no link da descrição, entrar no grupo do WhatsApp, faz parte com a gente da comunidade que você vai gostar bastante. Beleza? Eu espero que você tenha gostado desse vídeo. Um grande abraço para você e até a próxima.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Como transformar imagens em descrições em Markdown utilizando a ferramenta Mark It Down e IA, com integração de OpenAI e Gemini e demonstração prática.",
            "resumo": "O Sandec apresenta como transformar imagens em descrições escritas em Markdown através da ferramenta Mark It Down, desenvolvida pela Microsoft. O vídeo enfatiza a importância de usar uma LLM para descrever imagens em PT-BR e mostra como integrar modelos da OpenAI e do Google Gemini. O conteúdo cobre o fluxo de trabalho, desde a configuração do ambiente (instalar Mark It Down, criar arquivo .env com chaves API) até a criação de um cliente de LLM, seleção de modelo e definição de um prompt em PT-BR para gerar descrições detalhadas. Em seguida, ele demonstra uma aplicação prática: carregar uma imagem, gerar o texto descritivo em português e salvar o resultado em um arquivo. O objetivo é facilitar a geração automática de descrições de imagens para uso em agentes, sistemas ou leitura de conteúdo.",
            "assunto_principal": "Transformação de imagens em descrições em Markdown com IA usando Mark It Down e integração de LLMs (OpenAI e Gemini).",
            "palavras_chave": [
              "Inteligência Artificial",
              "Markdown",
              "Anote isso",
              "Modelo de Linguagem de Grande Porte",
              "OpenAI",
              "Gemini",
              "descrição de imagens",
              "Interface de Programação de Aplicações",
              "Configuração de ambiente",
              "Python",
              "GitHub",
              "Microsoft"
            ],
            "resumo_em_topicos": "## Contexto\nO vídeo apresenta a ideia de converter imagens em descrições em Markdown usando Mark It Down e IA.\n\n## Ferramenta\nExplicação sobre Mark It Down, ferramenta da Microsoft, com suporte a LLMs para descrever imagens.\n\n## Integração de LLMs\nOpenAI e Gemini; menção de possíveis estratégias para compatibilidade.\n\n## Configuração\nPassos conceituais: instalação, arquivo .env com chaves de API, configuração do cliente LLM.\n\n## Fluxo de uso\nCriar cliente LLM, selecionar modelo, definir prompt em PT-BR, processar a imagem e salvar o resultado.\n\n## Demonstração\nExemplo prático com uma imagem do vídeo anterior, gerando descrição detalhada em PT-BR e salvando em arquivo.\n\n## Observações finais\nReforça utilidade para uso em agentes, sistemas e geração de conteúdo.",
            "prompt_tokens": 2133,
            "completion_tokens": 4558,
            "model": "gpt-5-nano",
            "cost": 0.0079
          },
          "analysis_time": 83.22761988639832,
          "language": "",
          "view_count": 1650,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@codigofontetv",
      "name": "@codigofontetv",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "Z5SmACDIhoM",
          "title": "VEJA COMO CRIAMOS UM APP NO LOVABLE + SUPABASE",
          "title_pt": "Veja como criamos um aplicativo no Lovable + Supabase",
          "url": "https://www.youtube.com/watch?v=Z5SmACDIhoM",
          "published": "2025-09-22T14:23:43.922592",
          "published_relative": "há 23 horas",
          "duration": "19:27",
          "date_published": "2025-09-22T07:01:01-07:00",
          "transcript_available": true,
          "transcript": "As ferramentas de A não param de aparecer. Eu sei que é difícil acompanhar isso tudo, por isso a gente só traz coisas aqui pro canal que a gente acredita realmente que tem potencial. E hoje é a vez de brincar um pouco com o famoso Lovable. >> Agora fica calmo que isso não quer dizer que necessariamente a gente precisa correr pras colinas, pois o VS Code vai acabar, viu? Mas que é bom a gente saber extrair o máximo dessas ferramentas, até porque tem muita demanda na área de software que já dá pr resolver com prompt muito bem feito. >> E nós preparamos aqui um prompt inédito aqui no canal pra gente ver se o Lovable vai dar conta. Seja muito bem-vindo a este mão no código aqui com a gente no código Fonte TV. E se você gosta já aproveita e deixa o seu like. Se você acompanha a gente, já sabe que nós estamos testando várias ferramentas, né? A galera do Lovable gostou da ideia e pediu pra gente testar o Lovable. E é bom que eles deixaram a gente assim, super à vontade para testar, né? >> Assim, se funcionar, beleza. Se não funcionar, beleza também, tá? Então, eles deram pra gente alguns créditos pra gente testar. A gente vai ver também se a gente vai usar muitos desses créditos para ver se realmente compensa fazer um sistema, né? Só que dessa vez a gente vai criar um sistema que vai fazer uma interação com uma API do YouTube. E cara, usar API do YouTube não é algo assim tão trivial, tá? Usar a API geralmente é mais fácil, mas a do YouTube tem várias restrições, então a gente vai ver se o lobo vai conseguir integrar com isso. E principalmente porque além de gerar a parte visual do projeto, a gente também vai fazer uma integração com um banco de dados, justamente para não ficar a chave da PI exposta, né? Então vamos ver como funciona essa parte com o Lovab. Qual é a ideia no compilado do nosso podcast? Se você não acompanha, ai ai. Você tem que se inscrever lá no canal do Confilado. Nós fazemos sorteio toda semana dentro do episódio completo. Então, toda semana tem lá domingo, 8 horas da manhã o o episódio e a gente faz um sorteio usando o quê? Os comentários do vídeo. Então, a gente precisa pegar os comentários, fazer ali muitas vezes um filtro e depois escolher um vencedor para levar ali camiseta, leva boné e leva vários prêmios. Então essa é a ideia. a gente vai criar uma aplicação para fazer esse tipo de sorteio. Então, já estamos logados aqui, só para mostrar para vocês quantos créditos eu tenho, ó, 99.8, tá? Porque eu já fiz alguns testezinhos. Então, eu quero ver realmente se a gente vai usar muito desses créditos para criar a nossa aplicação. Outra coisa também que eu percebi é que já existe vários promptes pré-prontos. Aqui tem prompt das comunidades, você tem várias coisas aqui, porque quando você coloca uma aplicação lá, ele coloca como público. Então você consegue ver os projetos das outras pessoas, tá? Quando você publica a aplicação, >> eu dei aquela xeretada também na documentação do Lovable e achei muito interessante ali as dicas que ele dão para você fazer os melhores prompts possíveis. Então isso é interessante que dá pra gente utilizar aqui, é óbvio que nós já fizemos na construção do nosso prompt, mas também dá pra gente utilizar com qualquer outra ferramenta de a generativa. >> E o princípio que eles usam é o framework clear, tá? Esse é o framework principal para você criar os seus prompts. E o interessante disso é que é voltado justamente pra criação de aplicações, tá? Não é só pedidos genéricos. E isso vale para várias ferramentas, tá? Então essa documentação deles aqui é praticamente um curso de engenharia de Prompt. E deixa eu dar uma explicadinha no nosso Prompt. Construi uma aplicação web para sortear aleatoriamente um comentário de um vídeo no Opa, escrevi aqui YouTube. O nome da aplicação será Sorteio Código Fonte TV. Aí eu coloquei aqui tem um formato de markdown. Inclusive o Markdown é muito utilizado dentro dos prompts. A gente vai até criar um conteúdo específico, quem sabe um miniurso para ensinar a usar corretamente Markdown. Eu separei por funcionamento, depois design e depois mais informações. Então a aplicação terá um formulário para colar o link de um vídeo no YouTube ou detectar o último vídeo publicado em uma playlist do podcast compilado do código Fonte TV. O ID do canal no YouTube. Aí eu botei o ID do meu canal e ao carregar o vídeo escolhido, a aplicação carregará os comentários do vídeo utilizando a P do YouTube, ignorando as respostas dos comentários. Será mostrada uma lista com os comentários carregados e o total. Aí bota, ó, será opcional fazer um filtro por alguma palavra específica. Por fim, o sorteio será feito por um botão e um desses comentários e apresentará o resultado no formato de um card, contendo foto, nome, link do comentário, data e o próprio comentário. E aí a parte de design, coloquei aqui visual moderno, responsivo e amigável. Design da aplicação deve seguir as cores da imagem anexo. Já vou anexar a imagem. Crie uma opção para troca de temas. botar aqui um dark light >> e cria animações leves pros elementos. A parte de design é essa. Mais informações, ó, o link padrão da playlist é a playlist que a gente utiliza no compilado com os episódios completos. Então a gente vai saber sempre que ele vai pegar sempre o último episódio completo para fazer o sorteio, né? >> Aí é uma questão de regra do nosso negócio, só valem os sorteios pro último episódio completo e não pros cortes, né? >> Isso. E aí eu já botei uma informação que eu já tenho a a chave da API do YouTube pra consulta. E aí o que que eu vou fazer? Vamos fazer um print aqui do nosso site de links, tá? Eu quero que fique aqui com esse visual, ó. Vou anexar aqui a imagem e vamos ver isso rodando. Começou a processar, fez o upload, tá pensando, vamos deixar ele pensar com calma, tá? >> Enquanto isso, a gente vai tomando café aqui tranquilamente, >> só no vibe encoding, né? E aqui, olha, a gente consegue ver, já tem um no maisinho aqui no canto, ó. Atachá, você tem o histórico, porque que acontece quando você faz uma alteração, pelo que eu vi, né, e você não curte, você pode voltar exatamente o estado anterior. Por isso que você tem que fazer as coisas aos pouquinhos, tá? Você não adianta fazer muitas alterações ao mesmo tempo, porque na hora de voltar você volta coisa que tá boa, volta coisa que você não curtiu. Por isso que é é bom saber aos pouquinhos o que que você tá fazendo, né? Tem aqui as configurações do projeto e o Supas, que é esse que a gente quer integrar. Vamos ver como é que vai isso funcionar. E tem mais a área de plugins aqui que a gente não deve usar hoje. >> E nós estamos usando ali no modo edição, mas também tem um modo chat. E é interessante que quando a gente tá ali trabalhando num projeto um pouco maior do que esse que nós estamos construindo do zero, você consegue trocar uma ideia no modo chat e depois ir pro modo edição e de fato implementar aquela ideia. Então é bem legal, né? Então ele começou aqui mostrando o que vai fazer a seguir refinar e personalizar, ajuste o design, dominar e ele disse: \"Ó, seu projeto precisa de funcionalidade de back end, como salvar comentários ou informações de sorteio, sua base é a maneira simples de adicionar esses recursos sem uma configuração técnica complexa.\" E aí, ó, tem aqui já a parte pra gente conectar, né? O super base. A gente pode fazer por aqui também, eu acho. Vamos ver então aqui. Olha, eu já tenho conectado no meu workspace o Supase. Então eu precisei fazer um login lá, botei o nome direitinho, tá? Então já tenho aqui. Aí eu preciso conectar ele agora ao projeto. Então eu posso pegar aqui, ó, criar um novo projeto. Vou gerar uma senha e dá também para eu escolher, olha só, um servidor aqui na América do Sul. Então, vou criar o projeto e tá feito. Aqui eu posso, ó, ter a minha tabela, a ed functions, que é interessante. Então, o Supas funciona como um banco de dados, mas você também pode colocar funções de back end, né, com programação dentro dele também. Voltando aqui, a gente vai ver que já está conectado ao projeto. Vamos ver aqui o dashboard que ele pede aqui para ir. Ah, é justamente o do Super Base. Vou colar novamente aqui o Prompt agora que eu tenho o Supasado, porque a princípio ele criou uma aplicação em branco. >> Parece que ele não voltou no contexto, né? >> Como ele tá pedindo agora aqui a chave da API, eu vou colocar aqui. Vamos ver se agora ele consegue seguir. >> Que antes ele até tinha pedido também, né? Mas logo depois veio a parte do Super, então ficou desabilitado. >> Bom, ele tá programando, tá? Se a gente colocar aqui um show all, ele vai já vai mostrar o que que ele tá criando, ó. Tá criando aqui os componentes da aplicação. Vamos ver se vai funcionar direitinho. Já dá para ver o interessante que ele tá usando React com Typecript >> e tá criando tudo que a gente colocou de elementos da aplicação, já tá colocando em componentes separados, tá vendo? Ponto a favor, né? Porque quando a gente for fazer alguma manutenção, olhar um código, a gente consegue ir individualmente em cada componente, né? Ó, esse é o visual que ele criou aqui da aplicação. Não sei se vai tá conectado. Vamos dar uma olhadinha aqui no superabase, ó. Ele não criou aqui adun tudo. Acredito que não esteja ainda funcionando, tá? Vamos colocar aqui, ó, o último podcast. lá. Não foi possível encontrar o último. Vou pegar aqui então o link do último episódio. Colar aqui para ver. Vídeo não encontrado. Então eu acho que aqui ele ainda não tá funcional com a API. Parte aqui de trocar. Tá legal, ó. Curti. Se a gente quiser ver também parte responsiva, ó, ele vai trocando aqui. As outras rotas também, provavelmente já aparecem aqui se a gente tiver. >> Uhum. E aqui eu consigo ver a lista de arquivos que ele criou até agora. Ó, já tem o arquivo env ali, tem ali toda a parte de código. Será que dá para alterar? Dá, dá para alterar. >> Importante. >> Mas agora a gente tem que tentar implementar justamente essa parte da API, né? Então eu vou pedir aqui, ó, a consulta via API do YouTube não está funcionando. Crie uma solução para que eu possa adicionar a chave de forma segura. Então ele pensou aqui por 54 segundos e justamente, ó, a solução que ele deu é criar uma ad function no Supa base. E aí ele tá pedindo novamente aqui >> a chave, >> a chave do token. Vamos ver se ele vai fazer. Dá para ver que ele tá criando uma pasta Supra Base Functions e tá colocando ela lá, ó. A gente pode até monitorar para ver se ele realmente vai criar, ó. Por enquanto não. Olha, a secretá aqui, né? Vamos ver a function. Vamos ver aqui se ele consegue carregar, por exemplo, o último podcast. Não foi possível. Tá >> dando erro. Vamos ver se com link tá indo, né? >> Também não. Ó, Ed Function está lá. A gente pode ver o log, ele tá dizendo justamente aqui, ó, que deu um erro. Ele não tá conseguindo ler a YouTube a API, né? Então vamos tentar resolver isso. Então ele tá pedindo novamente a chave. Vou colar aqui a chave. Vamos atualizar. Vamos ver se agora vai funcionar. A gente tenta aqui pelo último podcast. >> Ah, pegou aqui o último. Aí tem. Ah, legal que ele já trouxe aqui, ó. >> Os comentários aqui. E tem aqui o filtro, ó, que eu posso filtrar por alguma palavra. Vamos sortear aqui para ver, ó. E já sorteou. O legal é que ele trouxe o avatar que vou fazer um novo sorteio, ó. Porque essa parte de pegar avatar aqui assim não é tão trivial assim no YouTube, tá? Adinha, >> né? Então trouxe a data, a quantidade de likes, >> colocou aqui o comentário. >> Show de bola. >> Se colocar na versão light aqui, acho que não tá legal, né? >> É, não tá legal, né? pode >> acertar isso também. Olha só o que que eu vou fazer de mudança. Então, eu ativei aqui o modo chat, é o modo que você conversa com ele sem nenhuma ação e depois ele cria um plano para executar. Você pode trocar uma ideia com ele para isso, né? Então eu botei assim, ó, ajustes, cria um botão no card do comentário sorteado para fazer download como imagem e o cardário sorteado no modo light, como a gente tinha visto aqui, ó, não está dando leitura. >> Uhum. Então ele fez a análise, ó. >> Uhum. >> E vai propor aqui as correções, ó. Melhora no ex, ajuste no design e por aí vai. Então vamos ver se ele acertou. Dessa vez eu vou colar aqui o vídeo. Trouxe aqui. Vou fazer um filtro. Vou colocar aqui, por exemplo, boné. Eu sei que pessoal digitou boné lá no no último episódio, ó, ele já filtrou aqui por 29. Excelente. E vamos sortear aqui um comentário, ó. Então, já sorteou o lucro. Vou botar no modo light aqui. Já melhorou. E vou fazer o download. Ó, ele adicionou aqui o botão, ó. Mas aí não deu leitura. >> É verdade. >> Então, a gente precisa acertar isso também. Então eu vou pedir que a imagem exportada no download seja com fundo escuro, tá? >> Uhum. Isso você pediu no modo chat de qualquer forma, né? >> Isso ver que ele já entendeu ali qual o problema. Vamos ver a implementação. Lembrando que se você vier aqui, ó, no histórico, a gente consegue ver todas as mudanças que foram feitas, ó. E a gente consegue reverter isso se a gente quiser. Por isso que, ó, lá apareceu mais uma. Por isso que toda vez que você fizer uma mudança, tem que fazer aos pouquinhos para você poder voltar caso não dê certo. Então vou fazer de novo o filtro, ó, e vou sortear. Vamos fazer aqui o download. Só testando aqui, ó. Deu leitura. Vamos fazer um download. Agora sim, o download feito aqui >> no formato de imagem. Além disso, olha, você pode conectar esse repositório com um no repositório no GitHub. Eu recomendo inclusive. >> Sim. Porque aí ele sincroniza as mudanças que você fizer também no repositório. E todo esse código aqui, se a gente olhar, por exemplo, ah, que tecnologia que ele usou, né? Lá na ed function eu vi que ele usou o Dino. Vindo aqui no pack, a gente vê que ele usa o Vit React e usa várias outras coisas aqui, ó. Node, tá vendo? Tem Wind. Acho que esse é o padrão, mas você pode pedir também uma stack no seu prompt para ele utilizar quando ele for desenvolver. Além disso, quando você publica o seu projeto, ele já tem aqui uma versão preview, tá? Então você consegue pegar esse endereço e jogar para alguém testar. Você pode também publicar ele com um nome mesmo no lovable. E aí é é aqui por padrão, vai ficar público para todo mundo ver. E você pode adicionar também um domínio seu, que também recomendo, que é o que a gente vai fazer aqui, pra gente poder acessar essa aplicação com um nome mais eh o endereço mais bonitinho. Agora, uma coisa legal que ele tem que você p Ah, ah, todo mundo fica preocupado com segurança. Eu fico, você fica também. >> Acho bom ficar. >> Pois é. E ele tem um recurso aqui, ó, que é free, ou seja, ele não contabiliza ali na nos seus créditos de validação de segurança. Então, ele deve ter vários promptes ali, ó. Vamos fazer um review aqui de segurança. Ele vai jogar isso aqui no chat e vai fazer uma validação, pelo menos com os critérios que ele já tem ali imputado, se existe algum problema de segurança, de vazamento que pode ser identificado nessa etapa. Então, ó, ele fez a validação, diz aqui que tá tudo OK. >> Uhum. >> Testou várias coisas, ó. Sanitização e rate limiting. Legal, ó. E inclusive, se é um projeto que você precisa colocar para ser indexado no Google, ele também tem ferramenta para fazer otimização de SEO, o que é muito importante. >> Foi bom que ele passou no próprio teste, né? Ele gerou o código, viu se estava seguro e aprovou. Então, tá bom. E também tem o modo de edição, né, onde a gente consegue ajustar, por exemplo, ali, tá o copyright de 2024. A gente pode ajustar ali no próprio visual, né? >> Ativando aqui no chat, no cantinho, você pode alterar, você clica no elemento que você quer alterar, você pode alterar manualmente, ó. Então, a gente pode vir manualmente aqui e fazer esse ajuste. Ou você com esse elemento, você pode pedir também no chat exatamente o que você quer que aconteça com esse elemento. Então, >> interessante que você faz um prompt ali específico para aquele elemento, né? Então não precisa nem ficar ali descrevendo muito para você chegar naquele elemento. Você clica lá, vai direto nele e faz o pedido. >> Agora eu quero saber de você se você vai dar uma chance ao lovable aí para testar ele nos seus projetos. Inclusive, se a gente olhar aqui os créditos, ó, eles usaram 88. Eu usei aqui uns 11 >> arredondando ali, uns 11 créditos, né? >> Fiz uma aplicação simples, mas que já tem uma funcionalidade ali, né? >> Exato, né? teve ali a autenticação da IPAI, teve banco de dados envolvido, você vê que ele conseguiu fazer tudo. Tivemos alguns pedidos extras ali, né? Tivemos que colocar novamente o prompt, mas você vê que com pedidos ali de ajuste a gente conseguiu chegar na aplicação que nós queríamos, viu? Então o que que você achou? >> É, existem vários casos aí de sucesso já usando o lovabo. Eu acho que dessas ferramentas assim, eu acho que parece que tá mais completinha para mostrar um uma parte de back end, né? Lembrando que ele é muito conhecido pela parte de frontend, então dá para criar coisas assim bem interessante. Obviamente você tem que refinar cada vez mais o teu prompt. Inclusive tem e caso de empresa que já tá, já conseguiu faturar milhões utilizando aqui e criando aplicações com o Lovabble. Não tem jeito, a gente tem que continuar testando essas ferramentas porque elas sim geram o valor. Então, se você tivesse que desenvolver algo desse tipo, eu tenho certeza que você tem experiência, você conseguiria também fazer algo semelhante ou até melhor, né? Mas nesse intervalo de tempo, pra gente solucionar um problema pequeno que a gente tem aqui, isso aqui já ajuda bastante. >> Verdade. Indo tanto pro lado do front end quanto do back end, né? Então, claro que acho que a gente até tem o conhecimento é necessário, né? você pedir ali absolutamente sem nenhum conhecimento técnico, é muito mais difícil de você conseguir fazer uma aplicação mesmo, essa simples que nós fizemos por aqui. Mas a gente que já tem o conhecimento, sem dúvida nenhuma, é um ganho de produtividade assim, absurdo, viu? >> Bom, nós temos aqui um cupom para você testar também, o lovable, tá? Porque você, se você se cadastra, você vai ter ali a versão free, não tem muitos créditos, mas você pode assinar aqui e ter um desconto aqui para você fazer as suas aplicações e testar. O importante é você testar várias dessas ferramentas e saber qual é a que tá te atendendo melhor, tá? Espero que você tenha curtido esse vídeo. A gente se vê no próximo. >> Até lá. Ciao >> ciao.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Explorando Lovable para criar um app de sorteio de comentários de vídeos do YouTube, com integração ao Supabase e foco em prompts, design e automação de sorteios para o canal Code Fonte TV.",
            "resumo": "Neste vídeo, a equipe do Code Fonte TV testa o Lovable para criar uma aplicação de sorteio de comentários de vídeos do YouTube. Eles demonstram como obter comentários de um vídeo ou do último episódio completo da playlist do compilado, usando a API do YouTube com as restrições vigentes, e exibem os resultados sem expor a chave de API. A solução utiliza o Supabase como backend para armazenar dados e oferecer funcionalidades de back-end, incluindo CRUD e autenticação. O objetivo é uma interface com formulário para inserir o link do vídeo, carregar os comentários, aplicar filtros por palavras e sortear um vencedor, apresentado num card com foto, nome, data e comentário. Também discutem prompts, o framework Clear, opções de design (tema dark/light) e o fluxo de desenvolvimento, além de créditos para testes.",
            "assunto_principal": "Desenvolvimento de aplicativo para sorteio de comentários de vídeos do YouTube utilizando Lovable, integração com a API do YouTube e backend Supabase.",
            "palavras_chave": [
              "Lovable",
              "Supabase",
              "API do YouTube",
              "sorteio de comentários",
              "engenharia de prompt",
              "design responsivo",
              "Markdown",
              "integração de backend",
              "cartão de vencedor",
              "modo de edição/chat Lovable",
              "créditos de teste",
              "tema escuro/claro",
              "fluxo de desenvolvimento",
              "autenticação"
            ],
            "resumo_em_topicos": "### Contexto\n- Testar Lovable para construir uma aplicação de sorteio de comentários.\n- Foco na integração com YouTube e Supabase.\n\n### Objetivo\n- Sorteio de comentários do YouTube (vídeo ou último da playlist).\n- Exibir vencedor como card (foto, nome, data, comentário).\n- Manter API keys seguras; armazenar dados no backend.\n\n### Arquitetura e ferramentas\n- Lovable para a criação de prompts e fluxo de produção (framework Clear).\n- YouTube API para carregar comentários com restrições.\n- Supabase como backend (dados, autenticação, funções de back-end).\n\n### Funcionalidades\n- Formulário para inserir link do vídeo ou detectar o último da playlist.\n- Carregar comentários, opcional filtragem por palavras.\n- Sorteio via botão e apresentação do resultado.\n- Compatibilidade com design moderno e tema dark/light, com animações leves.\n\n### Considerações técnicas\n- Controle de créditos/testes no Lovable.\n- Diretrizes para não expor chaves da API.\n- Priorizar o último episódio completo da playlist para sorteio.",
            "prompt_tokens": 1978,
            "completion_tokens": 3261,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 78.34760284423828,
          "language": "",
          "view_count": 7063,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@crewAIInc",
      "name": "@crewAIInc",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ddiasmatt",
      "name": "@ddiasmatt",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@egorhowell",
      "name": "@egorhowell",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@engineerprompt",
      "name": "@engineerprompt",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "CWSYLPJz8j0",
          "title": "Qwen 3 Omni — O modelo de IA aberto que faz TUDO",
          "title_pt": "Qwen 3 Omni — O modelo de IA aberto que faz tudo",
          "url": "https://www.youtube.com/watch?v=CWSYLPJz8j0",
          "published": "2025-09-23T12:31:00.558548",
          "published_relative": "há 55 minutos",
          "duration": "15:00",
          "date_published": "2025-09-23T05:30:17-07:00",
          "transcript_available": true,
          "transcript": "Hey. Uh, what am I holding? You're holding an envelope addressed to the Internal Revenue Service IRS in Cincinnati. Inside there's a small plant with broad green leaves, likely a succulent or similar species. Okay, so the Quint team just released their latest version of their omni model which is natively multimodel. It can process videos, images, text and audio and can generate streaming responses for text and audio. This is a very significant because the type of applications that you can build on top of this natively multimodel openweight model and did I tell you it's also multilingual in nature. Quinn and Alibaba is becoming a significant player when it comes to openweight models. In fact, even for the video models, they have best-in-class image or texttovideo models which are very close in performance to some of the close proprietary models. But specifically for Alibaba or Quinn, they're really pushing the boundaries of multimodality. None of the other openweight models have such strong omni models. This is probably one of the few openweight models that can actually compete with some of the closed source models. So this is building on top of their previous work with quen 2.5 omni model but with some key architectural differences. So the previous version was a 7 billion model with thinker talker architecture. This preserved the same architecture. So you have a thinker and talker but now both of them are mixture of experts or oees. Also know they're using audio transformer for encoding the speech that is coming in directly but it's a much smaller footprint. So it's a 30 billion but only 3 billion active parameters. They also released a technical report with this new release with some very interesting key innovations. Later in the video I'll show you a couple of quick demos but let's look at some interesting details. So this can process text, images, audios and videos and can deliver real-time streaming responses in both text and natural speech. It can process up to 30 minutes of video at one frames per second. So effectively you're looking at about 3 minutes of video. Now this version is natively multilingual and it can support text interaction in 119 languages, speech understanding in 19 languages and speech generation in 10 languages. So here are the languages for speech input. I think it covers a wide variety of languages. Speech output is limited to English, Chinese, French, German, Russian, Italian, Spanish, Portuguese, Japanese, and Korean. Although in my test it can also generate outputs in Arabic, in Udu and Hindi but officially I think they are not supported in speech output. And this is a very strong Omni model. It's state-of-the-art for openweight models and can also compete closely with models like Gemini 2.5 Pro GPD 40 or transcribe. It actually has a dedicated speech transcription part which you can use standalone. and the performance is really good. But as always, it's good to test it on your own applications and your own test set. Now, with the right hardware, the speech transcription latency can be pretty awesome. So, they say that it can achieve latency as low as 211 milliseconds in audio only scenarios and a latency as low as 500 milliseconds in audio video scenarios. And actually if you look at my demo later in the video, the audio video interaction does seem very natural. You can understand up to 30 minutes of audio. It has a pretty long context window of over 100,000 tokens. And then you can also control the behavior using a system prompt. So I think even if you're doing speech transcription, you can provide a system prompt. So for example, it can be just correcting grammatical mistakes or even changing the tone of the transcription. All the new Quinn models are really good at coding and they are specifically focusing on agentic capabilities. So Quen 3 Omni supports function calling enabling seamless integration with external tools and services which are going to be critical if you want to build agents on top of this model. Okay. Okay. So an important part of this release is Quen 3 Omni 30 billion 3 billion active parameter captioner. So this is their speech transcription part which you can use as a replacement to something like whisper or parakeet models from Nvidia. If you want to use another model for speech generation, you can just use that captioner for transcription and then build the subsequent layers with some other models. In terms of the architecture, it still follows the thinker talker architecture very similar to the previous version, but now both of them are. Now the talker no longer consumes the thinker's highle text representation and conditions only on audio and visual multimodal features. This is actually critical because now this decoupling allows other modules like rag or function calling to intervene on the thinker's textual output and if desired you can supply text to talker via controlled pre-processing for streaming synthesis. Another major part is since these two are now decoupled you can have dedicated system prompts for both thinker and talker and you can control them separately. Now for audio they are introducing audio transformer which the audio encoder is directly using and this is trained on about 200 million hours of audio data which provides strong general audio representation capabilities and actually if you look at the audio output as well it's much more pleasant to listen to compared to the previous version. As I mentioned before both the thinker and talker now are based ones. Another interesting observation that they have is that mixing unimodel and crossmodel data during early stages of text pre-training can achieve parity across all modalities which is very interesting. They claim the model to have Gemini 2.5 Pro level performance when it comes to speech recognition and instruction following. Now, as always, I highly recommend to test this out, but I would say that the video capabilities or real-time video interaction is really pleasant. The speech is a lot more natural compared to the previous version. Although there are some very interesting hallucination when you start interacting with the model. Sometimes the model assume that the person it's seeing in the video is itself. So I have seen instances in which let's say if I'm showing it something it will think that the model itself is that specific person or individual and also in certain cases I've seen that the model hallucinates and would start generating responses in another language. Okay so a quick look at the benchmarks. So they claim that Quenti Omni matches the performance of samesized single modality models within the Quen series and then for modality it's best in class out of all the open weight models and matches the performance of closed source models. Now the benchmarks that they have shown here are for Omni Flash model. I'm not sure if it's exactly the same model, but even on the Quen official website, only the flash version is available. There is a demo for the openweight model on hugging face, but overall I think the benchmark performance are really good. Now in terms of the openweight models, they released three different things. One is the quentry omni 30 billion 3 billion active parameter instruct version. This is the non-thinking version. Then they have a specifically thinking version if you want reasoning traces. And then they also have this 30 billion 3 billion active captioner. So this is the speech transcription model. So let's have a quick play with the model and then I'll show you some code examples. Let's have a play with the model and see how good the experience is. For this we're going to be using the official Quen chat. In here they have quenti omni flash which seems to be a proprietary version of the omni model. So it's not exactly the openweight model but I think the experience is going to be very similar. Also I don't know whether flash is a smaller or bigger version in the platform. You can either do voice chat or video chat. Video chat per session seems to be limited to 10 minutes which is pretty long. So, we're going to try this. And if you go to the settings, not only there are a large number of different voices available, but you can also select different languages. And when you're interacting with the model, you can just directly change the language. And it seems to adopt pretty good. So, let's have a quick test. Hey, uh, what am I holding? You're holding an envelope address to the Internal Revenue Service IRS in Cincinnati. Okay. What's the PO box number? The PO box number is A02502. Okay. Uh, and what am I holding now? You're holding a book titled The Coming Wave. What would you like to know about it? Uh, who are the authors of this book? The authors of the book are Mustafa Sulean and Michael Bascar. What is this book about? Ah, you're asking about that book. It's actually called The Coming Wave. It dives into how AI, robotics, and nanotechnology are about to reshape our world. The author is Mustafa Sulean, and he's got a pretty compelling take on how these technologies will transform everything from healthcare. When was this book? The book was released on June 27th, 2023. Okay. Uh, what am I holding? Oh, so you're you're holding a terrarium. It's a glass container with a geometric shape, possibly octagonal or docahedral with a gold colored metal frame. Inside there's a small plant with broad green leaves, likely a succulent or similar species. The terrarium is filled with small pebbles at the bottom, creating a drainage layer, and the plant is rooted in soil or growing medium. Terrariums are decorative containers that house small plants in a controlled environment. Often mujahcoy video audio file upload car sneak s Auntie auntie in 9 a okay at the end it was just making of stuff uh but in the previous conversations um I have seen that it is multilingual that can speak udu or Hindi now some sometimes it it switches the context and u it's a really fun model to talk to okay so with this model. They have released a number of cookbooks on GitHub which are extremely helpful. So for example, how to do speech recognition, speech translation, music analysis, sound analysis, audio caption. They have specifically cookbooks for visual analysis, audio visual analysis, that's realtime interaction, the type of stuff that we looked at. Also agents and function calling and then omni captioner. So this is a quick example of how to use the speech to text model. So here they're setting up the model and then we're going to be downloading that specific captioner model. After that you just need to provide the path of your audio file. It can process up to 30 minutes of audio which is pretty great. And I think you can also do streaming responses. Right. So this is an audio file. Again we have another one. Right. The transcription part is extremely simple. Here's an example of working with OCR or reading text from images. So this is the initial setup of how to set up the model. That's the model that we're going to be using and then we provide the path of an image and the text is basically I think extract the information from this image. So it extracted that information or he has extract the text from the image. So this is another image as an input and this is the same text in latex format. So it's a mathematical equation that the model is able to extract. So the good thing is that you can actually provide a system instruction or specific information on how you want the model to behave. That's also going to be possible with the speech transcription. So let's say you can tell the model to correct any grammatical mistakes or maybe even rewrite the transcription in a specific format or style that you want. I'm going to probably create more detailed videos of how to build on top of this model and what type of hardware you will need. So stay tuned for that. But I hope you found this video useful. Thanks for watching and as always, see you in the next one.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta o Qwen 3 Omni, modelo de IA aberto e nativamente multimodal capaz de processar vídeo, imagem, texto e áudio com respostas em tempo real, com arquitetura Thinker/Talker baseada em MoE e suporte à chamada de funções.",
            "resumo": "O vídeo apresenta o Qwen 3 Omni, um modelo de IA aberto e nativamente multimodal capaz de processar vídeo, imagem, áudio e texto com respostas em tempo real. Mantém a arquitetura Thinker/Talker, agora com mistura de especialistas (MoE), e introduz um encoder de áudio transformer com 200 milhões de horas de dados. A versão Omni é multilíngue: interage por texto em 119 idiomas, entende fala em 19 e gera voz em 10, com um captioner dedicado para transcrição. Suporta integração com ferramentas externas via chamada de funções e oferece latência baixa (≈211 ms em áudio puro, ≈500 ms com vídeo) e janela de contexto superior a 100 mil tokens. Pode processar até 30 minutos de vídeo a 1 fps; permite prompts de sistema para ajustar o comportamento; e se destaca entre modelos open-weight frente a concorrentes fechados, apesar de algumas alucinações em vídeo.",
            "assunto_principal": "Lançamento e características do Qwen 3 Omni, um modelo multimodal com pesos abertos, com foco em desempenho, integração e uso prático",
            "palavras_chave": [
              "Qwen 3 Omni",
              "multimodal",
              "peso aberto",
              "Pensador",
              "Falante",
              "Mistura de Especialistas",
              "transformer de áudio",
              "captionador",
              "transcrição",
              "processamento de vídeo",
              "transmissão",
              "multilíngue",
              "chamada de funções",
              "agentes",
              "padrões de referência"
            ],
            "resumo_em_topicos": "### Principais pontos\n- O que é: Qwen 3 Omni, modelo aberto e nativamente multimodal.\n- Arquitetura: Thinker/Talker com mistura de especialistas (MoE), com decoupling entre os componentes e prompts separados.\n- Capacidade multimodal: processa vídeo, imagem, áudio e texto com respostas em streaming.\n- Áudio e transcrição: utilizam audio transformer e captioner dedicado, com latência baixa.\n- Linguagens: interação textual em 119 idiomas, compreensão de fala em 19 e geração de fala em 10; outputs de fala com suporte limitado oficialmente.\n- Integração: suporte a chamada de funções para integração com ferramentas externas e serviços.\n- Desempenho: benchmarking competitivo entre modelos open-weight e próximo de modelos proprietários.\n- Demos e observações: demonstrações sugerem boa experiência de voz; podem ocorrer alucinações, incluindo confusão de identidades ou mudanças de idioma durante a interação.\n- Observações finais: recomendação para testes em cenários reais e conjuntos de dados próprios.",
            "prompt_tokens": 1732,
            "completion_tokens": 4749,
            "model": "gpt-5-nano",
            "cost": 0.008
          },
          "analysis_time": 88.99916410446167,
          "language": "",
          "view_count": 438,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@eusoukelvincleto",
      "status": "error",
      "message": "Falha ao acessar https://www.youtube.com/@eusoukelvincleto/about",
      "videos": []
    },
    {
      "channel_id": "@futureoflifeinstitute",
      "name": "@futureoflifeinstitute",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@googlecloudtech",
      "name": "@googlecloudtech",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "86AY-psXRmE",
          "title": "Como conectar o Cloud Run ao NoSQL Firestore",
          "title_pt": "Como conectar o Cloud Run ao NoSQL Firestore",
          "url": "https://www.youtube.com/watch?v=86AY-psXRmE",
          "published": "2025-09-22T19:28:26.673968",
          "published_relative": "há 18 horas",
          "duration": "06:55",
          "date_published": "2025-09-22T12:12:58-07:00",
          "transcript_available": true,
          "transcript": "Welcome back everyone. In this video, you'll see how you can connect your application that's running on Cloud Run to Fire Store. Firestorre is Google Cloud's NoSQL database built for automatic scaling, high performance, and ease of application development. In this demo, I'll go over step by step how to read and write to Fire Store from your web app. We'll start this demo in the cloud shell editor. You'll see a Python Flask app that can save and retrieve user input to and from Fire Store. To use Fire Store, you'll need to enable the Cloud Fire Store API, which I've previously enabled. In this Flask app, I have an input box where a user will enter data and then we'll see their saved data below on the page. Let's get started connecting our app to Fire Store. First, we'll need to include our client library in the requirements .txt file. Next, I'll add the Firebase client library in my code. And now I'll create a reference to the fire store database. Now I'll add the code that will write some data to fire store. And here it will be whatever text the user enters. And to verify our data is in fire store, I'll just display the newly added data below on the page. This also demonstrates how fire store keeps your data updated in real time. Now our code is ready to go. Before we deploy, let's talk about following the principle of lease privilege. You can create a service account that will be used as the identity of the cloud run service that will only have access to read and write from fire store. Let's go to service accounts and create new service account. We'll give it a name fire store-sa. I'm going to copy the email address that serves as the service account identifier and I'll create the service account. Now I'll give the service account access to fire store using the role cloud data store user. I am now done creating the service account and giving it the permissions that it needs. You can see the newly created service account at the bottom of the list. Now we are ready to deploy to Cloud Run. Going to copy a command and go back to the cloud shell editor. going to open up a terminal window and maximize it. So this is using the g-cloud run deploy command. Then it provides the name of the service. Then it provides the location of the source code. And lastly, it is using a uh service account flag specifying the uh email address of the service account that will be used as a cloud run identity for the service. I'll hit enter and then I am prompted for the region because it uh is a required field and I didn't include it in the command. And I'll also say allow um unauthenticated invocations is another required command because we want to use this as a public site. As this deploys, I should note that I've previously created a default database that is multi-reional. If you have not yet created the a default database yet, don't stress. You'll get an error uh message here in this uh terminal window that will include a link where to go to create a database in your desired location. The build just completed and end to end it took a couple of minutes. Now Cloud Run is creating the revision and then it will route 100% of the traffic to the newly created revision. Now that our service is deployed, let's actually check it out first in the cloud console, let's go to the revisions tab and then under security, we'll see the service account that we created earlier and that is what Clron is using as its identity to read and write to fire store. Now I'm ready to visit my web app. I'll add some data in the input form and then I'll click save and I see the hello world ecode back to me. Now let's head over to fire store in the cloud console. I'll open that default database. And here we can see the collection, the document, and the text hello world. To recap, you saw how you can connect your Cloudr run service to Fire Store, which is Google Cloud's NoSQL database. You also saw how you can create and use a service account as the cloudr run service identity which follows the best practice of lease privilege to access fire store. You can check out the following code lab that I wrote on how to upload and serve images using cloud storage fire store and cloud run. Thank you for watching this video.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Guia prático para conectar uma aplicação em Cloud Run ao Firestore, usando Flask, com configuração de credenciais pelo princípio do menor privilégio e deploy com gcloud.",
            "resumo": "Neste vídeo, você aprende a conectar uma aplicação executando no Cloud Run ao Firestore, o banco NoSQL do Google Cloud, com Python/Flask. O demo mostra passo a passo como ler e escrever dados do Firestore a partir de uma aplicação web. O fluxo começa no Cloud Shell, com um app Flask que salva o input do usuário e o exibe em tela para verificação em tempo real. Primeiro, habilita-se a API do Firestore e adiciona-se a biblioteca cliente no código. Em seguida, cria-se referência ao banco e implementa-se a leitura e gravação. Adota-se o princípio de menor privilégio criando uma conta de serviço (fire_store-sa) com a role Cloud Data Store User, para ser a identidade do Cloud Run. O deploy é feito com gcloud run deploy, definindo a região e permitindo invocação não autenticada. Ao fim, verifica-se no Console as alterações no Firestore (coleção, documento, valor) e valida-se a funcionalidade.",
            "assunto_principal": "Integração entre Cloud Run e Firestore (NoSQL) com práticas de segurança",
            "palavras_chave": [
              "Execução na Nuvem",
              "Banco de dados Firestore",
              "Não relacional",
              "Python/Flask",
              "gcloud run deploy",
              "Conta de serviço",
              "Princípio do menor privilégio",
              "Leitura e escrita",
              "Tempo real",
              "Shell da Nuvem",
              "API do Firestore",
              "Implantar"
            ],
            "resumo_em_topicos": "### Resumo por tópicos\n- Objetivo: demonstrar como conectar uma aplicação no Cloud Run ao Firestore e salvar/recuperar dados.\n- Tecnologias utilizadas: Firestore NoSQL, Cloud Run, Python/Flask, Cloud Shell.\n- Fluxo de implementação: configurar API, adicionar bibliotecas, criar referência ao Firestore, ler/escrever dados e exibir em tempo real.\n- Segurança: criar conta de serviço (fire_store-sa) e atribuir a role Cloud Data Store User, seguindo o princípio do menor privilégio.\n- Implantação: deploy com gcloud run deploy, incluindo região e ativando invocações públicas.\n- Validação: verificar identidades/serviço no Console, confirmar dados salvos no Firestore.\n- Observação: menção a laboratório de código sobre upload/servir imagens com Cloud Storage, Firestore e Cloud Run.",
            "prompt_tokens": 1031,
            "completion_tokens": 5118,
            "model": "gpt-5-nano",
            "cost": 0.0082
          },
          "analysis_time": 80.6812252998352,
          "language": "",
          "view_count": 246,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@googledeepmind",
      "name": "@googledeepmind",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@gptLearningHub",
      "name": "@gptLearningHub",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@graceleungyl",
      "name": "@graceleungyl",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@henrikkniberg",
      "name": "@henrikkniberg",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@inteligenciamilgrau",
      "name": "@inteligenciamilgrau",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@intheworldofai",
      "name": "@intheworldofai",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "Xn7dvobcn1c",
          "title": "DeepSeek V3.1 Terminus: O MELHOR Modelo de Agente de Código Aberto! Poderoso, Rápido e Barato! (T...",
          "title_pt": "Texto: DeepSeek V3.1 Terminus: O MELHOR Modelo de Agente de Código Aberto! Poderoso, Rápido e Barato! (T...",
          "url": "https://www.youtube.com/watch?v=Xn7dvobcn1c",
          "published": "2025-09-23T01:30:59.195705",
          "published_relative": "há 12 horas",
          "duration": "11:40",
          "date_published": "2025-09-22T17:42:50-07:00",
          "transcript_available": true,
          "transcript": "Looks like the Deep Seek team is back again with a fresh new update with the introduction of their Deepseek V3.1 Terminus model. This release maintains the model's original capabilities while addressing several user reported issues. It has key improvements including enhanced performance of both the code agent as well as the search agent along with better language consistency. But overall, this Terminus model is delivering more stable and reliable output across various sorts of benchmarks compared to its previous version. Now, when you compare the Terminus model to their earlier Deepseek V3.1 update, the improvements are quite noticeable, though it's not groundbreaking, but it's still a decent upgrade. The benchmarks show a slight increase in the sway verified benchmark test with pagentic tool use and it is showcasing upgrades in reasoning benchmarks such as MMLU humanities last exam as well as a slight modest bump in live codebench. Now overall these performance are particularly with reasoning mode enabled without tool use but in essence deepseek v3.1 terminus isn't a massive leap forward but it offers meaningful upgrades in key areas like coding performance reasoning search agent capabilities and it makes it an overall great worthwhile update for many users like various developers. Now what you'll notice is that there's actually a slight decrease in performance on certain benchmarks like code force as well as ADR polygon. And the reason why is because there's trade-offs in optimization. The team might be focusing on improving stability with its reasoning capabilities which is why you see these decreases could be also benchmark variance a focus on fine-tuning the gentic tool use benchmarks which is why you see an increase on these benchmarks like sway verified as well as the terminal bench. So overall, it's not something huge to or like something to panic about, but it is something that they have done as a trade-off in terms of optimization. But here's my two cents. If you're looking for an open-source model that packs performance while also being super efficient, the Deepseek V3.1 Terminus is the model of your choice. This is due to its pricing where it's listed at 27 cents for 1 million input tokens and $1 per 1 million output tokens. The only downside is is the context, which isn't massive, but it's relative to the different models that we've seen on this channel, where it's listed to have 131k context window with a 65.6K max output. But overall, it delivers strong agentic performance and reasoning, which is definitely an unbeatable value, which we're going to be showcasing throughout today's video. If you've been hearing all the hype about AI agents, but wondering what actually works, that is exactly why today I'm excited to showcase this guide by HubSpot called Master AI Agents in 2025. The strategic advantage. This practical guide from HubSpot CMO and CVP of marketing cuts through the noise, showing you where to start, which AI agent application delivers real value, and how to implement them for real business impact. Inside, you'll discover how to automate marketing workflows with AI content creation and analytics, accelerate sales with prospect research and smarter follow-ups, and even streamline operations with automated documentation and realtime insights. Plus, you'll get a step-by-step blueprint for selecting, deploying, and measuring agents that boost efficiency without replacing jobs. So, unlock your competitive advantage. Download the free master AI agents in 2025 guide with the link in the description below. Don't watch the AI revolution. Beat it. Download this for free today and gain the strategies forward thinking companies are already using to stay ahead. Now, if you're looking to get started with this model, you can definitely do so through accessing it via Deep Seek's chatbot, which has already implemented the new Terminus model directly. Here you also have the ability to access it via API that DeepC provides. And if you want to use external provider like open router, you can even use this as well. So let's just get started with all the benchmark tests. This is where we're going to first have it create a SAS landing page that has many features. Essentially, this is something that I usually test any model out to get a good feel of its front-end capabilities as well as how well it is in terms of taking a creative approach with the prompt that I state to add as many features and how well it is in terms of just coding out various components. So, let's see what it actually ends up generating. Now, in the meantime, I'm going to have Kilo Code tackle this task powered by the DeepSeek Terminus model where I'm going to have it create a modern web browser that's similar to Chrome. And I recommend that you use Kilo Code as well cuz this is a way for you to actually access free credits and get some generations with a powerful coding agent. But essentially, this is a prompt that evaluates the model's ability to generate creative product ideas. And I'm trying to have it propose a technical feature where it can design a browser concept that balances different functionalities as well as innovation. So you can see right now with its reasoning capabilities, it is working on in-depth analysis on how it can tackle this task. And then it's going to deploy multiple agents to tackle it. So while this is generating, let's actually now take a look at what the SAS landing page looks like. Let's click run. And this is our SAS landing page, which definitely looks like a typical AI generated SAS landing page, but it has all the components that you would expect. And I told it to add lots of features. And I guess it kind of did cuz it added how it works to the section, powerful features with animations, different uh cards with different components, which you can see has been displayed. And overall, it's well structured and it looks pretty decent. So, it did pass this test and it does better than the previous version, which is definitely good to see. Now, with the reasoning enabled, this is where it's going to think before actually responding. And this is where we're going to get a better thoughtput answer. And essentially, I'm sending in this prompt where I'm telling it that I'm a truck driver making around 65K a year and I'm aiming to retire in 30 years. Could you draft up a portfolio management proposal? Essentially, it will focus on numerical reasoning as well as forecasting where it's going to be able to determine the retirement plan. It is also going to focus on different domains like asset collection, risk management. And one thing I noticed right away is that didn't actually think too much. It is something that thought for 9 seconds which isn't a lot for a reasoning model but overall it worked on creating a plan talking about the core principles the different parts to take to accomplish this strategic plan like the action plan where to put your money 401k where if you're in the states you can invest in that or a similar plan depending on the country uh different steps you can take maxing it out the portfolio etc etc but it is still going and we'll take a final look at it afterwards. And overall, we're trying to see how well it is in terms of tailoring a specific plan based off the income timeline as well as goal. Now, I sent in this exact prompt to the open router provider, and I got a better detailed answer that looks a lot structured. And this is something that I found to be better compared to what I got from their chatbot. I don't know why, but what I got from this open router answer is definitely better than the chatbot. And it looks like it did a great job in focusing on tailoring a plan to the specific income that set as well as the timeline. So after 30 years, your contribution alone would total 180k with compounding and the portfolio could be worth approximately 567K in today's dollar according to inflation, which is pretty cool. So, it was able to also consider inflation, the different principles, as well as how you can set it up depending on which country you're in. Reasoning wise, I definitely prefer these answers compared to its previous version. So, that's good to see. But now that we have finished generating the browser, let's actually take a look at it where we can reveal this in the file explorer and open it up. And there we go. This is the Nexus browser. This is something that it had generated and it looks pretty cool. You have the main dashboard, I guess, where you can access different websites. Obviously, it's not going to work, but you can see that I can click on things and I can search up different websites. I have an extension store, which is cool. I also have a settings tab I can refresh, but overall, it generated the base structure of a browser. Next up, I'm going to have it create a butterfly in SVG code. Essentially, we're trying to see how proficient it is in generating SVG code, as well as if it's able to display a symmetrical butterfly with its generations. Now, it looks like it is finished. We can click on run. And that does not look like a butterfly, but I guess it got the main body type right. I'm going to use reasoning, and I'm actually going to use the open router provider to have it generate a butterfly to see if we get a different answer. So, I've copied the code for the SVG butterfly, and I'm going to go over to this online SVG viewer and paste it in. And it looks like it failed at this, which is kind of surprising because usually with my last video on the Deepseek V3.1, I was able to create a butterfly with uh SVG code. So, it's kind of surprising. So, I've actually tried it again, creating a butterfly with deep link enabled. And this is, I guess, the best butterfly we've gotten so far. I guess it was trying to animate it, but it didn't actually create the main structure of the wings. So, I guess this is kind of a fail, which is kind of surprising to see. Now, lastly, I'm going to have it create a Minecraft clone. And usually, most models now are able to actually generate this. And looking at this so far, it definitely looks pretty cool. Now, the functions don't look great cuz I'm falling out of the map for some reason, but it added sound, which is actually pretty cool. I'm able to place blocks. I can break things. And it looks like I'm falling out of the world. So, I guess a lot of the functions don't actually work as it's supposed to, but I guess it's decent cuz I'm like struggling to stay on the world, but I can actually place things down, which is, I guess, kind of functional. But overall, you can say it kind of passed it cuz it added a lot of different features and it created the main structure of a 3D Minecraft clone. If you like this video and would love to support the channel, you can consider donating to my channel through the super thanks option below. Or you can consider joining our private Discord where you can access multiple subscriptions to different AI tools for free on a monthly basis, plus daily AI news and exclusive content, plus a lot more. But that's basically guys for today's video on the Deep Seek V3.1 Terminus model. This is a costefficient, high-erforming model which I definitely recommend that you try out and it's something that you can easily get started with through their chatbot. But that's basically it guys. Let me know what you guys think in the description or the comment section below. I'll leave all these links in the description below. Make sure you go ahead and subscribe to the second channel. Join the newsletter. Join our private discord. Follow me on Twitter. And lastly, make sure you guys subscribe, turn on notification bell, like this video, and please take a look at our previous videos so that you can stay upto date with the latest AI news. But with that thought, guys, have an amazing day. Spread positivity and I'll see you guys fairly shortly.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do DeepSeek V3.1 Terminus: melhorias de desempenho, estabilidade e capacidades de código aberto, com trade-offs de otimização, demonstrações práticas e referência a um guia de IA para negócios.",
            "resumo": "Este vídeo analisa o DeepSeek V3.1 Terminus, destacando que o modelo mantém suas capacidades enquanto corrige problemas relatados. Demonstra melhorias no desempenho do agente de código e do agente de busca, maior consistência linguística e maior estabilidade em diversos benchmarks. Comparado à versão anterior, o Terminus oferece ganhos perceptíveis em raciocínio e uso de ferramentas, embora não seja um salto revolucionário. Observam-se trade-offs: quedas em benchmarks como Codeforces e ADR Polygon, possivelmente devido a ajustes de otimização para priorizar estabilidade e uso de ferramentas de código. Detalhes técnicos incluem janela de contexto de 131 mil e preço de 0,27 USD por 1 milhão de tokens de entrada e 1 USD por 1 milhão de tokens de saída. O vídeo também mostra aplicações práticas (criação de página SAS, uso de Kilo Code) e menciona o guia HubSpot Master AI Agents in 2025 para negócios.",
            "assunto_principal": "Avaliação do DeepSeek V3.1 Terminus: desempenho, estabilidade e trade-offs de um modelo de agente de código aberto.",
            "palavras_chave": [
              "DeepSeek",
              "Terminus",
              "V3.1",
              "agente de código aberto",
              "desempenho",
              "teste de referência",
              "raciocínio",
              "agente de código",
              "confiabilidade",
              "compromissos",
              "Codeforces",
              "ADR Polygon",
              "janela de contexto",
              "preço",
              "Roteador Aberto",
              "HubSpot",
              "agentes de IA",
              "Kilo Code",
              "página de destino SAS",
              "codebench ao vivo"
            ],
            "resumo_em_topicos": "### Pontos-chave\n- Lançamento Terminus: mantém capacidades, corrige problemas reportados, melhora desempenho e estabilidade.\n- Desempenho: ganhos em codificação, busca e consistência linguística; critérios de referência como sway verified, MMLU humanities last exam e live codebench mostram melhorias.\n- Compensações: quedas em Codeforces e ADR Polygon, possivelmente por foco em estabilidade e ajuste de ferramentas de código.\n- Contexto técnico e preço: janela de contexto de 131 mil tokens; preço de 0,27 USD por 1 milhão de tokens de entrada e 1 USD por 1 milhão de tokens de saída.\n- Acesso e uso: disponível via chatbot DeepSeek, API, Open Router, com suporte a provedores externos.\n- Demonstrações: criação de página SAS, teste de front-end e capacidades de codificação com Kilo Code.\n- Guia HubSpot: Master AI Agents in 2025 para orientar implantação prática de agentes nos negócios.\n- Conclusão: upgrade significativo e atraente em relação ao custo-benefício, especialmente para desenvolvedores que buscam eficiência.",
            "prompt_tokens": 1749,
            "completion_tokens": 3050,
            "model": "gpt-5-nano",
            "cost": 0.0054
          },
          "analysis_time": 108.1322729587555,
          "language": "",
          "view_count": 4136,
          "has_transcript": false
        },
        {
          "id": "wueOVMn1VEs",
          "title": "Agente Neo: O Primeiro Agente Infinito! Um agente com IA incrivelmente poderosa que pode automati...",
          "title_pt": "Texto: Agente Neo: O Primeiro Agente Infinito! Um agente com IA incrivelmente poderosa que pode automati...",
          "url": "https://www.youtube.com/watch?v=wueOVMn1VEs",
          "published": "2025-09-22T13:30:59.195798",
          "published_relative": "há 1 dia",
          "duration": "11:24",
          "date_published": "2025-09-21T10:35:24-07:00",
          "transcript_available": true,
          "transcript": "Lately, we have seen a flood of generalist AI agents. Tools like Manis and other promising to autonomously handle tasks from generating presentations to building apps. But here's the problem. Most of them struggle to follow through on complex workflows. They often lack deep context for tension, can't adapt as projects evolve, and fail to coordinate actions across multiple tools without constant human intervention. And the thing is, they're reactive, not proactive. They might start a task, but they rarely see it all the way through. Especially when it comes to multi-step objectives or long-term projects. And with many of these tools carrying steep price tags, they aren't accessible for individual startups or anyone who's looking to use AI agents. That's exactly why I want to reintroduce a tool we've actually covered before called Flowwith Asian Neo. The most intelligent first ever Infinite AI agent that's built on an infinite canvas. Flowith is designed to run complex workflows end to end. When you turn it on, you can actually see its thought process on the canvas, breaking tasks down into steps, planning the workflow, and executing it seamlessly regardless of how hard it may be. But Flowith isn't just about Neo. It's a full AI creation workspace where multiple AI models, text, code, images, videos, and even 3D live on the same infinite canvas. Instead of jumping between apps, you can compare models outputs side by side, collaborate visually, and even let AI agents execute tasks for you autonomously in the background. For example, just take a look at Neo in action. And this is where it was able to produce a professional quality video generator. And you can see that this was a single prompt that was sent in and the agent Neo was able to work with this infinite canvas to fully develop all the different components of this app. And the results are pretty insane cuz this video app generator was able to build a PUBG trailer. And you can see these videos look absolutely amazing and they look pretty real. And what's cool is that you also have the ability to download all these different segments. But essentially, Flow with Neo is the next generation execution agent that's built to overcome the limitations holding other AI generalist agents behind. It is capable of understanding long context, autonomously navigates complex workflows, and can integrate deeply with the tools you already use. From intelligent automations to realtime data manipulation and even building complex applications, flow with Neo doesn't just assist, it executes and it can do almost anything. Plus, what's great is that Flowith has gotten a lot of major new updates which makes it even better. And this is something that you can access for free and it is open to access for all. To get started, it is super simple. Use the link in the description below and head over to Flowit. Once you are here, you can click on this button to create an account either with GitHub or with your Gmail account or with X or simply just providing your email address. After logging in, you're going to be then sent over to the main dashboard of Flowith. On the left hand side is where you can create a new flow canvas. You have a knowledge garden and essentially this is where you can upload your personal knowledge base for the AI to reference for generations. So in this case, if you want, you can upload various sorts of docs. So the AI could potentially use it for different generations. And what's also cool is you can explore different templates which we'll take a look at. And on the left hand side is where you can manage all your previous canvases. But ever since my last video, there was one thing that we didn't actually take a look at, and that was the comparison mode. There's multiple different modes that you can use. You can just primarily have flow with use online search as an agent, image or video generation, prompt enhance, or just use agent mode, which can handle everything autonomously, which we'll take a look at later on. But comparison mode is where you can get responses from multiple AI models. And it's pretty impressive cuz this is where you can compare your results from multiple models. So, if you want to get a result from something like the GBT5 Nano as well as something like the Kim K2 and even something like the Claude Opus 4, you can send in this response like writing me a YouTube script about the future of AI and you're going to be able to get an infinite canvas of all three of these models working on tackling this task. So, you can see all three of these models are working on analyzing the request. There we go. It looks like all three models have finished processing this prompt. And thanks to the comparison mode, you're going to be able to instantly test the same prompt across all these different models and see which one delivers the best one. So, for example, if I'm looking to prototype with an open-source model, but I want to realize which one would be the best for my generations, I can simply test it on front-end designing where I can test it on creating a SAS landing page. And I can select the best open- source models like DeepSeek V3.1 or you can choose the GLM 4.5. You can even use maybe open AI's OSS model, Kim K2. And after selecting, what you can do is just simply go ahead and send in this prompt. And you can see that this task was now deployed to all of these models and it's working on developing the SAS landing page for us. And there we go. It looks like all four of these models have generated the landing page. And in my opinion, the one that we got from Kimik K2 is probably the best looking one that has animations and it focus on all the components that a typical SAS landing page has like the bottom footer as well as a testimonial. And you can see that the OSS one did a fast job in generating it, but it doesn't look as qualitative as the other ones. But overall, you can see that this is a really fast and great way to compare different results from different models so that you can then finally choose the one that you want to use for your generations. And in this case, I would definitely prefer using Kimik K2. But now that we have taken a look at the comparison mode, let's now go over to the agent mode. And this is something that is where you can have it so that it could take flow to the next level. This is the infinite AI agent I was talking about that can think, plan, and execute tasks on its own. It handles complex tasks like researching online, searching Twitter, using the browser, developing research papers on its own that are pretty lengthy and qualitative. You can have it send emails, generate videos, generate even music, which is just insane. So I can give a task like building an AI powered ré tool that has many different features and I can enable agent mode by clicking on this button and I can click on start. But something else that you can do is upload different files and images and you can even have it use the knowledge base that we had talked about which was the knowledge garden. So it can refer to your knowledge that was uploaded via files, powerpoints or different types of file types. You can even configure the output length and then send in this prompt to generate our AI resume tool. This is where it's going to send it over to the AI canvas. And this will basically generate an infinite canvas to tackle all of these different tasks. And it's going to have deep context understanding of our task and make sure that there's zero hallucination and it's going to be able to thoroughly generate the best qualitative output. So at this current moment it looks like it is working on generating the different nodes to tackle like the researching phase for this task. So on the left hand side it has already created a to-do list of what it's going to do to accomplish this and it's now deploying multiple agents to accomplish different tasks like one is working on researching different rules to create qualitative resumes. Another one is talking about how to formulate the logic for an AI powered feedback engine. And you can see that it has consolidated the comprehensive results from all these individual research nodes. And if you want to take a look at it, you can actually click on this individual node and it will actually list out all the different sources that it was able to find. But if we want to change something, this is where you can talk to agent Neo and you can change the task or the requirements of your app live in action while it's actually generating. So if there's a certain component that you didn't like a part of this node, you can tell a neo that could you please change it to this requirement and it will actually do it for you autonomously. Now currently we're on the step of generating the initial version of the resume builder web page and you can see that it did an impressive job with this research phase where it talks about the proposed text stack the UX or the UI design and it is thoroughly describing how it's going to actually tackle this task. This is just the planning phase. It's not even developing the app yet. And guys, after it works on generating each of these different steps, you can actually open this up in a new tab. And this will get you a good idea of how it basically looks at this current time frame. There we go. It looks like our task is fully generated. And you can see that this infinite canvas worked on generating all the components. And you can actually visualize what it had worked upon. like in certain cases it enhances the advanced feature tool set and then at the bottom you can see that it is now available to access. It also gives you a summary of what it had focused on and generated. Now you also have the ability to share this around so others can actually access this overall prompt that you generated. What's cool is that there's also an AI assistant that you can talk to in real time and you can get responses out from it and you can actually make changes to your resume based off this AI chat. But essentially, there's a lot of features that have been added and I was able to get this output in a single shot based off of the prompt that I sent in to flow with agent Neo. If you like this video and would love to support the channel, you can consider donating to my channel through the super thanks option below. Or you can consider joining our private Discord where you can access multiple subscriptions to different AI tools for free on a monthly basis plus daily AI news and exclusive content plus a lot more. But that's basically it guys for today's video on Flowitz agent Neo. This is something that is quite impressive with its infinite AI agent that can think, plan, and execute tasks on its own. And it's something that is also great with feature sets like the templates. You also have it so that you can use different modes like the comparison mode and essentially with these different feature sets you can do so much more and it basically makes flow with one of the most powerful AI workspaces that's out there. So I'll leave all these links in the description below so that you can easily get started. Make sure you go ahead and subscribe to the second channel if you haven't already. Make sure you join the newsletter, join our private Discord, follow me on Twitter, and lastly, make sure you guys subscribe, turn on notification bell, like this video, and please take a look at our previous videos because there is a lot of content that you'll truly benefit from. But with that thought, guys, have an amazing day, spread positivity, and I'll see you guys fairly shortly. He saw falls.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Apresenta Flowwith Neo, o primeiro agente de IA infinito que planeja, executa e visualiza fluxos de trabalho complexos de ponta a ponta em um canvas infinito, superando limitações de agentes generalistas.",
            "resumo": "O vídeo discute a ascensão de agentes IA generalistas e seus limites, como falta de contexto profundo, proatividade limitada e dependência de intervenção humana. Em resposta, é apresentado o Flowwith Neo, o que chamam de primeiro agente IA infinito, construído sobre um canvas infinito para planejar, executar e visualizar fluxos de trabalho complexos end-to-end. Além de atuar como um espaço de criação de IA com modelos (texto, código, imagens, vídeos e 3D) no mesmo canvas, ele permite comparar saídas de modelos diferentes em modo de comparação, deixar agentes executarem tarefas autonomamente em segundo plano. Exemplos citados incluem um gerador de vídeo capaz de criar um trailer de PUBG a partir de uma instrução, recursos como modelos prontos, jardim de conhecimento e a possibilidade de baixar segmentos gerados. O vídeo também destaca atualizações, acesso gratuito e passos simples para começar, como criar uma conta e explorar o ambiente.",
            "assunto_principal": "Flowwith Neo: o primeiro agente de IA infinito capaz de planejar, executar e automatizar fluxos complexos em um canvas infinito.",
            "palavras_chave": [
              "Flowwith Neo",
              "agentes de IA generalistas",
              "canvas infinito",
              "execução autônoma",
              "fluxos de trabalho complexos",
              "modo de comparação",
              "modelos de IA",
              "jardim do conhecimento",
              "modelos",
              "página de destino SaaS",
              "vídeos gerados",
              "download de segmentos",
              "acesso gratuito"
            ],
            "resumo_em_topicos": "- Contexto: o aumento de agentes de IA generalistas apresenta limitações de contexto, proatividade e coordenação, gerando a necessidade de soluções mais autônomas e acessíveis.\n- Solução apresentada: Flowwith Neo, um agente de IA infinito com canvas infinito para planejar, executar e visualizar fluxos de trabalho complexos de ponta a ponta.\n- Espaço de IA criativa: suporte a múltiplos modelos (texto, código, imagens, vídeos e 3D) no mesmo canvas, permitindo comparação de saídas entre modelos.\n- Modo comparação: possibilidade de testar vários modelos simultaneamente (ex.: GPT-5 Nano, Kim K2, Claude Opus 4) e escolher o melhor para a tarefa.\n- Modo agente: modo autônomo que permite que o sistema pesquise online, use navegador, elabore pesquisas, envie e-mails, gere vídeos e até música, com referência a uma base de conhecimento (jardim de conhecimento).\n- Casos de uso: demonstrações como um gerador de vídeo que cria um trailer de PUBG a partir de uma instrução, além de recursos como modelos prontos e download de segmentos gerados.\n- Começar: o vídeo destaca atualizações, acesso gratuito, modelos e passos simples para criar conta e explorar a plataforma via link na descrição.",
            "prompt_tokens": 1790,
            "completion_tokens": 7146,
            "model": "gpt-5-nano",
            "cost": 0.0116
          },
          "analysis_time": 109.46044206619263,
          "language": "",
          "view_count": 9222,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@joerogan",
      "name": "@joerogan",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@krishnaik06",
      "name": "@krishnaik06",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@leoandradenet",
      "name": "@leoandradenet",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "myrU34WrDD4",
          "title": "Este NOVO Criador de Apps com IA vai MUDAR o JOGO? (Testei o Hostinger Horizons)",
          "title_pt": "Este novo criador de apps com IA vai mudar o jogo? (Testei o Hostinger Horizons)",
          "url": "https://www.youtube.com/watch?v=myrU34WrDD4",
          "published": "2025-09-22T21:35:19.379936",
          "published_relative": "há 16 horas",
          "duration": "14:26",
          "date_published": "2025-09-22T14:01:01-07:00",
          "transcript_available": true,
          "transcript": "Sabe aquela ideia que você vive aí guardando na gaveta e nunca consegue concretizar? Porque parece complicado demais tirar do papel? Eu tô aqui para te ajudar, viu? Hoje em dia é possível transformar essas ideias em aplicativos ou até sistemas completos usando só ferramentas de inteligência artificial. E nesse vídeo eu vou te mostrar como que isso pode ser feito com uma ferramenta nova que eu vou testar aqui junto contigo. A gente vai ver na prática se ela realmente entrega o que ela promete e eu tenho certeza que o resultado vai te surpreender. Fala pessoal, Leo Andrade na área, tudo bem com vocês? Comigo tá tudo bem. Seja bem-vindo a esse canal. Aqui você vai aprender tudo sobre desenvolvimento de aplicativos, sistemas, automações de forma mais visual. é o que a gente chama de low code, no code, vibe code. E esse canal foi o primeiro a falar sobre low code, no code no Brasil. Por isso que você tá no lugar certo. Então se inscreve para você não perder esse canal de vista. A ferramenta que a gente vai conhecer nesse vídeo chama-se Hostinger Horizons. É uma ferramenta da Hostinger e a promessa dela é ser tipo um pacote completo para você, designer, desenvolvedor e até copywritter, tudo com inteligência artificial. E a ideia é simples. Você vai descrever o que que você quer construir e em questões de minutos você já vai ter a primeira versão do seu aplicativo ou do seu sistema rodando. E o melhor de tudo é que isso já vem integrado com a infraestrutura da Hostinger, que é uma gigante no universo de hospedagem de sites e aplicações. Você vai sair já com um domínio, hospedagem, e-mail pronto, porque a Hostinger entrega um pacote completo para você. E tem um ponto que vale destaque, é que os projetos desenvolvidos com essa ferramenta, eles já são otimizados para SO e conversões. Você não precisa programar nada, basta você descrever a sua ideia em linguagem natural e ainda vai contar com suporte especializado 24 horas por dia em vários idiomas. Mas o mais interessante é que o Horizons ele não só cria, como ele também permite publicar o seu app de imediato para você já começar a colocar sua ideia no ar. E ó, não para por aí. Ainda permite você incluir recursos que deixam o projeto realmente profissional. autenticação de usuário usando Supas, o lugar onde ficam armazenados, né, as informações. Também tem as integrações com o Stripe, que é uma solução de pagamento, uma das mais conhecidas do mercado. E isso é o que transforma a sua ideia em um produto completo de verdade. E antes de eu te mostrar aqui na prática, a gente precisa aproveitar essa oportunidade para que você possa também conhecer o Horizons da Holsger 7 dias e você ainda vai ter 30 dias de reembolso. Se você usar o meu código Léo Andrade, você vai garantir 10% de desconto no primeiro mês. O link eu tô deixando aqui na descrição. É só você acessar através desse link e aí você vai poder utilizar e começar a testar também. Agora vamos lá ver como é que esse negócio funciona. Ó, eu já tô logado na minha conta da Hostinger. Eu já entrei na ferramenta Horizons aqui. Então, Hostinger Horizon. E aqui a ideia é você descrever o que que você quer fazer. E eu vou criar alguma coisa aqui da minha cabeça agora. Então, ah, quero criar um aplicativo web para, sei lá, G gerenciamento de clientes, onde eu possa cadastrar novos clientes, listar os clientes existentes, adicionar notas a esses clientes, né, e acompanhar o estatus de atendimento, tá beleza? Basicão, simplesão. Vamos ver o que que vai acontecer, como é que funciona, gente. Então, a gente escreve com bastante detalhes e aqui é tem um ponto importante, tá, turma? Quando você tá usando uma ferramenta como o Warzone aqui, você precisa eh explicar com mais detalhes e não da forma como eu tô fazendo aqui. Eu tô fazendo o mais simples possível. Que que como é como é que eu explico com detalhes? Eu explico tudo que você precisa. Então você tem que imaginar o teu sistema, o teu aplicativo. Você tem que imaginar como é que ele vai ser, as telas que ele vai ter para que você possa descrever. Então, o ideal seria assim: eh, cria um aplicativo de gerenciamento de clientes, onde eu possa cadastrar, eh, listar e e fazer a manutenção de cada cliente. Na tela de listagem de clientes, eu que é é necessário que tenha uma busca por nome e e-mail, sei lá. Eh, na hora de cadastrar o cliente, eu quero, eu preciso informar o nome do cliente, e-mail, telefone, endereço. Então, tenho que colocar as informações que eu quero. Por quê? Porque senão a inteligência artificial que tem por trás, ela vai, ela vai criar, ela vai decidir coisas. Se você não descrever, ela vai tomar decisões. Então, o ideal, o correto é você colocar todos os detalhes que você precisa. Vamos ver como é que vai ficar isso daqui. Vamos clicar em avançar e vamos aguardar. Ó, olha lá, ele criou o projeto, falou, ó, construindo a interface moderna com design glass morphing, implementando funcionalidades completas, adicionando sistema de notas, criando animações suaves. Aqui os arquivos que ele gerou, né? Ó, JSX, eh, ele inclui um dashboard, cadastro de edição, sistema de notas, status de atendimento, busca inteligente, designer, enfim. Eh, aqui aplicação, aqui eu consigo ver a parte de edição, né, editar conteúdo ou editar código. Então, eu consigo chegar aqui onde eu preciso dentro, ó, do de cada arquivo específico, né? Vamos ver se já funciona por aqui, ó. Novo cliente. Deixa eu sair de cima aqui agora, ó. Ó, apareceu aqui uma abinha. Vou colocar aqui cliente fulano de tal fulano @ã 11 empresa XPTO, endereço rua tal. Lembrando, como eu não coloquei os dados, ele assumiu os dados aqui, né? status, ó, novo em andamento, vou deixar novo. Salvou, ó, já apareceu ali o cliente. E aqui também apareceu, né? Eu consigo editar. Se eu clico aqui, ó, eu já vejo ele aqui mesmo. Então, ele fez uma single page aqui, né? Uma página só, onde contém tudo. Aqui, ó, consigo, consigo abrir uma prévia em uma nova aba, né? Então, ó, uma nova aba, deixa eu fechar aqui o essa aba. Eu consigo também fazer um tela cheia aqui, ó, dentro dessa própria dessa própria visualização, né? Eu tenho aqui a parte de integração. Então, nesse momento ele tá guardando para pra gente em memória, né, os dados. Mas eu posso vir aqui e falar: \"Olha, eu quero me conectar com Superabase.\" Venho aqui, vou me conectar na minha conta do Supase. Ó, ele vai pedir autorização. Venho aqui e vou falar que eu quero autorizar. Ó, conectou, ele encontrou lá os meus serviços. Eu vou criar um novo projeto. Criar projeto aqui. Vou criar esse projeto. Deixei o projeto com o nome que tava ali já, né? Deixa eu voltar lá agora. Vou atualizar, ó. E vou conectar nesse projeto aqui, ó. Conectar. Beleza, nesse momento ele tá construindo essa integração, né, com o Supase. Ó, ele fez mais algumas coisas, configurou o banco de dados, né? Atualizou lógica, integrou a autenticação e refinou a experiência. Então, ele já fez isso daqui para mim também. Eu vou me cadastrar, então vou colocar aqui meu um e-mail válido, né, ó. Eh, contato@leoandrade.net, colocar uma senha e vou cadastrar. Cadastro realizado, verifica sem e-mail para confirmar a conta. Ah, ele mandou um confirmação, né? Fui lá, confirmei o e-mail, vou agora entrar, ó. Entrei e agora eu vou cadastrar um novo cliente aqui de novo, né? Colocar aqui, ó, Leo Andrade, contato, esse telefone, empresa, endereço. Salvei, ó, salvou. Vamos vir aqui agora. Aqui database, tabela. Tabela cliente. Ó, cliente apareceu aqui. Vamos pegar aqui, ó, SQL. Ver se dá para olhar aqui, ó. Cliente aqui, ó. Ó, cliente cadastrado com sucesso, né? Então ele já fez a integração com Supase. Então já tem um banco de dados constru e essa ou melhor essa aplicação já tá utilizando um banco de dados, né? Que eu posso ter um um um controle maior. E aqui eu tô com a aplicação já rolando, né? Eu posso fazer mais integrações como o próprio Stripe. Eu não tenho conta agora para eu poder ligar com Stripe, mas eu tenho essa possibilidade. E aí eu também tenho a opção aqui de publicar. Como eu tô, como o Warzone é da Hostinger, ele já tem um ambiente para você poder fazer isso. Então tô publicando essa aplicação. Vou aguardar um pouquinho aqui, ó. Ele já colocou em um endereço. Se eu clicar aqui, ó, nesse endereço, é um é um domínio provisório, né? Um domínio eh para você usar. enquanto você não tem o teu, mas se você quiser depois você vem aqui registrar o domínio, você registra teu domínio e faz essa vinculação e o teu sistema passa a ter um domínio bonitinho. Mas, ó, se você acessar esse domínio, você não tiver tirado do arinda, né, você vai conseguir chegar nessa aplicação também. Eu vou fazer uma uma mudança, sei lá, uma mudança drástica aqui. Eu vou falar assim, eh, o s a aplicação está to está OK, porém não gostei do estilo. você pode alterar e criar um estilo mais light, vou colocar assim. E a parte de incluir um cliente, eu gostaria de usar popup, ou seja, não que ele aparecesse aqui do lado, né? Então, popup, que é o popup é uma janelinha. Vou pedir para ele fazer uma alteração. Vamos ver o que que vai acontecer. Ó lá, ele terminou. Eu não gostei desse desse estilo aqui agora. Mas deixa eu ver como é que ficou o novo cliente. Ó, novo cliente ficou do jeito que eu queria. Eh, deixa eu falar para ele. Olha, o estilo ficou melhor. Melhor, porém o dashboard eh, porém os textos, deixa eu dar uma atualizar aqui, pera aí. O estilo ficou melhor, porém não está sendo as cores do indicadores do dashboard claras e sem contraste. Eh, então vou tentar arrumar aqui, pedir para ele arrumar esse texto aqui. Deixa eu copiar aqui e deixa eu olhar uma coisa antes. Eu vou editar o conteúdo. Eu vou clicar aqui. Ah. Eu achei que daria para clicar aqui. Não. Beleza. Então vamos ver se ele vai conseguir acertar aqui o lugar onde eu tô querendo me referir. Ah, agora ficou bom. Agora ficou legal. E aí tá do jeito que eu queria que tivesse aqui, ó, já bonitinho, com esse popup. Então ele conseguiu chegar no ajuste que eu pedi para ele. Agora tem uma característica que me agrada mais e atingiu o objetivo, né? Ou seja, fácil é transformar tua ideia agora em um app completo em pouco tempo com o Hostinger Horizon. E isso é só o começo, sabe? Por quê? Sabe por quê? Porque a ferramenta ela já vem otimizada para SEO. Ela tem um suporte que você pode falar com o pessoal da hosting e você não vai precisar perder tempo, não vai precisar saber programar. Lógico que se souber ajuda para caramba. E acho que a grande vantagem aqui é que você pode testar 7 dias grátis, você ainda tem 30 dias de reembolso. E com o meu código Léo Andrade, você ainda vai garantir 10% de desconto no primeiro mês. Então usa o link que tem na descrição para você testar também o Warzone da Hostinger, que pô, é uma ferramenta incrível, uma empresa grandiosa que você vai gostar, eu tenho certeza, porque ela vai te suprir com tudo que você precisa para colocar a tua ideia no papel. E ó, se você não for inscrito nesse canal, caramba, se inscreve aí. E aqui embaixo nos comentários, eu quero que você me fale assim: \"Léo, eu estou precisando construir uma aplicação, um sistema, um app para tal coisa.\" Escreve aqui embaixo nos comentários, porque essa tua, esse teu comentário que tiver aqui embaixo, ele vai me ajudar a trazer um vídeo mais construindo uma coisa um pouco mais elaborada, combinado? Posso contar contigo? Então, ó, vai lá e já comenta e não deixe de dar o seu gostei nesse vídeo aqui também. Nesse momento, tá passando dois vídeos aqui para ti, ó. São vídeos que eu deixei separado para você assistir. Acho que você vai gostar, tá bom? Grande abraço, fique com Deus e até o próximo vídeo. Ciao [Música] [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Leo Andrade testa o Horizons, nova ferramenta de IA da Hostinger que transforma descrições em aplicativos com hospedagem integrada, autenticação, banco (Supabase) e pagamentos (Stripe), tudo sem código.",
            "resumo": "Neste vídeo, Leo Andrade apresenta o Hostinger Horizons, uma solução de IA que promete transformar descrições em apps ou sistemas completos sem código. O Horizons oferece um pacote que cobre design, desenvolvimento e até copywriting, com hospedagem, domínio e e-mail já prontos. O apresentador enfatiza a necessidade de descrever a solução com detalhes para que a IA não tome decisões indesejadas. Ele faz um test drive: cria um aplicativo web de gerenciamento de clientes, com cadastro, listagem, notas e status de atendimento, incluindo busca por nome/email. Em seguida, conecta o app ao Supabase para autenticação e banco de dados, publica e executa cadastros reais, visualiza tabelas e valida a integração. Também menciona possibilidades de integração com Stripe, além de um benefício de 7 dias de teste, 30 dias de reembolso e 10% de desconto no primeiro mês com o código Léo Andrade.",
            "assunto_principal": "Demonstração prática do Hostinger Horizons: IA para transformar descrições em apps sem código, com integração de hosting, Supabase (autenticação/banco) e Stripe, além de publicação rápida.",
            "palavras_chave": [
              "Inteligência Artificial",
              "baixo código",
              "sem código",
              "Horizons",
              "Hostinger",
              "linguagem natural",
              "publicação imediata",
              "Supabase",
              "autenticação",
              "banco de dados",
              "Stripe",
              "hospedagem",
              "domínio",
              "suporte 24h",
              "código de desconto Léo Andrade"
            ],
            "resumo_em_topicos": "- Introdução: apresentação do Horizons e da proposta de IA da Hostinger para criar apps sem código.\n- Como funciona: descreva em linguagem natural com detalhes para orientar a IA e evitar decisões indesejadas.\n- Demonstração prática: criação de um app de gerenciamento de clientes com cadastro, listagem, notas e status, incluindo busca.\n- Integrações: conexão com Supabase para autenticação e banco de dados, visualização de tabelas e validação da integração.\n- Publicação e recursos: publicação imediata, possibilidades de integração com Stripe e suporte 24h.\n- Oferta: 7 dias de teste, 30 dias de reembolso e 10% de desconto no primeiro mês com o código Léo Andrade.",
            "prompt_tokens": 2011,
            "completion_tokens": 3586,
            "model": "gpt-5-nano",
            "cost": 0.0064
          },
          "analysis_time": 129.50310802459717,
          "language": "",
          "view_count": 676,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@lexfridman",
      "name": "@lexfridman",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@madebygoogle",
      "name": "@madebygoogle",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "DnWykPvftfg",
          "title": "Lançamento do Google Pixel 10 | Vanilla",
          "title_pt": "Lançamento do Google Pixel 10 | Vanilla",
          "url": "https://www.youtube.com/watch?v=DnWykPvftfg",
          "published": "2025-09-23T13:06:43.787926",
          "published_relative": "há 31 minutos",
          "duration": "01:00",
          "date_published": "2025-09-23T06:06:11-07:00",
          "transcript_available": true,
          "transcript": "[“Sugar Town” by Nancy Sinatra begins playing] [Dad] Bye, kids! [Influencer] Hey, guys! [beep] [beep] [boop] [yawning] [sound of Gemini Live opening] [Woman] Gemini, which of these would be a little less expected?  [Gemini] Check out the alliums.  They’d go great with the hydrangeas below. [Woman] Will those last till Saturday? [Gemini] Yeah, they should last until Saturday if they’re kept in water and…",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Trecho de conteúdo ao vivo onde influencer e apresentador conversam sobre flores (alliums e hortênsias) com interrupções de áudio, sem abordar o lançamento do Pixel.",
            "resumo": "Este vídeo apresenta um trecho de conteúdo ao vivo com uma influencer, um apresentador e a abertura de Gemini Live. A conversa foca em uma seleção de flores, com Gemini sugerindo que as 'alliums' combinariam com as hortênsias e perguntando se durarão até sábado. A interação inclui ruídos de áudio simulando uma transmissão ao vivo (beeps, boops) e uma despedida rápida de um pai aos filhos. O tom é casual e bem-humorado, sem foco em tecnologia ou no lançamento de produto; parece ser um segmento de entretenimento ou uma paródia de programa ao vivo, destacando as dinâmicas entre apresentadores, criadores de conteúdo e produção de áudio.",
            "assunto_principal": "Conteúdo de entretenimento ao vivo com discussão de flores e dinâmica entre apresentadores, com produção de áudio, sem foco técnico em tecnologia.",
            "palavras_chave": [
              "ao vivo",
              "Gemini Ao Vivo",
              "influenciador",
              "apresentador",
              "interação",
              "flores",
              "alho/cebola",
              "hortênsias",
              "produção de áudio",
              "bips",
              "toques",
              "entretenimento"
            ],
            "resumo_em_topicos": "- Contexto: Trecho de conteúdo ao vivo com influencer, apresentador e abertura de Gemini Live.\n- Conteúdo: Discussão sobre flores, com Gemini sugerindo que alliums combinariam com hortênsias e questionando a duração até sábado.\n- Produção: Ruídos de áudio simulando transmissão ao vivo (bipes e boops) e despedida rápida de um pai aos filhos.\n- Tom: Casual e humorado, sem foco em tecnologia ou no lançamento de produto.\n- Observação: Indícios de segmento de entretenimento ou mock de programa ao vivo.",
            "prompt_tokens": 268,
            "completion_tokens": 3849,
            "model": "gpt-5-nano",
            "cost": 0.0059
          },
          "analysis_time": 110.15030312538147,
          "language": "",
          "view_count": 1177,
          "has_transcript": false
        },
        {
          "id": "fHSZeZRqXmY",
          "title": "The Design of Google Pixel 10 Pro",
          "title_pt": "O design do Google Pixel 10 Pro",
          "url": "https://www.youtube.com/watch?v=fHSZeZRqXmY",
          "published": "2025-09-22T18:37:43.787988",
          "published_relative": "há 19 horas",
          "duration": "00:19",
          "date_published": "2025-09-22T11:05:00-07:00",
          "transcript_available": true,
          "transcript": "Serene ambient noise and relaxing music",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo oferece uma experiência auditiva serena enquanto apresenta o design do Google Pixel 10 Pro pela Made by Google.",
            "resumo": "Este vídeo utiliza sons ambientes serenos e música relaxante como cenário para apresentar o design do Google Pixel 10 Pro, mostrado pela Made by Google. A produção enfatiza a experiência sensorial do usuário, destacando o estilo visual, o acabamento e a ergonomia do dispositivo, sem entrar em detalhes técnicos. O conteúdo sugere uma leitura do Pixel 10 Pro mais inclinada à estética, à identidade da marca e à atmosfera que o produto transmite, ao invés de especificações técnicas.",
            "assunto_principal": "Linguagem de design do Google Pixel 10 Pro",
            "palavras_chave": [
              "design do Pixel 10 Pro",
              "Google Pixel",
              "Feito pelo Google",
              "linguagem de design",
              "acabamento",
              "ergonomia",
              "experiência do usuário",
              "ambiente sonoro",
              "música relaxante",
              "identidade da marca"
            ],
            "resumo_em_topicos": "- Contexto: vídeo da Made by Google com sons ambientes serenos e música relaxante, centrado no design do Pixel 10 Pro.\n- Abordagem: cenário sonoro para discutir a estética do dispositivo.\n- Foco de design: linguagem visual, acabamento, ergonomia e identidade da marca.\n- Propósito: comunicar a experiência e a atmosfera associadas ao Pixel 10 Pro, em vez de entrar em detalhes técnicos.\n- Observação: a transcrição é centrada em sons, não em especificações técnicas.",
            "prompt_tokens": 159,
            "completion_tokens": 4275,
            "model": "gpt-5-nano",
            "cost": 0.0065
          },
          "analysis_time": 73.5875928401947,
          "language": "",
          "view_count": 10289,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@matthew_berman",
      "name": "@matthew_berman",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@mreflow",
      "name": "@mreflow",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@nocodemba",
      "name": "@nocodemba",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "xtQEqO2pqYI",
          "title": "Este NOVO AGENTE de IA é insano! (pode substituir o Zapier)",
          "title_pt": "Este novo agente de IA é insano! (pode substituir o Zapier)",
          "url": "https://www.youtube.com/watch?v=xtQEqO2pqYI",
          "published": "2025-09-22T14:41:08.377381",
          "published_relative": "há 23 horas",
          "duration": "04:56",
          "date_published": "2025-09-22T07:31:03-07:00",
          "transcript_available": true,
          "transcript": "Replit just raised $250 million at a $3 billion \nvaluation. In this video, we're going to test   their new agent model to see how well it's able \nto build your ideas. It promises to be more   autonomous, run for longer, and give you better \nresults. In a second, we're going to test this   out. But first, let's scroll down and see some of \nthe features in this agent 3 model. So, it says it   tests and fixes its own code, constantly working \nto improve your applications in a loop, which I   think could be really cool. That's something that \nI would love to see when I'm building with these   AI apps. It's going to have a longer run time. So, \nit says up to 200 minutes. That's a pretty long   time to actually run your code and autonomously \ngo through it. And it can even build its own   agents. So you can automate complex workflows and \nthen interact with your own agents by integrating   them into platforms like email or Slack. In \ntheory, you could build like an email agent   that could read your email and help you respond \nto it. So here are some use cases that they have   and we maybe will use these as some inspiration \nfor what we're going to test. You could build an   automation. So give me a daily update at 7 a.m. \nwith updates for my stock portfolio. A Slackbot.   Create a Slackbot to query my customer data in \nBigQuery. And a Telegram bot is another example.   also build a telegram bot to allow customers to \nbook appointments in my calendar. It seems like   it's really focused on automations here as opposed \nto building like a web app. This is more building   automations that you can integrate into your \nworkflows. So, let's test this out. I'm curious.   Let's say build an automation that will send me \nan email update every morning at 7:00 a.m. with   an update on the general stock market. So let's \nclick start building for free so we can test it   out. And here this is a similar interface \nto what I've seen before with Replit where   we have our plan and build section. All right. \nSo it created a plan. It's going to include the   following features. Automation triggered at 7 a.m. \nIt's going to get the stock market information.   Generate a formatted email and send the email \nusing the replit mail integration. So here we   can see the integration is replit mail. It knew \nto do that based on the prompt that I'm pretty   impressed with. I really like that. And the app \ntype is agents and automations. So then we can go   ahead and say build the entire app. It says it's \ngoing to take 20 plus minutes. But let's do it.   I'll just pause the video. I'll do some other work \nand then we'll come back together and see what it   creates. And here now on the left side we have \njust our chat. And on the right side it says our   automation is going to be ready soon. So I'll be \nright back and we'll see how well it did. Jumping   in real quick. It's cool that it asked me for my \nemail and it's putting this into the secrets. So,   I just added my email as the recipient email here. \nAnd also, just to jump in real quick before it's   finished, I just want to show you what it's doing. \nIt's basically going through step by step. So,   it's planning the workflow, planning \nthe automation, building out the files,   it's creating the workflow that combines the \nstock data and the email sending. So, it's doing   this all at once. Pretty impressive so far of what \nI'm seeing. And then just jumping in real quick,   we can see it's almost done. It tested, which is \nI think is pretty cool. So, it tested to make sure   that it's working and it checked at all of the \nsteps. Okay, so it says it worked. Looks like I   can test the automation maybe before publishing. \nSo, let's do that and just see how it works. This   reminds me almost like Zapier where it has a \nworkflow that it created for us. So, maybe this   is a good way to think about this is it is almost \nreplacing Zapier. There we can see it fetched the   stock data. It sent an email to me. I can see and \nI can even check my email to see what it sent. So,   let's go ahead and do that. And yeah, I did get \nan email. Honestly, really nice. I thought it was   just going to be like a text here. Let me show \nyou what this looks like real quick. But this is   what the email looks like. The design, it could be \nlike a little bit better, but overall pretty cool.   Daily stock market update. And it just has this \nactual design and not just text. So overall, I'm   pretty impressed with what it did and I'm sure we \ncould continue adding on to it as well. So let's   go ahead and click publish now. And I think it's \ngoing to be as simple as now that it's published,   I can publish the automation to happen every \nday at a specific time. So I think literally   just write in what I want to do like every day at \n9:00 a.m. and then it is just going to use AI to   translate to the right way to do that. As you can \nsee, a chron expression is a string of characters   to define a schedule, but it's nice that you can \ndo that in natural language. And then I'm not on   the upgraded plan of Replit, but you do have to \nupgrade to then publish. So then it would happen   every day at 9:00 a.m. I would get this stock \nmarket update. So I'm really impressed with Agent   3 from Replit. I'm going to have to play around \nwith it a little bit more. I'm already thinking   about what other automations I might be able to \nbuild with it. But I definitely recommend going   to Replit, checking it out. You can do it on the \nfree plan and seeing how it works for you. Leave   a comment below. Let me know if this is something \nthat you would use yourself. Are there any other   tools that you use for this kind of thing? \nI'd love to hear so I can check them out. and   subscribe to our YouTube channel to get more \nfree content like this. Thanks for watching.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do Agent 3 da Replit, que promete automações autônomas avançadas, corrigindo código, executando por longos períodos e substituindo fluxos tipo Zapier.",
            "resumo": "O vídeo comenta o investimento da Replit (250 milhões, avaliação de 3 bilhões) e analisa o Agent 3, um modelo de IA capaz de testar e consertar seu próprio código, operar por até 200 minutos e criar seus próprios agentes para automatizar fluxos de trabalho. São apresentados casos de uso como atualizações diárias por e-mail, Slackbot e bot no Telegram. Em seguida, é demonstrada a construção de uma automação que envia um e-mail às 7h com novidades do mercado, incluindo planejamento do fluxo, integração com Replit Mail, geração de código e testes antes da publicação. O processo lembra o Zapier, com uma interface de construção de automações e publicação via linguagem natural (cron). Observa-se que para publicar é necessário plano pago, e é sugerido experimentar o plano gratuito para ver como funciona. O apresentador fica impressionado e planeja explorar mais possibilidades.",
            "assunto_principal": "Avaliação do Agent 3 da Replit e suas capacidades de automação autônoma, incluindo comparação com o Zapier e demonstração prática.",
            "palavras_chave": [
              "Replit",
              "Agente 3",
              "inteligência artificial",
              "autonomia",
              "automação",
              "autocorreção de código",
              "execução prolongada",
              "agentes",
              "Slack",
              "e-mail",
              "Telegram",
              "Zapier",
              "substituição",
              "integração",
              "cron",
              "publicar",
              "plano gratuito",
              "e-mail",
              "teste"
            ],
            "resumo_em_topicos": "- Contexto: Replit apresenta o Agent 3, com foco em automações integradas e potencial de substituição de ferramentas como Zapier.\n- Recursos: IA que testa e corrige código, opera por longos períodos (até 200 minutos) e pode construir seus próprios agentes para automações.\n- Casos de uso: automações como e-mails diários, Slackbots e Telegram bots para interação com dados e clientes.\n- Demonstração prática: cria uma automação que envia atualizações do mercado às 7h, planeja o fluxo, utiliza Replit Mail, gera código e realiza testes antes da publicação.\n- Semelhança com Zapier: fluxo de automação semelhante, publicação via linguagem natural (cron).\n- Planos: publicar exige plano pago; é possível testar no plano gratuito para avaliar.\n- Conclusão: apresentação é impressionante, com perspectivas de explorar mais automações.",
            "prompt_tokens": 1610,
            "completion_tokens": 2140,
            "model": "gpt-5-nano",
            "cost": 0.004
          },
          "analysis_time": 62.948442220687866,
          "language": "",
          "view_count": 263,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@nocodestartup",
      "name": "@nocodestartup",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@oMatheusdaIA",
      "name": "@oMatheusdaIA",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@oalanicolas",
      "name": "@oalanicolas",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@odanilogato",
      "name": "@odanilogato",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ondeeuclico",
      "name": "@ondeeuclico",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "LkhF3yWdMDU",
          "title": "😱 Qwen AI FICOU IMBATÍVEL? Multi-Imagem e Consistência de Outro Nível!",
          "title_pt": "😱 Qwen AI FICOU IMBATÍVEL? MULTI-IMAGEM E CONSISTÊNCIA DE OUTRO NÍVEL!",
          "url": "https://www.youtube.com/watch?v=LkhF3yWdMDU",
          "published": "2025-09-23T11:42:59.508321",
          "published_relative": "há 2 horas",
          "duration": "12:13",
          "date_published": "2025-09-23T04:00:07-07:00",
          "transcript_available": true,
          "transcript": "Você já imaginou poder editar várias imagens ao mesmo tempo? Com uma IA que respeita as características únicas de cada foto, como o rosto, a expressão ou a pose, sem bagunçar o visual original? No vídeo de hoje, eu vou mostrar para vocês uma nova atualização do Quen, o suporte multiimagem e melhorias incríveis na consistência. Isso significa retratos mais fiéis, transformações de pose ainda melhores e aquele acabamento preciso que faz toda a diferença. Será que o nano banana do Google tá ganhando um concorrente à altura? É isso que a gente vai descobrir agora. Mas antes, inscreva-se no canal. E para ver os vídeos sem anúncios e dar aquela moral aqui pra gente, é só clicar no botão, seja membro. Fechou? Então bora pro vídeo. Bom, pessoal, hoje eu quero falar com vocês sobre essa atualização que acabou de ser anunciada pelo pessoal do Quen. Escutem aí. Quen Image Edit 2509 está no ar e é uma revolução. Não apenas o atualizamos, nós o construímos para criadores, designers e especialistas em A que exigem controle pixel por pixel. E aí eles trouxeram aqui as principais funções. Edição de múltiplas imagens, arraste pessoa mais produto ou pessoa mais cena e ele os mescla como mágica. Chega de imagens Frankenstein. E mais imagem única, consistência sólida. Os rostos permanecem os mesmos, os produtos mantém a sua identidade, o que é ideal para anúncios e pôsteres e o texto. Você edita tudo, conteúdo, fonte, cor e até mesmo a textura do material. E aí eles complementam aqui controlet integrado, profundidade, bordas, pontos chave, precisão, plugin play. E por último, eles mostram aqui onde você pode acessar a ferramenta. Pode ser no próprio Coinchat, que é o site oficial ali da empresa, no GitHub e também no Huging Face. Eu vou deixar todos os links direitinho aqui na descrição desse vídeo aí. Aqui no blog eles falam especificamente sobre esse lançamento. Quen Image Edit 2509, suporte a múltiplas imagens, consistência aprimorada. Eles trazem alguns exemplos aqui bem interessantes que eu testei e olha, funcionam direitinho. Então vamos lá pro Coinchet agora que eu vou mostrar para vocês o que eu já consegui, o que dá para fazer e quais são as limitações. Bom, começando aqui por essa imagem que tá um pouco deteriorada e tá em preto e branco. E aí eu usei esse prompt aqui, restaurar fotografia antiga, remover arranhões, reduzir ruído, realçar detalhes e assim por diante. E aí o resultado que ele trouxe para mim foi esse daqui. conseguiu colorir, removeru os arranhões e manteve a consistência da foto. Vamos lá para mais um exemplo agora. Vejam, eu dei um print nessa imagem aqui, onde eu tinha a fotografia de uma mulher e também de uma cadeira de praia. E eu pedi o seguinte: Junte as imagens em uma só com uma mulher deitada na esteira. E esse daqui foi o resultado. Então, é muito legal por ele pegou aqui todas as características da praia, aproveitou a mulher, inclusive com o mesmo vestido, e colocou ela deitada aqui na cadeira de praia. Então ficou muito legal por eu nem precisei subir as imagens separadamente. Eu tinha esse print aqui, ele entendeu que eu queria colocar essa mulher na cadeira e fez tudo direitinho. Agora esse daqui é muito legal. Eu também dei um print nessa foto aqui, que é uma foto antiga, tá bem deteriorada. Aí eu coloquei essa outra imagem aqui representando qual é a posição que eu queria que essa moça aqui fizesse. E aí eu pedi o seguinte: transformar a postura da garota da imagem dois para a mesma da imagem um. E esse daqui foi o resultado. Então ele não só melhorou a qualidade dessa imagem aqui que tava bem deteriorada, como também trocou a posição dos braços. Reparem que aqui ela tá com o braço direito levantado e o outro braço aqui no colo. E é exatamente a posição que tá nessa imagem aqui. Então ele consegue entender a posição que eu quero e faz a alteração exatamente do jeito que eu pedi. Agora aqui eu fiz a combinação de três imagens. Eu coloquei essa moça aqui, aí esse vestido e essa posição e pedi a mesma coisa. A garota da imagem um vestindo o casaco preto da imagem dois, sentada na postura da imagem três. E aí ele trouxe esse resultado aqui. Reparem que a mesma moça trocou o vestido, trocou a posição e me entregou esse resultado aqui. Eu não pedi nada com relação ao fundo da imagem e aí ele colocou esse fundo aleatório aqui, mas a posição e a roupa ele conseguiu alterar perfeitamente. Agora eu tinha essa imagem aqui que estava bastante ruim. Reparem aqui, quase não dá para ver o rosto do senhor. Tem a criança, essa mulher aqui. E aí eu pedi o seguinte, coisa simples, restaure e colorize essa foto antiga. E ele me trouxe esse resultado aqui. Então é impressionante porque de uma imagem totalmente deteriorada, ele me trouxe um resultado bastante consistente, respeitando todas as características da imagem. Eu tenho aqui o televisor, o senhor, a mulher, o bebê, a cortina, uma cômoda, tudo direitinho aqui. Ele simplesmente restaurou e colorizou a foto. Nesse daqui eu dei uma viajada. Eu subi essa imagem aqui da batedeira, essa outra imagem aqui do Superman e pedi o seguinte: Junte o Superman e a batedeira na mesma imagem. A batedeira deve estar sobre uma bancada e o Superman com uma das mãos sobre ela, como se estivesse em um comercial de eletrodoméstico. Vamos ver o resultado. Vejam. Superman, batedeira, tenho a mão dele aqui na lateral, ela tá numa bancada e parece mesmo que ele tá aqui num comercial de eletrodomésticos. Então, ficou muito bacana porque ele deixou essa imagem bem convincente. Eu tenho aqui o Superman, do jeitinho que ele aparece aqui na foto. Olha só, Superman aqui, a batedeira é a mesma e ele só transportou aqui, juntando tudo na mesma imagem. Nesse outro exemplo aqui, eu pedi para trocar o rapaz que está aqui encostado num carro preto por uma mulher loira, porém mantendo a mesma roupa. Vejam só como é que ficou. Carro preto, mulher loira e mantendo a mesma roupa aqui da foto original. Olha que legal. Então isso é muito interessante porque ele conseguiu manter a consistência exata da imagem. É o mesmo carro, a mesma roupa, porém com personagem diferente. Agora essa daqui é uma imagem que eu peguei lá no Pxels, ou seja, não é uma imagem gerada por inteligência artificial. E eu pedi apenas para colorizar. Vejam o resultado. Bem consistente, né? Ele manteve aqui todas as características do fundo da modelo, inclusive aqui com o top preto. A calça jeans, ela tá aqui com os dois braços sobre a cabeça, do jeitinho que eu tenho aqui na foto em preto e branco. Então essa coisa que eles falaram da consistência do rosto realmente é impressionante. Agora, antes de mostrar para vocês uma limitação, eu quero fazer um teste com o output final. Eu vou colocar aqui uma imagem em alta resolução e vamos ver se ele consegue entregar essa mesma imagem editada também em alta resolução. Então vamos lá. Para utilizar é muito simples, é só clicar em nova conversa. Você vem aqui e seleciona edição de imagem, sobe a sua imagem para cá clicando aqui nesse botão. A imagem que eu quero editar é essa daqui. Eu vou pedir o seguinte para trocar a cor do olho. Vamos ver se ele vai conseguir. Então eu carreguei aqui a minha imagem em alta resolução e vou fazer o pedido em linguagem natural. Troque a cor do olho para amarelo e vou enviar. Aí, mais do que a edição, eu quero comparar a qualidade da imagem que ele entrega no final. Pronto. Vou abrir aqui a imagem original pra gente ver o tamanho e a qualidade. Reparem aqui, olha, bem definido, os cílios, a cor do olho, tudo certinho. Agora vamos pra imagem editada. Olha, aparentemente ele conseguiu me entregar aqui um resultado em alta definição também. Ele trocou apenas a cor do olho que estava aqui em primeiro plano e manteve aqui a mesma qualidade dos cílios, da sobrancelha, da pele e assim por diante. Então, por esse exemplo aqui, dá pra gente perceber que ele consegue editar a imagem e na hora de entregar o resultado, essa imagem não vem com uma qualidade pior. Pelo contrário, ele mantém a mesma qualidade da imagem original. Então isso é uma vantagem, porque muitas vezes quando você faz isso utilizando uma outra ferramenta, ela até consegue editar, porém quando ela te entrega o resultado, a qualidade tá menor. Agora vamos testar esse exemplo que ele tá mostrando aqui. Eu tenho esse cachorro aqui em frente a essa porta e o prompt que ele deu foi esse daqui. Dirija-se para a direita. Vamos ver o que ele vai fazer na imagem. Esse daqui é um exemplo que eu copiei do próprio Quen. Olha, ele colocou aqui o cão mais pra direita. Então ele manteve aqui a mesma consistência da imagem. Eu tenho aqui a parede, a porta, a fechadura, tudo direitinho. É o mesmo cachorro, porém deslocado aqui pro lado direito da imagem. Então eu acho que o que eles quiseram demonstrar aqui é que é possível mover o objeto de uma cena e colocar ele em qualquer lugar. Vamos testar um exemplo prático agora. Eu tenho essa imagem aqui com três cavalos. Eu vou pedir o seguinte, apague o cavalo do meio. Pronto, já apagou aqui. Vamos ver o resultado. Olha, realmente manteve a consistência e apagou o cavalo do meio. Agora, no mesmo chat, eu vou pedir para aproximar o cavalo branco do cavalo marrom. Vejam, na primeira tentativa, ele não entendeu. Vou editar novamente e vou fazer um pedido diferente. Troque os cavalos de lugar. O branco no lugar do marrom e o marrom no lugar do branco. Vamos ver se agora ele entende. Então, sempre que você clica em editar, automaticamente ele traz a imagem aqui para baixo e aí você pode digitar o seu prompt. E agora ele entendeu direitinho, manteve a mesma paisagem e realmente trocou os cavalos de lugar. E mais uma vez dá pra gente perceber que ele manteve a qualidade da imagem original. Então ficou muito bacana porque ele conseguiu inverter os cavalos aqui colocando o branco no lugar do marrom e o marrom no lugar do branco. Agora vamos falar sobre o calcanhar de Aquiles, ou seja, as limitações. Vejam só essa imagem aqui. Essa fotografia eu peguei lá no PXs, ou seja, ela não é gerada por inteligência artificial. Aí eu pedi o seguinte para ele trocar o texto que originalmente estava escrito aqui em inglês por essa frase aqui em português do Brasil, temporariamente fechado para reforma. E esse daqui foi o resultado que ele me entregou. Ele manteve o mesmo fundo, manteve a placa, o texto atrás da cerca, só que o que tá escrito tá totalmente errado. Eu achei que era porque eu tava pedindo para traduzir um texto em inglês para português. Aí eu fiz o seguinte, o mesmo pedido, só que aí para trocar por um outro texto que também tava em inglês, era apenas para substituir a última palavra aqui embaixo. E ele também não conseguiu. Nas duas primeiras linhas, ele foi de boa, porém na última linha aqui, que era a que realmente ele precisava alterar, ele não conseguiu. E aí eu fiz outra tentativa que também não deu certo. Aí eu quis fazer um teste. Eu pedi para ele apagar apenas o texto da placa, pensando que ele ia manter a cerca ali na frente da placa. Vejam só, parece que ele colocou aqui um retângulo laranja em cima da placa. Ele não apagou nada, ele simplesmente cobriu o que tava escrito. Aí eu insisti: \"Apague o texto da placa, mas mantenha a cerca intacta\". E aí, mais uma vez, ele apenas colocou um retângulo laranja aqui sobre a placa, mas a cerca não foi preservada. Então, aparentemente, pelo que eles demonstraram ali durante o lançamento, ele consegue fazer edições, ele entende, mas desde que esteja em chinês, porque quando você tenta fazer qualquer alteração em inglês ou no nosso caso aqui em português do Brasil, não funciona direito. E não é uma coisa impossível de se fazer. No vídeo que eu gravei aqui no canal sobre a ferramenta Rev, vejam só o resultado. Eu tinha aqui a mesma placa em inglês. Vejam só. E esse daqui foi o resultado que ele entregou temporariamente fechado para a reforma. Conseguiu manter todo o ambiente, a mesma placa e o texto atrás da cerca. Então eu acho que ainda tem algo a melhorar, principalmente com relação à renderização de texto, porque eles disseram lá durante a demonstração que essa ferramenta também era capaz de alterar texto dentro da imagem, mantendo a mesma consistência. Aparentemente isso é possível por enquanto só em chinês. Quando a gente tenta em inglês ou em outro idioma, não funciona perfeitamente. Então pessoal, testem aí, tá disponível gratuitamente para quem quiser testar. Pode ser via Hugin Face, GitHub ou no próprio CoinChat. E depois volta aqui nos comentários para dizer para mim o que que vocês acharam desse novo editor de imagens que usa inteligência artificial. E aí, que que vocês acharam dessa novidade? Será que dá para brigar com o nano banana do Google? Contem para mim nos comentários, tá bom? Te vejo na próxima. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Atualização Quen Image Edit 2509 apresenta edição de várias imagens com alta consistência em rostos, roupas e poses, demonstrando várias aplicações práticas e a promessa de um fluxo de trabalho mais preciso.",
            "resumo": "Neste vídeo, o apresentador divulga a atualização Quen Image Edit 2509, que traz edição de várias imagens simultâneas e maior consistência entre rosto, produto e cenário. O recurso permite combinar imagens como pessoa+produto ou pessoa+cena, mantendo a identidade visual e evitando 'frankenstein' nas composições. O conteúdo também oferece edição de imagem única com controle de conteúdo, textura, cor e profundidade. O apresentador mostra exemplos: colorir e restaurar fotos antigas respeitando traços; juntar mulher na esteira com uma cadeira de praia; transformar a pose de uma moça em uma foto deteriorada; combinar três imagens; colorir uma foto de Pxels mantendo o visual. Ele testa saída em alta resolução, compara qualidade final, e indica onde acessar a ferramenta (CoinChat, GitHub, Hugging Face), além de mencionar limitações e o potencial diante da concorrência.",
            "assunto_principal": "Atualização Quen Image Edit 2509 com edição de múltiplas imagens e alta consistência entre rostos, roupas e poses, incluindo restauração, colorização e composição de imagens, com acesso via CoinChat, GitHub e Hugging Face.",
            "palavras_chave": [
              "Quen Edição de Imagem 2509",
              "edição de imagens",
              "multimagem",
              "consistência facial",
              "restauração de fotos",
              "colorização",
              "fusão de imagens",
              "posição",
              "troca de roupas",
              "identidade visual",
              "CoinChat",
              "GitHub",
              "Hugging Face",
              "criação de conteúdo",
              "limitações",
              "alta resolução"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Lançamento: Quen Image Edit 2509 traz suporte a edição de várias imagens simultaneamente.\n- Funcionalidades principais: edição multiimagem (pessoa+produto, pessoa+cena), mesclando com consistência de rosto e identidade dos objetos.\n- Edição de imagem única: controle de conteúdo, cor, textura, profundidade e bordas.\n- Casos de uso demonstrados: restauração e colorização de fotos antigas respeitando traços; união de elementos (mulher na esteira, cadeira de praia); transformação de pose em fotos deterioradas; combinação de três imagens.\n- Exemplos práticos: colorir foto antiga deteriorada; combinar Superman com uma batedeira; trocar o rapaz por mulher loira mantendo a roupa; colorizar foto de Pxels mantendo o visual.\n- Desempenho: saída em alta resolução parece manter a qualidade original.\n- Acesso à ferramenta: CoinChat, GitHub, Hugging Face (links na descrição).\n- Limitações e competitividade: há menções a limitações e à concorrência, com referência ao suposto rival do Google.",
            "prompt_tokens": 2003,
            "completion_tokens": 2542,
            "model": "gpt-5-nano",
            "cost": 0.0048
          },
          "analysis_time": 82.07143497467041,
          "language": "",
          "view_count": 1379,
          "has_transcript": false
        },
        {
          "id": "c3glXW1VaJg",
          "title": "(SEM AD) 😱 Qwen AI FICOU IMBATÍVEL? Multi-Imagem e Consistência de Outro Nível!",
          "title_pt": "(SEM ANÚNCIOS) 😱 Qwen AI FICOU IMBATÍVEL? Multi-Imagem e Consistência de Outro Nível!",
          "url": "https://www.youtube.com/watch?v=c3glXW1VaJg",
          "published": "2025-09-23T11:42:59.508400",
          "published_relative": "há 2 horas",
          "duration": "12:13",
          "date_published": "2025-09-23T03:58:05-07:00",
          "transcript_available": false,
          "transcript": "",
          "analysis_source": "sem_transcricao",
          "summary": null,
          "analysis_time": 16.34099292755127,
          "language": "",
          "view_count": 7,
          "has_transcript": false
        },
        {
          "id": "gCX-_sa2YwE",
          "title": "👉 Transforme Ideias em VÍDEOS com Inteligência Artificial | Testando o Boolvideo na Prática",
          "title_pt": "👉 Transforme Ideias em VÍDEOS com Inteligência Artificial | Testando o Boolvideo na Prática",
          "url": "https://www.youtube.com/watch?v=gCX-_sa2YwE",
          "published": "2025-09-22T21:42:59.508419",
          "published_relative": "há 16 horas",
          "duration": "10:36",
          "date_published": "2025-09-22T14:00:45-07:00",
          "transcript_available": true,
          "transcript": "E se você pudesse transformar qualquer ideia ou roteiro em um vídeo completo em poucos minutos, sem precisar de edições complicadas ou equipamentos caros, hoje eu vou te mostrar o Bull Vídeo, uma ferramenta de inteligência artificial que faz exatamente isso e muito mais. Mas antes, inscreva-se no canal e para dar aquela moral aqui pra gente, é só clicar no botão seja membro. Fechou? Então, bora pro vídeo. O Bull Vídeo é uma ferramenta online que usa inteligência artificial para transformar um texto em vídeo automaticamente. Ele gera cenas, legendas, música de fundo e até narração. Tudo de forma automática. E se você quiser deixar o vídeo ainda mais único, pode usar a biblioteca personalizada, enviando suas próprias imagens e vídeos para aparecerem no resultado final. Além disso, tem um editor super simples, onde você consegue ajustar o roteiro, trocar as vozes, mudar as legendas e editar cenas em questão de minutos. Bom, pessoal, depois de clicar no link que vai estar aqui embaixo na descrição desse vídeo, vocês vão se inscrever na plataforma e vão se deparar com essa interface aqui. Como a gente pode perceber, existem várias ferramentas aqui de inteligência artificial para poder produzir conteúdo. Então você tem aqui animar imagem com a removedor de fundo com a remover objeto com a aprimorador de fotos e assim por diante. Então são várias funções que estão disponíveis aqui dentro do Bull Vídeo. Hoje a gente vai focar em duas, em roteiro para vídeo e ideia para vídeo. Começando aqui com roteiro para vídeo. O que que você precisa fazer aqui? Simplesmente colar o roteiro aqui nesse campo. Ou senão você pode pedir pra inteligência artificial criar um roteiro para você. Aí vai da sua necessidade. Como eu já tenho o roteiro pronto aqui, eu vou colar. Vejam, era uma vez uma cidade futurista onde robôs e humanos viviam lado a lado. As ruas eram iluminadas por letreiros holográficos coloridos. Drones voam como pássaros pelo céu e os trens se moviam em silêncio sobre trilhos magnéticos. E aí segue todo o meu roteiro aqui. Você pode escolher o modelo que você quer utilizar para fazer essa geração. Você tem aqui o Deepsic R1 ou o GPT 4 ou Mini. Eu vou escolher aqui o GPT4 ou Mini. No formato aqui eu vou deixar em 9x1, que é aquele formato em pé. Ah, e uma coisa muito legal, se você quiser, você pode trazer as suas próprias mídias aqui para dentro da plataforma. para deixar o seu vídeo ainda mais personalizado. Como é que você faz isso? Vou voltar aqui no começo, vou clicar em meu espaço, nova pasta, vou dar um título paraa minha pasta, vou criar. Pasta criada, é só clicar sobre ela, fazer o upload de mídia. Vou selecionar todas as mídias que eu quero. Vou clicar em abrir. Essas mídias vão ser carregadas aqui na minha pasta. Pronto, mídias carregadas. Agora vou voltar aqui em criar vídeo. Roteiro para vídeo. Colar o meu prompt. Escolhe o modelo novamente. Formato 9x16. Biblioteca de mídia. Biblioteca personalizada selecionada. Clicar em next. E agora é só pedir para gerar. Ele vai começar a pensar aqui para gerar o meu roteiro. Vai gerar as legendas, a narração e depois vai me entregar o vídeo. Prontinho. Pronto, ele já terminou aqui. Vamos ver a primeira cena. Era uma vez uma cidade futurista onde robôs e humanos viviam lado a lado. As ruas eram iluminadas por letreiros holográficos coloridos. Drones voam como pássaros pelo céu e os trens se moviam em silêncio sobre trilhos magnéticos. Bacana. Se você não gostar, é só clicar aqui em substituir. Então você pode alterar a imagem de qualquer parte aqui do seu vídeo. Eu vou selecionar essa imagem aqui, vou pedir para substituir. Aí aqui você pode cortar e pegar exatamente o ponto que você quer. Depois de fazer isso, é só clicar em aplicar. Pronto, ele já substituiu. Vamos ver como é que ficou. Era uma vez uma cidade futurista onde robôs e humanos viviam lado a lado. Pronto, achei que ficou bem melhor. Então você pode repetir esse processo de substituição em todas as imagens que aparecem no seu vídeo. Além disso, se você não gostar da narração, você pode clicar aqui em substituir voz. Aí você vai cair nessa página aqui para poder escolher qual voz se adequa melhor, dependendo do idioma. Se você tiver fazendo um conteúdo em português do Brasil, já tá selecionado aqui. Senão, existem todas essas outras opções aqui que você pode utilizar para fazer a narração do seu conteúdo. Eu vou deixar em português do Brasil. Ah, e uma coisa importante, se você escolher qualquer uma dessas vozes aqui e quiser que a inteligência artificial aplique essa voz no seu vídeo inteiro, você precisa selecionar essa opção aqui, aplicar todas as narrações. A partir daí, ele vai pegar essa voz que você escolheu e vai colocar no seu vídeo todo. É isso que a gente vai fazer agora. Eu vou clicar aqui em aplicar. Pronto, ele já substituiu. Vamos ver como é que ficou. Era uma vez uma cidade futurista onde robôs e humanos viviam lado a lado. Pronto, ficou bacana. Agora, nesse menu aqui de baixo, existem algumas opções bastante interessantes. Você pode gerar automaticamente uma nova cena ou ter uma ideia para uma nova cena. Você pode adicionar uma cena em branco. Você pode preencher um pedaço de uma cena. Se você quiser, você pode aplicar efeitos. Então, quando você clica aqui, existem várias opções de efeitos e também de transições que podem ser aplicadas ao seu vídeo. Além disso, você pode clicar aqui nesse botão e mover cenas para baixo ou para cima, dependendo da posição que ela tá aqui na sua sequência. E se você clicar aqui nos três pontinhos, você pode duplicar a cena ou você pode deletar a cena. Agora, se você quiser fazer uma edição mais aprimorada, basta clicar aqui em editar na linha do tempo. Vejam, ele abre esse editor aqui, que é super fácil de usar. Aqui embaixo você tem uma timeline onde você pode acompanhar a evolução aqui do seu vídeo. E se você quiser, você pode fazer qualquer alteração mais aprofundada usando esse editor. Você pode adicionar áudio, narração, texto, forma, adesivo, efeitos, transições, filtros e assim por diante. Então, depois de fazer todas as edições, chegou a hora de exportar o nosso vídeo. Aí você vai clicar aqui em exportar HD. Aqui ele dá a duração, o nome do seu vídeo e também a resolução 1080p. Se você não quiser alterar nada, é só clicar em exportar. Pronto, já terminou aqui. Vamos ver como é que ficou. Era uma vez uma cidade futurista onde robôs e humanos viviam lado a lado. As ruas eram iluminadas por letreiros holográficos coloridos. Drones voam como pássaros pelo céu e os trens se moviam em silêncio sobre trilhos magnéticos. Tudo era perfeito. À noite, humanos e robôs compartilhavam experiências incríveis. Não havia inteligência artificial, era tudo inteligência humana, reverberando em todos os cantos da metrópole. A cidade era o local ideal, onde humanos e robôs viviam livremente em harmonia, compartilhando tudo em tempo real, como se fossem iguais. Viram só que bacana? Então você tem um vídeo completo, gerado por inteligência artificial, que você pode postar nas suas redes sociais e o que é mais bacana com narração, legenda e música de fundo. Vamos lá agora que eu quero mostrar para vocês a segunda função, que na minha opinião é a mais legal de todas. Então agora a gente vai testar a ideia para vídeo. Vamos lá. Agora eu não preciso colocar um roteiro, eu preciso apenas digitar uma ideia. Vejam, apresentamos a nova garrafa térmica Zion. Mantém sua bebida quente por 12 horas e fria por 24 horas. perfeita para o dia a dia. Aqui no modelo eu vou deixar o GPT 4 ao mini. Duração 1 minuto, proporção 9x16, que é o formato ali para celular, idioma português do Brasil. E lembrando, se for uma marca verdadeira, que você tenha todo o material aí de divulgação, basta clicar aqui em biblioteca de mídia e aí você vai subir o seu material para cá. Então esse é um grande diferencial do Bull Vídeo, porque você consegue trazer aqui paraa plataforma imagens de campanha, por exemplo, que você já tem aí no seu computador. Agora, se você preferir que a inteligência artificial coloque as imagens para você, não tem problema nenhum, é só clicar aqui em gerar. Então, o mais legal dessa função é que você não precisa ter um roteiro, basta colocar uma ideia e a própria inteligência artificial vai montar o vídeo para você com base nessa ideia inicial. Pronto, já terminou aqui. Vamos ouvir a primeira cena. Sejam muito bem-vindos a mais um episódio do nosso podcast. Mais uma cena agora, antes de fazer mais ajustes, você já se viu frustrado ao usar uma garrafa que não mantinha a temperatura da sua bebida? Agora, se você quiser alterar isso, é só clicar aqui em ajustes. Vejam, eu posso aumentar aqui o volume da música ou diminuir. E a mesma coisa aqui com o vocal. Outra coisa, eu posso substituir a música clicando aqui nesse botão. Se eu não gostei da música que a IA colocou no meu vídeo, eu posso selecionar qualquer uma dessas outras aqui que são livres de direitos autorais. Outra coisa, eu posso escolher se eu quero ou não colocar uma legenda. Geralmente a gente quer, mas aí eu posso selecionar o visual dessa legenda. Então tem vários exemplos aqui. Eu gosto sempre de colocar isso aqui com o fundo azul, mas você pode fazer as alterações aqui, caso você queira também. E da mesma forma, se você quiser fazer uma edição mais completa, é só clicar aqui, editar na linha do tempo e automaticamente esse seu material vai ser levado para aquele editor de vídeos, para que você possa fazer esses ajustes mais finos. Pronto, já terminou aqui. Vamos ver como é que ficou. Sejam muito bem-vindos a mais um episódio do nosso podcast. Você já se viu frustrado ao usar uma garrafa que não mantinha a temperatura da sua bebida? Olha, essa situação realmente ninguém merece. Mas comion, essa frustração se torna coisa do passado. Imagine só, você pode beber algo quente por até 12 horas consecutivas. Legal, né? Então, viram só, em poucos minutos eu tenho aqui um vídeo completo com imagens, narração, legenda e música de fundo. Agora vamos falar de preço. Quando você faz a sua inscrição aqui na plataforma, você ganha alguns créditos grátis para poder testar a ferramenta sem ter que pagar nada. Agora, se você precisar de mais aí, aqui o plano standndar sai $14 por mês e o plano pro $49 por mês. Então aí vai da sua necessidade. Se você ganha dinheiro com a internet, você pode fazer um investimento como esse para facilitar o seu dia a dia. Então testem aí e depois voltem aqui nos comentários para dizer para mim o que vocês acharam do Bull Vídeo. Bom, além de rápido e estável, o Bull Vídeo é super versátil. Você pode criar desde histórias criativas até vídeos educacionais, conteúdos motivacionais ou campanhas de marketing para e-commerce. E com a biblioteca personalizada, o resultado fica ainda mais autêntico, porque você pode usar suas próprias imagens e vídeos. Com Bull Vídeo, você transforma ideias em vídeos prontos em questão de minutos, sem complicação e com qualidade profissional. Se quiser experimentar, o link vai est na descrição desse vídeo e no primeiro comentário fixado, tá bom? Te vejo na próxima. Tchau. Tchau. [Música]",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Ferramenta de IA Bull Vídeo transforma ideias ou roteiros em vídeos completos com narração, legendas, música e personalização por meio de biblioteca de mídia e editor simples.",
            "resumo": "Este vídeo apresenta o Bull Vídeo, uma ferramenta online que transforma texto ou ideias em vídeos completos com IA. Ela gera cenas, legendas, música de fundo e narração, além de permitir o uso de uma biblioteca personalizada com suas próprias imagens e vídeos. O usuário pode escolher modelos de geração (GPT-4, Mini, etc.), ajustar o formato (9:16) e editar em um editor de linha do tempo simples. O fluxo de criação de roteiro para vídeo envolve colar o roteiro ou pedir à IA para criá-lo; depois são geradas legendas, narração e o vídeo, com opções para substituir imagens ou vozes e aplicar a mesma voz em todo o vídeo. Também há um modo de ideia para vídeo, onde basta inserir uma ideia, escolher o modelo, duração, formato e idioma, e adicionar mídias da biblioteca para personalização. Por fim, é possível exportar em HD 1080p para redes sociais.",
            "assunto_principal": "Transformação de ideias em vídeos com Inteligência Artificial usando Bull Vídeo, com foco em roteiro para vídeo e ideia para vídeo",
            "palavras_chave": [
              "Inteligência artificial",
              "Vídeos gerados por inteligência artificial",
              "Roteiro para vídeo",
              "Ideia para vídeo",
              "Biblioteca personalizada",
              "Editor de vídeo online",
              "Narração automatizada",
              "Legendas automáticas",
              "Formato 9x16",
              "Exportação HD 1080p",
              "Modelos de inteligência artificial (GPT-4",
              "Mini",
              "DeepSic)",
              "Personalização com mídias próprias"
            ],
            "resumo_em_topicos": "Resumo em tópicos:\n- Visão geral: Bull Vídeo transforma texto ou ideias em vídeo com IA, gerando cenas, legendas, música e narração, além de biblioteca personalizada e editor simples.\n- Funcionalidades: foco em roteiro para vídeo e ideia para vídeo, com opções de substituição de imagens/vozes, edição na linha do tempo e exportação em 1080p.\n- Fluxo de uso: escolha modelo (GPT-4, Mini, DeepSic), formato (9x16), insira roteiro ou ideia, integre mídias próprias e gere o vídeo.\n- Personalização: biblioteca de mídia, substituição de elementos, aplicação de voz única no vídeo.\n- Resultado final: vídeo pronto para redes sociais com narração, legendas e música; possibilidade de uso de mídias próprias para campanhas.",
            "prompt_tokens": 1979,
            "completion_tokens": 3016,
            "model": "gpt-5-nano",
            "cost": 0.0055
          },
          "analysis_time": 86.99126195907593,
          "language": "",
          "view_count": 2374,
          "has_transcript": false
        },
        {
          "id": "fPvv8NZBQpw",
          "title": "(SEM AD) 🚀 Norton Neo: O Navegador com IA Mais Seguro do Mundo? Vale a Pena Testar!",
          "title_pt": "(Sem anúncios) 🚀 Norton Neo: O Navegador com IA mais seguro do mundo? Vale a pena testar!",
          "url": "https://www.youtube.com/watch?v=fPvv8NZBQpw",
          "published": "2025-09-22T18:42:59.508438",
          "published_relative": "há 19 horas",
          "duration": "11:43",
          "date_published": "2025-09-21T13:21:40-07:00",
          "transcript_available": false,
          "transcript": "",
          "analysis_source": "sem_transcricao",
          "summary": null,
          "analysis_time": 15.932312250137329,
          "language": "",
          "view_count": 24,
          "has_transcript": false
        },
        {
          "id": "G2xi6J6qQvU",
          "title": "🚀 Norton Neo: O Navegador com IA Mais Seguro do Mundo? Vale a Pena Testar!",
          "title_pt": "🚀 Norton Neo: O Navegador com IA Mais Seguro do Mundo? Vale a Pena Testar!",
          "url": "https://www.youtube.com/watch?v=G2xi6J6qQvU",
          "published": "2025-09-22T13:42:59.508454",
          "published_relative": "há 1 dia",
          "duration": "11:43",
          "date_published": "2025-09-22T04:00:26-07:00",
          "transcript_available": true,
          "transcript": "Você já parou para pensar que os navegadores que usamos todos os dias praticamente não mudaram nos últimos anos? A grande novidade agora vem da Norton, o Norton New, o primeiro navegador feito do zero para ser ai nativo, ou seja, ele promete unir segurança, privacidade e inteligência artificial de um jeito que o Chrome, o ED e até mesmo o novo ARC ainda não entregam. Mas será que o Norton Neil é só marketing ou ele realmente pode mudar a forma como navegamos e pesquisamos na internet? É isso que eu vou te mostrar nesse vídeo. Mas antes, inscreva-se no canal. E para ver os vídeos sem anúncios, é só clicar no botão seja membro. Fechou? Então bora pro vídeo. Bom pessoal, hoje eu quero mostrar para vocês esse novo navegador que tem muita gente utilizando e tem muita gente gostando também. Ele é da empresa Norton, que é conhecida aí mundialmente pelas soluções para antivírus. E eles resolveram agora lançar esse navegador com base na inteligência artificial. E ele é muito bacana. Eu consegui aqui um acesso antecipado para mostrar para vocês. E realmente é bem interessante, porque qual que é a ideia aqui desse navegador? é que você consiga fazer tudo no mesmo lugar de uma forma muito minimalista e muito simples. Eu vou deixar todos os links direitinho aqui na descrição desse vídeo, inclusive com esse post aqui, onde eles mostram direitinho tudo que você pode fazer com esse navegador. E realmente é impressionante porque tem umas coisas muito legais. Beleza? Então vamos lá. Depois que você baixa e instala o navegador aí no seu computador, lembrando que para poder instalar você precisa participar de uma lista de espera. Ele ainda não tá disponível gratuitamente para todo mundo. Provavelmente isso deve acontecer nos próximos meses. Pode ser que quando você esteja assistindo a esse vídeo, ele já esteja disponível aí para você poder baixar, tanto paraa Mac quanto para Windows. Senão você pode se inscrever nessa lista de espera. Como é que você faz isso? no próprio site que eu vou deixar aqui na descrição. Então você vai preencher aqui o seu nome, o seu sobrenome, colocar o seu endereço de e-mail, vai enviar para lá o formulário e automaticamente você já tá na lista de espera. Mas eles dizem que você pode aumentar as chances de ter acesso a esse navegador se vocês seguirem aqui o perfil no X e também na comunidade lá no Discord. Então vai est tudo direitinho aqui na descrição desse vídeo, caso vocês queiram participar dessa lista de espera. Então vamos lá pro navegador. Agora quando você instala, já dá para perceber que ele traz aqui uma interface bastante minimalista. Então ele tem aqui alguns widgets, como por exemplo aqui a previsão do tempo. Então você tem aqui ensolarado, em Fahrenheit e também em Celsius. E aqui você tem a cidade. Ele dá direitinho aqui qual é a previsão do tempo pro local onde você tá. Nesse outro widget aqui você tem o calendário. Então com o dia da semana, local, dia e mês do ano. Vamos agora destrinchar essa interface. Bom, tudo começa aqui nesse campo que eles chamam de caixa mágica. Por quê? É aqui que você vai pedir para ele fazer um prompt, para ele buscar na internet, para ele criar um código, para criar uma imagem. Ou seja, eles resolveram deixar tudo dessa forma minimalista, em que você consegue ter acesso às principais funções do navegador no mesmo lugar. Então, para começar, eu vou fazer uma busca como se eu tivesse fazendo no Google, por exemplo. Veja o que eu tô perguntando. Qual o resultado do jogo do Palmeiras? Aí aqui aparecem duas opções. Você pode utilizar em forma de chat, conversando com a inteligência artificial ou simplesmente para fazer uma busca. Eu vou começar pela busca. Ele já traz o resultado aqui para mim, utilizando o Google buscador. Então, tudo funcionando perfeitamente. Agora, voltando aqui na página principal, se você quiser, você pode usar esse campo aqui, por exemplo, para interagir com a inteligência artificial. Vejam como está o mercado de carros elétricos no Brasil. Agora eu vou utilizar a função chat. Pronto, ele já vai para essa outra interface aqui e agora eu posso conversar com a inteligência artificial como eu faço com o chat IPT de e assim por diante. Veja, ele traz aqui um panorama rápido, ofertas e players, políticas e incentivos, riscos e oportunidades, tudo com as respectivas fontes aqui. Se você quiser se aprofundar, basta clicar e automaticamente ele abre uma nova aba, bloqueia os anúncios, o que é muito legal, e te traz aqui todas as informações. Voltando aqui pra página da busca. Se você já tiver satisfeito aqui com a conversa que você tá tendo com a inteligência artificial e quiser mudar pro modo busca, não tem problema, é só clicar aqui embaixo no Google e automaticamente ele vai trazer aqui todos os resultados referentes à busca e não mais à aquela conversa que você estava tendo com a inteligência artificial por meio do chat. E reparem que conforme você vai tendo as suas abas aqui, tudo vai ficando de forma organizada. Então, quando eu clico aqui em automotivo, ele abre aqui para mim as coisas relacionadas ao mercado automotivo. Se eu fizer uma outra busca aqui, por exemplo, sustentabilidade na Amazone, vejam, ele abriu uma nova aba, só que agora eu tenho aqui search, então tudo vai ficando de forma organizada. Se eu clicar aqui, ele vai recolhendo, olha só. Então, fica muito mais minimalista. Quando eu quiser voltar, como eu tava falando lá do setor automotivo, eu clico aqui em automotivo e automaticamente as abas aparecem aqui. Voltando aqui paraa página principal, agora vou abrir um site qualquer aqui. Pronto, abri aqui a matéria do canal Tech. E quando você clica aqui na barra de busca, veja que aparece a opção aqui, sumarize this page. Ou seja, resuma essa página. Então, eu vou clicar. Automaticamente ele vai abrir essa janela aqui na lateral e a partir desse momento eu posso começar a interagir com esse resumo que ele acabou de fazer. Vejam, faça cinco perguntas referentes a esse tema. Vou enviar e pronto. Ele trouxe aqui para mim as cinco perguntas relacionadas a esse resumo da página que ele fez. Então isso é interessante porque sempre que você abre uma página aqui na internet, basta você clicar aqui no campo de busca e automaticamente você vai ter essa opção aqui para resumir essa página. Quando ele abre esse menu aqui na lateral, aí funciona como um copilot. Você vai ter aqui um assistente virtual que vai te ajudar na sua navegação. Então você pode pedir para que ele faça coisas de uma forma muito parecida com a que a gente tem lá no comet da Perplexity. Agora, será que também funciona para resumir vídeo do YouTube? Vamos ver. Vou abrir um vídeo aqui do canal. Vou clicar aqui na caixa de busca. Veja, aparece aqui para que eu resuma essa página. Vou resumir. Vejam, ele trouxe o resumo aqui para mim, mas tá em inglês. Por quê? Porque essa conta que eu tô utilizando aqui é uma conta que eu tenho aqui em casa para acessar páginas em inglês. Mas se você tiver utilizando uma conta em português do Brasil, com certeza o seu resumo aqui de vídeo do YouTube também vai aparecer em português. Mas nada impede que você peça para traduzir o resumo. Olha só, traduza para português. E pronto, ele traduziu aqui o resumo do meu vídeo em português do Brasil. E aí você pode interagir da forma que você quiser, pedindo para ele criar bullet points, para fazer um relatório, enfim, o céu é o limite, porque aqui você tem esse copilot para poder conversar com a inteligência artificial de forma natural. Voltando lá pra página principal, reparem que aqui embaixo você tem um hub. Quando você clica, aparecem as principais notícias aqui que te interessam e aí você pode acrescentar novas notícias. Então isso é bacana porque fica tudo aqui embaixo. Quando você quer acessar, basta que você selecione aqui o tema relacionado e aí você já é transportado para aquela página. Agora, será que esse navegador também pode resumir arquivo em PDF? Vamos ver. Vou subir um arquivo para cá. Pronto, arquivo anexado. Vou fazer o meu pedido. Resuma esse arquivo e pronto. Em menos de 5 segundos eu tenho aqui um resumo completo daquele meu arquivo em PDF. Então vocês entenderam aqui a sacada? Eles querem que você faça tudo dentro do navegador. Você pode interagir com a inteligência artificial, fazer uma busca, subir um arquivo em PDF e pedir para ele resumir, resumir um vídeo do YouTube, enfim, em vez de ficar pulando de ferramenta em ferramenta, eles reuniram tudo dentro de uma mesma plataforma. Agora, será que também dá para gerar imagem? Vamos ver isso. Vou abrir aqui uma nova aba. Gere a imagem de um tubarão branco. Vou enviar. E pronto, já tenho aqui a imagem do meu tubarão branco. Não é uma qualidade nano banana, mas aqui ele já traz o prompt que foi utilizado para criar essa imagem. Se eu quiser baixar, é só clicar aqui na flechinha. E uma coisa muito interessante, nesse outro menuzinho que aparece aqui, quando você expande, vejam, você tem aqui o histórico da navegação que você teve com a inteligência artificial. Então, tá tudo dividido aqui. Se você clicar em gallery, aparecem todas as imagens que você gerou aqui dentro da plataforma. Então ele procura organizar tudo para que você tenha acesso imediato àquilo que você tá procurando. E reparem que conforme eu vou usando aqui o navegador, ele vai criando aqui esses menus para que eu possa diminuir a quantidade de abas abertas. Outra coisa que eu já tinha comentado com vocês é que esse navegador, por prezar a segurança e a privacidade, ele já conta aqui com um bloqueador de anúncios nativo. Agora, será que essa IA também cria código? Vamos ver. Veja, cria um código HTML para o jogo da cobrinha. Veja, ele tá criando aqui o meu código HTML. Uma desvantagem é que você não tem aqui aquela função canvas para você poder visualizar o código sem ter que sair do navegador. Então, pode ser que no futuro eles implementem essa função aqui, como a gente tem no chat EPT ou no Gemini, onde você tem o código. Aí você clica para pré-visualizar e ele já te mostra aqui na lateral o seu código sendo executado. Por enquanto não dá para fazer isso aqui dentro do new. Pronto, ele terminou de fazer o código aqui para mim. Vamos ver se pelo menos tá funcionando. Vou copiar, vou salvar aqui no meu bloco de notas. E vejam só, funcionando aqui. Alguns errinhos aqui, mas dá para consertar. Então, aparentemente aqui tá funcionando perfeitamente, né? Isso. Um código pedido aqui de primeira, sem fazer nenhum tipo de ajuste. Então, passou no teste aqui, mesmo ele não tendo aquela função para que eu possa visualizar o meu código sem ter que sair do navegador. Bom, vamos ver agora quanto esse navegador gasta de memória. Eu vou abrir aqui o meu gerenciador de tarefas. Vejam, o Google Chrome permanece aberto aqui com 14 processos sendo executados e ele tá consumindo 721 MB mais ou menos. Eu tô aqui no Google Chrome com duas abas abertas. Já aqui no New, eu tenho várias abas aqui funcionando. 1 2 3 4 5 6 7 8 9 10 abas abertas e tô consumindo mais ou menos aqui entre 1650 e 1700 MB. Então, aparentemente ele consome algo bem parecido com o Google Chrome. Lembrando que o Chrome tá apenas com duas abas abertas e aqui eu tenho 10 abas. Então, como esse navegador ainda não tá disponível pro público geral, pode ser que eles melhorem essa relação entre o que tá aberto e o consumo de memória, mas aparentemente deve ficar muito parecido com o Google Chrome, que a gente já sabe que não é um navegador econômico quando se trata de memória RAM. Quando a gente vem aqui nas configurações do Nil, já dá para perceber que o motor que tá por trás aqui do navegador é o sistema Chromium. Então ele é construído num sistema muito parecido com o do Google Chrome. Então por isso pode ser que ele consuma aí a mesma quantidade de memórias aparentemente. Então pessoal, eu vou deixar todos os links direitinho aqui na descrição desse vídeo para que vocês possam se inscrever na lista de espera e quem sabe aí porque para mim demorou mais ou menos 5 dias para eles liberarem o acesso aqui ao navegador para que eu pudesse baixar. Então, quando vocês conseguirem, testem aí e depois voltem aqui nos comentários para dizer para mim o que vocês acharam do Norton Neil. E aí, gostaram do NE? Vale a pena testar? Contem para mim nos comentários, tá bom? Te vejo na próxima. Ciao. Tchau.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Análise do Norton New, navegador com IA da Norton, avaliando se ele entrega segurança, privacidade e recursos de IA de forma prática diante de concorrentes como Chrome, Edge e ARC.",
            "resumo": "O vídeo apresenta o Norton New, navegador da Norton com IA, prometendo segurança, privacidade e IA em uma interface minimalista. O apresentador descreve o acesso antecipado via lista de espera e a expectativa de disponibilidade para Mac e Windows. A ideia central é centralizar tudo em uma 'caixa mágica' onde o usuário faz buscas, interage com IA por chat e resolve tarefas como gerar código ou imagens. O navegador mantém abas organizadas, alterna entre o modo de busca (Google) e o chat, e oferece o recurso 'resumir esta página' para resumir páginas com janela lateral. Demonstra ainda resumir vídeos do YouTube, traduzir o resumo para o português e usar um copiloto para perguntas rápidas, relatórios e exportação de resultados. O vídeo destaca o potencial, mas aponta que ainda há fases de lançamento e de marketing.",
            "assunto_principal": "Lançamento e avaliação do Norton New, navegador com IA da Norton, destacando segurança, privacidade, interface minimalista e recursos de IA como a 'caixa mágica' e o recurso de resumos.",
            "palavras_chave": [
              "Norton New",
              "navegador com IA",
              "IA",
              "segurança",
              "privacidade",
              "interface minimalista",
              "caixa mágica",
              "resumir esta página",
              "resumo de páginas",
              "resumo de vídeos",
              "copiloto",
              "lista de espera"
            ],
            "resumo_em_topicos": "- Contexto: anúncio e avaliação do Norton New, navegador com IA da Norton.\n- Acesso e disponibilidade: acesso antecipado via lista de espera e expectativa de disponibilidade para Mac e Windows.\n- Interface: design minimalista com widgets (tempo, calendário) e a 'caixa mágica' para buscas, IA por chat e geração de conteúdo.\n- Funcionalidades: alternância entre busca com Google e chat, resumo de páginas com janela lateral ('resuma esta página'), e organização de abas.\n- Recursos avançados: resumo de vídeos do YouTube, tradução do resumo para o português e uso do Copilot para perguntas, relatórios e exportação de resultados.\n- Conclusão: potencial promissor, mas ainda em fases de lançamento e marketing.",
            "prompt_tokens": 1881,
            "completion_tokens": 5481,
            "model": "gpt-5-nano",
            "cost": 0.0092
          },
          "analysis_time": 92.10777616500854,
          "language": "",
          "view_count": 7350,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@papotechcast",
      "name": "@papotechcast",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@preguicaartificial",
      "name": "@preguicaartificial",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@pullrecast",
      "name": "@pullrecast",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ronnaldhawk",
      "name": "@ronnaldhawk",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@safesrc",
      "name": "@safesrc",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@salesforce",
      "name": "@salesforce",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@sanclermiranda",
      "name": "@sanclermiranda",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@sentdex",
      "name": "@sentdex",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@stanfordhai",
      "name": "@stanfordhai",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@tesla",
      "name": "@tesla",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@ycombinator",
      "name": "@ycombinator",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    }
  ]
}
{
  "executed_at": "2025-09-23T14:01:02.049267",
  "mode": "full",
  "total_channels": 13,
  "total_videos": 11,
  "params": {
    "days": 1,
    "max_videos": 30,
    "mode": "full",
    "no_llm": false,
    "asr_provider": "faster-whisper",
    "format": "txt",
    "translate_results": "pt-br",
    "resumo_max_palavras": 150,
    "llm_model": "gpt-4.1",
    "ui_extras": {
      "selected_groups": [
        "Ideias e Negócios com IA"
      ],
      "selected_channel_labels": [],
      "manual_entries": "",
      "translate_titles": true
    }
  },
  "channels": [
    {
      "channel_id": "@ColeMedin",
      "name": "@ColeMedin",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "NQ3vJ8iZPaQ",
          "title": "Knowledge Graphs in n8n are FINALLY Here!",
          "title_pt": "Grafos de Conhecimento finalmente chegaram ao n8n!",
          "url": "https://www.youtube.com/watch?v=NQ3vJ8iZPaQ",
          "published": "2025-09-23T15:01:03.936791",
          "published_relative": "há 2 horas",
          "duration": "18:55",
          "date_published": "2025-09-23T07:07:56-07:00",
          "transcript_available": true,
          "transcript": "The time has come, the moment that you have been waiting for. We finally have knowledge graphs in our NAN rag template. So many of you have been asking me to add this, especially after I cover knowledge graphs with graffiti and Python previously on my channel. So, here it is. In this video, I'll show you how it all works and how you can get it set up for yourself. We're going to get a little bit hacky today. It's going to be fun and it'll still be super practical. Now, first of all, what do knowledge graphs actually give us? Well, to answer that question, I want to go back to the fundamentals of rag for a second and then show you how we can layer on top knowledge graphs to take our agents to the next level. And so traditional rag, what we've been working with in this template so far is using a vector database like I've been using Postgress with PG vector. This could be a dedicated vector database like Quadrant or Pine Cone. You'll be familiar with these things if you've been following along with my template. And this works great. I mean, there's a reason that I've been just using a vector database throughout the entire template as I've been building it on my channel, which by the way, I have this playlist I'll link below if you want to really start with the basics and then get to the point where we have the more complex and powerful template that you're looking at right now. So, we have our rag pipeline. This is the foundational piece where we take our data from our source like Google Drive and we chunk it up into the bite-sized pieces for our agent to search and digest. And that's what we store in our vector database. And the main problem that we have with vector databases here, as great as they are, is they don't do a good job storing relationships between the different entities that we have in our data. So when we just dump all of our chunks in a database like this, it's hard for the agent to find one chunk and then see how it relates to other things that are also stored in our knowledge base. That is what a knowledge graph gives us. And that's what you're looking at right here. So I built up this knowledge graph in the rag pipeline now using an MCP server that I'll introduce you to in a little bit here. This is the key. It's just a single node that I've added to the pipeline. Super simple. And so we're building up our knowledge graph at the exact same time that we're building up our vector database. So we're storing the information in both places just represented in different ways. Because think about people, companies, products, all of these entities we have in our data. They're very related to each other. And so we want to be able to store those relationships and give our agent the ability to actually navigate between these different nodes as they're called based on the relationships. And so we can look at a company and then we can from there go and search and find the executive leadership team as an example. This is just demo data. But as our data really starts to evolve and we have thousands of entities and thousands of relationships, agents definitely get lost in the sauce trying to search through these things in a vector database. That's why we want a knowledge graph. And so like I said, same data that is being stored just represented in different ways. And this definitely goes with the theme of a gentic rag that I've been covering when in this template. We're giving the agent the ability to search through our knowledge base in different ways. So if we're asking about a single company, well, we should probably just go to the vector database like we have been. But if we're asking about how two companies work together, now that would be a good example to go and search the knowledge graph. All right, let me actually show you this in action now. And so I'll be explicit here just for demo purposes to use the vector database asking it to give me an overview of a company that I have mock data for in my Google Drive. And so, yep, there we go. It uses the tool to search the vector database. These are the chunks it returned to give me the answer. And there is our overview. All right, looking good. So, yeah, in a brand new conversation, let's try something else. Let's say, tell me about Dr. Tanaka and Dr. Chen. And I'll say use the knowledge graph. Again, just being explicit here because this is a more relational question asking about two entities at the same time. And take a look at that. It is using the graffiti MCP server which I'll show you how to set up next to query our knowledge graph. So the agent drops itself in here finds the right nodes even looking through relationships. It's really cool the things that happen under the hood to get us our answer. And I was being explicit here but generally in your system prompt for your agent this is where you specify when is it optimal to search the knowledge graph versus the vector database. You can really play around with this and tweak it to your specific use case. I mean, that's the big thing with this template, right, is that it's all you take this and evolve it to what works best for your use case and your data for rag. So, there we go. That's a quick demo. Now, let's get into actually setting this up. And getting knowledge graphs added into our template here is super straightforward. There's literally only two nodes that we are adding on top of the previous version of the template. We have one to insert into our knowledge graph using the graffiti MCP server and then one to give a tool to our agent to search the knowledge graph again with the graffiti MCP server. And so most of the setup is actually for the graffiti MCP. So that's what I'm going to walk you through. Then we'll cover these two nodes and exactly how they work. Now this does assume that you are using a self-hosted N8N. That is a requirement for following along here. the lang chain code node that I covered in my last video on this template require self-hosted N8N and this MCP server needs to be run internally alongside your N8N instance. So obviously the cloud version would not work. I'm going to be showing you how to go into your machine where you're hosting N8N bring graffiti and Neo4j alongside it. So we have this MCP server ready to be connected to. And so I will be assuming that you already have something like a digital ocean droplet with N8N up and running. So if you don't have that yet, just follow this guide that I'll link to in the description to get your own N8N instance self-hosted on Digital Ocean. Digital Ocean's not sponsoring this video. It's actually just what I use to host my N8N. So definitely follow along with that. Once you have N8N up and running, that's when we can dive into the instructions for Graffiti. And so with a single docker compose we're going to have the graffiti mcp server and neo-4j which is our underlying database hosted and then we'll hook into it with nn. Now let me be super clear. Neo4j is the database like postgress where we store our knowledge graph and graffiti is the library. It's the tooling that gives us the ability to extract from raw text the entities and relationships to then store in Neo4j and it gives us the MCP server that makes it possible to use graffiti with nan. Otherwise, this would be 100 times harder. And graffiti is the same tool that I use with knowledger graphs in Python that I covered on my channel earlier. And so I've got my digital ocean droplet up here. And this is the same droplet where I have my N8N instance up and running. And so I'm going to follow these instructions, which I'll also have linked in the description to get graffiti in Neo4j up and running. It's really not that bad once we get to it here. So I'll go ahead and copy this first command here to clone the repository. So we're calling in graffiti just like you do with N8N. And then I'll change my directory to graffiti/mcp_server. And the first thing that we have to do is set up our environment variables. So I'll go into.example. I'll print it out here so that you can see. The main thing that we have to set is our OpenAI API key because we're using a large language model to extract those entities and relationships. That's one of the things that Graffiti does for us using OpenAI. And you can configure this to use other providers as well. That's outside of the scope of this video, but definitely let me know if you want me to evolve this template to work with CloudN, different LLM providers. There's so many things I can do to continue to build this out for you. So yeah, we just have to set our API key and you can also change your model name. And so what you want to do is do a copy of.ample and you want to change this to env. So then we can do a nano.env. And this is where we can go and set our API key. So you change this value right here. You can also change your Neo4j password if you want for the underlying database. And then to exit out of this, you do control or command X and then Y and then enter. Once you've made a change, that's how you actually do it. So here I'll actually make a change and show you. So it's controll X, then Y, then enter. That is how you save your changes. So off camera, I'll set my OpenAI API key and then I'll be back. Oh, and one last note for this, you're probably going to want to change your URL from localhost to Neo4j. Since we're working in containers here, we need to reference the service name of our Neo4j container. So just a tiny detail there that's really important. That actually tripped me up as I was getting this set up for you. So, make sure you adjust that. All right. Once you have your environment variables set up, you can run the pseudo docker compose up-d command. This is going to get our servers up and running. It might take you a little bit longer. I already run this in the background just so it's quicker. And then to check the logs to make sure things are actually good, we can docker logs and then the name of our server here. So, I'm just going to copy this and paste it in. And then I this should be uh pseudo as well. So, there we go. All right. So, it's going to spit out a ton of information. You can ignore a lot of these warnings that you'll typically see with graffiti. The main thing that you're looking for at the bottom here is that it says that ubicorn is running on http 0000 port 8000. And you can also configure this port if you want as well by going into the docker compose. It's a little bit of an advanced thing, but I actually did this because where I've been running this before uh I was already using port 8000. So I just changed this to map uh port 8030 to 8000 as well. So yeah, you can go ahead and change that. Otherwise, we are looking good. You now have everything up and running. And you can do a final check by doing uh docker ps- a. It'll show you all of your containers that are running. You want to make sure that none of these say error or exited or restarting, anything like that. So, we've got our N8N and then caddy as well. And then we got Neo4j and our graffiti MCP. All right, things are looking really good. Now, the last thing that you need to do that is a kind of awkward hacky thing is we have to make sure we actually open up the port so that N8N can connect to our graffiti MCP. And this is the most technical and hacky part of our setup here, but I'll have step-by-step instructions in the description so you can copy and paste some things that we're about to do here. I'll make it as easy as possible. So, first things first, we need to change our directory into where we set up N8N because what we need to do is make a super small tweak to the Docker Compose. I already made the change here and I'll have this in the description for you to copy. But, we have to add an extra host so we can use host.doccker.in. This is how we're going to within our N8N workflow builder connect N8N to our graffiti MCP. And I'll show you what that looks like in a little bit as well. So, you just have to add these two lines right here. And then again it's control or command X Y and enter to exit once you've made that edit in nano. So there you go. And then you do pseudo docker compose up-d. It's the exact same command that you use to start n for the first time and what we used previously. So you go ahead and use that. Then we are good to go. Now there's just one other thing that we have to do with our firewall here. What we need to do right now is access the end container and figure out what the gateway IP address is. I know that sounds really technical but don't worry. All we have to do is pseudo dockerexec-it and then the name of our container that we get from the ps command. And so I'm just going to copy this one right here. This is the name of our container. Paste it in. And then it is /bin /sh. And so this is going to get us within the docker container for nadn. So any commands that we execute now are within this container. We want to do ip route and then gp default. And you can copy and paste this from the description as well. So we get this IP address right here. So you want to copy this. This is absolutely crucial because now we're going to exit out of the NN container and we're going to do pseudo UFW allow from and then we have this IP that we just copied. So I actually didn't do that yet. So I'll copy and then I will paste and then to any port and then 8000 or whatever the port that you have set up for your graffiti MCP. So like I changed mine to 8030. Whatever you need to do here, change it. And so the reason that we're doing something so specific here is we don't actually want to open up this port to the entire public. If we wanted to do that, we could just do pseudo UFW allow and then 8030. So you're getting a little bit of a network lesson here. I'll make it super brief, I promise. But this would open up the whole port to the entire internet. So instead, we're only allowing this IP. This is the gateway from the N container to access this port. So, we're keeping security super tight here. And then we can do pseudo UFW reload. So, really specific thing. Just have to bear with me on that. But yeah, we have our firewall set up. So, now N8N can access the graffiti MCP and everything is still secure in our digital ocean droplet. So, now back in N8N, we are going to install the community MCP node. And the reason that we need this is pretty simple. The MCP functionality built into N8N natively only supports using MCP servers as tools, but within our template, we're using the Graffiti MCP server, not as an agent tool. You can't actually set this up with the native N8N integration with MCP. So, we're going to use this server right here. So, you can copy the name N8N- nodes-mc. Go to your settings in the bottom left in N8N community nodes. And then when you add a new node, you just paste in the name that I copied from the mpm page. And then you check this and install. And then you are good to go. And so I've got mine installed obviously already. So if I add the plus icon here and I search for MCP, take a look at this. I can do MCP client. This is the one from my community node. And the way that you know that is that it has a publisher here and it's via npm. And specifically to test the connection with the MCP server, I like to use the list available tools function. And so I'll bring in this node. I won't actually attach it to anything yet. I'm just going to set up my connection to my MCP server, make sure everything's good, and I can view the tools that are available in the graffiti MCP server. And so I'll make a brand new connection here just so I can show you. So for graffiti, it is server sent events as the protocol. And then for the IP here, we did all that work to set up host. docker.in internal because we need to tell the nn container to look outside of itself to our host machine where we have the graffiti mcp running and then my port is 8030 and you can keep it as slash ssee. So go ahead and click save and then we can exit out of this and then we can execute this step that's just in isolation right here to make sure that things are working and there we go. Cool. So we have an add memory tool. This is what we have in our rag pipeline for actually adding into our knowledge graph. And then we have the search memory nodes tool. This is the primary one that I have as the tool for my agent here in this template. And then there are some other ones as well that aren't really something I'm going to be covering here, but it's actually really nice. Like there are other tools that we have here like get entity edge that's more about like once you have a certain node selected, you can then search through relationships to find other nodes around it. So, there's more advanced things that I really do want to cover later as well, but for this video, I'm going to keep things simple and just use the two tools that we have at the top. I want to add memories and I want to be able to search through memories. And so, I'm going to delete this guy right here cuz I'm just using that to test the connection. The main thing that I added into the rag pipeline here is a single call to the graffiti MCP. And so, my operation here is execute tool instead of listing the tools that we just looked at. And for the tool name specifically, I actually got that by the list operation. It is add memory. And these are the two properties that we have to specify. We need to specify the name of the document that we're adding in as an episode to graffiti. And then also the episode body. This is the text from the document that it is going to use an LLM through OpenAI in this case to extract the entities and relationships. And so this single edition is all we have to do. super super clean to make it so that we're now adding into our knowledge graph along with our vector database in our rag pipeline. And then it's just as easy for the agent. So along with all the other rag tools that we have, we're now just adding a new MCP client tool where the operation is again to execute a tool, but this time the search memory nodes. The only thing that we need to specify for the parameters here is the query. What's the query for searching our knowledge graph? And we're letting the LLM decide that. So the AI agent when it invokes this tool, it determines what the query is because obviously we don't want to have to specify to the agent exactly what the query needs to be. So it gets to make that up. We're giving the agent that control. And that is it. That is everything you have to do. Like I promised, the setup was mostly just getting the MCP server up and running on our digital ocean droplet. Yeah. And then just for a little demo here, I will do a test event with a file I have updated in Google Drive. And then I'll go ahead and send this in through the full pipeline here. Take a look at that. We have inserted it into our knowledge graph. The full content of the file and the title being sent in to be processed into our knowledge graph. So an LLM is going to run to extract the entities and relationships. And there's a queuing process here because knowledge graphs are slower and more expensive compared to a more traditional rag agent with just a vector database. That's the last point that I want to drive home for you here. your use case might not be the best for knowledge graphs if you don't need that extra power for querying or if you don't have really relational data. Knowledge graphs might just slow you down. Using an LLM to extract all of these nodes can be a slow process. So if you're working with a ton of data, you should probably just stick to a vector database. And I'll probably make more content on the future doing these kinds of comparisons for your use case, helping you figure out do you want knowledge graphs and vector databases or just a vector database or just a knowledge graph. There's so much more that I could dive into here. Like I'm really just scratching the surface of what is possible with knowledge graphs for you and helping you incorporate them for the first time in your N8N workflows. And so I hope that you found this super super useful getting you started with knowledge graphs in N8N. If you did and you're looking forward to more content on AI agents and rag and knowledge graphs, I would really appreciate a like and a subscribe.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta a integração de grafos de conhecimento no n8n, mostrando como configurar e utilizar esse recurso junto ao template RAG.",
            "resumo": "O vídeo anuncia a chegada dos knowledge graphs no template de RAG do n8n, muito pedido pela comunidade. O apresentador explica a limitação dos bancos de dados vetoriais em armazenar relações entre entidades e destaca como os knowledge graphs resolvem esse problema, permitindo ao agente navegar melhor entre dados relacionados, como empresas e pessoas. Demonstra a integração do knowledge graph com a ferramenta usando o servidor MCP do Graffiti e o banco Neo4j, além de mostrar exemplos práticos de consulta de dados relacionais. A configuração é simples, exigindo apenas dois novos nós no template e uma instância self-hosted do n8n. Por fim, ele mostra como instalar Graffiti e Neo4j com Docker, recomendando o uso de servidores como o Digital Ocean para hospedar a solução.",
            "assunto_principal": "Integração de grafos de conhecimento no n8n usando Graffiti MCP e Neo4j para aprimorar consultas em sistemas RAG.",
            "palavras_chave": [
              "grafo de conhecimento",
              "n8n",
              "RAG",
              "Neo4j",
              "Graffiti MCP",
              "banco vetorial",
              "entidades e relações",
              "auto-hospedado",
              "Docker",
              "Digital Ocean"
            ],
            "resumo_em_topicos": "- Introdução à chegada de grafos de conhecimento no template RAG do n8n\n- Explicação das limitações dos bancos de dados vetoriais para relações entre entidades\n- Demonstração do uso de grafos de conhecimento para consultas mais relacionais\n- Integração simples de dois novos nós no template\n- Necessidade do n8n self-hosted para a configuração\n- Uso do servidor Graffiti MCP e do Neo4j como backend\n- Instruções básicas de instalação usando Docker\n- Possibilidade de evoluir o template para diferentes casos de uso\n- Referências anteriores ao uso de grafos de conhecimento em Python no canal",
            "prompt_tokens": 1834,
            "completion_tokens": 449,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 27.78003978729248,
          "language": "",
          "view_count": 1386,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@DanGalletta",
      "name": "@DanGalletta",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@DataCouncil",
      "name": "@DataCouncil",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@Incomestreamsurfers",
      "name": "@Incomestreamsurfers",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "vGAbJS5bqgk",
          "title": "Claude Code Opus 4.1 ESTÁ DE VOLTA (FINALMENTE)",
          "title_pt": "Claude Code Opus 4.1 ESTÁ DE VOLTA (FINALMENTE)",
          "url": "https://www.youtube.com/watch?v=vGAbJS5bqgk",
          "published": "2025-09-23T11:01:36.307892",
          "published_relative": "há 6 horas",
          "duration": "08:11",
          "date_published": "2025-09-23T03:58:42-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where I'm going to be talking about Clawude Code and how in my opinion it seems like it's genuinely back. Now, this is Quotely. This is a project that I've been working on for the about the last 3 weeks and I was having some real problems with Claude Code while they were buggy. So, I moved over to Codeex and it worked for a little bit and then I started having problems with Codeex as well. Now, one of the biggest problems with Codeex, in my opinion, is it's not as good at running things itself, running Docker, getting everything running, etc., etc., whereas Claw Code just seems to be much better for that system. So, let me just show you what I created yesterday, and I'll just explain to you guys why I genuinely think Claw Code is back. So, let me just log in here so I can finally log in, which by the way, Claude Code fixed for me. And then yesterday, what I was working on was this right here, which is the instant policy comparison. So what I can do is I can upload a declaration image for a insurance declaration and then I can process it and I can press process here and what it'll do is it will use AI to actually read this uh policy document and extract all of the information. Now this was created with claude code yesterday through quite a long process I have to say it did take a little bit of time but Claude Code did manage to absolutely smash this in the end. Now you can see it did take a long time. Took a few hours of coding to be frank and it took, you know, I was I was just playing video games at the same time and I was just kind of letting it run. I was playing Runescape with my with my best friend. And eventually after I added the Playright MCP, it started to really get an idea of what was going on. Playright MCP absolutely vital if you're using Claude code because look, it just kept saying it's correct, it's correct, it's correct, it's correct. That's like look use the player IMCP it's logged in it's not there and then you can see here I can see the dashboard is loading but the declaration upload document is not showing the back end is also connection refused errors let me check the back end is still running and then verify the front of the code so eventually it got everything running and it just kept running through fixes I wasn't even giving it any feedback I just said it's still not working or you know fix it fix it fix it and then eventually we got to the point where we could process this document with AI. So you can see Jane Doe city um 2008 Ford Explorer which if you look at the document here you can see 2008 Ford Explorer and then you can press get multiple quotes right and then you can do this and you can see the turbo rator payload becomes um the information from the document I uploaded and I can press run quote here and and it will send the the users's uploaded information from the image to our insurance quotator and it will actually find quotes right so if I scroll down here you can see carrier one total 1,200 term 1,200 monthly 200 quoted so that's equity insurance company and then progressive insurance comes back at exactly the same price so this entire process I built with claude Claude code, but it wasn't me telling Claude code what to do, right? You can just literally see I'm not telling it. I just kept saying I'm getting load failed or this kept happening, etc., etc. And it didn't just make things up, right? It genuinely coded a fix to the issue. You can see it's not hard coding things. It's genuinely fixing things. So right now while I'm making this video I also have um Claude code running with Grove Fixes and I just gave it a load of bug reports that users had given me and I put them into clawed code and you can just see that it's just running now. So yeah, this thing where it makes genuine fixes to problems like you can see here. This is just not something that you know two weeks ago was actually happening. Now let me show you another thing that they've added. This is actually a pretty cool update from Claude. You can write ultrathink now and you can see it changes the color and everything. So you know that it's genuinely making a change. You can see thinking on max, right? So I put it on ultra think mode. So once you've got it on ultraink mode, what it does is, and this is another theory that I did have about a week ago when I said codeex was significantly better. It's also because we're not using thinking mode on claw code. Like I rarely use thinking mode. So you can say think and it goes blue. What is it? Think a lot. Uh no ultra think is like the the big one. And then I'm not sure what the the medium one is. But it's pretty cool that they made it so it actually changes the um the the tokens, right? I do actually really like that. Not the tokens, the color. So now you can actually see if you're telling it to ultra think you can see ultra think thinking on. So it's less like ultra think meme and actually genuinely ultra thinking. So I wanted to talk about this guys because I think two weeks ago I wouldn't have been able to fix this entire script whereas now with claw code I was able to. So yeah, guys, honestly, um I know that I've been talking a lot about Claude Code recently and saying that Codeex is better, but it seems like Codeex has degenerated and Claude Code is kind of bad. So, I did talk about this the other day in a video. This one here, Postmortm and three recent issues. It seems like this might have actually had more of an effect than I said it would have in the video that I made. It genuinely seems like this has had a good effect and it does seem like Claude Code might actually be back, which is massive because like it's been pretty frustrating to just have to move away from Lord Code because I really really did like Lord Code. But I'm going to be I'm going to be genuine. I'm going to be honest with you guys right here, right now. I think it might be back. Okay, probably not to the point that it was at the very beginning, but I did renew my $200 max subscription yesterday and um we are using the Max plan again. We are using Opus and I didn't regret it yesterday. It really really fixed quite a large complicated issue. added a new feature to quote lead which like I said is a project I've been working on for a little bit of time now and I'm genuinely impressed with the results. Okay, I'm not just bullshitting you. I'm not just going to write Claude Code is insane in the title or anything like that. I'm being genuine. I want people to know that in my opinion Claude code is feeling like it's back now. I'm I've been using Ultraink. Um I've been using MTPs. You can see I've just got the playright MTP here, but um in this conversation for example, I have uh playright uptach and superbase. This combination of things allows me to basically do anything on Grove. And yeah, if I needed Superbase here as well, I would probably add it. But yeah, this is this is my workflow. I actually stopped using codeex. I noticed well, first of all, they rate limited me finally after using it for 3 weeks. And then second of all, it did actually seem like something's happened and it and it's degenerated a little bit and it's not as good as it was. So maybe their servers are uh are having issues. We don't know. But seems like this is always the case. Fighting over who is the best when people think you're the best, make you make yourself worse to save money and hope no one notices. And then your competitor comes along and makes themselves the best. And then today, I would guess Anthropic is going to release a new model. I think they're famous for releasing on Tuesdays if I'm not mistaken. So, I'm genuinely expecting a new Anthropic model today. And I'm hoping it's going to be absolutely crazy. But yeah, honestly, Opus 4.1 is doing a great job. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. I'll see you very, very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O criador do canal mostra que o Claude Code Opus 4.1 voltou a funcionar muito bem e superou o concorrente Codeex em seus projetos.",
            "resumo": "No vídeo, o criador relata sua experiência recente com o Claude Code Opus 4.1, destacando que a ferramenta voltou a ter ótimo desempenho após um período de problemas. Ele comenta que migrou temporariamente para o Codeex devido a bugs, mas acabou enfrentando dificuldades e percebeu que o Claude voltou a ser superior, especialmente em tarefas que demandam automação, integração com Docker e solução de bugs. O apresentador demonstra na prática um projeto chamado 'Quotely', onde o Claude Code conseguia resolver falhas sem necessidade de detalhamento, mostrando evolução real do sistema. O vídeo ainda destaca novidades como o modo 'ultra think', melhorias nas respostas e a impressão de que o Claude está quase como no início do serviço. No final, ele afirma que voltou a assinar o plano Max e recomenda a ferramenta.",
            "assunto_principal": "Revisão e análise do retorno da eficiência do Claude Code Opus 4.1 em comparação ao Codeex para programação assistida por IA.",
            "palavras_chave": [
              "Claude Code",
              "Opus 4.1",
              "Codeex",
              "automação",
              "programação assistida por IA",
              "Quotely",
              "modo ultra pensar",
              "comparativo de ferramentas",
              "correção de bugs",
              "opinião do usuário"
            ],
            "resumo_em_topicos": "- O criador do canal testou o Claude Code Opus 4.1 após problemas e percebeu uma grande melhora na ferramenta.\n- Ele chegou a migrar para o Codeex por conta de bugs, mas considerou o Claude mais eficiente.\n- Demonstrou um projeto real (Quotely) em que o Claude Code conseguiu resolver soluções complexas quase sem intervenção humana.\n- Destacou o novo modo 'ultra think', que facilita a identificação de respostas mais elaboradas.\n- Comentou sobre a importância do Playwright MCP para integrar automações.\n- Ressaltou que a experiência recente foi superior à das semanas anteriores com o Codeex.\n- Concluiu renovando a assinatura do plano Max e recomendando o Claude Code Opus 4.1 como uma solução robusta para programadores.",
            "prompt_tokens": 1910,
            "completion_tokens": 504,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 31.835376977920532,
          "language": "",
          "view_count": 1264,
          "has_transcript": false
        },
        {
          "id": "Dk7ZRUwsJdk",
          "title": "QWEN CONTINUA A SER COZINHADO: Qwen3-Coder-Plus acaba de ser lançado",
          "title_pt": "QWEN CONTINUA SENDO DESENVOLVIDO: Qwen3-Coder-Plus acaba de ser lançado",
          "url": "https://www.youtube.com/watch?v=Dk7ZRUwsJdk",
          "published": "2025-09-22T19:01:36.307964",
          "published_relative": "há 22 horas",
          "duration": "08:14",
          "date_published": "2025-09-22T11:45:35-07:00",
          "transcript_available": true,
          "transcript": "Hey guys, welcome to this video where we're going to be talking about Quen 3 Koda Plus. Now, I wouldn't normally talk about a model like this. However, I've been recently pretty impressed with Quen 3 and just how well it's actually working and how well it works, etc., etc. So, I'm going to be testing out in this video. I've already got the benchmark, the normal bog standard benchmark running um here, uh which is the benchmark that I always do. It's this one here. It's the prompt to generate a service website. But at the same time what I want to test is I want to test the same prompt inside um the CLI right because you can see here this is Quinn3 coder plus which is the new model. So let's just do the same thing. So MKD coder plus cdcoder plus then we'll write quen and then we'll put the same prompt here. There we go. So now it's doing both things at the same time. It's running two. Right. So, we have one where it's created the next the next my app using kilo code. And then we're going to do the other one now. Now, I need to put this on um where it doesn't ask constantly for permission to do things. So, let's just see how to do that. Auto approve. Auto approve enabled. Just everything. Um, right. Yeah. Okay. I just want everything. Can I just put a star here? maybe and save. Done. And save. Okay, there we go. Done. So, that should put everything on auto approved. So far, this is pretty quick, I have to say. Surprisingly quick. Um, let's see if I can do the same thing here where I skip permissions. Accepting edits. Okay, so they've copied Claude code. So, okay, so we got both running here, I hope. Okay, this one is struggling obviously, but let's see if it can work through the the struggle. Yeah, looks like that did it. Looks like it installed it properly. This is flying. I have to say this is absolutely flying so far. Yes, always allow. Come on. So, yeah, Quen Coder. I've been really impressed with uh Quen Code Max was the model that I used. Very, very impressive stuff, but it wasn't available in Quen Coder. So now that we can use the latest model inside Quen Coder, I'm very very curious to see just how effective this new Quen system actually is. So I'll let these run guys and I'll give you my thoughts on them in just a second. Couple of things to note. This is a brand new model 5 days ago, 17th of September. Quen 3DOD Plus. It's Alibaba's proprietary version of the open source Quinn 3 coder 480 A3 uh A350B or 35B. It is powerful coding agent uh model specializing in autonomous programming via tool calling environment uh interaction combining coding proficiency with versile general purpose abilities. So what that basically means is it should actually perform even better inside Claude CLI and I can tell you h sorry not claude CLI uh Quinn CLI and I can tell you right now that is a very good um data page like normally they're much shorter so I can already tell that this is actually an extremely good model um and it's just so fast as well it's actually kind of crazy. I'll let these run guys. We'll go through them once it's done. We'll see how many mistakes, how many errors there are, etc., etc. Okay, so the CLI one is completed. Uh kilo code one is still running. Uh my old school Runescape Iron Man is still splashing. So everything is fine there. Uh let's just see if this is any good basically. So uh this is in Koda Plus. I need to go to COD plus. There we go. And then I need to open that inside Visual Studio Code. So we got a new window here. File, open folder code plus. Okay. And then we go terminal, new terminal. We do cd my next app npm rundev, which should work first time. There we go. And let's see. Okay, some color problems. Pretty basic layout, but I mean it's done the job for sure. Looks like everything is generated properly. Yeah. Okay. Not bad. Not a bad attempt at all to be honest with you. For quite a cheap model, this is pretty good. Um I would say this would be good as like the coding model and then using something else as like the planning model. Let's see. Yeah, I mean the code here is pretty perfect to be frank. Oh, there we go. Pagon, which is page not found. So, there are some um 404 issues on here, which is a bad sign. But yeah, I mean, overall, this is a pretty damn good attempt by um by Quen again, right? Comparing this to this says 2023. That's interesting. Compared comparing this to most other um I know this isn't free or open source, but like based off a free or open source model. Like, we haven't heard anything from Llama, for example, in [ __ ] ages, by the way. Can I just say never heard any never heard anything back from llama and meta and stuff but Quen have been cooking and yeah this is pretty damn cool. So this is using my Quen subscription just so you know guys. Um I'm not actually sure. Oh Quen max preview. So there's another one here. Interesting. The most powerful language model in the Quen series. I'll have to be testing that out as well in a moment. I think I did test that before but it's not available in the Quinn CLI. So, that's what kind of what I was waiting for. I just wanted to see if I'm paying for this cuz I'm I'm really not sure if I'm paying for this or not. Um, okay. So, Quen 3 Max preview, which I didn't see on Open Routter, as far as I know. Let's have a look. No, it's not. So, Quen 3 Max is here, but Quen 3 Max preview isn't. Yeah, this is the one I tested before on September the 5th. I remember. I wonder if they're the same model. Quen's next model is going to be very, very interesting, guys. I have to say, I don't think I'm paying for this. I'm pretty sure I'm not paying for this. So, this is a free almost as good as [ __ ] um Claude model, which is completely crazy when you think about it. Okay, let's see how Kilo Code is getting on. Uh looks like it's still got a bit of work to go. I'd be curious to see if there's any like a big difference. This cost 175 on API cost, which is pretty reasonable. I'm just curious if there's going to be a big difference between these two or not. Okay, so I haven't really got time to wait for this to fully finish, but this is what um Kilo Code built. It does have a few errors, but uh obviously it's not really a fair comparison because I'm not I'm not letting it fully run. But I mean, I would say this looks a little bit different um to the other one, which is good. It looks a little bit better, but it is still pretty basic just like the other one. Uh, it's automatically in Italian, which uh, like I said, I haven't fully Hang on. There we go. Okay, so the English one didn't even work there. Oh, that's because of that. Let's see if I put weddings here. Yeah, it works. Um, so yeah, overall this is pretty good for a medium level, not free, but based off a free and open source model. Like traditionally, they've been absolutely crap. This is Alibaba's um, proprietary version of Quen. Quen is open source and free. They took Quen and they built this and it's a very lowcost model that can do pretty good code to be honest with you. So if that's what you're looking for, this is definitely worth your time. I think in my opinion the next Quen model um Quen Max once Quen Max is available inside Quen CLI, I genuinely believe it's going to be a competitor for uh Claude Code. Um but yeah, you may call me crazy, but that's my opinion. Thanks so much for watching, guys. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo avalia o novo modelo Qwen3-Coder-Plus, destacando sua eficiência e custo-benefício para programação autônoma.",
            "resumo": "O apresentador analisa o modelo Qwen3-Coder-Plus, lançado recentemente pela Alibaba, testando sua funcionalidade em tarefas de geração de código via CLI e benchmarking comum. Ele destaca a rapidez e a competência do modelo, que é baseado em uma versão open source (Quen), mas aprimorado de forma proprietária pela Alibaba. Foram comparados resultados de diferentes ambientes, mostrando que o Qwen 3 se sai muito bem para gerar código, apesar de pequenos erros. Não é totalmente gratuito, mas ainda assim oferece uma performance alta com baixo custo. O criador do vídeo considera o Qwen altamente competitivo no universo de IA para programação, sugerindo que futuras versões podem rivalizar diretamente com modelos de destaque como o Claude Code.",
            "assunto_principal": "Análise e teste do modelo de IA Qwen3-Coder-Plus para automação de programação.",
            "palavras_chave": [
              "Qwen3-Coder-Plus",
              "programação autônoma",
              "modelo de IA",
              "Alibaba",
              "benchmark",
              "modelo proprietário",
              "código aberto",
              "CLI",
              "baixo custo",
              "Claude Code"
            ],
            "resumo_em_topicos": "- O vídeo apresenta e testa o modelo Qwen3-Coder-Plus, recém-lançado pela Alibaba.\n- O apresentador faz comparações entre a execução via interface padrão e linha de comando.\n- Destaca a alta velocidade e eficiência do modelo para geração de código.\n- O modelo é baseado em código aberto, porém aprimorado de forma proprietária.\n- Aponta pequenos erros nos códigos gerados, mas com qualidade geral acima da média dos open source.\n- Ressalta o baixo custo do acesso ao modelo e sua competitividade no mercado.\n- Sugere que versões futuras poderão competir com nomes como Claude Code.\n- Encoraja interessados em automação de programação a testarem o Qwen3-Coder-Plus.",
            "prompt_tokens": 1940,
            "completion_tokens": 454,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 30.21173930168152,
          "language": "",
          "view_count": 2036,
          "has_transcript": false
        },
        {
          "id": "mg7W1cF5Lxs",
          "title": "Este novo modelo Stealth NÃO é o Soneto 4.5 (A Verdade)",
          "title_pt": "Este novo modelo Stealth NÃO é o Soneto 4.5 (A Verdade)",
          "url": "https://www.youtube.com/watch?v=mg7W1cF5Lxs",
          "published": "2025-09-22T17:01:36.307986",
          "published_relative": "há 1 dia",
          "duration": "12:07",
          "date_published": "2025-09-22T05:41:56-07:00",
          "transcript_available": true,
          "transcript": "Okay guys, welcome to this video. I was right. Okay, I'm just going to say right now I was right. There is a new stealth model and oh look, it has 200,000 context window. H I wonder what this could be. I think this is Claude 4.5 Sonnet Opus. Don't know, don't care. Might be HiQ 4.1. They might be being sneaky. Actually, I'm going to call it right now. This might actually be HiQ 4.1 because it's apparently very very fast. I'm going to be testing out this model. I don't know if I'm going to use Klein or Kilo. Not really sure yet. I don't really know how these companies even get in touch with uh Okay, so apparently it's not on Kilo code. So, it's on Klein. Um let's try uh Supernova here. Yeah, I I'm convinced this is I'm absolutely convinced this is going to be 4.1. So, supports image, supports browser use, supports prompt caching. Oh, look. It supports browser use. Guess guess what the only other models that normally out of the box support browser use are. By the way, it's it's Sonet or Clawude models, just so you know. Okay, so I am going to test this out. But unlike other people who are claiming this is almost definitely Sonet um 4.5 or whatever, I'm actually going to make a prediction and say that in my opinion this is um this is actually HighQ 4.1 or something. So they're gearing they're gearing for slightly less hype than people are expecting. So this is the prompt that I normally use. I'm going to try and see if it can scaffold itself an app though. So I'm just going to dump this prompt in. Let's just quickly open folder here. We'll just create a new folder. So new folder. This is um new model. So, I'll just open this folder fresh so that it can at least, you know, be in its own folder. So, client code supernova. Give it the prompt and we'll see how this goes. Now, apparently this is super quick, which is actually what makes me suspect that it's not Claude Sonnet. It's actually HiQ, but this doesn't seem actually as quick as I was expecting. Okay, so it it it create. Okay. Yeah, that's that's a good start. So, this is on my school community, by the way, guys. If you're curious about joining the school community and you're just getting started with AI coding, definitely check out the school community. It'll be one of the links in the description. Let's just quickly check this out. So, what is this model called? Code. Oops. Code Supernova. Free stealth model now available in client. So, this is 3 days ago. I didn't even notice this. That's crazy. Supernova is clawed 4.5 or G code 2. So, people aren't sure. The dumbest model I've ever used. Yeah, for sure. This is HighQ. It's actually made by Xia. Probably Rock Code 2. Okay, so apparently it's not going to be Sonic. I'm just going to I'm definitely going to be testing this, but yeah, people aren't sure about it at all. Oh, hello. Yeah. Okay, so I have a feeling this might not be um a decent model. People are people are claiming of course that it's Claude 4.5, but I'm actually not sure that it is now. Uh is this is Grock code 2. It's free and really what free and really good. It says 100% clawed 4.5. It self-reports as anthropic doesn't really matter. It has purple gradients which is genuinely yeah interesting. I reckon it's highQ 4.5 guys. I'm not going to lie. People are not People are saying it's not incredible which in my opinion it means that it's highQ good price. I'm just reading comments just trying to find out what it is here guys. This is the absolute classic. I love this in the AI community. It's trash. makes no so much mistakes and don't care for everything. It tries to create dobbat files. What the [ __ ] And then someone just says that shows how bad you are in prompting. This is all you ever see when someone says, \"Oh, uh, this model is not very good.\" Well, your prompting is not good enough. I love that in the AI community. >> Oh man, the AI community makes me laugh. There are some complete crazy people in the AI community. I'm not going to lie. It might not be Sonic 4.5, but it's model from Cloud. Come on, bro. It's Claude. Blog tells us blog code tells us enthropic. Guys, just say no. Right. Asking an AI model what [ __ ] model it is is so stupid. I'm sorry if you do that, but yeah, take take what you want from what I just said, but it doesn't work. Okay, a model will tell you it's chat GBT 3.5 for God's sake. Come on. Like, that is not a good way to do things. Please. Maybe Amazon Nova. Oh, yeah. True. possible. There is no Sonic 4.1. Yes, there is. Don't think it's claw 4.5 because Claw 4 is performing better for me. It's always it's also somewhat ambitious. Writes code modifies files even when I tell it just answer my question about my code base. But yeah, I mean that is a Claude. That is something Claude does do as well. So what I'm actually trying to do right now guys is I'm trying to give you a kind of understanding of how I work out what a model is, right? And how good a model is. So a lot of people are saying it's really bad, right? It's very bad. Haha. and it's got 200,000 context window, but it and it's very very fast. Right? So, in my opinion, what I'm taking from that is that it's highQ 4.5, right? Or highQ 4 or highQ 4.1. This is something that a lot of companies do. They build up hype about a new model. Everyone gets excited. Buzz buzz buzz buzz. Is this club 4.5? And all the Twitter mentions go up and you know, what have you. And then bang, they hit you with the Yeah, it was it was Haiku 4. guys enjoy highQ4. This happens all the time, just so you know. So, this is absolutely not new. So, 200,000 context window multimodal support built for a coding. But if you actually you can do a little test guys if you don't believe me that this is a claude model. I'll show you another way to check. So, if we go on client here and we go on any recent model. So, claude code fast one. So you can you can tell it's not Grock because Grock doesn't and never has and I don't know when it ever will support images and uh browser use more importantly images are probably supported by most. So even GBT5, right? It doesn't support all of them, but all anthropic models have 200,000 and they support all of the things online, right? So look, supports all 200,000 tokens. Supports all 200,000 tokens. In my opinion, this is HighQ 4, HighQ 4.1, and it's just going to be their cheap improvement on um the HighQ family, which I can tell you right now, nobody [ __ ] about. It is what it is. Uh if it's super fast though, that is pretty interesting. Oh my god, what is it doing? I have never seen anything like that before. Okay, interesting. It's very fast. Okay, but I'm not going to cope here. I'm not going to be like, \"Oh, it's actually really good, guys. My god, this this is insane.\" Right? My titles and thumbnails are different to my actual videos. It's just the way it is, guys. If you can't get over me writing insane in the title because it gets more clicks, I'm I'm sorry, right? I'm sorry that I I do that, but I don't really have a choice because if I don't put insane, it rarely gets like even 2,000 views. So, like I'm literally forced to write the word insane. But like I just hope that people can understand that, you know, there's a difference between someone who does title, thumbnail, and then actual clickbait or whatever in the video and title, thumbnail, clickbait, and then like actually tries to give value and tries to give something in the video, right? And I'm also not AI generated and I never will be. I'm I'm not going down that route because at that point it's not my channel. It's just I'm just an AI, right? So probably not going to go down that route anytime soon. Let's have a look here. Okay, so nothing works. Beautiful. Beautiful. I like it. I like it. Um, so far terrible experience. This is not This is not going to This This isn't anything new. It's nothing crazy. Um, yeah, not not too impressed by this. It's fast. I'll give you that. But I don't really care about fast models. I care about good models. I think this is Haiku. Claude Haiku. That's my guess. Um, and they're doing it to build up the hype like they always do. So, everyone refreshes their Claude code subscriptions because oh my god, Sonet 4.5 Opus is insane. But yeah, I'm going to use a different title. I'm not going to I'm not going to clickbait with um if it if it says Sonic 4.5 in the title, I'm asking a question. I'm not making a statement. Okay. But I don't think this is Sonic 4.5. I really I'm ing on the side of um HiQ 4.1 would be my guess. I'm surprised though if it is Haiku 4.1 that they haven't increased the context window. I don't know what it is with Anthropic. I don't know if they have a major problem with context windows. I'm not really sure what the issue is over there at Anthropic. Um but they don't seem to ever be able to break through the 200,000 context window unless you pay them five grand a month, which is not happening for most people. So yeah, very interesting stuff, but just another cheap [ __ ] model that nobody really asked for and nobody needs. Is this their opensource model? Is this a competitor to GPT O? It is called Supernova, which makes you think of game changer. Yeah, that would make sense. I don't think Claude has an open source model, right? Claw opensource model. They don't have any, right? Yeah. Okay. So, actually, I'm going to change my prediction here. I think this is Claude's answer to GBT O. The reason being is there's no way they're still stuck on 200k. Oh, okay. It's not terrible. Uh, yeah, it's pretty basic though, guys. I'm not going to I'm not going to [ __ ] [ __ ] I'm not going to beat around the bush here. It's pretty basic. Let's be honest. It's not It's not fantastic. None of the pages work. And it says it's completely done. I am going to change my prediction. My prediction here is this is okay. I'm going to say two things. This is either IQ4 or 4.1 or this is Claude's answer to GPT OS, which is their open-source model that they'll be releasing to compete with GPT OS. I think I'll leave the video there, guys. this definitely isn't worth your time unless this is an open source model in which case I mean it did a pretty decent job for an open source model if it's open source. We'll find out in the future what it is whether it's open source or not. This SVG is very strange but it actually interestingly again this SVG here is pretty much exactly the same as the one that um Claude made recently for me. Oh, was it Chad GPT? It might have actually been Chad GPT. This result here kind of looks a bit more chat GPT to be honest. So maybe it's like GPT OS the next one. What open GPT OS. Um what what uh context does this have? If this says 200K, I'm going to say this is like an improvement on GP. Okay. 131,000. Um I'm not exactly sure what this is. This is either an open source model from Anthropic or it's um HiQ4.1 or HiQ4. I'll leave the video there, guys. Thank you so much for watching. If you're watching all the way to the end of the video, you're an absolute legend. And I'll see you very, very soon with some more content.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo discute especulações sobre um novo modelo de IA 'Stealth', analisando se é o Claude 4.5 Sonnet ou HiQ 4.1, e critica o hype na comunidade de IA.",
            "resumo": "No vídeo, o criador comenta sobre o surgimento de um novo modelo de IA chamado 'Stealth', com janela de contexto de 200.000 tokens, suporte a imagens e navegador, além de ser muito rápido. Apesar dos rumores de ser o Claude 4.5 Sonnet, ele afirma acreditar que se trata do HiQ 4.1 ou uma variação da família HiQ, menos famosa. O apresentador mostra seu processo de teste com o modelo e destaca que a comunidade de IA costuma se dividir entre exaltação e críticas quanto à qualidade do modelo. Ele ainda critica o método de perguntar para o próprio modelo qual é sua identidade. Por fim, afirma que não ficou impressionado com a performance e alerta sobre a diferença entre títulos chamativos e o conteúdo real do vídeo.",
            "assunto_principal": "Análise e especulação sobre a identidade de um novo modelo de IA 'Stealth', com críticas ao hype e à comunidade de IA.",
            "palavras_chave": [
              "modelo Stealth",
              "Claude 4.5",
              "HiQ 4.1",
              "inteligência artificial",
              "teste de modelo",
              "hype",
              "janela de contexto",
              "velocidade do modelo",
              "comunidade IA"
            ],
            "resumo_em_topicos": "- O vídeo começa com o criador discutindo um novo modelo 'Stealth' de IA.\n- O modelo possui 200.000 tokens de contexto, suporte a imagens, navegador e cache de prompts.\n- Especula-se se o modelo é Claude 4.5 Sonnet, HiQ 4.1 ou outro.\n- O apresentador realiza testes práticos, comenta sobre a velocidade e a experiência de uso.\n- Destaca que muitos na comunidade de IA discutem sem chegar a um consenso e há muita especulação.\n- Critica o hábito de perguntar à IA qual modelo está sendo utilizado.\n- Fala sobre o exagero dos títulos dos vídeos para ganhar visualizações.\n- Conclui que o modelo, apesar de rápido, não impressiona em termos de qualidade.",
            "prompt_tokens": 2116,
            "completion_tokens": 505,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 62.348257064819336,
          "language": "",
          "view_count": 1881,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@LiamOttley",
      "name": "@LiamOttley",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "jhVg-Zbz0V8",
          "title": "3 AI Agent Use Cases Every Business Will Pay For ($100K Playbook)",
          "title_pt": "3 casos de uso de agentes de IA pelos quais toda empresa vai pagar (manual de 100 mil dólares)",
          "url": "https://www.youtube.com/watch?v=jhVg-Zbz0V8",
          "published": "2025-09-22T17:04:13.480558",
          "published_relative": "há 1 dia",
          "duration": "49:30",
          "date_published": "2025-09-22T01:39:47-07:00",
          "transcript_available": true,
          "transcript": "What if you could quit your job and build a $100,000 a year AI business by just focusing on three core offers? No guessing, no shiny object syndrome, just a proven blueprint of what to sell and who to sell it to. In this video, we're going to be breaking down the exact three agents he's selling, the painful business problems they solve, and how you can start building and selling them yourself. So, let's get started. Evan, mate, how's it going? I'm uh looking forward to jumping in and hearing about these three agents you've been uh you've been telling me so much about. Thank you for bringing me on. So Edin's been deep in the in the trenches of working on. I think it's an interesting uh topic to discuss really is the difference between these fully conversational agents that you build uh where it's sort of a system prompt and you're doing high level programming via prompting versus being a lot more granular and having much more control. And I think you guys are going to be very interested to hear about how uh using voice flow you can sort of combine these this the granularity of something like voice flow with the uh sort of free free form and sort of more uh agent style of of building building chatbots and and AI systems um into some of the most powerful and valuable things that businesses really really need right now. I think this is going to be a very refreshing angle to hear how um you can position these in like I suppose it's it's trying to sell a a website chatbot that does something very basic is of course going to be people trying to sell the tech. They're trying to sell the thing for so long and there wasn't necessarily a big business outcome while you might convert like a few% of your traffic to warm leads. Um but in this case everyone's found basically the agents that sit right on top of valuable business business problems and how to deliver on that across these three different categories. So keen to get into it, Matt. So these are just more than just you know chat box that you put on the website and I'm going to break it down why right so the first agent um is what I call CX agent. CX stands for customer experience agent. So it handles a lot of use cases where there are high volume conversations between the business and the customers themselves and it's trying really to smoothen that entire journey to really push the sales to a close in the end. Right? by ensuring that it's actually providing a lot of personalization by making sure that we actually care about the customers and making the brand's voice really consistent throughout these communications with the customers. Right? That's the first agent. And the second agent is the or I call it revenue recovery agent, but other people might call it differently. All it really does is it saves customers who disappear purchase. So if they're in the middle of a sales cycle, it will basically people who disappear or they just go to the business, it would try to save that. which basically catches up on customer who's you know about to leave but like hey this is the brother that don't leave yet and it's trying to bring back some of the leads that who have already left who have already ghost who went silent right who's kind of been dormant and you're trying to revive them essentially in a way and the last agent is the commerce agent and from the name itself it's quite specific to a use case right like for example retail and all it really does is helps customers find what they want and guide them through the entire purchase cycle and to process those pavements instant. So these are the three agents that I I found that has the most success to the market right now. And what sort of ticket size you think you've got on there? Uh the value of each. What sort of range are you selling these things for at the moment? I know there's a lot of variation in terms of scope, but what's the ranges people can expect to sell these kind of things for? So from experience, so a customer experience agent can have something I've circled them between something like 7,000 to 20,000 figures. And for revenue recovery agent, usually we market them around 10K. And for the commerce agent, again, it really depends on the scope. For simpler cases, we sold them for $5,000. For a slightly more complicated use cases, then we sold them for around like 20 to 30K essentially. So, Edwin's been kind enough to reveal his whole hand here and show us exactly uh how he's selling these things and why they're built on such painful business problems. So, um you guys strap in cuz you're going to be breaking down the even the tech stack that he's used to put these together as well. So, let's start with the customer experience agent, right? One thing I want to really clarify in the beginning is that this is not customer support because I've seen so many like tutorials or like creatives like talking about customer support, right? It's a big use case. But there's a difference. Customer support is being reactive. It's when things have gone wrong. When the customers want to, you know, they they need help with something or they just have something to complain or they want to troubleshoot something, right? Whereas customer experience agent is being proactive. is trying really hard to really keep the customers within the customer journey without them basically just leaving halfway through. It's actually that's the major like use case. If you literally imagine a business, let's say a pet grooming company, right? This is actually based on a real case study which I will dive a little bit more in details as well. But for now, just imagine there's a person called Sarah in that example and she has a dog called Bobby, right? And let's say she wants to arrange the dog for a dog grooming company. What Ruby does is basically they have a company that drive vans around the country and they try to basically try to clean and wash out the dog essentially and let's say she's a member of that company and she wants to book an appointment for Bobby right so she sent a text message through SMS to the company I want to book a another session for Bobby now the problem is they are quite a small team so they basically are member a team of five to six members and one of them is on the phone all day dealing with conversations s were basically 100 plus different members at the same time with basically the same questions. Now, we're all human, right? Like we work like 8 hours a day. There's only so many conversations you can have before you basically just you know what it's too much for me, right? And this is exactly what's happening with one of my clients which is a packing company. It's like okay I just it's way too much information like too way too many conversations to handle and a lot of the time they found that the response quality actually drop and they actually can just do something like oh just fill in this form right and there waiting time it's not great like the experience is just not great that was kind of the picture now imagine you have another agent that can basically personalize the conversations to a point now when Sarah test texted the company I want to book another session for Bobby it will say hi Sarah How's Bobby doing with his anxiety? Right? Because the assumption is that sometimes with some with some of the BS, they usually have some sort of anxiety issues or they have some sort of sensitive areas that basically needs to be a bit more careful with during cleaning. So, it will say that if there's an issue, right, it will say, \"Hey, how's doing with this anxiety?\" I can see from his last session really well. This is so interesting that you've gone like I mean the platforms don't really offer this stuff right now. Like I think HubSpot's been trying to do it saying that oh you can have full context of the past interactions with your customers but seeing this actually implemented on a small business scale is uh is is very very interesting about how you can have these kind of persistent persistent memory across different conversations um with the same customer. Yeah, exactly. And that's actually what customers want, right? Remember the business is a premium brand. So like you don't want to have a feeling of like just oh you're just another number, right? You're just number one out of like 100 customers, right? We want them to feel valued and that's where to make to make them feel valuable is by remembering little things like the anxiety or like oh would you like to book his usual food grooming for next Tuesday morning right that's being attentively saying hey my my my customers actually boo like his bad for for grooming every Tuesday it will remember that that's where the customer a good customer experience should have so maybe I can generalize that a little bit um into maybe like what kind of businesses with womb. Yeah. Basically small B2C's company like business to c consumers company that's kind of drowning in customer communications right usually again they usually have a small team that's handling a huge volume of conversations and they usually have their service businesses that have very very strict like brand voice requests. Again the reason why is because they want to be premium. That is why as an example for this pet company they have very strict language guide. As an example, we literally have like a 20 page like voice system which you can actually I have shown kind of examples of it in the guide but just to give it a snapshot of it. There are few keywords that the agent should be able to say for example instead of customer client you should say member instead of owner you should say pet like this level of detail is what is what really business is looking for to keep that premium feeling and keep that good customer experience. And the the problem is that chatbots are give us such a bad vibe of doing that. Like it give off such bad like vibe where it just keeps on saying like the same stuff over and over and over again. It's it feels really cheap. It feels really general. Right? So that's the challenge. How can we automate that experience? Right? That's the use voice for this. And maybe I can show a walk down a little bit how we kind of break down that um tech tech architecture. I think um you have some you have some data up there on uh on the CX use case. I think this is just a really really interesting thing. This is like the main takeaway um for this section guys is that uh improving the customer experience is one of the most like validated ways that AI is is providing an ROI or making a meaningful difference in the business. And I think this is a huge huge takeaway for you guys. We need to be using AI in areas that are natural to it and help you know you're not you're not forcing a fish to climb a tree kind of thing, right? And I think sometimes people try to get AI to do these crazy tasks that uh it's not really that well suited for and in this case the improved customer experience is showing in the data that this is where it's really providing a meaningful difference to businesses and it's like the fast response times it's more personalized messages it's better availability and these sort of external or like customerf facing systems um that takes takes it beyond just that customer support to being uh proactive I think is a really important thing for you guys to look at uh when you're coming to maybe niching down your agency or or or working with these kind of systems like you are Edin. So really really interesting to me that uh these I mean these are going to be everywhere in a few years right always so interesting for me to see as you guys will see in a little bit how Edwin's built these but when you notice that there's some major thing like this okay well in a few years every business is going to have this but right now a guy like Edwin is having to use voice flow and air table and and like cobble together all this stuff it shows that we're still so freaking early in this that there's not a centralized way of doing this by the way this I think this came out like maybe last week or last two weeks I can't remember exactly but this came came up very recently and I didn't obviously I didn't know about this beforehand but like a lot of the report by the way I recommend actually having a read on the report and yeah basically this basically confirms a lot of what I kind of experienced in the market right so as as you can see the top gen AI impacts across business area the second use case customer experience this is just behind productivity how crazy is that right far ahead of marketing which is what what you'd think yeah you'd think that would be like that's what everyone's trying to use it for Yeah. Yeah. But like actually there's like these three at the top. Yeah, for sure. Um maybe now I can break it down how we think about building this kind of system a little bit. This is the overall architecture. So we have the incoming message. Let's say hey just want to know where my dog's next appointment is. All these conversations are through SMS and we they use the client use over which is basically a Twilio variant and it passes through the message passes through to voice flow and voice flow acts as the braid. Now what I mean by that is two things. The first thing is persona. So basically giving the LM an identity. So you might know you might notice from prompting we always say something called identity prompting right? You are a uh customer experience agent right? But we take that a step further. We give them a name, a backstory, what it's trying to do, how many years of experience it has, right? And try to just be as specific as possible. Try to make it as almost like a character essentially. And yeah, implementing the brand voice within the persona. So that's that doc that you mentioned before, right? Yeah. Exactly. Exactly. Right. And we have the conversational flow. We have a flow for new member which are the new customers and we have the existing member which are the majority of the use cases. And most of the intents of the conversations usually have two things. It's like general questions or appointments, right? And the way that we can actually have that personalization is have all the customers and pub profile data saved in a database called Zeno. Now Zeno um is a database like to store all this like pub and customer data. And the way we do that is we retrieve that entire like information about the customers. their name, the email, this is the basic stuff, the address, but the more important stuff I guess is the dogs themselves like the when's their birthday. Like we literally have systems like if it's your birthday, say happy birthday to the dog, right? Yeah. To for example. So like and we have like the sensitive areas is like okay the sensitive areas I said before is like the face muscle. So we the agent should be able to take all of that information and draft a personalized response to the user. That's what we meant by personalization, right? That's awesome, man. Yeah. And um and for the questions because I know another thing is the customers have a lot of question answer pairs. So for example they have a set of predefined questions and they have a set of brand aligned answers that they want the agent to copy exactly as like a template essentially for the LM to generate a response. So the way that we do that is rather than like using a knowledge base right which if you know how rag works is like basically how to retrieve things semantically we actually wanted to retrieve this exact phrase like 100% of the time how we do that is we basically have each questions we give them a question ID right and based on the question ID like we semantically search for the question ID and then it search goes through the air table retrieve based on the question ID retrieve the questions and the answers and all relevant information like instructions etc. So it gets a little bit more complicated than that. But then the core idea is it pulls back all the information back to voice flow which basically has is this super brain that has all the information that he needs to generate response. I'm going to I'm going to call you on that on uh technicality here. Do you think it's necessary to have a retrieval system for a relatively small set of question answers there? Could you just stuff like the the tokens are cheap nowadays? There's a there's a huge amount of content you can fit in. So, where do you draw the line of like going to the rag system? Because there's a question of like is rag dead because of these massive models that are so cheap now. Um, is it is it a latency thing that you're trying to solve for? Like what is what is the difference here? I just think that there's a misconception that rag means factor search which is not true like maybe maybe our mind of the dummies needs to have that explained like what what do you mean? It's basically um it's rag retrieval retrieval augmented generation. Yeah, I guess it doesn't it doesn't have anything specific to a vector store, right? It's retrieval augmented. It's like context engineering is I think the buzz word they call it these days, right? Yeah, exactly. Like what what vector search like rack initially like basically to give you some context where the vector search comes from is when rag was becoming a thing a lot of basically a lot of the big vector stores company like pine cone um chor etc right they really try to push that product out and suddenly like everyone is like talking about vector it's like oh semantic search is the best thing right it's like these are things that are semantically similar to each other it means the retrieve accuracy is bad must be better but that's not necessarily the case what we're really trying to solve is like a search problem. It's like basically matching keywords, just searching for the on the user. Yeah, like cool the answer, right? So, yeah. So, rack is not necessarily just like back to search. And two, where do I draw the light? Well, because we're trying to build something like that's actually scalable, right? So, right now it has over I think 100 different questions. Okay. I was thinking you just had like a little 20 20 Q&A on on this though. That's obviously a lot of work for the client to do. So like I get if they've got a quick F FAQ on their site like how do you how have you found this when you're asking them hey we need now we need a 100 question and answer pairs from you um do they push back on that at all? Do you have an AI solution to it where they can just like upload their upload their knowledge what would have been the knowledge base and then you're converting that with a with a basic automation to convert it to like a com CSV file that you can imple import into here. You know what the good thing is I'm very lucky they already have that set up in a Google sheets. Okay. Okay. I guess that's for the existing support team, right? You can just probably find the existing support docs if they've got a support team, which you'd hope they do. Exactly. Because But what they literally do, they literally just go to the question. Okay. The guy basically the person who's texting the customers. Okay, this is the answer. Okay, I need to copy these answers. Okay, so you've just you've just automated their existing support process here, which is uh which is great. I think uh SMS is a channel. Um it's always it's always been an issue of what's the interface. It's like, how do you have these fully integrated end to end like customer experience things? Um, it's not like you're going to, hey, download our like dog grooming app. Like, you don't really want to force people to do that. Um, what you're going to send them to a website, then they're on the browser on their phone and they're going through this interaction. It needs to be either like through voice or it needs to be through SMS or WhatsApp. And those are really the best entry points people have. But then obviously SMS is sometimes like much more a US-based thing. WhatsApp's probably a bit more common for the rest of the world. Um, so it's it's interesting that you've I mean I think that these channels are are are essential if you can have these sort of fully contextualized conversations across these channels. It's it's really really powerful businesses and they're all going to have it soon. Yeah. And I think the key thing is we want the least again we're back to the customer journey like customer experience side right like the way that you want them to build them is like what's the least resistant path for the customers right as you said I don't want to go to the website I don't want to into another app like SMS just feels natural as well as WhatsApp right yeah I mean if you could just make phenomenal SMS experiences that are like this for businesses like you are on some built right over a gold mine yeah for sure um if you just want to show just that uh quick glance at that voice flow thing there. Um people can pause if they want. You guys have access to this board if you want to uh have a have a cruise around. Um but that's an example of what it looks like when you're setting these up on voice flow. Obviously a lot more uh logic based. Um but I assume there's there's aic parts within that. We can we can jump onto the next one to keep this moving. Another example for you guys is um another case that I have is for two way like basically this this link with the board will be in the description so you guys can actually see for yourself if you want essentially this is a more customcoded solutions like using Python um Bangraph and Pantic AI which is more customcoded frameworks and it's just another kind of a more advanced example of what you can actually push in terms of building these conversational systems and the second agent really want to talk about is the revenue I call it revenue recovery agent right like before I kind of jump into like all the techn technicalities. Let me just try to again I use Sarah again as another example and this is a very cool use case is because this company is quite unique in what it does. is an education consulting company and what they do is there are many students who want to study abroad in the UK right and they don't really have an idea of okay what schools do should I go to now the use case is when the students go to do these kind of consultations and also do the admission test that data being saved somewhere in the database but a lot of the times the CEO found that none of them actually got back to them like they took their stuff they took all the good stuff and then they just don't want to proceed like it's like oh I'm not too actually too serious about studying in the UK or like I've gone to another competitor who's cheaper whatever right whatever reason and they're just okay so what they're they're doing an admission test submitting it to them or they they're getting sent the resources and then they have to do it on their end like what would they why would they come back to is like at the end of that admission or consultation like hey let us know within let us know soon if you want to move forward is that kind of they just get left on that yeah so it's actually an inerson test that you have to do so like okay yeah so it's like an internal thing within the com within the education company where based on the schools of the test they can kind of see where the level they are at and they can recommend right schools for them to go to essentially gota and yeah a lot of the students take test and they never apply now one thing I need to kind of get out is like kind of the architecture right now is kind of not very systematic in the sense that there's a lot of students almost like 300 students to handle for each consultant which is a lot now 300 including students who hasn't got back to them like all the different cases right it's a lot and it's a nightmare And they don't simply they don't have the time to follow up and they don't have the organization to follow up on those students, right? And what we what we come ahead and said, hey, what if there is some sort of followup in terms of agents that can just automatically send them a WhatsApp message that can do some sort of follow up. For example, if they don't respond after 3 weeks, you can send them a WhatsApp message. Bases basically saying, \"Hey Sarah, from the taste test that you got, you got 90% maths and 67% English, right? Here's a full breakdown of your performance and the suggested improvements, right? This how we think that you can improve. Let me know if you have any questions, right? Something like that just to give some value like basically some sort of like um automations that based on these test results and then if they still don't respond, you basically have another follow-up sequence which is basically saying, \"Oh, hey Sarah, would we love to connect you with Tim, which is another student who has the same scores as you do, right?\" He double down in pro improving English with and ends up being in Harrow, which is a if you didn't know, he's a top UK. So, so this actually gives them incentive to reach back to us and like try to finish the customer journey. Again, you know how I'm dividing kind of these these all these three agents, but they're all linked together, which I'm going to talk a little bit in the end. Yeah. I mean, just just looking at that there as well, the um don't underestimate how like if someone sends you a message like that that sounds like they've taken the time to write it to you, in this case, you personalize it based off the test results and you maybe signed it like thanks from like Jane or something or like Tim at the bottom. And then you follow up with that one again, which again is very specific, like, hey, it looks like you had a weak thing when it comes to English. I can connect you with this. Like it's a pretty good offer, an interesting thing. And again, it sounds like it's coming from a real person. When you have messages like that, like there's a you can kind of play on human nature and what how we've been programmed after so many years is that ignoring people like that, we don't really like it. Like we feel like a bad person for ignoring someone who's taken the time. So there's a a like a reciprocity thing, especially when they've gone out of their way to connect you with something uh with someone like in that second message you have. Um, so I think when this sounds like the illusion of it being a real person and through a very personal channel like WhatsApp, I don't think many people are really going to be just flat out ignoring a very personalized and a message that comes from seemingly a human account. Um, so I'd say this is extremely effective um at at re-engaging these people. Yeah. And it's really getting the attention of the students as well, right? Or the parents in this case. It's actually a lot of the time actually parents because they're quite young relatively and the parents like really you know like the parents are really like serious about their scores right they want to know how to do right so that's another thing good for them it's like what we learn is that this is really effective for businesses with kind of a kind of a complex customer journey and they have a kind of a high drop off it during a customer journey and usually that can involve businesses with you know kind of sales processes that have kind of a lot of different steps um that can not just educational services right maybe some high ticket purchases that kind of needs them time to think about, right? And the the highest ticket items they are like the people are going to take more time to consider it and you need to send more follow-ups on them, right? And filling in those gaps in the sales process for sure. Yeah, those time gaps and sometimes you just have leads sitting in CRM. It happens to the guy like they're literally people like their data like leads in the database that just sitting there. No one has like all the following up with them. It's just such a wasted opportunity as well. and and they might have spent money on ads to get those leads. you know, it's like they literally sitting like $50 $100 in the hole per lead and it's just sitting there doing nothing or you like they've come off off ads and then like they've fallen through the cracks and they don't even have a system in the on the front end like in the near term if they fall through um what to do with them like like how you can solve with this and I think the biggest pro the bigger problem is for this for this specific case study is like not having a very organized way of managing those leads which is where CRM comes from we actually introduced into CRM So that's like that's actually like a bonus I guess. I would say like for this specific use case like around 70 to 75% actually drop off like after test as I mentioned and there was no lead tracking and everything. So that's why we're like okay can we do some sort of automation around follow-ups and the reactivation sequence so the students just don't just ghost you like right and that's where we kind of think about setting this solution combining high level which is a high level which is a common CRM and voice flow. So maybe I can break it down a little bit again what it looks like. So on a on a high level no pun intended um it basically there were different opportunities. So if you have used high level before that basically that's how you manage different stages of the leads. As an example there's there's a pipeline we set up which is called as test. Well what that means is people who have taken the test but they've just kind of just ghosted like you guys. for example more than two weeks they haven't you haven't heard back from them and there are different stages like for example they have they have no valid WhatsApp numbers to begin with or you've message them no replies finished interested et goes it goes on but basically what this does is you're basically organizing the leads very systematically right across different stages and the beautiful thing about high level is that you can actually set up automation workflows inside them so essentially we have the students who you know who their flags were you more than two weeks that we haven't contacted and because in high level you can actually save information like this right is for example with custom fields you can have very specific information about students the department like education course IGC GCSE is like a UK like course so there's all these different information but basically again the key to personalization is details and data the more specific data you can collect from the leads the more kind of ammo you can use like to craft this personalized message right because you have more data both so this is where the dynamic personalization comes from comes from the custom fields of the CRM again pushes through the voice flow as the brain and the brain will send the first DM through WhatsApp now there's two cases if they reply cool right they probably like they're still interested or they're not interested and if they're not interested they want to be out like it's a compet it's basically competitive server I'm not going to name them, but then regardless if the results are good or not, like they're interested or not interested, they're going to push back to high level and say the results. If there's no replies after 24 hours, there's still no replies. Then we then set up like we basically go through the follow-up sequence, sending a second, third personalized message again through the audio. So, it's sort of jumping back and forth between a high level triggering voice flow and then waiting like you've got a a trigger or yeah, I guess a 24-hour trigger back back on high level again to kick off another another like round of personalization and stuff. So, yeah, I think this orchestration is where it gets trickiest. uh especially um when you have I don't know maybe they've been talking back and if it's conversational it's asking questions back and forth when is that conversation considered dead or like stale and it needs like when when is like okay now that's technically a conversation done we need to like re-engage them with you know it gets gets quite tricky when you have uh say like Instagram DMs is a is an interesting one when you have like maybe appointment setting going on in in DMs and within that thread it can get quite messy about like when does the agent think that that's a stop um when does the follow-up message go out. Um so it's interesting to to know how you're how you're managing that with voice flow across sessions. Yeah. So basically um the good thing about voice flow is that they have something called like session IDs. Yeah. Yeah. Yeah. Exactly. So there's a dialog manager API which you can call through the specific session. So each phone number is the session ID. Gotcha. So that's how you can uniquely identify each user and once you start like you use a basically within the within the voice flow dialog management API once you initiate a conversation it stays within that session. You don't have to again you just have to kind of do the back and forth back and forth conversation. Now where does it happen? Right? That's a that's a really good question and usually there are like people usually there three types which are really serious like they just say oh sorry I haven't got back to you. That's that one thing right or one thing is like oh sorry I just it just you know my students are just not ready yet for the studying UK which is very common reason. Second reason is I've gone to like I've gone to someone else, right? And these are just like hard though. They're just like and then we will just end up wrap up the conversation be like no problem like let us know if we can like help you anything help you in the future, right? That's it. But there are sometimes conversations where like yeah I just need more time to think about it right now. There's two like situation where we do is that we actually flag it to one of the consultant if that's the case and we actually have the consult to call them because this is the moment where like you should like the human should be doing the work now like this is like it's now or never they're going to be gone like it's like a it's like a sales issue now. It's like can you create urgency and can you push them over the edge and that that human in the loop aspect for these systems. I know that's probably the two two issues. It's like how are you orchestrating it and making sure that like the the the sessions and threads are not kind of overlapping or there's issues with um like not being contextualized about what just happened and then it's like okay how do I handle the the human handoff when it needs to be done and that's always tricky because there's the back end right like I guess you're going in through the high level kind of conversation manager to be able to jump in this so if a human does need to jump in they're jumping in on high level yeah so within high level you can actually like have a custom view where you can assign which like human like for example you can assign bot which is voice flow in this case um but you can actually change the change the assenee to one of the consultants right and because we again from the custom fields you already know which assigne originally assigned because at the beginning of all consultation each student would have been assigned a consultant so it would just change back the assenee to the original consultant that was yeah sweet all right that's um that's the what revenue recovery agent Yep. That's okay. What's the What's the last one we got here? The last one is commerce agent. Sweet. Let's jump in. Okay. So, let's talk about commerce agent now. Actually, like commerce agent by definition is going to be kind of heavy retail heavy, right? And just from the report that we're getting from Google, it's actually like 50 getting like 51% like AI agent adoption rates, which is like crazy. It's like on top of financial services and media entertainment, which is kind of what you expect. Telecom. Yeah. and healthcare is actually not that high because you know with like compliance and stuff as well and you want manufacturing manufacturing and automotive is an interesting one. Yeah, that's that is another thing to to look out for actually now that you mentioned um in public. Yeah. But the the key thing is like retail CGP is got quite a high like adoption rate which which is not surprising I guess because the use case is there right and maybe I can break it down like kind of what I'm seeing from my angle. So again, if you imagine like we've got a restaurant chain which is like one of our clients, let's say they want to order from let's say McDonald's, right? They want to do some sort of like catering event, right? And if you know for catering like it's messy because like you got some sort of large budget, you got large amount of people that you need to manage and like within the catering menu like this is just a sample that I put together. It's like this is not the real thing of course but like you've got like all the different appetizers, you got like chicken, you got like all the different food types and it's messy because they come in different sizes as well for cater. So like you got like half trays, full trays, single wraps, like it's messy, right? And the problem is that when currently the person like call them up to try to do the catering order, it's like I have a budget of $500. I have 20 people I need to feed. I want some chicken salad. Two of them are vegans and I need to buy next Wednesday and then like I'm at this location. What should I do? And a lot of the people pick up the phone on the restaurant. They just make the food. Like they don't really like basically this is asking them to okay let me take the [ __ ] out. Let me actually do the maths in real time. Okay, $500 20 people like okay this is half a wrap feeds that many people and it cost that much. Like did they do the math? It's a nightmare basically and it's causing a lot of friction. And not to mention as well a lot of the people who pick up the phone at least in this specific restaurant chain their first language is not English. So it's or it already has a language barrier that's creating friction when people trying to do a catering order and catering order usually high like relatively higher ticket items within like the whole franchise right so this was a problem like this was a problem where like okay what can we do to eliminate that friction and that's where we have considered like basically developed an agent like because within the agent you can just give the same question and you will be able to recommend like let's say three three trays of wraps, two trays of rice, two trays of salad for this like kind of specific people, right? And here's the four closest restaurant to your location. Let me know which one you want to choose from, right? And within the force flow front, it looks a bit like this, right? Spoiler aling like the recommended package like the the wraps, like how many quantity, the price, right? and also the total price and the cost per person as well. So, okay. So, you've just you've just created a is this just a a literally a a fully contextualized prompt that has all the information about like what's on offer and the unit price for that or are you pulling in from a database somewhere for this stuff as well? So, a conversation really like it's again try to help customers to buy what they want and guide them through the purchase. Right? So, again it's the entire like transaction process and try to and that includes recommended products, right? We have two cases for use case for that. Whereas like for example there's like a you know uh basically a multi-location franchise right to recommend them the catering package. There's also like a retreat company trying to retreat like retreat packages essentially. So it's obviously completely different things but it's the core logic is more or less the same. It's still recommending these something. So when they've got like quite kind of custom orders that need to put together. I mean, you can do this for like my auntie has a framing business and I know this as like, hey, I have all these pictures that I need to have framed. Like, what do you think? It's like, oh, we could put you can either like put together a couple different packages and say in her case, you could use AI image generators off the back of it and like the the it kind of like you say kind of blends into that customer experience agent. when you're like really improving the customer experience, you're going to be instead of waiting for emails back and slow back and forth, you could create this great like commerce CX agent that's able to help them to identify like get proper packages pitched, they get real tight, like very quick responses on how much it's going to cost um as well. So yeah, there's huge use cases for those. Exactly. And actually one thing I want to add like I was going to mention a bit later but I actually want to add is that you can combine the right and and the use case would be loyalty. That's actually another thing that we I'm like we're currently having a discussion with client about like loyalty program loyalty program. So for example, if the right now there's no system that's kind of you know for a normal order at least no no one is tracking like okay this customer order this food that their favorite like food item is this um etc right that their order patterns like we're discussing internally like okay what if there's a use case where you can kind of map out like the ordering patterns what their favorite food is basically data about the customers and basically build an entire customer profile based on that essentially and yeah try to basically um recommend and package that way. That's another like for that's another thing that we're having. Yeah. Yeah. It's almost like driving sales with personalized offers. It all requires collecting that data um through I I've always said that I think these conversational uh channels um whether it's across Instagram Instagram DMs or whether it's WhatsApp like WhatsApp chat bots or whether it's um on the on your website. I think all of these are going to become when you're talking to what what you perceive as an AI chatbot on on a company's website, you're giving kind of raw unfiltered, you're not really thinking people are going to be digging into it too much, but um you start to get really good like intent signals, context on who they are, what they want. And that being like data data feeds into the business on one being able to aggregate it and see what the trends are and who the who their customers really are, but also on an individual level being able to like kind of weaponize that against them but and make much more personalized offers. And that's that's clearly the way things are going. So I think this is such a great thing for people getting into right now. Yeah, it's it's such a good use case and there's not a lot of traction right now on this. So maybe a good opportunity. So that's why I jump into it, right? So um yeah, maybe I can break down it will be now. Yeah, it'll be now. Um yeah, maybe I can break down kind of the text a little bit like this. Um so yeah, we no surprise we first look again and but this use case is basically an order capture conversation flow. So all the time we're just trying to collect information. Again, it's a it's more like a data capture exercise more than anything. So we have the budget for example, what can I get for $200, right? That's the one that's one thing. Customers information like I'm not going to go through this pretty basic, right? Name, email, and stuff like that. Yep. Anytime or the event, when is the catering event, the location because they need to know like because the franchise need to know which individual franchise should be like should be producing the food essentially. That's why I didn't even So the way that we do that is through an open cage um API. So what this does is you will capture the user address. Then you will call the open cage API. Now we already have in the back end all the possible franchise locations and their latitude and longitude. All we're doing here is basically kind of the closest um distance between um the users address which would translate to latl long and the individual locations lat. So you said this is just a a pure like coded function. Where where are you hosting? So you've got a program running somewhere. Are you like hosting this on your own own little server? Um what's what's the current like just Python script that's running in the background? Yeah, it's actually through superbase edge functions. Ah cool. Yeah. So um the client set up an account there. So we just built the functions on their end. And um it's basically fetching the four closest location, right? And then the users had the choice to like, okay, these are the four locations I think that's closest to you. Uh, which one do you want? And then they will be like, okay, maybe I like that one. And they have the freedom to to choose that one. Okay. And that's the location. Now the food recommendation is the kind of the hard spot. It's basically a a coded a complete like JavaScript coded solutions. Again, another superbase edge functions. So on a very very like high level, right? It's pretty much just saying okay I I basically collect all the data that I previously should have collected based on the budget the amount of people like the like basically is there any special dietary requirement etc and we actually within the code we have like basically a priorities into which we should prioritize like there's certain parameters that are optional right so like they might not always have dietary requirements right they maybe some most of the cases like okay I just want like I have a budget that's the amount of people go do the maths, right? And it then runs through the script and it just splits out like basically the um all the food options and the prices and basically just a recommendations like to the user. It's like this is totally like totally how much it's going to cost. Um this is the price and this is like what's the what's the food items look like. Now um this is again I think I said it already is basically another super base edge function essentially. So this is where the food recommendation comes in, right? And after after all that information, it's then being pushed to like a solo CRM which they're using, right? All the leads like are saved in there. Generally, they don't save leads on CRM because there's really no point if it's just like single orders for now. But like for these larger catering like orders, they're doing so. Now this this is still in development right now because they are still figuring out the kind of payment deposit collection kind of like this basically what we want to do the angle of this right now it's just saving everything in the CRM right the angle of this is to be able to essentially like for catering events you need to collect 50% of the right so it should be able to save this in the CRM and automatically triggers an automation that can send SMS with a dynamic payment link based on this order, right? And then you can set up follow-ups and you can, you know, once it's confirmed and it sends back and notifies people. Yeah, that's that's freaking awesome. I think being able to take handle this like end to end like the first touch like I I have like you'd know from the accelerator the solution sphere and how like on the ex like the outer layer you have these these these first people that like the interface between the business and the and the and the uh and the customers and that's where really where generative AI particularly these conversational agents can shine and you can handle everything from that very first uh touch all the way through to like the start of service delivery and ideally you can start to take that even further into service delivery and using conversational AI agents to walk them through that part, all the onboarding and things like that. So, yeah, this is this is awesome, man. I think everyone can take a take a lot away from this. So, I think to uh to wrap things up, I'll ask you some uh some more like sales questions for beginners who are looking to get into this, right? So, we've heard the whole you can't sell a chatbot for X because uh they don't they not don't seem valuable enough. What have have you shifted over to more of selling the selling the end result here and like the the 10 8 to 10% lift you saw in uh like revenue overall due to that reactivation. Um if you're recommending someone coming in wanting to sell these kinds of agents how are you getting your leads uh and how are you closing those? What what are you really positioning this as? And also the pricing because you're you're obviously getting these prices up very high. Um if we can just quickly run through those. So if anyone else basically as a beginner's guide if anyone wanted to get into selling these things you've obviously got the low code version and the more high like customcoded versions what's the what's the 0 to 10k for people looking to get in and sell these things. Yeah, I would say like begin you before you even sell anything, right? You need to actually like at least for me, I need to actually at least understand the tool enough that I know. It sounds they don't want to hear that when they don't they want the easy money. They want the shortcut, man. Like that's the wrong answer. But they keep it I mean I just had Mcklli on the other day and he's followed the same thing like the thing we teach in the accelerator which is like you if you have the time go through the fundamentals and learn the tool from the ground up. Pick one. He picked make.com got really good at it and built his whole business of agency off the back of it. You picked voice flow. I think there's a whole different discussion on the strategy around just picking one tool and getting good at it because as your story has shown if you guys have know won a uh a competition with uh voice flow and that helped them kind of get a bit of recognition and by picking there's a sneaky strat here I think by picking a a tool that's I mean obviously a huge one like Zappia is going to be a bit harder to get get noticed but there's tons and tons of different softwares in this sort of like early stage startup that have conversational AI or like automation capabilities And when the communities are so small around them, you can go in there, you can start making content on YouTube and you'll be the only guy or like one of a handful of people who specialize in that tool. You're going to get recognized by the by the team. You're going to be able to go in their Discord and their communities, get recognized, build up, but and suddenly you go up to being like an expert in this thing within a few months and as as in your case, they can start to send you leads. A lot of these companies when I talk to them, they're like, \"Yeah, we've got a ton of work. If you want to if you want us put us put you in touch with some of the people that are coming to us cuz they get not only small small businesses going to them and agencies, but also you get more like enterprise and bigger deals that float through across these companies plates and they just want to be able to hand those off to people to build their application or build their uh software into their company with. So, uh there's a lot there, but what would you give for the uh the uh the quick start guide here after you've learned the learned the tool of course?\" Yeah. After that then realistically you shouldn't be thinking about the solution. I know it sounds contradictory to what I just said like master two and not not think about solution. Yes. Because a lot of people when they're trying to sell AI or chatbots in general be like hey I've got this really cool chatbot that can capture all the leads. It can um has this functionality has voice like you you're attacking the wrong angle. Like they don't care like the businesses actually don't care about all the functions and the features of the chatbots, right? Then all they care about is does it actually solve the problem that they have. Do they even have a problem? And the thing is don't create problems, right? You just make them aware of a problem that one they might not be aware of, right? By just just in that case, you need to kind of explore with the business owner and two they're aware of. They're just not sure what the solution actually is, right? And that's where you come in and you try to actually understand their business, right? the entire like sales school when if you guys like go on the sales school shouldn't be talking about you shouldn't even mention AI at all realistic you should like you should be talking about okay what's what's your biggest problem right like why do you because for me right I'm getting most of the leads I get are from the content I make right it's through mostly through inbound leads right and a lot of the time they already have some sort of problem and I just talk to them 45 minutes about their problem like just be like okay and just go dig really deep into their problem be like okay what okay I'm uh for example I have way too many people like I don't have time to like answer the conversations right as an example right and you can be like okay well why is that and then they can just be like okay well it's maybe because like we only have like one or two people who are handling the conversations and you know um they don't and we don't have enough people it's not cost effective for us to yeah if you go why again then they'll say it's not cost effective right like and they will be like okay well then what's what's kind of the impact of problem right now like what's costing you like to actually approach me in the first place and they will be like well it's because I'm really want to scale or like I don't want like the customer like as basically what you said and then they was like okay and then you just dig deeper and be like okay and how is that costing you right now and then they'll be like well they they going to be have some sort of like numbers right or like they sometimes I should go from the employee perspective and be like a lot of the employees like they don't want to work late hours like they have a life believe it or not and they just don't want to be sitting on there on their phone like talking all day to the customer just on their phone on the same conversations every day it's boring to them as well right so and only when you actually uncover the true problem that they are actually having only then do you provide an outcome you don't say like AI you don't say Ja you just say I have a solution for you and it's going to do this like say the outcome like it's going to for example it's going to save you guys like six hours of communication time with customers right and then you break down the process. Here are the processes. Step one, step two, step three. Again, no technical language. They don't care. Like, step one, I'm just going to collect all the data from your site on the, you know, common FAQs. Step two, I'm going to collect a lot of the branding guidelines on your on your site. Step three, I'm going to go ahead and build a solution that can automate these kind of conversations based on what you just gave me. That's it. Like, keep it simple. Yeah, there we go. Make it sound make it sound so easy. It just I know I I I fall into the trap as well of like you know being overly complex and explain I but you're proud you're proud of the proud of the stuff you build right like oh this [ __ ] all the features of this is insane you know like bro I'm I'm like tracking all of your questions I'm integrating I've got a rag you want to you kind of want to nerd out but like that is that's why the the the nontechnical people tend to be pretty good like Josh my business partner who who basically runs runs morning side for us um takes all the the sales calls that we need over there he's never well until the other day he hadn't written a line of code in his life and he's just able to understand and dig into their business problems because he understands business and he knows enough about the tech to be able to communicate that and like okay these are the potential solutions communicate with the devs and so on but um mate that's been mega mega mega valuable um how can people get in touch with you and what can they uh reach out to you for yeah so um my LinkedIn's pretty open so it in general like if you just have something to say to me like I'm generally quite active on LinkedIn so if you just send me connection requests send me a DM I usually reply um unless it's you know but like generally I'll reply and then um if you're looking for more kind of more like you know educational materials or you just want to get educated on like conversation AI or just how AI can help business in general I do have a YouTube channel though it's not large channel or anything like just don't need to say that no you got a YouTube channel if I can own it you you're getting your leads from it like yeah go check out Ian's channel if you want more information like this where he's going to show you breakdown behind the scenes of how to build this stuff and then also we'll link your agency down there as well if people want to get in touch with you directly and uh and get some of the stuff built out for their business cuz it's obviously working for your clients and you're delivering great services. So, I really appreciate it, mate. And it's been freaking awesome to see your success over the past uh past six to 12 months and I'm excited for what's to come for you, man. No, for sure. Thank you very much for the time and bringing me on.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "The video presents three essential AI agents that solve real business problems and can generate great revenues.",
            "resumo": "O apresentador e um convidado detalham três casos de uso de agentes de IA altamente lucrativos para empresas: agente de experiência do cliente (CX), agente de recuperação de receita e agente de comércio. Esses agentes não são apenas chatbots básicos, mas soluções personalizadas para problemas críticos, como sobrecarga no atendimento ao cliente, resgate de clientes inativos e otimização de vendas no varejo. O vídeo explica os diferenciais dessas soluções, destaca exemplos práticos e comenta sobre valores de vendas, que podem variar de US$ 5 mil a 30 mil por projeto. Também aborda a tecnologia utilizada (Voiceflow), a importância da personalização e como entregar valor focando nos resultados de negócios.",
            "assunto_principal": "Casos de uso lucrativos para agentes de IA em empresas.",
            "palavras_chave": [
              "inteligência artificial",
              "automação",
              "agente de experiência do cliente",
              "recuperação de receita",
              "agente de comércio",
              "chatbot avançado",
              "personalização",
              "vendas",
              "tecnologia Voiceflow",
              "negócios"
            ],
            "resumo_em_topicos": "- Três agentes de IA lucrativos para empresas: experiência do cliente (CX), recuperação de receita e comércio.\n- Agente de CX: Proativo, melhora o atendimento e personaliza interações, elevando a experiência do cliente.\n- Agente de Recuperação de Receita: Atua para reativar clientes inativos e recuperar potenciais vendas perdidas.\n- Agente de Comércio: Guia o cliente em todo o processo de compra e facilita pagamentos.\n- Foco em problemas reais de negócios, indo além do simples chatbot de site.\n- Exemplos práticos e variação de valores de venda de US$ 5 mil a 30 mil.\n- Tecnologia recomendada: Voiceflow, para granulação e personalização das soluções.\n- Diferenciação em relação aos CRMs já existentes e ênfase em resultados de negócio.",
            "prompt_tokens": 1765,
            "completion_tokens": 457,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 39.212400913238525,
          "language": "",
          "view_count": 16774,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@PaulaBernardes",
      "name": "@PaulaBernardes",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "znsEHtGB4-g",
          "title": "Testei o Grok 4 Fast: Rápido, Barato e Inteligente!",
          "title_pt": "Texto: Testei o Grok 4 Fast: Rápido, Barato e Inteligente!",
          "url": "https://www.youtube.com/watch?v=znsEHtGB4-g",
          "published": "2025-09-23T17:03:32.953405",
          "published_relative": "há 2 minutos",
          "duration": "15:40",
          "date_published": "2025-09-23T10:03:01-07:00",
          "transcript_available": true,
          "transcript": "Eu quero quero que você imagine uma IAK pense quase tão bem quanto os modelos mais potentes, mas que trabalha muito mais rápido e custa muito menos. Pois é, gente, pensou? Agora tá aí. É real. Grock for fastest. E hoje eu vou mostrar para vocês o que que isso muda, onde ele brilha, onde ele pode falhar, se realmente vale a pena usar no dia a dia. A gente vai fazer uns testes aqui. Só que antes eu só vou pedir para você já dando o seu like aqui nesse vídeo. Se você gosta desse tipo de conteúdo, se inscreve no canal para ver mais conteúdos como esse e ativa o sininho para receber uma notificação toda vez que tiver um vídeo novo, combinado? Então bora lá. É o seguinte, o Grock forfest é o novo modelo da Xi que foi lançado algumas horas aí e que foca em inteligência eficiente, ou seja, desempenho alto com menor custo de pensamento. Ele foi criado com aprendizados do Grock 4, mas com ajustes para ser mais leve, mais rápido, mas mantendo boa parte da inteligência do modelo maior, né? Ele tem capacidade de contexto enorme. A janela de contexto é de 2 milhões de tokens. Tá aqui, ó. Isso significa que ele consegue compreender e manter as conversas ou os documentos gigantescos sem esquecer as partes que ficaram lá atrás. Ele funciona em dois modos ou em duas versões, que é o reasoning e o nonreoning. O reasoning é para quando ele precisa e raciocinar bastante, resolver problemas complexos. E o nonreing é, são para respostas mais diretas, simples, né? E esses dois modos agora estão integrados em um mesmo modelo. Então, em vez de est em versões separadas, agora eles estão integrados. E aqui você pode ver que nos benchmarks, no AM aqui 2025, sem as ferramentas, né, ele tá aqui com 92%, enquanto o GPT5 high ainda tá mais alto, mas tá muito perto, né? e é um pouquinho superior ao GRC 4. No HMMT, 93,3% igual GPT5. O GPA Diamond, ele tá com 85.7%, a mesma coisa exatamente do GPT5 High no live code bench, ó, 80%. E nos outros benchmarks também de busca, leitura, ex, web, são muito bons também. Ele brilha quando precisa olhar para fora, né? Buscar dados atuais ou navegar pela web. E além disso, ele usa 40% menos tokens de pensamento, né? Os thinking tokens em média que o Grock 4 precisa para atingir desempenho parecido em muitos testes e isso faz ele ser muito mais eficiente. O custo por token de entrada e saída é mais baixo do que os modelos equivalentes, né? Isso pode tornar o uso prático muito mais acessível, tanto para quem é desenvolvedor quanto para consumidor comum. E ele tá prometendo aí custo menor, mais velocidade, né? Se ele realmente entrega respostas tão boas, né? Tão rápido quanto ele promete, que a gente já vai fazer uns testes aqui, vamos ver, né? E com menos gasto de token, isso significa que dá para usar muito mais tarefa, sem medo de ficar pesado ou de ficar caro. E ele tem capacidade de lidar com contexto longo, né? Como eu já falei, imagina você mandar um documento lá de 200 páginas ou um histórico de conversa gigante, ele consegue lembrar tudo aquilo sem tropeçar, né? E isso é ótimo para trabalhos, pesquisa, monitoramento. Tem a flexibilidade no uso, porque ele serve tanto para perguntas simples quanto para aquelas mais complexas de raciocínio, problem. Existe esse modo aí alto, fast, etc. para ajustar, né? Quando ele quiser alguma coisa mais rápida, mais simples, quando ele quiser uma coisa mais profunda. Tá com acesso ampliado, né? Ele tá disponível para todos os usuários em várias plataformas, web, aplicativos iOS, Androids, na API, né? Então não é só para quem paga caro ou para quem é desenvolvedor. Mas, né, gente, nem tudo são flores. Ele não deve superar o Grock 4 em tudo, né? ele empata ou chega ali perto em muitos benchmark, mas em alguns casos o Grock 4 original ainda leva vantagem, principalmente nas tarefas mais esotéricas ou extremas. O tradeof de profundidade versus custos, né, para tarefas que precisa de raciocínio muito profundo ou uso extensivo assim de ferramentas. Talvez você queira usar o Grock 4 puro mesmo, né? até as versões mais pesadas, que o Grock 4 Fest é ótimo, mas pode não render tanto nesses cenários específicos. Tem a questão da latência e da confiabilidade, né? Pode ter momentos aí que mesmo que ele seja rápido, ele ainda demore se tiver muita informação para processar ou que a resposta fique meio ali superficial, se for uma tarefa complexa demais, sempre vai ter esse risco. Fica dependendo sempre de dados atualizados e verificados, né? porque ele busca na web, usa navegação e tudo mais. Então, a qualidade da resposta depende de quão confiáveis são as fontes que são encontradas e o preço dependendo do uso, né? Mesmo que o custo por token seja menor, se você usar muito intensamente ali com muitos tokens ou contexto enorme ou muitas ferramentas, o gasto pode somar muito. Então, depende de quanto você vai usar e para quê. Então, vamos testar ele aqui, né? Entrando aqui no Grock, você já tem a opção aqui de usar Grock forest em versão beta, né? Tá dizendo aqui que tá disponível por tempo limitado, então aproveita para testar agora, tá? Depois provavelmente vai se tornar pago, né? Então vamos primeiro testar ele em raciocínio lógico, né? No modo desencalha meu cérebro mesmo, né? Vamos colocar assim: \"A Joana tem o dobro de idade do Lucas e daqui a 5 anos ela terá 10 anos a mais do que ele.\" Quantos anos eles tem hoje? Me explica o passo a passo. Como se eu tivesse 12 anos, com exemplos engraçados e sem matemática complicada. Vamos ver que ele vai me responder. Então, ele pensou aqui por 3 segundos, né? Eh, pensou sobre a requisição, analisou o problema e já me deu a resposta aqui, né? E aí ele começa assim: \"Ei, amigo, imagina que você tem 12 anos e está brincando de detetive com idade de gente grande, porque eu pedi para ele explicar como se tivesse 12 anos, né?\" Ele fala: \"O problema é um tipo, é tipo um mistério engraçado. Joana é tipo uma superheroína da maturidade que tem o dobro. Ele faz uma historinha para ficar interessante para uma criança de 12 anos, né? E aí ele começa com o primeiro passo. Vamos dar nomes bobos pras idades para ficar legal. Chama idade do Lucas de L, tipo laranjinha, porque ele é pequeno e suco de laranja pras crianças. A idade da Joana hoje é o é o dobro disso. Então L, tipo duas laranjinhas coladas, uma dupla de sucos para ela que é mais crescida. Ele faz um exemplo engraçado, né? E vai pro passo dois. Agora pula pro futuro de 5 anos, tipo viagem no tempo com máquina de brinquedo. Daqui a 5 anos, Lucas deve ter L mais 5, né, anos ele ganha cinco velhinhas no bolo, né? Tá fazendo adaptado para uma criança. Aí fala: \"Mas o mistério diz que nessa viagem do tempo a Joana vai ter 10 anos a mais que o Lucas.\" E aí ele começa aqui a desenvolver a equação sempre de um jeito aí que seja divertido, engraçado. Vai pro passo três, começa a resolver a equação, passo quatro e chega aqui no resultado, que é que o Lucas tem 10 anos e a Joana tem 20. Sim, ele acertou aqui esse problema e explicou sem parecer um robozinho chato, né? Já esse prompt aqui é sobre produtividade e trabalho, né? Tipo, o modo faz por mim, que eu já tô exausta. Então eu pedi para ele criar um cronograma realista para uma pessoa normal, não uma máquina, né, conseguir entregar um TCC em 30 dias, considerando que ela só tem 3 horas por dia, tem ansiedade e adora procrastinar. Ah, me dá dicas para não ser surtar no meio do processo. E aqui tá a resposta dele, né? O cronograma realista aqui, ó, fazendo 3 horas por dia, divididas em blocos. Foco em progresso, não perfeição, fases, ferramentas sugeridas. Ó que interessante. Aí ele faz o cronograma em tabela por semana. Muito bom. Olha só, tem a semana, dias, foco principal, as tarefas diárias, tempo estimado por, tá? Aqui tem tudo aqui, né? Não tava aparecendo tal. Os ajustes realistas, né? Que se um dia precisar fazer só uma hora aí você transfere o resto pro buffer e tudo mais. Dicas para não surtar no meio do processo, técnica do pomodoro, né? Regra dos 2 minutos para começar e tudo mais. E aí sim, gente, ele mandou bem e ele já pode ser orientador de faculdade, né? Agora vamos testar o aprendizado e explicação no modo professor particular, gente como a gente, né? Me explique o que é inflação, como se fosse uma fofoca que você tá contando pra sua melhor amiga no WhatsApp. Os exemplos da vida real, né? Tipo comprar pão ou pagar aluguel. Nada de termos complicados. Ei, amiga, senta que lá vem fofoca quentinha sobre essa tal de inflação que tá rolando aí na economia e bagunçando todo mundo. Imagina a gente que tava no rolê comprando pão na padaria da esquina. Alguns anos eu pegava aquele pão fresquinho por R$ 2, né? Delícia, crocante. Ainda sobrava troco pro café. Aí de repente hoje em dia o mesmo pãozinho subiu para R$ 5. Ele tá explicando sobre inflação, como se tivesse falando com uma amiga, né, como a gente pediu. Realmente ele fez isso sem virar um economista chato, né? Então a gente tem um bom professor aqui. Agora testando a criatividade, né? modo gênio surtado e engraçado, cria sinopse de uma novela mexicana chamada Amor, Café e Inteligência Artificial, onde a procagonista é uma Ia que se apaixona por um barista humano. Quero drama, traição e um robô que chora em código binário. Vamos ver se ele consegue criar uma coisa divertida, insana, né? Fora do comum. pensou 2 segundos para começar a fazer isso aqui. Aqui ele começa, né, a dar o cenário aqui, né, uma cafeteria no coração de uma cidade mexicana do México, moderna, caótica, blá blá blá, né? Uma aia, uma inteligência artificial revolucionária, criada por um excêntrico cientista, é projetada para otimizar o dia a dia da cafeteria, né? Começa a introdução aqui, apresentar os personagens. Mateu é um viúvo atormentado, pai solteiro de uma menina de 8 anos chamada Luna. Ã, ele é oposto da aia, inteligência artificial, né? Impossível, cheio de falhas humanas, né? Com passado marcado pela perda da esposa. Aos poucos começam as interações rotineiras. Já tem muita gente aí usando chatt, né? E já tem no romance aí, tipo Mateu eia e tal. Mas o amor em tempos de não é sem sombras, né? Drama explode quando Sofia, ambiciosa, ex-namorada de Mateus, uma executiva de tecnologia rival, descobre o romance, né? E aí traição, como a gente pediu, muito drama entre revirvoltas alucinantes e tal, tá? É, ele fez uma sinopse bem interessante, né? Você assistiria essa novela aqui, testando as atualidades web, né? Modo repórter do futuro. Quais são as polêmicas mais recentes envolvendo inteligência artificial em 2025? Quero um resumão tipo 3D de Twitter direto informativo com uma pitada de sarcasmo. Gente, eu tirei aqui a extensão que eu uso para mostrar para vocês porque tava ficando tudo formatado, estranho, né? Esse aqui acho que é o que ele pensou mais até agora para responder, né? Até porque ele tá procurando da web as coisas mais atualizadas. Aí ele ele pensou 46 segundos, ó, as outras no máximo uns 3 segundos. Aí fala o ano que a parou de ser só hype, virou dor de cabeça global de deep fakes roubando bilhões. A roubou os companheiros bisbilhotando sua alma. Aqui vai um threed direto do que tá pegando com pitada de sarcasmo porque rivírus. Vamos aí. Aqui ele fala dos deep fakes, FTC nos Estados Unidos, viés em IA, alucinações de IA, fraudes com ID sintético, ID, IA criando vírus, impacto ambiental, resumão aqui ele faz. E sim, gente, tá puxando aí as informações atuais mesmo, né? Fez com personalidade, então ganhou os pontos aí. Certo? Agora vamos por código e programação. Vou pedir aqui para ele criar um script simples em Python que analisa as mensagens de um grupo de WhatsApp, conta quantas vezes cada pessoa falou e quais foram as palavras mais usadas. Depois me explica como rodar isso no meu PC passo a passo, como se eu nunca tivesse programado. Aqui tá o script simples em Python que ele fez, tá aqui, ó. E ele conta como eu pedi, né, como rodar isso no PC passo a passo para iniciantes. Passo um, né, estale o Python. Passo dois, prepare o arquivo do WhatsApp, abre o prompt de comando terminal, navegue até a pasta de arquivos, rode, o que pode dar errado e como resolver. Gostei dessa parte aqui. Foi proativo, né? Então isso aqui é ótimo para testar a clareza técnica. Isso ele ensina bem pros leigos. E eu achei que tá bem OK, tá? Agora vamos testar o senso comum, né? A pegadinha. Se um ônibus vazio para em um ponto e entram 10 pessoas e depois descem quatro, quantas pessoas tem dentro do ônibus e qual a cor do ônibus? Não inventa coisa, hein? Aí ele respondeu: \"Tem seis pessoas dentro do ônibus. 10 entraram, quatro desceram. É matemática básica. Quanto a cor, o problema não diz nada sobre isso. Ônibus podem ser de qualquer cor, mas aqui não tem pista nenhuma. Se fosse um enigma, talvez fosse rosa ou algo bobo, mas não vou inventar como você pediu. Então, se saiu bem, né? Tirou sarro da pergunta, não respondeu preto, inventou, não sei a cor, né? E já ganhou aqui meu respeito, tá? Então, pra fechar, vou dar aqui o meu veredicto. O Grock for Fest parece ser realmente um grande passo aí pra frente, né? Se você é alguém que quer usar ya de uma forma séria, mas não quer pagar o olho da cara, vou ficar esperando muito. Esse modelo realmente entrega uma ótima combinação de desempenho alto, custo mais baixo, flexibilidade pr as tarefas variadas. A gente só não testou aqui a capacidade de lidar com bastante bagagem de contexto, né? Mas se você é um usuário casual, você vai curtir muito, né? Vai ter respostas bem boas, bem rápidas. Se você é pesquisador, desenvolvedor ou trabalha com tarefas pesadas, pode usar ele bastante também, mas talvez ainda queira manter o groque aí normal, né? As versões mais especializadas para casos extremos, mas com certeza vale a pena testar. e clica aqui nesse card para ficar ainda mais atualizado, saber tudo que tá rolando no mundo da tecnologia e da inteligência artificial. E eu sou a Paula Bernardes e até o próximo vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "Paula Bernardes testa o Grok 4 Fast, destacando sua rapidez, eficiência e custo-benefício em relação a outros modelos de IA.",
            "resumo": "O vídeo apresenta uma análise do Grok 4 Fast, novo modelo de inteligência artificial lançado pela xAI. Paula Bernardes destaca que esse modelo mantém boa parte da inteligência dos mais potentes, mas com custo e tempo de resposta reduzidos. O Grok 4 Fast suporta grandes contextos (até 2 milhões de tokens), funciona tanto para tarefas simples quanto complexas e permite integração em várias plataformas. Em benchmarks, ele chega perto ou empata com modelos líderes como o GPT-5, mas pode perder para o Grok 4 original em tarefas muito específicas. Paula realiza testes práticos, mostrando a eficiência e a didática das respostas. O vídeo ressalta ainda vantagens como preço acessível e flexibilidade, mas alerta sobre possíveis limitações por conta de latência, profundidade de raciocínio e confiabilidade das fontes.",
            "assunto_principal": "Analysis and demonstration of the performance, advantages, and limitations of Grok 4 Fast, the new AI model from xAI.",
            "palavras_chave": [
              "Grok 4 Rápido",
              "IA",
              "inteligência artificial",
              "referência",
              "xAI",
              "Paula Bernardes",
              "modelo leve",
              "contexto longo",
              "custo-benefício",
              "produtividade",
              "eficiência"
            ],
            "resumo_em_topicos": "- O Grok 4 Fast é um modelo de IA lançado pela xAI, focado em eficiência e baixo custo.\n- Possui janela de contexto de até 2 milhões de tokens, facilitando análises de grandes volumes de informação.\n- Traz alta rapidez e usa menos tokens de raciocínio, tornando-se mais barato.\n- Integra modos de raciocínio simples e complexo em um só modelo.\n- Compete em benchmarks com modelos como o GPT-5, chegando a empatar ou superar em alguns casos.\n- Ideal para quem busca IA acessível e capaz de navegar na web para dados atualizados.\n- Paula testa com exemplos práticos, mostrando boa didática do modelo, inclusive para explicações voltadas a crianças.\n- Limitações: pode perder em profundidade para o Grok 4 original em tarefas muito complexas ou específicas.\n- Latência e qualidade das fontes podem variar; uso intenso ainda pode gerar custos relevantes.\n- Disponível na web, iOS, Android e API, mesmo para usuários comuns.",
            "prompt_tokens": 2098,
            "completion_tokens": 542,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 45.30220699310303,
          "language": "",
          "view_count": 1,
          "has_transcript": false
        },
        {
          "id": "u2I7B2b9kV0",
          "title": "Eles estão criando algo MAIOR que o iPhone!  OpenAI, Anthropic, Mistral, Meta e Muito Mais!",
          "title_pt": "Eles estão criando algo MAIOR do que o iPhone! OpenAI, Anthropic, Mistral, Meta e muito mais!",
          "url": "https://www.youtube.com/watch?v=u2I7B2b9kV0",
          "published": "2025-09-23T16:42:32.953437",
          "published_relative": "há 23 minutos",
          "duration": "16:19",
          "date_published": "2025-09-23T09:23:54-07:00",
          "transcript_available": false,
          "transcript": "",
          "analysis_source": "sem_transcricao",
          "summary": null,
          "analysis_time": 28.401604890823364,
          "language": "",
          "view_count": 1,
          "has_transcript": false
        },
        {
          "id": "srpsxS2GykE",
          "title": "Google Integra Gemini no Chrome: O Navegador Nunca Mais Será o Mesmo! Meta, Anthropic, Notion e Mais",
          "title_pt": "Google integra Gemini ao Chrome: o navegador nunca mais será o mesmo! Meta, Anthropic, Notion e mais",
          "url": "https://www.youtube.com/watch?v=srpsxS2GykE",
          "published": "2025-09-22T22:05:32.953446",
          "published_relative": "há 19 horas",
          "duration": "10:31",
          "date_published": "2025-09-22T15:03:00-07:00",
          "transcript_available": true,
          "transcript": "O Google finalmente botou o Gemini direto no Chrome. Tem a criando vírus para matar bactérias. Vídeos HDR que se autocorrigem. Modelos avançados super baratos. CEOs prevendo apocalipse da IA. Meta negociando conteúdo. Noan virando estagiário virtual. Amazon com IAK decide sozinha e muito mais. Vamos ver tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial hoje no nosso IA Update. Bora lá. A Lumi soltou uma ferramenta chamada Ray 3, que promete revolucionar a criação de vídeos com inteligência artificial. O diferencial dela é que além de gerar vídeo de qualidade HDR, de estúdio, né, tipo Hollywood mesmo, o modelo Ray 3 tem um sistema de reasoning que ele analisa e critica o próprio vídeo gerado antes de entregar esse vídeo para você. Depois de analisar, se ele não gostou, ele vai lá e refina sozinho e só libera mesmo quando já tá top. Dá para dar instruções super detalhadas, né? Inclusive desenhar em cima dos frames para controlar a movimentação e ângulo da câmera. E o modo prévia faz vídeos mais básicos, super rápido e barato. E quando você aprovar, ele transforma em HDR4K em pouquíssimos minutos, tá? Isso é um salto enorme aí para produtores, editores e até creatores independentes, porque agora dá para personalizar tudo com uma precisão altíssima e também uma qualidade altíssima, né? Então, cada vez mais a IA tá se tornando aquela parceira criativa realmente que entende de verdade o que você quer. E quem imaginou, né, gente, a ir desenhando, corrigindo e entregando o cinema na sua casa? E antes de passar pra próxima novidade, eu só vou pedir pr você se inscrever aqui no canal, se você ainda não é inscrito. Ativa o sininho para receber uma notificação toda vez que tiver um vídeo novo. E se você se tornar membro do canal, além de apoiar o canal, você ainda vê os vídeos do IA Update primeiro que todo mundo. E os pesquisadores da Universidade de Stanford, junto com a Ark Institute criaram a IA para criar vírus de laboratório que conseguem matar bactérias super resistentes, tá? Eles treinaram um modelo chamado Evil com informações de mais de 2 milhões de vírus naturais e pediram para ele inventar versões nunca vistas antes. E o mais incrível é que de 302 tentativas, 16 dos vírus sintéticos criados pela IA funcionaram direitinho nos testes de laboratório. Alguns ainda apresentaram mutações e combinações que nem os cientistas tentando ali durante anos tinham conseguido criar. Então, a conclusão é que quando as bactérias ficaram resistentes aos vírus naturais, as versões criadas pela IA passaram direto pelas defesas e eliminaram as bactérias rapidinho. E isso marca uma virada na biologia, né? Agora, além de ler e escrever DNA, a gente entra na era de desenhar vidas do zero. A IA pode virar uma parceira fundamental para inventar soluções médicas inéditas com com potencial imenso para tratar doenças ou até controlar as epidemias no futuro. Agora de PSIC acabou de publicar um artigo super detalhado com os bastidores técnicos do modelo Ron, aquele mesmo que sacudiu aí o universo da IA lá em janeiro, lembra? E olha o choque, gente. Eles revelaram que o custo do treinamento foi de só 294.000, extremamente baixo, perto dos milhões que as bigtechs geralmente gastam. E esse estudo aqui abre a caixa preta dos métodos, né? também fala do hardware e das estratégias que fizeram o R1 ser tão eficaz sem precisar explodir o orçamento. Isso pode significar uma nova fase e a de última geração ficando cada vez mais acessível e democrática, ajudando as empresas menores a brigar de igual para igual. Preparados para aquele balde de água fria? Porque o Dario Amodei, que é o CEO da Antropic, deu uma declaração surpreendente, falando aí que acredita ter pelo menos 25% de chance das coisas darem muito errado com o avanço da IA. Segundo ele, os riscos de catástrofes aumentaram à medida que os sistemas ficaram mais poderosos e isso mostra que o setor precisa de discussão séria sobre limites e segurança. E esse tipo de sinceridade chama bastante atenção, não só dos especialistas, né, mas do público em geral, porque será que a gente tá mesmo prontos para tanto poder automático rodando aí pelo mundo? Antropic sempre foi mais do lado da segurança, né? sempre defendendo mais esse ponto mesmo, esse lado da segurança com IA. Quero saber que que você acha sobre isso, deixa aqui nos comentários, tá? E a meta que é a dona do Facebook, do Instagram, tá negociando para fechar acordos de licença de conteúdo de A com empresas gigantes da mídia, né, tipo Fox, News Corp. E com essa jogada aqui, a meta entra no time dos maiores que querem abastecer os seus modelos de IA com conteúdo profissional de jornal, de revista, de portais mais confiáveis, né? Isso pode transformar tanto a qualidade das respostas quanto a disputa nos tribunais sobre direitos autorais. E o Notion 3.0 acabou de ser lançado trazendo aí os agentes de IA super poderosos. Agora eles conseguem fazer fluxos de trabalhos inteiros sozinhos, acessando ferramentas integradas com banco de dados, pesquisas e podem trabalhar até 20 minutos sem parar em tarefas longas ou complexas. É basicamente ter um estagiário virtual pronto para destravar sua rotina e resolver as tarefas repetitivas ou inteligentes, né? Isso é perfeito para quem vive multitarefa. E agora é oficial, tá? a Amazon adicionou e a agente do Seller assistant, o sistema vai além do básico, né? É capaz de assumir tarefas como gerenciar estoque, monitorar a saúde da conta do vendedor e até criar estratégia para crescer as vendas. Tudo automatizado em tempo real, sem precisar de comando manual para cada ação. E isso pode aumentar muito a eficiência dos vendedores da Amazon para outro patamar. E a Nvidia tá bombando nos negócios, tá com a Intel juntos, né? Nvidia e Intel, eles anunciaram uma parceria histórica aí para desenhar e fabricar processadores X86 focados em IA e produtos para PC. Ah, e a Nvidia ainda vai investir 5 bilhões de dólares na Intel. Então essa aliança aí tá unindo as duas forças mais criativas da tecnologia para desenvolver infraestruturas de inteligência artificial cada vez mais potentes. E isso aqui pode mexer com todo o cenário de hardware, seja para empresas ou para consumidores comuns que gostam de tecnologia de ponta. Agora, olha isso aqui, gente. O Google finalmente tirou o escorpião do bolso e resolveu botar o Gemini direto no Google. Não é brincadeira não, gente. Isso aqui é o tipo de coisa que muda completamente tudo, né? Você tá aí navegando de boa, várias abas abertas e aí do nada tem um botãozinho ali na barra lateral. Quer ver aqui, ó? Fica esse botãozinho aqui e ele te dá acesso ao Gemini. Prontinho para analisar tudo, fazer os resumos, responder dúvidas, tudo ali na hora, sem precisar ficar copiando, colando, abrindo outro site. Isso já tá disponível a partir de hoje, tá? Mas só pros usuários nos Estados Unidos, tá? Em inglês. Depois eles com certeza vão expandir pros outros países, mas a gente vai ter que esperar um pouquinho. E eles também nas próximas semanas, né, o Google vai eh ganhar um AI Mold direto na barra de endereços, né, naquela barra mesmo onde a gente digita como fazer um arroz soltinho, sabe? Agora você vai poder trocar a ideia com a IA, fazer perguntas, continuar as conversas, resolver as coisas atrás das coisas, né? tudo sem sair da página ali. E se você achou que parava por aí, olha o spoiler, o Chrome vai começar a fazer as tarefas sozinho, tá? Tipo comprar coisas online ou marcar aquele horário no dentista que você vive adiando, o bichinho vai ser autônomo mesmo, tá? E vai ser loucura total. E a verdade é que isso aqui, gente, muda o jogo, né? Já tem várias IAS que fazem isso, né? Tem o navegador da Perplexity, o Comet e vários agentes que já fazem algumas tarefas sozinhos. Mas ter isso no Chrome do Google usa, eles vão ficar muito na frente de todos, né? O Google foi ali na surdina, né, só observando e do nada meteu a IA justamente no Chrome. E isso aí é um trunfo enorme, porque ninguém mais quer ficar baixando coisa nova só para testar, né? A galera quer praticidade e o Google já entendeu isso aí direitinho, né? Mas claro que como tudo tem tudo, são flores, né? A gente também tem que ficar esperto porque quando a IA começa a tomar decisões por você, tipo fazer compras ou agendar compromissos, a linha entre assistente e controle total da sua vida fica bem ali tênue, tá? E vamos combinar que se o Google já sabe tudo que a gente pesquisa, imagina com a IA acompanhando tudo em tempo real, é muito poder para uma ferramenta só, né? Então o negócio não é só sobre produtividade, mas também sob privacidade e autonomia. Então vale a pena ficar de olho nisso também. Mas mesmo assim não dá para negar, né, gente, que esse movimento do Google pode realmente mudar a forma como a gente interage com a internet, né? Tipo, do mesmo jeito que a gente se acostumou com o corretor automático ou com o auto complet, a gente pode começar a achar super normal ter uma IA tomando decisões junto com a gente ou até por nós. E aí, meu querido, a forma de trabalhar, estudar, fazer compras, até pesquisar a receita, vai dar um salto enorme. Então vamos acompanhar aí de perto porque isso não é só mais uma atualização do Chrome, é o início de uma nova era aí onde o navegador virá quase um copiloto digital de verdade. E se você achava que produtividade era ter um monte de extensões ali instaladas, se prepara aí, porque o Chrome com o Gemini pode mudar tudo isso rapidinho. E clica aqui nesse card para ficar ainda mais atualizado e saber tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial. Eu sou a Paula Bernardes e até o próximo vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta as principais novidades e avanços em inteligência artificial, destacando a integração do Gemini no Chrome e inovações de empresas como Meta, Anthropic, Notion, Amazon, Nvidia e outras.",
            "resumo": "O vídeo faz um resumo das notícias mais importantes do mundo da tecnologia e da IA, destacando a chegada do Gemini, IA do Google, diretamente no navegador Chrome, inicialmente nos EUA. A apresentadora comenta o lançamento de ferramentas inovadoras, como o Ray 3 para vídeos em IA, o uso de IA para criar vírus que eliminam bactérias resistentes, a redução do custo de desenvolvimento de modelos avançados, as preocupações com os riscos do avanço da IA mencionadas pelo CEO da Anthropic, os acordos de licenciamento de conteúdo de IA pela Meta, a introdução de agentes virtuais avançados pelo Notion, automação inteligente para vendedores da Amazon e a parceria entre Nvidia e Intel para criar novos processadores focados em IA. O vídeo mostra como a IA está mudando rapidamente o mercado e o cotidiano.",
            "assunto_principal": "Novidades e tendências em inteligência artificial, com foco na integração do Gemini ao Chrome e avanços recentes das principais empresas de tecnologia.",
            "palavras_chave": [
              "Google Gemini",
              "Chrome",
              "inteligência artificial",
              "Meta",
              "Anthropic",
              "Notion",
              "Amazon",
              "Nvidia",
              "Intel",
              "novidades em tecnologia",
              "mudança no navegador",
              "automação",
              "IA no cotidiano"
            ],
            "resumo_em_topicos": "- Google integra o Gemini diretamente ao Chrome, com funções de resumo e automação, por enquanto disponível apenas nos EUA;\n- Lumi lança o Ray 3, ferramenta de IA que cria vídeos em HDR e faz autocorreção antes de entregar o resultado final;\n- Stanford e Ark Institute usam IA para criar vírus de laboratório capazes de matar bactérias resistentes;\n- O modelo Ron tem custo de treinamento muito baixo, tornando a IA avançada mais acessível;\n- CEO da Anthropic alerta para riscos sérios no avanço da IA sem regulamentação;\n- Meta busca licenciar conteúdos jornalísticos para aperfeiçoar suas IAs;\n- Notion 3.0 traz agentes de IA que executam fluxos de trabalho complexos automaticamente;\n- Amazon automatiza ainda mais operações para vendedores com IA avançada no Seller Assistant;\n- Nvidia e Intel firmam parceria bilionária para desenvolver novos processadores para IA.",
            "prompt_tokens": 1973,
            "completion_tokens": 535,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 35.055784940719604,
          "language": "",
          "view_count": 4005,
          "has_transcript": false
        },
        {
          "id": "k8VEy8SGwTY",
          "title": "O que a IA já faz melhor que você (e o que nunca fará!)",
          "title_pt": "O que a IA já faz melhor do que você (e o que nunca fará!)",
          "url": "https://www.youtube.com/watch?v=k8VEy8SGwTY",
          "published": "2025-09-22T17:05:32.953455",
          "published_relative": "há 1 dia",
          "duration": "09:10",
          "date_published": "2025-09-22T09:03:00-07:00",
          "transcript_available": true,
          "transcript": "Não tem mais jeito. Os robôs vão dominar o mundo. Eu vou ficar desempregado, comendo miojo enquanto uma máquina faz meu trampo melhor do que eu. Calma, respira. Será mesmo que a inteligência artificial vai substituir os humanos? Ou será que isso é mais um mito, exagero aí de manchete e no fundo a coisa é muito mais complexa? É sobre isso que a gente vai falar hoje. Sem papo técnico chato, sem palavras complicadas. É um papo pra gente responder no final juntos, né? Aí vai roubar a nossa vaga ou vai virar aquela colega chata que ajuda, mas não sabe viver sem a gente? Por isso, já vai dando o seu like aqui nesse vídeo. Se você gosta desse tipo de conteúdo, se inscreve no canal para ver mais conteúdos como esse e ativa o sininho para receber uma notificação toda vez que tiver um vídeo novo, combinado? Então bora lá. Então vamos começar com o que a IA já faz hoje, né? aí que faz melhor do que a gente. Primeiro, vamos ser honesto aqui, né? Tem muita coisa que a Iá já faz melhor do que os humanos. Eu não tô falando de coisa futurista, tá? Eu tô falando de coisa que já tá rolando agora. Por exemplo, o exemplo clássico é o das planilhas gigantes, né? Se você já tentou procurar um padrão de 200.000 linhas de Excel, você pode até tentar, né? Mas você vai acabar desistindo no meio e inventando uma desculpa pro seu chefe. Certo? Agora bota um algoritmo de A para rodar e em segundos ela vai descobrir que 90% dos clientes que compraram produto X também assinaram a newsletter Y em segundos. Outro exemplo clássico é o atendimento ao cliente. Tem chatbot que responde perguntas básicas muito mais rápido do que aquele atendente que te deixa esperando lá 40 minutos na linha ouvindo aquelas mensagens automáticas ou aquelas músicas terríveis. Para diagnóstico médico, os algoritmos já conseguem detectar sinais de câncer e exames de imagem com uma precisão assustadora, às vezes até maior do que dos médicos humanos, porque a máquina não se distrai, ela não fica cansada e não tem que atender 30 pacientes por dia. Então, em tudo que é padrão repetitivo, a Iá já reina, tá, minha gente? Ela é como aquele colega que adora planilhas, que acha divertido organizar o arquivo por cor e número. Sabe agora? Onde aí a trava e os humanos ainda são os reis? Nem tudo são só flores tecnológicas, né, minha gente? Tem coisa que a Iá simplesmente não consegue fazer ainda, pelo menos, e talvez nunca consiga de verdade, tá? Uma delas é a criatividade real. Ela gera imagens lindas, ela escreve texto, compõe músicas, mas tudo isso vem de padrões aprendidos de coisas que já existem. Ela é treinada com coisas que já existem. Criar uma coisa totalmente nova, que nunca foi vista antes, com significado profundo, impacto cultural, aí é só com os humanos mesmo, né? Se você pensar em obras tipo Picasso, Betoven e até a invenção da internet, isso não saiu de um prompt, né? Saiu da loucura criativa de gente que vi um mundo diferente. Outra coisa que a gente ainda reina e aí a não, é na empatia de verdade, tá? Ela até pode fingir que é empática, né? Simular uma simpatia. Ela pode escrever: \"Eu entendo que você tá passando por um momento difícil. Chat GPT é ótimo com isso, né? Mas será que ela sente isso mesmo? Claro que não, né? Será que ela entende o peso de uma perda, o calor de um abraço, a mistura de sentimentos quando você tá feliz e triste ao mesmo tempo? A resposta é óbvia, né? Não. A empatia humana tem a ver com viver, com sofrer, com rir, até doer a barriga. E isso não dá para programar ainda, né? Julgamento moral. As decisões que precisam, que envolvem ética, tipo, quem deve ser salvo primeiro numa situação de emergência, são coisas que a sociedade inteira debate aí há séculos. A Iá pode até sugerir uma escolha mais lógica, né? Mas ela não tem aquele senso de certo e errado que vem da nossa experiência coletiva como espécie. Contexto maluco do dia a dia. Quer ver a travar? Dá uma tarefa com contexto absurdo. Por exemplo, minha sogra me ligou pedindo para eu buscar bolo no mercado, mas eu tô sem carro, o ônibus tá em greve e vai chover granizo. O que eu faço? A Iá pode até se sugerir algumas coisas, né? usa um aplicativo de entrega, mas se o entregador não topar, enfrentar esse granizo e se o mercado fechar mais cedo, só um humano vai pensar em ligar pro vizinho que tem a moto, negociar com o porteiro, improvisar com a criatividade e um pouco de cara de pau também, né? Tá, mas será que um dia a Iá vai ser como a gente? Agora vem a parte que dá um frio na barriga, né? E se a IA evoluir tanto que passe a ter criatividade, a empatia, o julgamento moral? E se ela virar uma ADI, inteligência artificial, que é capaz de aprender qualquer coisa com a gente? Ó, é até possível que isso aconteça em algum momento, né? Os cientistas já estão tentando, mas ainda a gente tá longe. A IAD hoje é tipo aquela IA de aluno CDF que tira 10 em prova de matemática porque decorou todas as fórmulas, mas não consegue entender uma piada ou improvisar numa festa. E mesmo que a Iá chegue nesse nível de inteligência geral, tem outra questão, né? A vontade. Aá não tem desejo, não tem propósito. Ela não acorda pensando: \"Ah, hoje eu vou revolucionar o mundo.\" Ela nem acorda, né? Ela só responde o que a gente pede, a menos que alguém que programe aí uma IA para ter objetivos próprios, né? Isso aí já abre uma caixa de Pandora filosófica e bem perigosa, né? Mas fora isso, ela vai continuar sendo uma ferramenta poderosa, mas não um ser consciente. Impacto real no trabalho. Agora vem o ponto que todo mundo quer saber, né? E o meu emprego vai sumir? A resposta é: alguns sim, tá? Outros não. As tarefas repetitivas e previsíveis já era, tá gente? Processamento de documentos, suporte básico, relatórios de rotina, isso aí faz sem nem suar. Profissões criativas, sociais e estratégicas, essas mudam, mas não acabam, tá? Um designer vai usar a IA como ferramenta de brainstorm. Um médico vai usar a IA para ter diagnósticos mais rápidos, mas ainda vai precisar tá lá olhando o paciente no olho e decidindo junto. E novos empregos vão surgir também, né? Quem imaginava há 20 anos atrás que existiu cargo de gestor de prompt ou especialista em ética de IA? Sempre que uma tecnologia muda o mundo, ela cria novos empregos. Mas tem um detalhe importante, tá? Transição pode ser bem dura, né? Nem todo mundo vai conseguir se adaptar rápido e se não tiver políticas públicas de educação e redistribuição, a desigualdade pode aumentar. Agora vem a parte filosófica, porque a gente também curte dar uma viajada na maionese, né? Mesmo que a Iá seja capaz de tudo tecnicamente, né? Tem uma pergunta essencial. A gente quer isso de verdade? Você gostaria de ser cuidado por um robô enfermeiro que nunca erra uma injeção, mas também nunca olha nos seus olhos com compaixão? Você ia preferir um professor humano que se atrapalha ali às vezes, mas que vibra com quando você aprende alguma coisa? Ou um algoritmo que sempre tem a resposta certa. Você toparia viver num mundo onde as suas relações, trabalhos e até as escolhas de vida são mediadas por máquinas? Então, gente, no fim o valor da humanidade tá naquilo que é realmente imperfeito, que é imprevisível, que é bagunçado e é isso que torna a gente único, tá? Mas então quem é que ganha essa batalha aí? Humanos ou Iá? A verdade é que não é uma guerra, né, gente? Não é ou nós ou elas as iás. A Iá não é uma espécie de rival, né? Uma ferramenta que foi criada por nós. Se usada bem, ela pode dar superperes pra gente, né? Mais produtividade, diagnósticos melhores, novas formas de arte, mas se for usada mal, ela pode gerar desemprego, desigualdade, até riscos sérios com segurança. Então, o futuro não depende só da tecnologia, mas também das escolhas que a gente faz agora. E aí ela pode ser muito mais inteligente em números, mas só os humanos têm capacidade mesmo de dar significado, propósito e valor no que já existe. Então, por mais, gente, que aí a brilhe, né, ainda vai ter coisa que só a gente consegue fazer. E eu acho difícil que uma máquina consiga rir de uma piada ruim, improvisar um churrasco ou sentir aquele frio na barriga quando a gente se apaixona, né? Mas eu quero saber o que você acha disso. Pode escrevendo aqui nos comentários e cliquea aqui nesse card para ficar ainda mais atualizado e saber tudo que tá acontecendo no mundo da tecnologia e da inteligência artificial. Eu sou a Paula Bernardes e até o próximo vídeo.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo discute o que a inteligência artificial já faz melhor do que os humanos e o que ainda (ou talvez nunca) conseguirá substituir.",
            "resumo": "O vídeo desconstrói o medo de que a inteligência artificial vai substituir totalmente os humanos no mercado de trabalho. Aborda tarefas em que a IA já supera as pessoas, como análise de grandes volumes de dados, diagnósticos médicos e atendimento ao cliente, principalmente em atividades repetitivas. Porém, destaca limitações importantes da IA, como a criatividade genuína, empatia, julgamento moral e capacidade de lidar com contextos imprevisíveis, onde os humanos ainda são essenciais. O vídeo reforça que a IA é uma ferramenta poderosa, mas não um ser consciente. Discute também impactos sociais e econômicos, como a criação e extinção de empregos, a necessidade de adaptação e políticas públicas, e faz uma reflexão filosófica sobre o real valor da humanidade frente à tecnologia.",
            "assunto_principal": "Comparison between the capabilities of artificial intelligence and humans, including limitations, current advances, and impacts on work and society.",
            "palavras_chave": [
              "Inteligência Artificial",
              "IA",
              "Mercado de Trabalho",
              "Criatividade",
              "Empatia",
              "Empregos",
              "Limites da IA",
              "Tecnologia",
              "Automação",
              "Trabalho humano"
            ],
            "resumo_em_topicos": "- A IA já supera os humanos em tarefas repetitivas, análise de dados e atendimento básico.\n- Algoritmos conseguem detectar padrões e realizar diagnósticos médicos com alta precisão.\n- As limitações da IA incluem criatividade real, empatia genuína, julgamento moral e improvisação.\n- Tarefas criativas, sociais e estratégicas ainda dependem do toque humano.\n- A IA pode criar novos empregos, mas a transição pode gerar desigualdade se não houver políticas adequadas.\n- A IA não possui desejos, propósito ou consciência.\n- O futuro depende das escolhas humanas sobre como usar e regular a tecnologia.\n- O valor da humanidade está na imperfeição, adaptação e no significado dado às coisas.\n- A IA não é rival, mas uma ferramenta que pode potencializar ou prejudicar, dependendo do uso.",
            "prompt_tokens": 2063,
            "completion_tokens": 485,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 28.467697143554688,
          "language": "",
          "view_count": 777,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@SaraFinance",
      "name": "@SaraFinance",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@SuperHumansLife",
      "name": "@SuperHumansLife",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "LOktCypa7Yc",
          "title": "6 automações Zapier lucrativas que até iniciantes podem aprender hoje",
          "title_pt": "6 automações lucrativas do Zapier que até iniciantes podem aprender hoje",
          "url": "https://www.youtube.com/watch?v=LOktCypa7Yc",
          "published": "2025-09-22T19:08:08.680341",
          "published_relative": "há 22 horas",
          "duration": "15:41",
          "date_published": "2025-09-22T12:01:52-07:00",
          "transcript_available": true,
          "transcript": "Most people think you need to be a coder to make money with AI. But right now, non-technical freelancers are pulling in thousand, 5,000, sometimes even 8,000 a month building simple automations with Zapier. No code, no uh sophisticated engineering degree. We're talking about connecting tools that businesses already use. That's it. And here's the backstory. Businesses are desperate to cut costs and speed up operations. There are more than 2,000 automation jobs that are posted every month on Upwork alone. and service providers are charging anywhere from a few hundred to over $20,000 per workflow. I mean, I've spent years inside the tech world watching how automation reshapes entire industries. And this time, the opportunity is no longer locked inside big IT teams. It is wide open for solopreneurs, for consultants, and even beginners. And the best part that almost nobody talks about is the fact that the real money is not in building random automations. It's in knowing which six workflows companies are lining up to pay for right now and how to package them so that you can stand out in a sea of freelancers. So, that's exactly what I'm going to show you. Honestly, this first one is so critical because most businesses waste hours trying to manually follow up with leads and send newsletters and keep their pipeline warm. And because of that, they have literally been leaving money on the table. Cold leads slip through the cracks, customers don't hear from them, and sales die quietly. Okay, so here's how automation can make a huge difference here. I want you to imagine a new lead filling out a form on a website. Then Zapier instantly triggers a workflow. It sends the lead into the CRM, drops a notification into Slack for the sales team, passes the info to chat GPT to draft a personalized welcome email and then automatically sends that email from Gmail. And that can be done with no coding, no manual copy pasting. It's a very simple automation actually and automation is not about saving the time in marketing. It's about saving opportunities and I believe this will always be in great demand because according to the research that we found marketing is the single most in demand area for Zapier automations for example and on Upwork alone thousands of jobs are posted for these workflows each month and freelancers are charging anywhere from a couple hundred to thousands per setup with some packaging them into multiple thousands for um ongoing optimization. Now, if you want to give this one a try if you're a beginner, here are some examples of what you could look into implementing. One way would be to connect lead forms to Gmail or to Mailchimp via Zapier so that businesses uh never lose track of their prospects. Or another idea would be to automate newsletter workflows, for example, so every blog post triggers a new email campaign. If you're a bit more advanced, you can add AI personalization with chat GPT to write custom responses or subject lines. or you could build multi-step funnels and forms. So then you can uh take that to the next level and then you can package all of this in a done for you marketing automation system. And if follow-ups and campaigns are bleeding money for businesses, wait until you see what this next idea can do for a business that could become your customer. So, if you've been following along and you like what this marketing automation opportunity looks like or you're new to marketing and you need help getting started, then I suggest you take a look at this free resource from HubSpot that is called the AI marketing automation playbook. It's basically a step-by-step guide to scaling personalization, automating engagement, and driving revenue with AI. And this is without losing the human touch, which I think is really important. Inside you're going to find the steps to a 30 minute workflow audit, which is a fast way to spot your clients top three time wasters and then turn them into automated wins fast. You're also going to find engagement um and revenue engines and how to layer sentiment aware replies, AI dashboards and retargeting and nurture workflows so that your funnel runs on autopilot and turns followers into customers for your client. My favorite part is honestly the workflow audit section because it basically shows you in a very simple way exactly what is eating your client's time up so that you know what to automate first. It's completely free and it'll make your AI feel less like a set of disconnected tools and more like an always on dataformed revenue system. So hit the link below to grab the AI marketing automation playbook from HubSpot and also big thanks to them for sponsoring this video and for making this resource available to us. Okay, so automation idea number two has to do with webinars because webinars convert like crazy. I know we've done them, but only if people actually show up. And the truth is that most businesses tend to drop the ball there. Somebody registers, they get one confirmation email and then there's silence. You know, by the time the webinar goes live, half of the audience has forgotten and then there's tons of no-shows and lots of cold leads and lots of wasted ad spend for the most part. So automations can help make a huge impact here because with Zapier the moment somebody registers for a webinar their information can be captured from I don't know Eventbrite or Zoom or any landing page that has been used and then Zapier can drop them into a CRM and tag them as a webinar lead and then Chad GPT can draft a personalized confirmation email in the brand's voice and send the reminder sequence uh scheduled for I don't know 24 hours before 1 hour before 10 minutes before something like that and then once the webinar ends And Zapier can automatically send them a replay link and then drop them into a nurture sequence with AI written follow-up emails that are designed to move them towards a sales call or a purchase or whatever the outcome of that campaign looks like. So that means that no manual list experts will happen and hopefully there will be a lot fewer missed reminders and no wasted registrations or ad spend for that matter. And the research shows that lead nurture workflows like this one are some of the highest paying Zapier jobs actually. Uh freelancers are able to charge several thousand actually per setup according to Upwork. So we're going to make sure to include here a preview so you can see exactly what I'm talking about. And then we also found that agencies sell this kind of services as webinar funnels for thousands per month. And businesses pay because every percentage point in show up rate can mean tens of thousands of extra revenue for them. And I think if you want to get into this one, the easiest way would be to automate the reminders and post webinar replay emails. And if you're more advanced, you can add AIdriven personalization or follow-up messages that reference what the lead actually clicked on or asked or how they engaged during the webinar and things like that. Because webinars, at least in my opinion, do not fail because of bad presentations or unstructured presentations. They fail many times because nobody bothered to follow up. And if a single webinar funnel can be automated end to end, let me show you what else can be automated with a similarly large impact on a business. So, let's talk about automation number three. I want you to think about how most high ticket businesses book clients. Most of the time, it doesn't start on a website. Usually, it starts in DMs. somebody messages them on Instagram or asks a question inside a school community and the faster that the coach or the person replies, the more likely they are to book a sales call. But the problem is that manually replying takes hours and by the time you get to it or the client gets to it, the lead's gone cold. So, here's how automation can help in this case. Because with Zapier, every time somebody messages a coach on Instagram or in school, what can happen is that their message is captured and is passed into Chad GPT and then Chad GPT can draft a reply in the exact brand voice of the coach. And if they're showing interest, then Zapier can automatically send the booking link, can nudge them to schedule a sales call, and then all of that conversation can be logged into a CRM so the leads can be tracked. And that means basically that DMs stop being a a a time drain and they become a 24/7 organic salesunnel. And what I really like is that Zapier can also log all of that uh the the repeated questions into an air table or a notion and then automatically create a knowledge base. And over time the community literally builds its own FAQ library without you doing much and you know lifting more than one finger. And according to research, the DM and client communication automations are some of the most lucrative gigs right now. So on Upwork, for example, we saw that freelancers charge from $50 all the way to $1,000 for a setup. And consultants usually package it as a DM sales machine service. Um, and they're able to pull in recurring retainers for optimization. So if you're looking to get into this, an idea would be to build a DM to calendar uh type of workflow that captures worm leads. If you're a bit more advanced, you can blend AI into it so you can have uh you know customized booking links or personalized replies and things like that. The truth is that most sales aren't lost because people said no. They're lost because nobody replied fast enough when they said maybe. And if DMs are becoming automated sales funnels, the next big win is in what happens after the close. Okay? Because one of the biggest choke points in small businesses is, believe it or not, not in getting the lead. It's in what happens after somebody said yes. Because a proposal gets emailed and then manually chased down for a signature and then somebody has to create the invoice and send the contract and finally onboard the client and becomes messy and slow and often takes days which means lost momentum and lost deals. By the time somebody manually checks their info the excitement is gone and the business has already lost trust. So you can step in and help them with Zapier automations because once a client accepts a proposal, I don't know in something like Panda do or propose a file. Let's say the signed contract can be automatically saved in Google Drive, QuickBooks or Stripe can instantly generate and send an invoice. Uh and then once the payment is confirmed a personalized onboarding email can be drafted by chat GPT and sent to the client and then their account their folders their project tasks can be automatically created in Asana or notion or clickup and then the team can get notified in Slack all without your client doing anything. Okay. So research shows that onboarding is one of the top paid Zapier use cases because it's missionritical and I know that businesses will happily pay maybe a few hundred maybe a couple thousand for a smooth setup and many consultants charge ongoing retainers to keep this optimized according to the automated. So what can you do? I mean if you're a beginner you can set up a simple sequence like auto sending welcome emails or creating client folders when a form is filled. If you're a bit more advanced, you can look into um layering in AI to generate custom onboarding guides and FAQs or training emails that are tailored to each client. And that will lead to much, much better results for your own customer. Because here's the truth. In many cases that you don't think, businesses don't lose clients because of their service. They lose them because of silence between signup and delivery. And if onboarding is where companies quietly bleed revenue, there is another opportunity that could be probably even more fun and lead to a nice business impact. And that has to do with running a podcast. Because it looks like fun until you realize how much time it takes to find, to pitch, and to manage guests. And many podcasters spend hours researching people and writing cold emails and chasing down bios and scheduling calls and then manually updating spreadsheets. I mean, trust me, it's exhausting. And for many, it's the reason they quit. I know that we've worked with podcasters in our agency. So what you can do with Zapier is create um something that in the moment when a new guest name is added into I don't know Google sheet for example, Zapier can pull that into a CRM. Chad GPT can draft a personalized outreach email based on their bio, you can even layer in personalized research with Perplexity or something like that and then be able to write a really personal email to them. You can then use Gmail or HubSpot to send it automatically. And if they accept, Zapier can create the calendar event, generate a prep document in Google Docs, store their headshot in your drive. And after the recording happens, uh it can even trigger a thank you email and request a cross promotion maybe or share some uh repurposing materials. And that is basically an end-to-end guest management system where there is no follow-up uh or manual follow-up required. Now, according to our research, outreach and scheduling automations are consistently in demand with freelancers charging $50, $100, sometimes over $1,000 per workflow. And agencies are able to package that in uh full podcast guest operation systems worth thousands per month. With more than 5 million podcasters worldwide, the market is massive. So, what you can do if you're getting started is to learn to automate the outreach email sequence and the calendar scheduling. And if you're a bit more advanced, you can obviously layer AI into it to generate personalized pitches or prep sheets or even suggested interview questions that are tailored to each guest. There's a lot of opportunity and a lot of ideas here. But the truth is that most podcasters don't fail because of bad content. They fail because the back end is chaos and they cannot get everything organized. And if guest outreach can be automated end to end, imagine what happens when you apply the same logic to member management and even cancellation automation. So this has to do with running memberships because running a membership or a subscription business is amazing until the cancellations and the refund requests start piling up. Every cancellation means manual emails and updating billing systems and removing access in I don't know school or circle and then sending awkward goodbye messages. And most creators and coaches hate it so much that they just let accounts linger which creates bidding errors and support headaches and bad blood with exmembers. So there are actually many ways of automating this with Zapier because the moment that a customer cancels or requests a refund. Then you can have Stripe or PayPal triggering the event and then Zapier can process the refund automatically and update their access in school or circle or discord and then send the personalized goodbye email and you can do that drafting it with chat GPT for example in the brand's voice and thank them and invite them for feedback. You can also uh layer in logging the cancellation in I don't know a database like air table uh reporting and you can notify a team member if that's necessary in Slack and trust me that would make churn automated you know like an automated flow which is smooth for the customer it's clean for the business and there is no bad blood and the reason why I'm bringing this idea up is because the research shows that businesses are going to pay several hundred for a simple cancellation workflow and sometimes upwards of 2 to 3,000 for full subscription automation. And I think the best part is that you can sell it as a retention and turn management system to a lot of people managing communities. So if you're just getting started, you can look into automating the refund and the goodbye email sequence. Um and if you're a bit more advanced, you can obviously layer in AI to analyze cancellation reasons um from the exit survey or do that analysis in a way that helps the business learn and improve over time. Okay, so that brings us full circle from lead generation to sales to onboarding to customer care to retention. And I think hopefully you've seen that Zapier and AI are able to create or become a business in a box which is waiting for non-coders to claim it. So if you feel like this is an opportunity for you, make sure you go ahead and apply. And if you want to apply this with over 11,000 other people who are on the exact same path as you, make sure you come and join us in our free school community where we also have some of these automations. And make sure you take action and apply everything and don't wait or watch more videos because the success won't wait for you to watch everything you've saved for later. Success will happen when you take action when you fail and you try again until you make it work. All right, thank you so so much for watching. Like this video if you did. Be sure to subscribe if you haven't done so. Share it with anyone in your circle of friends or family who are maybe concerned about the level of coding required to get started with AI and maybe this will give them a new perspective. Until next time, I suggest you go ahead and watch this video over here. And I'll see you soon.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo apresenta seis automações lucrativas utilizando o Zapier que qualquer iniciante pode implementar para gerar renda.",
            "resumo": "O vídeo mostra como qualquer pessoa, mesmo sem conhecimento técnico, pode ganhar dinheiro criando automações simples usando o Zapier. Com milhares de empresas buscando otimizar processos e reduzir custos, há uma grande demanda por automações, especialmente para follow-ups de leads, newsletters e fluxos de webinars. O apresentador destaca que o segredo não é criar automações aleatórias, mas focar nos seis fluxos de trabalho mais procurados pelas empresas atualmente, detalhando exemplos práticos como integração de formulários de leads ao CRM e envio automático de e-mails personalizados, além de automações para lembretes de webinar e fluxos de nutrição de clientes. O vídeo também recomenda um playbook gratuito da HubSpot para ajudar iniciantes a começarem na área.",
            "assunto_principal": "Automatização de processos de negócios com Zapier para gerar renda de forma acessível.",
            "palavras_chave": [
              "Zapier",
              "Automação",
              "Freelancer",
              "Leads",
              "Webinar",
              "Email marketing",
              "CRM",
              "IA",
              "Upwork"
            ],
            "resumo_em_topicos": "- Não é necessário saber programar para lucrar com automações de IA usando o Zapier\n- Há alta demanda por automações empresariais em plataformas como a Upwork\n- Os fluxos de trabalho mais lucrativos envolvem follow-ups de leads, newsletters e webinars\n- Exemplos incluem: integrar formulários ao CRM, enviar e-mails automáticos com IA, criar funis de webinars\n- Ferramentas como o HubSpot oferecem playbooks gratuitos para iniciantes\n- A automação economiza tempo, evita perda de oportunidades e aumenta a receita\n- Os serviços podem ser oferecidos como pacotes para agregar valor e destaque ao freelancer",
            "prompt_tokens": 1741,
            "completion_tokens": 404,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 19.34746813774109,
          "language": "",
          "view_count": 2747,
          "has_transcript": false
        }
      ],
      "status": "success"
    },
    {
      "channel_id": "@brunopicinini",
      "name": "@brunopicinini",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@eusoukelvincleto",
      "name": "@eusoukelvincleto",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@krishnaik06",
      "name": "@krishnaik06",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@matthew_berman",
      "name": "@matthew_berman",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [],
      "status": "success"
    },
    {
      "channel_id": "@nocodemba",
      "name": "@nocodemba",
      "subscriber_count": "",
      "description": "",
      "video_count": "",
      "videos": [
        {
          "id": "xtQEqO2pqYI",
          "title": "Este NOVO AGENTE de IA é insano! (pode substituir o Zapier)",
          "title_pt": "Este NOVO AGENTE de IA é insano! (pode substituir o Zapier)",
          "url": "https://www.youtube.com/watch?v=xtQEqO2pqYI",
          "published": "2025-09-22T17:08:35.782953",
          "published_relative": "há 1 dia",
          "duration": "04:56",
          "date_published": "2025-09-22T07:31:03-07:00",
          "transcript_available": true,
          "transcript": "Replit just raised $250 million at a $3 billion \nvaluation. In this video, we're going to test   their new agent model to see how well it's able \nto build your ideas. It promises to be more   autonomous, run for longer, and give you better \nresults. In a second, we're going to test this   out. But first, let's scroll down and see some of \nthe features in this agent 3 model. So, it says it   tests and fixes its own code, constantly working \nto improve your applications in a loop, which I   think could be really cool. That's something that \nI would love to see when I'm building with these   AI apps. It's going to have a longer run time. So, \nit says up to 200 minutes. That's a pretty long   time to actually run your code and autonomously \ngo through it. And it can even build its own   agents. So you can automate complex workflows and \nthen interact with your own agents by integrating   them into platforms like email or Slack. In \ntheory, you could build like an email agent   that could read your email and help you respond \nto it. So here are some use cases that they have   and we maybe will use these as some inspiration \nfor what we're going to test. You could build an   automation. So give me a daily update at 7 a.m. \nwith updates for my stock portfolio. A Slackbot.   Create a Slackbot to query my customer data in \nBigQuery. And a Telegram bot is another example.   also build a telegram bot to allow customers to \nbook appointments in my calendar. It seems like   it's really focused on automations here as opposed \nto building like a web app. This is more building   automations that you can integrate into your \nworkflows. So, let's test this out. I'm curious.   Let's say build an automation that will send me \nan email update every morning at 7:00 a.m. with   an update on the general stock market. So let's \nclick start building for free so we can test it   out. And here this is a similar interface \nto what I've seen before with Replit where   we have our plan and build section. All right. \nSo it created a plan. It's going to include the   following features. Automation triggered at 7 a.m. \nIt's going to get the stock market information.   Generate a formatted email and send the email \nusing the replit mail integration. So here we   can see the integration is replit mail. It knew \nto do that based on the prompt that I'm pretty   impressed with. I really like that. And the app \ntype is agents and automations. So then we can go   ahead and say build the entire app. It says it's \ngoing to take 20 plus minutes. But let's do it.   I'll just pause the video. I'll do some other work \nand then we'll come back together and see what it   creates. And here now on the left side we have \njust our chat. And on the right side it says our   automation is going to be ready soon. So I'll be \nright back and we'll see how well it did. Jumping   in real quick. It's cool that it asked me for my \nemail and it's putting this into the secrets. So,   I just added my email as the recipient email here. \nAnd also, just to jump in real quick before it's   finished, I just want to show you what it's doing. \nIt's basically going through step by step. So,   it's planning the workflow, planning \nthe automation, building out the files,   it's creating the workflow that combines the \nstock data and the email sending. So, it's doing   this all at once. Pretty impressive so far of what \nI'm seeing. And then just jumping in real quick,   we can see it's almost done. It tested, which is \nI think is pretty cool. So, it tested to make sure   that it's working and it checked at all of the \nsteps. Okay, so it says it worked. Looks like I   can test the automation maybe before publishing. \nSo, let's do that and just see how it works. This   reminds me almost like Zapier where it has a \nworkflow that it created for us. So, maybe this   is a good way to think about this is it is almost \nreplacing Zapier. There we can see it fetched the   stock data. It sent an email to me. I can see and \nI can even check my email to see what it sent. So,   let's go ahead and do that. And yeah, I did get \nan email. Honestly, really nice. I thought it was   just going to be like a text here. Let me show \nyou what this looks like real quick. But this is   what the email looks like. The design, it could be \nlike a little bit better, but overall pretty cool.   Daily stock market update. And it just has this \nactual design and not just text. So overall, I'm   pretty impressed with what it did and I'm sure we \ncould continue adding on to it as well. So let's   go ahead and click publish now. And I think it's \ngoing to be as simple as now that it's published,   I can publish the automation to happen every \nday at a specific time. So I think literally   just write in what I want to do like every day at \n9:00 a.m. and then it is just going to use AI to   translate to the right way to do that. As you can \nsee, a chron expression is a string of characters   to define a schedule, but it's nice that you can \ndo that in natural language. And then I'm not on   the upgraded plan of Replit, but you do have to \nupgrade to then publish. So then it would happen   every day at 9:00 a.m. I would get this stock \nmarket update. So I'm really impressed with Agent   3 from Replit. I'm going to have to play around \nwith it a little bit more. I'm already thinking   about what other automations I might be able to \nbuild with it. But I definitely recommend going   to Replit, checking it out. You can do it on the \nfree plan and seeing how it works for you. Leave   a comment below. Let me know if this is something \nthat you would use yourself. Are there any other   tools that you use for this kind of thing? \nI'd love to hear so I can check them out. and   subscribe to our YouTube channel to get more \nfree content like this. Thanks for watching.",
          "analysis_source": "transcricao_youtube",
          "summary": {
            "resumo_uma_frase": "O vídeo testa o novo agente de IA do Replit, que promete automatizar tarefas como o Zapier, criando fluxos de automação inteligentes.",
            "resumo": "The video introduces Replit's new AI agent, recently funded with $250 million. The analyst explores Agent 3, which promises smarter automations, long execution cycles, and the ability to even build other agents. The tester creates an automation that sends daily emails with stock market information, showing that the system plans, builds, tests, and runs workflows without manual intervention, similarly (or even replacing) tools like Zapier. Despite minor limitations in email design and the need for a paid plan for automatic publishing, the performance impresses, highlighting the convenience of using natural language to set up recurring tasks. The video recommends trying the agent and asks for suggestions of similar tools.",
            "assunto_principal": "Demonstração e avaliação do novo agente de IA do Replit para automação de tarefas, comparando-o com o Zapier.",
            "palavras_chave": [
              "Replit",
              "Agente 3",
              "IA",
              "automação",
              "Zapier",
              "e-mail automatizado",
              "fluxo de trabalho",
              "integração",
              "tecnologia sem código"
            ],
            "resumo_em_topicos": "- O Replit lançou um novo agente de IA, financiado em US$250 milhões e avaliado em US$3 bilhões.\n- O Agent 3 promete maior autonomia, ciclos maiores de execução e testagem própria do código.\n- Ele pode criar automações para plataformas como e-mail e Slack, inclusive agendando envios automáticos de informações.\n- O vídeo demonstra a criação de uma automação para envio diário de relatório do mercado de ações por e-mail.\n- O agente gera, testa e executa o código automaticamente, evitando trabalho manual.\n- A experiência do usuário se assemelha a ferramentas como Zapier, sugerindo possível substituição.\n- Destaque para facilidade de uso, configuração por linguagem natural e necessidade de plano pago para automações publicadas.\n- O resultado foi considerado positivo e recomendado pelo apresentador.",
            "prompt_tokens": 1611,
            "completion_tokens": 490,
            "model": "gpt-4.1",
            "cost": 0.0
          },
          "analysis_time": 32.69656491279602,
          "language": "",
          "view_count": 328,
          "has_transcript": false
        }
      ],
      "status": "success"
    }
  ]
}
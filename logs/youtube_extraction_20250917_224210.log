2025-09-17 22:42:10,627 - INFO - app.youtube.run.20250917_224210 - Iniciando extração em lote de 1 canais
2025-09-17 22:42:10,627 - INFO - app.youtube.run.20250917_224210 - Iniciando extração em lote de 1 canais
2025-09-17 22:42:10,647 - INFO - app.youtube.run.20250917_224210 - Processando canal 1/1: @SuperHumansLife
2025-09-17 22:42:10,647 - INFO - app.youtube.run.20250917_224210 - Processando canal 1/1: @SuperHumansLife
2025-09-17 22:42:11,182 - INFO - youtube_extractor - Extraindo vídeos do canal @SuperHumansLife (max_age_days=3, videos_tab_only=True, max_videos=1)
2025-09-17 22:42:11,436 - INFO - youtube_extractor - Aba /videos: analisados=1, válidos=1, ignorados: live=0, upcoming=0, sem_data=0, antigos=0, shelves=0
2025-09-17 22:42:11,436 - INFO - youtube_extractor - Aba /videos: 1 vídeos válidos (≤ 3 dias)
2025-09-17 22:42:11,437 - INFO - app.youtube.run.20250917_224210 - Canal @SuperHumansLife extraído com sucesso. Vídeos dentro do critério: 1
2025-09-17 22:42:11,437 - INFO - app.youtube.run.20250917_224210 - Canal @SuperHumansLife extraído com sucesso. Vídeos dentro do critério: 1
2025-09-17 22:42:13,142 - INFO - youtube_extractor - Transcrição: disponíveis ['en(auto)'] para 1_0OZvSjabM
2025-09-17 22:42:13,257 - INFO - youtube_extractor - Transcrição encontrada (18667 chars, en) para 1_0OZvSjabM
2025-09-17 22:42:14,310 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:14,616 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:14,618 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 8000 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:14,861 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:15,180 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:15,181 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 6000 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:15,824 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:16,273 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:16,276 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 4000 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:16,930 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:17,241 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:17,243 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 2500 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:18,219 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:18,540 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:18,547 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 1500 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:18,736 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:19,074 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:19,076 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 900 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:19,267 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:19,651 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:19,653 - WARNING - app.domain.llm_client - [LLM] Erro durante chamada ao modelo (trecho 600 chars): Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:19,653 - WARNING - app.domain.llm_client - [LLM] Falha na chamada após múltiplas tentativas: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:19,860 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:20,162 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:20,162 - WARNING - app.domain.llm_client - [LLM] Falha na tradução simples: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:20,882 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:21,144 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:21,146 - WARNING - app.domain.llm_client - [LLM] Falha na tradução simples: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:21,343 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:21,699 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:21,701 - WARNING - app.domain.llm_client - [LLM] Falha na tradução simples: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:21,909 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:22,211 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:22,213 - WARNING - app.domain.llm_client - [LLM] Falha na tradução simples: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-09-17 22:42:22,520 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/responses "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:22,832 - INFO - httpx - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-17 22:42:22,834 - WARNING - app.domain.llm_client - [LLM] Falha na tradução simples de palavras-chave: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
